<!DOCTYPE html>

<!--
Copyright 2019 Google LLC

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

  https://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->

<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="author" content="//google.com">
  <meta name="description" content="web.dev LIVE video transcript">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>SV-cgdobtTA</title>
  <link rel="stylesheet" href="../css/main.css">
</head>

<body>

<iframe id="youtube" src="https://www.youtube.com/embed/SV-cgdobtTA?enablejsapi=1"></iframe>

<div id="container">

<div id="options">
  <div id="google-translate"></div>
  <div>
    <input type="checkbox" id="videoSticky" checked>
    <label for="videoSticky">Video position sticky</label>
  </div>
  <div>
    <input type="checkbox" id="captionScroll" checked>
    <label for="captionScroll">Keep current caption visible</label>
  </div>
</div>

<section>
<p><span data-start="9.8" data-end="13.761">Hi, everybody. I am Ashe, I will be your guide today to describe our exploration</span> <span data-start="13.761" data-end="24.009">Learning and JavaScript World. Sorry i'm not a machine learning expert</span> <span data-start="24.009" data-end="34.33">That, but my mom is. She is an audiologist by training and she does work in digital filters</span> <span data-start="34.33" data-end="39.43">Acoustic models for hearing aids and then continue to work as speech recognizers.</span> <span data-start="39.43" data-end="46.98">I remember working in her lab one summer and people said these weird and intimidating</span> <span data-start="46.98" data-end="53.881">Then, and all these strange things on the wall, I'm overwhelmed. in</span> <span data-start="53.881" data-end="58.46">I basically didn't understand the time for it. So the process is also impressive</span> <span data-start="58.46" data-end="64.92">-A process of approaching her I can go to her and say, "I know what a cross is</span> <span data-start="64.92" data-end="72.78">Entropy is, "She's like," That's fine. Can you explain? !! "I think I can,</span> </p>
<p><span data-start="72.78" data-end="81.149">Explain to you and be fully prepared to use it. I have been learning deep learning</span> <span data-start="81.149" data-end="88.89">Out of curiosity, a little excited about the future, and also a sense of presence</span> <span data-start="88.89" data-end="94.14">The coming horrors of robots, they are going to consume all our work, and maybe</span> <span data-start="94.14" data-end="99.549">Our society may be ourselves. There might be the case for this matrix pod</span> <span data-start="99.549" data-end="106.85">Will happen. I have some exciting news. This is very, very impressive.</span> <span data-start="106.85" data-end="112.399">And they are a bit stupid. Like a fool in a very basic way. They are like this</span> <span data-start="112.399" data-end="117.399">May not accept your job-at least not in the next year or two-but they are</span> <span data-start="117.399" data-end="122.679">Change it, and change it very significantly. Now this is a very exciting moment</span> <span data-start="122.679" data-end="126.459">Enter this field. There is a huge amount of research and many new tools</span> </p>
<p><span data-start="126.459" data-end="132.43">We can use. Let's dive in. Before we dive in, I want to give a single definition.</span> <span data-start="132.43" data-end="139.599">I made this speech and a student was like, "So you say tension is like 100 times, that's</span> <span data-start="139.599" data-end="152.54">A terrible word. I feel nervous now. "Tension, if you look it up on Wikipedia, it's a number</span> <span data-start="152.54" data-end="160.03">Fields closed by some free operation. I would say that a tensor is a block of numbers.</span> <span data-start="160.03" data-end="164.879">We can have an actual block of numbers just a number, i.e. rank zero</span> <span data-start="164.879" data-end="173.739">Tensor or scaler. We can have a number, a line of numbers, a vector, an ice rink</span> <span data-start="173.739" data-end="181.78">1 tensor, matrix, square or square newspaper rectangle arranged by tensor, we can</span> <span data-start="181.78" data-end="190.6">Prisms are arranged in tensors, and they are constantly changing to become more and more difficult to draw.</span> <span data-start="190.6" data-end="196.26">So I don't plan to paint them. I just defined your tensor because I'm about to talk</span> <span data-start="196.26" data-end="205.969">About Tensor Flow, it is a state art machine learning framework. Available now</span> </p>
<p><span data-start="205.969" data-end="217.069">In JavaScript. So, let's break down the available, so in use</span> <span data-start="217.069" data-end="228.3">C ++ API, I am using the Pipeline API, I have a good grasp of mathematical operations on the CPU</span> <span data-start="228.3" data-end="235.12">GPU, capable of doing more operations in a, the parallel precision is slightly lower, and,</span> <span data-start="235.12" data-end="241.709">Then on the TPU, it's like a GPU, but there are even more, even crazy, computing units. it</span> <span data-start="241.709" data-end="248.54">Is Google's dedicated hardware, which is optimized for machine learning</span> <span data-start="248.54" data-end="255.709">especially. It turns out that machine learning is a whole bunch of very simple operations,</span> <span data-start="255.709" data-end="263.1">It is therefore desirable to be able to simply parallelize operations. JavaScript binding</span> <span data-start="263.1" data-end="272.889">Currently giving us CPU calculations under Node, and then Web binding is executed using WebGL</span> <span data-start="272.889" data-end="280.01">mathematics. Soon, node binding and the Tensorflow team promised to use a C ++ backend</span> </p>
<p><span data-start="280.01" data-end="286.53">Means that we should have performance equal Python libraries. Web binding</span> <span data-start="286.53" data-end="293.11">Performance using GPU is only half unfortunately C ++ libraries, but</span> <span data-start="293.11" data-end="298.55">You can do this in your browser, which is pretty cool. Another important part about doing</span> <span data-start="298.55" data-end="305.77">Machine learning research and development of these models is an ecosystem around core processing</span> </p>
<p><span data-start="305.77" data-end="311.06">The library and ecosystem we are using is huge in Python, and in the ecosystem</span> <span data-start="311.06" data-end="320.46">JavaScript is sad. And, it doesn't matter. If any Propel people or anyone doing science</span> <span data-start="320.46" data-end="324.7">Computing in JavaScript is here, I want to say your job is great, I really</span> <span data-start="324.7" data-end="332.04">Expect it, and its size community is currently small, but if</span> <span data-start="332.04" data-end="338.26">The history of the JavaScript framework is any indication that we will soon build a big and interesting one,</span> <span data-start="338.26" data-end="344.009">And a strong software ecosystem. Just the current situation is if you want to build</span> <span data-start="344.009" data-end="350.04">Your own great deep learning models and training their datasets</span> </p>
<p><span data-start="350.04" data-end="356.46">You might need to train on multiple computers in order to access, then you might go</span> <span data-start="356.46" data-end="362.66">Do this with Python in the cloud, but you can take these models and this is</span> <span data-start="362.66" data-end="368.18">Exciting things about tensorflow.js-you can take them and run them in the browser. it</span> <span data-start="368.18" data-end="374.72">Means you can use the power of machine learning to not send all of you in the browser</span> <span data-start="374.72" data-end="381.46">User data is sent to a provider in the sky, and you can continue to train those models</span> <span data-start="381.46" data-end="386.91">local. We can do something called "transfer learning" where we cut off the last point</span> <span data-start="386.91" data-end="393.66">Model, we adapt it without retraining all models deep</span> <span data-start="393.66" data-end="399.79">To give users machine learning, there are no advantages of machine learning</span> <span data-start="399.79" data-end="409.28">Privacy impact or entanglement surveillance. I just say "model", for example, 500</span> <span data-start="409.28" data-end="415.75">Times. What is a model? Let's say we have already happened</span> <span data-start="415.75" data-end="424.15">The world, this is a snake or it is a picture of a snake we want to model. we think</span> <span data-start="424.15" data-end="429.052">Understand it somehow. We want to simplify its version. This is the model: it</span> </p>
<p><span data-start="429.052" data-end="434.22">Is a simplified version of the world transformation into mathematics. So, in this case, we are leaving</span> <span data-start="434.22" data-end="441.55">Turn our snake into a wave shape. Through machine learning, we go through the training process there</span> <span data-start="441.55" data-end="449.349">We want to find a set of model parameters that allow us to adapt to the world as much as possible.</span> <span data-start="449.349" data-end="455.75">We can imagine trying different parameter sets, like different waves, random</span> <span data-start="455.75" data-end="465.199">Until we find something suitable for this snake. This is not ideal. We can sit here all day.</span> <span data-start="465.199" data-end="470.2">We do n’t have good metrics we are doing and we do n’t have that feeling</span> <span data-start="470.2" data-end="475.36">We are making progress. So we really want to find a way to pick</span> <span data-start="475.36" data-end="480.141">Some parameters, waveforms and its set iteratively improve it and do what he wants</span> <span data-start="480.141" data-end="486.99">We naturally improve ourselves and understand the situation before we find it</span> <span data-start="486.99" data-end="497.78">It fits well. We can implement a process called stochastic gradient descent. What if you are</span> <span data-start="497.78" data-end="502.61">Machine learning experts in the audience have various gradient descent techniques.</span> </p>
<p><span data-start="502.61" data-end="509.02">We now look at the simplest. Let's talk about a paint splash and i have no model</span> <span data-start="509.02" data-end="515.19">it. If I wanted to simulate the splash of paint, I would almost certainly not do it,</span> <span data-start="515.19" data-end="521.38">But I will treat it as a line because there are two parameters to make it easy to visualize</span> <span data-start="521.38" data-end="526.14">We need to visualize all kinds of things for them so i want to imitate splash</span> </p>
<p><span data-start="526.14" data-end="530.72">Paint as a line and we will become happy about it. First, I ’m going to throw</span> <span data-start="530.72" data-end="536.44">A coordination system under it, I turned around and divided these into X and Y points. I want to go back</span> <span data-start="536.44" data-end="542.019">Entering my depressed high school recall algebra to remember the equation</span> <span data-start="542.019" data-end="557.36">One line is Y = MXB. I have Y, line, B is line interception. If I choose random values</span> </p>
<p><span data-start="557.36" data-end="562.41">For these two parameters, I will get a line. I need-any two random values</span> <span data-start="562.41" data-end="570.19">Give me a line. This line is not very good. So, at this point, it is obsolete</span> <span data-start="570.19" data-end="578.2">These two points are good, if we go through and find that deviation</span> <span data-start="578.2" data-end="588.47">The whole set of examples, then what are we looking at a quantity called "loss". Lose,</span> <span data-start="588.47" data-end="594.51">How bad a long-term relationship is, just like the feeling you end up feeling</span> </p>
<p><span data-start="594.51" data-end="603.24">We did, and our model fits the data very well. This is a self-whipping machine learning ..</span> <span data-start="603.24" data-end="608.839">A common loss we use, especially for regression, and this is what we are doing</span> <span data-start="608.839" data-end="614.779">Now called mean square error, meaning we take the difference between the averages</span> <span data-start="614.779" data-end="620.8">Model and ground true squared. If we write it in JavaScript, it will</span> <span data-start="620.8" data-end="626.74">It looks like this. We can reduce the data and find the differences between the data</span> <span data-start="626.74" data-end="631.781">Our model predicts the value of this data point and the actual point, squared, divided</span> <span data-start="631.781" data-end="641.52">It presses the length and then gives us this function we can pass in-we have</span> <span data-start="641.52" data-end="648.51">Line function. We can pass model parameters here. Any two model parameters are in progress</span> <span data-start="648.51" data-end="654.61">This data generates specific losses. This means because we have two</span> <span data-start="654.61" data-end="660.22">Them, I can imagine it on a plane and say that this will be the slope of our line</span> <span data-start="660.22" data-end="668.279">-邋 — and the height of the X axis it is, and, for some given model parameter set,</span> <span data-start="668.279" data-end="673.48">In fact, for each set of model parameters, there will be some losses. So what can we do</span> <span data-start="673.48" data-end="680.25">Now figure out what was the loss and poke around that if my line</span> <span data-start="680.25" data-end="687.8">Comparison ? What if it's not so fuzzy? What about higher or lower? one of</span> </p>
<p><span data-start="687.8" data-end="693.68">Direction, we will reduce losses, and so we have to take a step in that direction</span> <span data-start="693.68" data-end="701.831">Along two axes. We will do it again. More slopy, less slopy, higher or lower. once again</span> <span data-start="701.831" data-end="715.93">Then again. At each step, we are using losses to indicate our direction of movement. Lose</span> <span data-start="715.93" data-end="724.47">Tell us where to go. It reveals that it is a lost landscape for us. what</span> <span data-start="724.47" data-end="729.631">What we are doing is we are working on the slope of this landscape at every point,</span> <span data-start="729.631" data-end="734.83">The general mapping of the slope of the landscape is its gradient, so this process</span> <span data-start="734.83" data-end="741.51">What we are doing is gradient descent. We roll down this landscape like rain</span> <span data-start="741.51" data-end="749.649">Fall into the closest valley truth. So there are many ways</span> <span data-start="749.649" data-end="755.46">We may adjust this process. One is to notice that if we calculate the loss for everyone</span> <span data-start="755.46" data-end="761.67">In the example, all the paint, that takes a while. Is not</span> <span data-start="761.67" data-end="767.1">It will take a long time to find a line and X, Y points, but if we have a larger model,</span> <span data-start="767.1" data-end="774.24">Then calculating the loss can be quite expensive, so we might catch some examples,</span> <span data-start="774.24" data-end="783.93">random. Randomly, you might say, if you want to say casually rather than randomly,</span> </p>
<p><span data-start="783.93" data-end="790.079">So this gives us a random descent gradient. We may choose other parameters</span> <span data-start="790.079" data-end="798.92">The size of the steps we took. This is called the learning rate. These quantities, sizes</span> <span data-start="798.92" data-end="803.15">The number of batches, such as the number we see, or the learning rate, they are</span> <span data-start="803.15" data-end="809.37">Did n’t learn, we do n’t train them, so they are not called model parameters, but super</span> <span data-start="809.37" data-end="814.01">Parameters are a very exciting word, and I don't think the model learns them</span> <span data-start="814.01" data-end="819.81">During training, we set it manually. We train the model, which usually runs hundreds of</span> <span data-start="819.81" data-end="828.65">Experiment and stare at the chart until our eyes bleed. Ok. This is a line.</span> <span data-start="828.65" data-end="835.49">It's like a very simple, very simple feature, and maybe not very useful, right? Have</span> <span data-start="835.49" data-end="840.41">We may use it for further functional learning. For example, we might use one of these</span> </p>
<p><span data-start="840.41" data-end="851.769">A set of sigmoid functions. These mimic neurons. Here, neurons are firing,</span> <span data-start="851.769" data-end="859.07">This is not the case here. They go well because they-because of this they are different</span> <span data-start="859.07" data-end="894.98">Essential . [Sound Distortion]. This is a difficult feature</span> <span data-start="894.98" data-end="921.23">A complicated function. That's it</span> <span data-start="921.23" data-end="929.47">X's math and zero. That's it. That function is easy to think of. We can imagine</span> <span data-start="929.47" data-end="935.3">Right, and-can't write a JavaScript series. The original one</span> <span data-start="935.3" data-end="940.42">Simple and easy to calculate is great for deep learning, where,</span> <span data-start="940.42" data-end="946.089">Once again, we did not do very interesting or complicated operations, we are definitely doing</span> <span data-start="946.089" data-end="953.269">A lot of people. We can imagine stacking up these rectifiers and we will be here</span> </p>
<p><span data-start="953.269" data-end="963.04">There are four layers, and four neurons are densely interconnected into two layers. Because they are densely interconnected,</span> <span data-start="963.04" data-end="970.149">We want to say that each neuron is fed by everyone on the second layer</span> <span data-start="970.149" data-end="976.079">Neurons in the first layer. So this one, for example, its input will be weighted</span> <span data-start="976.079" data-end="981.339">Sum inputs from all neurons to the previous layer, if you want</span> <span data-start="981.339" data-end="988.449">It, because of the shape of this function, what we are really doing is nesting if statements.</span> <span data-start="988.449" data-end="993.759">We nest if statements in if statements whose value depends on the previous output</span> <span data-start="993.759" data-end="1001.509">If statements, their thresholds are basically completely hard-coded. Next time you see the protector</span> <span data-start="1001.509" data-end="1006.759">Created a deep neural network at google just think about it, this will do something impressive</span> <span data-start="1006.759" data-end="1012.25">Google researchers have figured out 50 million random values ​​hard-coded in order</span> <span data-start="1012.25" data-end="1017.31">Do something impressive, which is basically what's going on. The impressive part is obviously</span> <span data-start="1017.31" data-end="1024.37">The training process found out our own hard-coded values, however, in</span> <span data-start="1024.37" data-end="1029.39">In the end, what the model is doing is basically lucky with a bunch of spaghetti codes</span> <span data-start="1029.39" data-end="1036.761">Simulating our brains is good. Even a model like this, the relatively small one, if</span> </p>
<p><span data-start="1036.761" data-end="1042.58">We consider the number of interconnections we see that between these two layers of neurons</span> <span data-start="1042.58" data-end="1048.93">We have 16. For a line we have two parameters and we are able to think</span> <span data-start="1048.93" data-end="1056.68">About its losses. This model has 16 parameters, I do n’t know about you, but</span> <span data-start="1056.68" data-end="1068.32">I can hardly imagine a 17-dimensional surface. It gets worse. What we see</span> <span data-start="1068.32" data-end="1078.08">Disclosed here is the visualisation of Loss Resnet's landscape, which is an image classifier.</span> <span data-start="1078.08" data-end="1088.281">Resnet has about 60 million parameters. It means that this is a heavy approximation. These ones</span> <span data-start="1088.281" data-end="1092.91">People made some interesting projections in order to make it even like something</span> <span data-start="1092.91" data-end="1098.8">Three-dimensional. Someone said the terrible thing of living in the base</span> <span data-start="1098.8" data-end="1103.69">The sea will wake up one day and consume the world. They have length, width, depth,</span> <span data-start="1103.69" data-end="1112.28">There are several other things, and maybe what this Lovecraft is talking about. Ok</span> <span data-start="1112.28" data-end="1116.48">News is that you don't have to train those role models. You don't even have to think about</span> <span data-start="1116.48" data-end="1124.41">They or keep their loss landscape heads in your loss because you can install them with MPM! with</span> </p>
<p><span data-start="1124.41" data-end="1131.19">It looks like-of course, if you want to train those models, I highly encourage it.</span> <span data-start="1131.19" data-end="1135.7">We will look at a transfer example to learn where we take a pre-trained model</span> <span data-start="1135.7" data-end="1142.59">Then train it to do something else. It lets us make the most of all our training time</span> <span data-start="1142.59" data-end="1150.32">In the bigger case, in this case, image recognition model and then use it to solve another problem</span> <span data-start="1150.32" data-end="1157.21">space. So we are going to transfer learning, what are we going to do, this is an example,</span> <span data-start="1157.21" data-end="1166.41">You can mention it on GitHub. I'm going to play Pac-Man with my elephant friend Tallula.</span> <span data-start="1166.41" data-end="1174.64">The way this works is I choose a bunch of examples using a webcam that represents an image</span> <span data-start="1174.64" data-end="1179.37">up down left right. I'm turning to the left. I'm trying to get into the framework,</span> <span data-start="1179.37" data-end="1185.08">Try not to find a representative in the framework, or give the network a representative</span> <span data-start="1185.08" data-end="1190.76">Where I'm going and how to hold her feel, you can see that I don't. we</span> </p>
<p><span data-start="1190.76" data-end="1199.33">Go train it. It's low. Then, when I play, the network will be highlighted</span> <span data-start="1199.33" data-end="1205.81">In the yellow direction it thinks I'm moving in, we can see that it works well,</span> <span data-start="1205.81" data-end="1212.27">At least Pac-Man didn't hold Tallula as well until I started getting stressed</span> <span data-start="1212.27" data-end="1219.36">My way during training. If you want to destroy friendship, use your friends as</span> <span data-start="1219.36" data-end="1226.86">Controllers are a great way! Now I am eaten. I was eaten. And i am happy</span> <span data-start="1226.86" data-end="1238.93">The report says that we are still friends! Thing we do is what we do is MPM installation</span> <span data-start="1238.93" data-end="1251.09">Everything including Tensorflow. One thing we did was install Tensorflow. then we</span> </p>
<p><span data-start="1251.09" data-end="1258.34">The model is loaded. Our model you can also install MPM, this special</span> <span data-start="1258.34" data-end="1264.251">The model is provided somewhere. And because we are transferring, we are</span> <span data-start="1264.251" data-end="1270.03">Going to make a little surgical model, so we're going to pull out this layer</span> <span data-start="1270.03" data-end="1278.4">conPW13relu, whatever that means, then we will build a new model</span> <span data-start="1278.4" data-end="1286.63">Use the main input as the mobile network output that is low but not the last layer. Actual final</span> <span data-start="1286.63" data-end="1295.19">The mobile network layer will be, like, 200 probabilities, or probabilities</span> <span data-start="1295.19" data-end="1300.51">There is a cat in this photo. Probability this photo contains a cow. Probability</span> <span data-start="1300.51" data-end="1305.07">This photo contains a laptop and then turns on an image of whatever category</span> <span data-start="1305.07" data-end="1310.97">The mobile web has been trained for recognition. What we wanted before, what was in it</span> <span data-start="1310.97" data-end="1318.14">This image has been reshaped into some arbitrary chunks of interesting data, but there are</span> <span data-start="1318.14" data-end="1329.221">It hasn't been eliminated to what it contains. We will see more in a second. When</span> </p>
<p><span data-start="1329.221" data-end="1334.17">I am adding examples and this is what is happening, it is controlling the dataset being built</span> <span data-start="1334.17" data-end="1342.78">A set of sample data. Then we build our model. Our model will take</span> <span data-start="1342.78" data-end="1347.48">The output of this Tensorflow layer, it is squashing it, it will finish it</span> <span data-start="1347.48" data-end="1355.56">A configurable number-let's call it 100-densely interconnected relu neurons, and,</span> <span data-start="1355.56" data-end="1361.63">So, in the end, we will have a soft Max layer. It is a different activation function</span> <span data-start="1361.63" data-end="1367">This is useful if you want a probability distribution, so, in this case, what we want</span> <span data-start="1367" data-end="1375.43">Probability distributions. The Num course is under four years old because we have up, down, left,</span> <span data-start="1375.43" data-end="1378.95">And that's between all the decisions we have to make. Output of our network</span> <span data-start="1378.95" data-end="1388.08">Will become relative probability I hold her, left, right, or</span> <span data-start="1388.08" data-end="1396.28">and many more. Then we configure an optimizer. We did not use stochastic gradient descent,</span> <span data-start="1396.28" data-end="1404.46">We are using the Adam technique of random gradient which is better. This is a little</span> <span data-start="1404.46" data-end="1412.43">A little smarter about how it decides the steps it needs. We want to compile this model</span> <span data-start="1412.43" data-end="1423.68">Has a loss function, and the loss function is "cross-functional entropy. The reason</span> <span data-start="1423.68" data-end="1428.64">If we have this example, that's an example I hold Tallula upside down and say</span> <span data-start="1428.64" data-end="1433.73">Down, the network predicts this-which is technically predicting what I am holding</span> <span data-start="1433.73" data-end="1443.28">Her right-how bad is this, really? Because, like, it ’s very close-predict</span> </p>
<p><span data-start="1443.28" data-end="1448.55">Is wrong. If these are flipped, it will think it is still a bit wrong</span> <span data-start="1448.55" data-end="1453.24">I have a 10% chance of holding her correctly, you know what? Reply</span> <span data-start="1453.24" data-end="1460.98">That question is what classification cross entropy does. How much is confused by this model</span> <span data-start="1460.98" data-end="1467.31">Different probability classes? Now you know. Finally, we call it suitable for this</span> <span data-start="1467.31" data-end="1473.381">Is actually starting to dispatch things on the GPU and we get these callbacks every time</span> <span data-start="1473.381" data-end="1479.25">When the batch completed. So every time we have calculated our loss</span> <span data-start="1479.25" data-end="1487.63">If we have updated the weights, then we have taken a step. Row. To play games,</span> <span data-start="1487.63" data-end="1494.16">We ask the mobile web to make predictions and we run our model to give us one of four probabilities</span> <span data-start="1494.16" data-end="1501.83">Course, then we find out which one is most likely, we do it. That is</span> <span data-start="1501.83" data-end="1508.68">Parkman. That is the tense of transfer learning or flow.js. I hope we go back</span> <span data-start="1508.68" data-end="1514.63">Understand what mobile web we are getting rid of, and, to do, I want to load</span> <span data-start="1514.63" data-end="1521.95">Mobile web, load the JSON file we loaded back in the browser. Here we will see</span> <span data-start="1521.95" data-end="1530.92">This is a deep learning system that lets us describe the Caris model as a bunch of layers,</span> <span data-start="1530.92" data-end="1543.4">Here it is the layer. come on. Click. So a deep learning network that recognizes images</span> <span data-start="1543.4" data-end="1549.14">It usually looks like this. We have got convolutional layers and normalization</span> <span data-start="1549.14" data-end="1553.13">Layers and activation layers. Activation layer we know what they look like-those</span> </p>
<p><span data-start="1553.13" data-end="1560.9">This is the relu layer we saw before. Normalization ensures that our values ​​are between 0 and 0</span> <span data-start="1560.9" data-end="1568.401">One person, they span a single batch, which is why they call it the batch layer. convolution</span> <span data-start="1568.401" data-end="1573.13">Layers have configuration parameters, like many things in machine learning,</span> <span data-start="1573.13" data-end="1580.4">They sound difficult, but they are not difficult. Convolutions are basically Photoshop filters.</span> <span data-start="1580.4" data-end="1585.77">If we have a bunch of input pixels, the convolutional layer will grab some blocks</span> <span data-start="1585.77" data-end="1593.4">Those pixels pass the filter and output it. It will filter the filter</span> <span data-start="1593.4" data-end="1600.09">The entire image produces an output image. If we do not allow this, you will notice</span> <span data-start="1600.09" data-end="1604.24">The filter slides down the edges and then we get something slightly smaller. We can</span> </p>
<p><span data-start="1604.24" data-end="1609.8">Decide what we want. This is one of many tunable parameters. Here comes the convolution</span> <span data-start="1609.8" data-end="1616.23">Various shapes and sizes. This is three times three. The key here is this</span> <span data-start="1616.23" data-end="1623.22">The filter is the same image throughout the process and it is trainable, which means</span> <span data-start="1623.22" data-end="1630.67">Actually, let's see what it means. So I left and went to the mobile network. place it here.</span> <span data-start="1630.67" data-end="1635.61">This is what happens in each one we see many, many convolutional layers</span> <span data-start="1635.61" data-end="1640.59">prior to. Yes it looks like a bunch of crappy Photoshop filters because it's a bunch</span> <span data-start="1640.59" data-end="1649.79">Terrible Photoshop filter. The interesting thing here is that it has started edge detection</span> <span data-start="1649.79" data-end="1656.3">And other distractions in our vision that mimic visual processes</span> </p>
<p><span data-start="1656.3" data-end="1663.7">Core twelve. This happens naturally when you train a system that can create these</span> <span data-start="1663.7" data-end="1670.72">Isolated image classification filter mimics image class tasks</span> <span data-start="1670.72" data-end="1675.43">We ourselves realized that it started to do the same thing as we did</span> <span data-start="1675.43" data-end="1683.5">Do, this is an interesting validation I think of this model. So I hope this will be popular</span> <span data-start="1683.5" data-end="1689.02">Learning is a bit less scary, implementing it is just a whole bunch of operations,</span> <span data-start="1689.02" data-end="1704.39">A bunch of adjusted spaghetti codes go through a very simple but big process. our world</span> <span data-start="1704.39" data-end="1710.36">Full of information and our interaction comes with it</span> <span data-start="1710.36" data-end="1715.38">Machine learning system. The system is not perfect. They have no training</span> <span data-start="1715.38" data-end="1720.98">We give them the data, and like them, they internalize the data's biases, and,</span> <span data-start="1720.98" data-end="1726.77">Just like us, they can be pushed into the services of anyone who wants to use them. There</span> <span data-start="1726.77" data-end="1732.44">This proves that the neural network is a universal approximation, which means that any function you have</span> <span data-start="1732.44" data-end="1741.71">Give them they can approach some level of precision if you believe in our own perception</span> <span data-start="1741.71" data-end="1746.45">Is a computable function and then we are moving into the basic task of the world</span> </p>
<p><span data-start="1746.45" data-end="1754.2">Cognition is now a machine where we can train things. So these are not real.</span> <span data-start="1754.2" data-end="1762.6">These are conceived by deep learning networks whose loss function is another network. The</span> <span data-start="1762.6" data-end="1770.91">The two networks improve each other and learn what dreams look like.</span> <span data-start="1770.91" data-end="1778.26">This is not Barack Obama. This is an actual recording of machine learning Obama synced to</span> <span data-start="1778.26" data-end="1785.39">Obama speaks. Existing systems can produce speech that sounds like anyone</span> <span data-start="1785.39" data-end="1793.26">it is good. So how do we respond? With the world we cannot believe in our eyes and the world</span> <span data-start="1793.26" data-end="1799.36">ear? One way is to ignore it and say that these techniques are not so good</span> <span data-start="1799.36" data-end="1807.64">-But. But if cognition is a computable function, then our society and ourselves are games,</span> <span data-start="1807.64" data-end="1814.95">It turns into a robot and is very good at playing games. In the history of computing,</span> </p>
<p><span data-start="1814.95" data-end="1821.45">We see these trends. So, first of all, very important work is done on a large main frame. then</span> <span data-start="1821.45" data-end="1827.851">The processor was improved and work turned to personal computers. Then the network improved and we</span> <span data-start="1827.851" data-end="1833.51">Put everything in the cloud. Now we are seeing the tide disappear when we start</span> <span data-start="1833.51" data-end="1840.08">Realizing how much power we have given up to know everything about everyone,</span> <span data-start="1840.08" data-end="1845.39">How much danger we rely on to feed on picking boxes outside our control</span> <span data-start="1845.39" data-end="1851.59">We have knowledge. So the information I give you is that these technologies are not necessarily opaque,</span> <span data-start="1851.59" data-end="1856.83">And they do n’t have to concentrate, and we can master the power of robotic thinking</span> <span data-start="1856.83" data-end="1865.51">pocket. We can use them to create, not just create forgeries, but previously discern the truth</span> </p>
<p><span data-start="1865.51" data-end="1869.78">So this is just the beginning. Everything we see here today, I think it's quite</span> <span data-start="1869.78" data-end="1875.87">Impressive, I think it will look downright awkward in a few years</span> <span data-start="1875.87" data-end="1881.98">You can talk to euro bot-your robot assistant, your voice mode will never leave</span> <span data-start="1881.98" data-end="1884.48">Your wrist. Thank you. [Cheers and applause]. If you are interested, you can find some people here</span> </p>
</section>

<!-- div#container ends -->
</div>

<img alt="The End" id="fin" src="../images/fin.jpg">

<script>
/*eslint-disable */
function googleTranslateElementInit() {
  new google.translate.TranslateElement({pageLanguage: 'en',
    layout: google.translate.TranslateElement.InlineLayout.SIMPLE
    }, 'google-translate');
}
/* eslint-enable */
</script>

<script src="https://translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script>

<script src="../js/main.js"></script>

</body>

</html>
