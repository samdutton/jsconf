<section>
<p><span data-start="0.16" data-end="1.16">Meet the Packets: How audio travels into your browser</span> <span data-start="1.16" data-end="2.16">Sara Fecadu KATIE: Hello. Welcome back. So, I keep forgetting</span> <span data-start="2.16" data-end="3.16">to do this and I apologize. But the big announcement right now is that the swag is ready. But do</span> <span data-start="3.16" data-end="4.16">not go get swag now because we're about to have a really awesome talk by Sara Fecadu.</span> </p>
<p><span data-start="4.16" data-end="5.83">I asked Sara for a fun fact and her fun fact was that she makes\h bakes a mean cookie which</span> <span data-start="5.83" data-end="6.83">unfortunately we can't all indulge in. So, as a follow up question, I said what prompted</span> <span data-start="6.83" data-end="7.83">you write this talk about an audio API. And she said, well, I had spent a year building</span> <span data-start="7.83" data-end="8.83">a checkout form and I just couldn't stand to look at it or think about it anymore and</span> <span data-start="8.83" data-end="9.83">I had to do something different. Which I think is something that literally all you have us</span> <span data-start="9.83" data-end="10.83">can probably identify really strongly with. So, anyways, Sara is gonna come up and talk</span> <span data-start="10.83" data-end="11.83">to us about the audio API. So, give it up for Sara.</span> <span data-start="11.83" data-end="12.83">[ Applause ] SARA: Hello. See if I can get my computer</span> <span data-start="12.83" data-end="13.83">started here. Okay. Welcome to my talk. Meet the packets. If not everyone has realized,</span> <span data-start="13.83" data-end="14.83">it's a play off meet the parents. I spent a lot of time working on that.</span> <span data-start="14.83" data-end="15.83">[ Laughter ] Let's see here. One second. Gonna progress?</span> <span data-start="15.83" data-end="16.83">No. Okay. We're gonna do it without the clicker. So, this will be interesting. As Katie said,</span> <span data-start="16.83" data-end="17.83">my name\h oh. My whole slide deck isn't progressing. Okay. One second. There we go. Okay. Thank</span> <span data-start="17.83" data-end="18.83">you for coming to talk. As Katie said, my name is Sara Fecadu. I am from Seattle, Washington.</span> </p>
<p><span data-start="18.83" data-end="19.83">And I don't have a ton of hobbies besides making cookies and listening to a lot of podcasts.</span> <span data-start="19.83" data-end="22.429">And by day I'm a software developer at Nordstrom. And Nordstrom is a clothing retailer founded</span> <span data-start="22.429" data-end="27.539">in 1901. While people don't usually associate 100 year old companies with tech, we have</span> <span data-start="27.539" data-end="32.599">a thriving tech org working on innovative ways to get you what you need and feel your</span> <span data-start="32.599" data-end="41.89">best. And a year ago I was hired on to do a rewrite of Nordstrom.com's redux. And as</span> <span data-start="41.89" data-end="50.64">of last May, we have been taking 100% of customer orders. Now, why am I talking about audio</span> <span data-start="50.64" data-end="58.43">streaming? Katie may have taken my joke here, but the answer is: Form fields. Our checkout</span> </p>
<p><span data-start="58.43" data-end="64.98">UI has 22 form fields. And they come in different groupings for different reasons. But many</span> <span data-start="64.98" data-end="69.99">of my waking moments over the past year have been spent thinking about these form fields.</span> <span data-start="69.99" data-end="76.45">And I just wanted to do anything else. So, I was sitting on my couch one night reading</span> <span data-start="76.45" data-end="82.44">a book on packet analysis, like one does, and watching a YouTube video. And I thought</span> <span data-start="82.44" data-end="88.43">to myself, how does that work? Like, on the packet level, how does audio video streaming</span> <span data-start="88.43" data-end="95.04">work? So, to answer the larger question, I started small with: What is audio streaming?</span> <span data-start="95.04" data-end="101.03">And audio streaming is the act of sending audio files over the network. And this talk</span> <span data-start="101.03" data-end="105.89">will be about on demand audio streaming. Now, the major difference between on demand streaming</span> <span data-start="105.89" data-end="110.6">and live streaming, is with on demand streaming we need all of the packets to get across the</span> <span data-start="110.6" data-end="115.31">wire. Whereas with live streaming, you may be more interested in keeping them up with</span> <span data-start="115.31" data-end="121.95">the event and a certain amount of packet loss is acceptable. Over the past few months, I</span> <span data-start="121.95" data-end="128.011">learned that audio streaming, even when limited to on demand, is as wide a subject as it is</span> <span data-start="128.011" data-end="135.4">deep. I have picked three topics that exemplify what audio streaming is. Why it's hard and</span> <span data-start="135.4" data-end="141.22">how to get started yourself. And we will talk about audio streaming protocols, TCP congestion</span> <span data-start="141.22" data-end="148.84">control and client players. Audio streaming protocols give us a stand how to encode, segment</span> <span data-start="148.84" data-end="155.73">and ship your code to the client. TCP congestion control handles congestion on the TCP layer</span> <span data-start="155.73" data-end="162.98">of the stack. And it is relevant with on demand audio streaming because we're shipping larger</span> <span data-start="162.98" data-end="169.44">audio files and we need every single packet to make its way to the client to play audio.</span> </p>
<p><span data-start="169.44" data-end="175.481">A client player is any network connected device with a play and pause button. So, this could</span> <span data-start="175.481" data-end="182.12">be your phone, your TV, your laptop, et cetera. And client players not only allow us to play</span> <span data-start="182.12" data-end="188.01">our audio, but when paired with modern audio streaming protocols, they hold a lot of decision</span> <span data-start="188.01" data-end="194.65">making power. Well, audio streaming protocols are the heart of audio streaming. And today</span> <span data-start="194.65" data-end="199.56">we'll talk about adaptive bitrate streaming it &s it benefits and how to convert your</span> <span data-start="199.56" data-end="205.41">own audio files to work with two popular audio streaming protocols. Before we get started,</span> </p>
<p><span data-start="205.41" data-end="212.06">I wanted to go over some terms that will come up. A codec encodes data and uses compression</span> <span data-start="212.06" data-end="218.46">techniques to get the highest quality for the smallest footprint. Encoding and trans</span> <span data-start="218.46" data-end="227.45">coding is converting it from one type to another. Trans coding can convert from digital to digital.</span> <span data-start="227.45" data-end="237.27">And then move from analog to other digital files. Bitrate is how many bits it takes to</span> <span data-start="237.27" data-end="242.29">encode a second of audio. And this number usually refers to the quality of the audio</span> <span data-start="242.29" data-end="250.23">file. When I think of playing music on the Internet, I think of an HTML5 audio tag with</span> <span data-start="250.23" data-end="255.849">a source attribute set to the path of my audio file. And this is a perfectly reasonable way</span> <span data-start="255.849" data-end="262.5">to do it. You can request and receive a single file containing an entire song. And it would</span> <span data-start="262.5" data-end="267.561">be referred to as progressive streaming and the major benefit here is you only have one</span> <span data-start="267.561" data-end="274.43">file to deal with. But let's say, for instance, you have a user and they have a slow network</span> <span data-start="274.43" data-end="281.23">connection and they can't download your one file. They're stuck. So, adaptive bitrate</span> <span data-start="281.23" data-end="287.3">streaming aims to solve this problem by encoding your audio in multiple bitrates and allowing</span> <span data-start="287.3" data-end="291.85">the client player to decide which quality is best for the user to listen to your audio</span> <span data-start="291.85" data-end="299.94">uninterrupted. This allows more users to access your audio. But it does add a layer of operational</span> <span data-start="299.94" data-end="307.26">complexity because now you've got a lot more work on moving parts. The audio streaming</span> <span data-start="307.26" data-end="314.28">protocols we'll talk about not only average adaptive bitrate streaming, but also use HTTP</span> <span data-start="314.28" data-end="319.32">web servers. They do this by encoding the file, segmenting they will, placing them on</span> <span data-start="319.32" data-end="325.87">a web server and then once requested, partial audio files are sent to the client one at</span> <span data-start="325.87" data-end="333.7">a time. Here is the secret to our modern audio streaming protocols is it's more of a series</span> <span data-start="333.7" data-end="340.051">of downloads than it really is a stream. But we'll refer to it as streaming anyway. The</span> <span data-start="340.051" data-end="346.24">two most popular audio streaming protocols today are HTTP lye streaming, or HLS, and</span> <span data-start="346.24" data-end="356.18">dynamic adaptive streaming over HTTP, MPEG DASH. It was created by Apple to support streaming</span> <span data-start="356.18" data-end="366.229">to mobile devices and it is default on all Mac OS and Apple devices. And MPEG DASH was</span> <span data-start="366.229" data-end="373.41">a direct alternative to HLS. It was created by the forum who want to make MPEG DASH the</span> <span data-start="373.41" data-end="385.639">international streaming. Let's look at them side by side. HLS takes the MPC, AAC, AC 3,</span> <span data-start="385.639" data-end="395.76">or EC 3, encodes\hthem into fragmented MP4 files. Those segmented files are in a play</span> <span data-start="395.76" data-end="402.01">list. If you have multiple bitrate streams, each stream will be in a media play list and</span> <span data-start="402.01" data-end="409.23">all of your media play lists will be in a master play list. With MPEG DASH, it is agnostic,</span> <span data-start="409.23" data-end="421.009">in theory you can convert any into MPEG DASH. It will be fragmented into a fragmented MP4</span> <span data-start="421.009" data-end="428.389">file. That will be displayed in an XML manifest file called a media presentation description.</span> </p>
<p><span data-start="428.389" data-end="434.901">Okay. We've talked about what files will be used and what they'll be segmented into, but</span> <span data-start="434.901" data-end="440.04">how do you get it there? You've got this audio file. What tools allow you to convert the</span> <span data-start="440.04" data-end="446.71">audio file? Well, you've got options. But most of these options are paid options. Except</span> <span data-start="446.71" data-end="452.91">for FFmpeg. Which is an open source demand line tool that among other things allows you</span> <span data-start="452.91" data-end="461.54">to convert audio files to be HLS or MPEG DASH. However, I founded learning curve for FFmpeg</span> <span data-start="461.54" data-end="472.46">to be pretty steep. And a lot of the documentation for HLS and MPEG DASH were for video streams.</span> <span data-start="472.46" data-end="480.1">Instead I used Amazon elastic trans coder. It's an AWS offering that converts files of</span> <span data-start="480.1" data-end="485.789">one type to another. In our case, we're taking an audio file and converting it to be used</span> <span data-start="485.789" data-end="495.04">with HLS and MPEG DASH. It's pretty much plug and play. You tell Amazon elastic trans coder</span> <span data-start="495.04" data-end="500.03">what type of files you have and what type of files you want and it outputs the stream</span> <span data-start="500.03" data-end="505.56">for you. And even though it's easy to use, it's not a free service. So, if you were going</span> <span data-start="505.56" data-end="510.91">to be converting a lot of files, it may be worth your time to learn more about an open</span> <span data-start="510.91" data-end="517.829">source alternative like MPEG DASH. My workflow when working with Amazon Elastic Transcoder</span> <span data-start="517.829" data-end="528.11">was to upload to an AWS object store. I told Amazon Elastic Transcoder where my audio file</span> <span data-start="528.11" data-end="535.92">was and what settings I needed it to convert my audio files to. And Amazon Elastic Transcoder</span> <span data-start="535.92" data-end="544.661">output my streams into that same S3 bucket. And I downloaded them for us to explore. This</span> <span data-start="544.661" data-end="549.92">is the basic set of files you would get with an HLS stream. And it kind of looks like a</span> <span data-start="549.92" data-end="556.089">lot. But we're going to break it down into four groups. In the top left, the master play</span> <span data-start="556.089" data-end="562.47">list. In our case, we have two bitrate streams represented and they will be linked out from</span> <span data-start="562.47" data-end="568.029">the master play list. And then in the top right you'll see those media play lists which</span> <span data-start="568.029" data-end="575.72">have each bitrate stream. And those will contain all of our links to our transport stream files</span> <span data-start="575.72" data-end="582.47">which are the fragmented audio files represented in both the bottom left and the bottom right.</span> </p>
<p><span data-start="582.47" data-end="588.119">On the bottom right we have our 64K bitrate stream segmented audio files. And in the bottom,</span> <span data-start="588.119" data-end="592.86">oh. Did I get that backwards? I'm not really good at right and left. But in the bottom</span> <span data-start="592.86" data-end="597.829">section you'll have your fragmented audio files. We'll take a closer look at those so</span> <span data-start="597.829" data-end="603.449">you can see really what's in it. This is the entirety of the HLS master play list. It contains</span> <span data-start="603.449" data-end="609.529">information about the specific bitrate streams and links out to those media play lists that</span> <span data-start="609.529" data-end="616.529">represent the streams themselves. Let's look at the 64K bitrate stream media playlist.</span> <span data-start="616.529" data-end="621.72">It has even more information about the stream including caching information, the target</span> <span data-start="621.72" data-end="627.769">duration of each segmented audio file, and most importantly, links out to our transport</span> <span data-start="627.769" data-end="634.61">streams. This is what one of those fragmented audio times looks like. And there's something</span> <span data-start="634.61" data-end="640.339">a little interesting going on here. If you'll notice, it's color coded\hand I kept trying</span> <span data-start="640.339" data-end="646.839">to figure out why. But then I realized a transport stream has the file extension .ts. And something</span> <span data-start="646.839" data-end="656.55">else has the file extension .ts, TypeScript. Ignore the colors. It's just a binary coded</span> <span data-start="656.55" data-end="664.869">file. Now our MPEG DASH audio stream has fewer files and looks more manageable. But it's</span> <span data-start="664.869" data-end="670.79">similar. We have our media presentation description, which is an XML manifest file which contains</span> <span data-start="670.79" data-end="677.6">all of our information about the stream. Then below we have our two segmented audio files.</span> </p>
<p><span data-start="677.6" data-end="683.829">All of the segments are encapsulated in a single file, but within them there are segments.</span> <span data-start="683.829" data-end="688.161">That's why there are fewer files in the MPEG DASH audio stream than in the other audio</span> <span data-start="688.161" data-end="696.16">stream. Look at the description. See a lot of stuff here. But there are three important</span> <span data-start="696.16" data-end="702.589">elements. All bitrate streams are represented in a representation tag. And then all bitrate</span> <span data-start="702.589" data-end="709.72">streams are enclosed in an adaptation set. Within the representation tag, we do have</span> <span data-start="709.72" data-end="715.699">our URL to our audio files. And taking a look at one of those audio files we'll see if looks</span> <span data-start="715.699" data-end="721.889">fairly similar to the segmented audio file we saw with HLS. Minus the color coding because</span> <span data-start="721.889" data-end="727.949">it's a .MP4 versus .TS. visual studio is not confused in this case.</span> <span data-start="727.949" data-end="734.75">Earlier we talked about progressive streaming which is streaming an entire audio file in</span> <span data-start="734.75" data-end="741.85">one two. We used an audio element and a source attribute with the path of our audio file.</span> <span data-start="741.85" data-end="746.42">With MPEG DASH and HLS, it's very similar. But instead of having the path to our audio</span> <span data-start="746.42" data-end="754.139">file, we have the path to the master play list for HLS or media presentation description</span> <span data-start="754.139" data-end="760.04">for MPEG DASH. We're going to take a hard left here and we're gonna talk about the second</span> <span data-start="760.04" data-end="768.019">topic in my talk. Which is TCP congestion control. And TCP is a transport layer protocol</span> <span data-start="768.019" data-end="772.869">and it has mechanisms in both its sender and receiver which are defined by the operating</span> <span data-start="772.869" data-end="778.989">systems of each to react to and hopefully avoid congestion when sending packets over</span> <span data-start="778.989" data-end="788.009">the wire. And they are called TCP congestion control. And today we talk about packet loss</span> <span data-start="788.009" data-end="796.459">congestion control and why it isn't so great. And more specific, the congestion window and</span> <span data-start="796.459" data-end="803.339">duplicate acknowledgment in packet loss based congestion control. Before we get started,</span> <span data-start="803.339" data-end="808.629">somewhere terms, bandwidth is the rate at which data can be sent. And throughput is</span> <span data-start="808.629" data-end="814.519">the rate at which data can be received. The congestion window is a TCP variable that defines</span> <span data-start="814.519" data-end="821.059">the amount of data that can be sent before the acknowledgment is received by the sender.</span> </p>
<p><span data-start="821.059" data-end="825.66">Let's say you have a user who has requested your audio file from the server. Your audio</span> <span data-start="825.66" data-end="831.689">packets travel down the network stack, across the physical layer, up the data link layer</span> <span data-start="831.689" data-end="837.829">in the network layer and arrives at the transport layer and unfortunately there's congestion</span> <span data-start="837.829" data-end="842.989">right before we reached our destination. Now, traffic congestion and network congestion</span> <span data-start="842.989" data-end="848.249">have very similar beginnings. Either too many cars or too many packets have entered the</span> <span data-start="848.249" data-end="855.751">roadway and there's nowhere for them to go. With traffic, you have to wait it out. Luckily</span> <span data-start="855.751" data-end="863.989">for us, TCP congestion control allows them to flow over the wire, even during congestion.</span> </p>
<p><span data-start="863.989" data-end="869.67">And before we get to the specifics of these TCP congestion control algorithms, let's talk</span> <span data-start="869.67" data-end="876.139">about the TCP happy path. We're going to start with a single packet sent from the sender</span> <span data-start="876.139" data-end="882.179">to the receiver flowing through the receiver's buffer. And being acknowledged by the receiver</span> <span data-start="882.179" data-end="887.549">and having an acknowledgment packet sent back to the requester. We talked about the congestion</span> <span data-start="887.549" data-end="894.93">window, the amount of data before a sender receives an acknowledgment. Another way of</span> <span data-start="894.93" data-end="900.519">thinking about the congestion window is as a sending rate. As the sender receives acknowledgments,</span> <span data-start="900.519" data-end="907.67">the congestion window grows. And\has the receiver's buffers fill and they drop all excess packets,</span> <span data-start="907.67" data-end="913.15">the sender responds by shrinking the congestion window. A second way of thinking about the</span> <span data-start="913.15" data-end="921.129">congestion window is as a bucket. And as packet loss occurs, the bucket shrinks. And as acknowledgments</span> <span data-start="921.129" data-end="928.049">are received by the sender, the bucket gross. There's a slight oversight in the bucket explanation</span> <span data-start="928.049" data-end="932.66">in that the receiver has no way of telling the sender that it is dropping packets due</span> <span data-start="932.66" data-end="939.589">to congestion. But one option the sender does have is to send a duplicate acknowledgment.</span> </p>
<p><span data-start="939.589" data-end="949.93">And a duplicate is if they're trying to send out of order packets. They send one, two and</span> <span data-start="949.93" data-end="954.47">three. For the purposes of our example, the receiver's not going to process them right</span> <span data-start="954.47" data-end="963.04">away. So, that when we send packet four, it's full and it has nowhere to go. So, packet</span> <span data-start="963.04" data-end="971.419">four dropped due to congestion. And they move on to process packet one, send an acknowledgment,</span> <span data-start="971.419" data-end="979.04">send for packet two and for three. However, when it looks at packet five, it says I can't</span> <span data-start="979.04" data-end="985.529">process you because this would be an out of order packet. drops packet five and sends</span> <span data-start="985.529" data-end="995.919">back for three. The sender is tipped off that it needs to sends packets four and five again.</span> <span data-start="995.919" data-end="1002.129">So, a more truthful version of the bucket metaphor would be that the congestion window</span> <span data-start="1002.129" data-end="1008.85">shrinks as old acknowledgments are received by the sender. And the bucket window grows</span> <span data-start="1008.85" data-end="1015.839">as new acknowledgments are sent by the sender. The first b congestion control algorithms</span> <span data-start="1015.839" data-end="1023.529">were written in the 1980s and the most recent were a couple years ago. We will talk about</span> </p>
<p><span data-start="1023.529" data-end="1037.17">TCP Reno and BBR. TCP Reno is the classic. And BBR was created by Google engineers a</span> <span data-start="1037.17" data-end="1045.65">few years ago to address issues that they saw when using packet based algorithms. TCP</span> <span data-start="1045.65" data-end="1052.76">Reno starts with a congestion period where it's set at some rate increasing by. It's</span> <span data-start="1052.76" data-end="1059.54">set at some value, excuse me, increasing by some rate. And as the sender receives acknowledgments,</span> <span data-start="1059.54" data-end="1066.85">the congestion window grows by one. And as the sender adds packets, it is divided by</span> <span data-start="1066.85" data-end="1074.85">some rate. I have chosen path. So, it's divided by two. And the main issue with TCP Reno is</span> <span data-start="1074.85" data-end="1080.35">that it assumes that small amounts of packet loss are congestion. And in a world where</span> <span data-start="1080.35" data-end="1085.6">the sender doesn't know the state of the receiver's buffer and the receiver is unable to tell</span> <span data-start="1085.6" data-end="1091.18">the sender that it has room left to process packets, you have an Internet moving at a</span> <span data-start="1091.18" data-end="1098.61">fraction of the capacity. In 2016, BBR was created to help you get the most out of your</span> <span data-start="1098.61" data-end="1106.14">Internet connection. It looks for the place where sending rate is equal to bandwidth.</span> </p>
<p><span data-start="1106.14" data-end="1113.53">In theory, you should be able to send to the receiver and move on to the application without</span> <span data-start="1113.53" data-end="1119.42">any queuing. Some companies have reported positive outcomes when using BBR in their</span> <span data-start="1119.42" data-end="1125.13">production systems. Firstly, it only has to be implemented in the senders side and is</span> <span data-start="1125.13" data-end="1134.41">in Linux operating systems with kernel 4.9 or higher. And they found BBR increased bandwidth</span> <span data-start="1134.41" data-end="1142.28">for the low bandwidth users for 10 15%, and the bandwidth for their median group 5 7.</span> <span data-start="1142.28" data-end="1148.51">Additionally, users in Latin America and Asia saw additional increases. But is it a fair</span> <span data-start="1148.51" data-end="1156.04">algorithm? Fairness, or using your fair share of bandwidth is the goal of every TCP control</span> <span data-start="1156.04" data-end="1162.11">algorithm. And in experiments in Google and Spotify, they found that BBR was able to co</span> <span data-start="1162.11" data-end="1170.62">exist with congestion control algorithms like TCP Reno or QBIC. However, some researchers</span> <span data-start="1170.62" data-end="1177.45">found that BBR's initial start algorithm pushed QBIC spenders back to where they couldn't</span> <span data-start="1177.45" data-end="1182.94">reestablish their fair share of bandwidth. And this is an issue currently being look</span> <span data-start="1182.94" data-end="1190.6">the at both in and outside of Google. We've reached the final section in this talk. And</span> <span data-start="1190.6" data-end="1196.87">so far we've talked about how audio files are processed to be streamed and issues that</span> <span data-start="1196.87" data-end="1203.16">may occur as they travel to devices. We'll wrap up by talking about the role of the client</span> <span data-start="1203.16" data-end="1210.11">player and how to create your own audio strings. Now, I'm a pretty big fan of Spotify and I</span> <span data-start="1210.11" data-end="1215.19">use it regularly. But have you ever looked at what's being sent back from the web server</span> <span data-start="1215.19" data-end="1222.01">to create those audio streams? This should look pretty familiar to what we were looking</span> <span data-start="1222.01" data-end="1227.53">at with our segmented audio files with HLS and MPEG DASH. But when I first saw these,</span> </p>
<p><span data-start="1227.53" data-end="1233.87">I did not have this context. And I kept thinking, do I need to write some client side JavaScript</span> <span data-start="1233.87" data-end="1240.48">to get this to play on the Internet? Is there an NPM package I can use? Or is there something</span> <span data-start="1240.48" data-end="1246.23">simple and obvious going on here that's going right over my head. And luckily for me and</span> <span data-start="1246.23" data-end="1252.2">hopefully everyone who writes JavaScript for the web, there is. Because HLS and MPEG DASH</span> <span data-start="1252.2" data-end="1257.55">handed over a lot of responsibility to the clients that process their streams. And this</span> <span data-start="1257.55" data-end="1265.38">not only includes picking the correct quality of audio to play, but it also includes allowing</span> <span data-start="1265.38" data-end="1271.23">elements like the audio element to process segmented audio files without any modification.</span> </p>
<p><span data-start="1271.23" data-end="1277.87">And most browsers do this by leveraging the media sources extension API and the encrypted</span> <span data-start="1277.87" data-end="1285.23">media extensions API. Additionally, libraries like HLS.JS and Dash.JS are available while</span> <span data-start="1285.23" data-end="1293.7">cross browser support is low. As a side note, if you need to support iOS Safari, you need</span> <span data-start="1293.7" data-end="1299.99">HLS. But with most other browsers, you have options. So, it would have been really fun</span> <span data-start="1299.99" data-end="1306">to reverse engineer Spotify's audio player. But I got tired of reading their minified</span> <span data-start="1306" data-end="1313.16">code. So, I decided to make my own audio player. And I started with a cassette that I found</span> <span data-start="1313.16" data-end="1319.9">from a box of cassettes. And I chose it because it has the words "Map squad" written on it.</span> <span data-start="1319.9" data-end="1326.56">And I used my iPhone's voice memo application to record the audio so the quality is so so</span> <span data-start="1326.56" data-end="1333.58">at best. But it works. And you can try it right now. But maybe wait until the end of</span> <span data-start="1333.58" data-end="1340.37">the talk because I want to show you how it's made. The entire application is a single in</span> <span data-start="1340.37" data-end="1348.49">docs.HTML file with an audio element in the body. When loaded into the browser, the immediately</span> <span data-start="1348.49" data-end="1356.48">invoked function runs, the init function. And at the top, we define the audio that's</span> <span data-start="1356.48" data-end="1364.45">equal to our audio element. Next web see if the media sources extension API is supported</span> <span data-start="1364.45" data-end="1371.38">in our browser. If it is, we will assume we can use dash.JS to enable MPEG DASH in most</span> <span data-start="1371.38" data-end="1381.86">browsers. Pass it to the dash.JS media player. And when the player is initialized, our audio</span> <span data-start="1381.86" data-end="1388.45">will be loaded with it. If the media sources extension API is not available, we're going</span> <span data-start="1388.45" data-end="1395.16">to assume we're using iOS Safari and we need to have an HLS stream. We will do this by</span> <span data-start="1395.16" data-end="1400.89">setting the source attribute of our audio element to the master playlist or the past</span> <span data-start="1400.89" data-end="1410.02">to our master playlist. And that\h this file is all you need to stream audio to most browsers</span> <span data-start="1410.02" data-end="1416.16">in 2019. If you want to try it out in the browser for yourself, or you want to create</span> <span data-start="1416.16" data-end="1418.91">your own audio streams, please feel free to fork 24 repo. Thank you.</span> <span data-start="1418.91" data-end="1419.91">[ Applause ] KATIE: I'm sorry. I think that scared me more</span> <span data-start="1419.91" data-end="1420.91">than it scared you. Thank you so much, Sara. Can you believe that is the first talk she</span> <span data-start="1420.91" data-end="1421.91">has ever given at a conference? Yes. Amazing. All right. So, we have about a\h a 15 minute</span> <span data-start="1421.91" data-end="1422.91">break right now. So, go out and pick up your swag bags. And we'll see you back here at</span> </p>
</section>

<section>
<p><span data-start="1422.91" data-end="1423.91"><span class="speaker">3</span>: 00. Patricia Ruiz Realini is talking about the importance of your local library. Which</span> <span data-start="1423.91" data-end="1424.91">is pretty cool because I hang out at the library. We'll see you back here at 3:00. No, wait.</span> </p>
</section>