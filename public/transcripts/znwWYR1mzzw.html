<section>
<p><span data-start="27.89" data-end="33.1">Wow! Okay, that was great. That's never happened before. (Laughing) can you do me a favor and</span> <span data-start="33.1" data-end="38.47">bring me the water. I left that with you. All right, this is called county queenses</span> <span data-start="38.47" data-end="43.71">of an insightful algorithm. The talk is for empathetic coding. We're going to delve into</span> <span data-start="43.71" data-end="51.86">specific examples and and in that spirit I want to start with raccoon tent warning, I'm</span> <span data-start="51.86" data-end="59.22">going to deal with a number of examples that are sensitive top Inc.s Greek PTSD, fertility,</span> <span data-start="59.22" data-end="64.72">racial profiling, con receivation camps sexual history concept and assault. While these are</span> <span data-start="64.72" data-end="69.28">not the major point of the talk, in about ten minutes we'll get into examples so you</span> <span data-start="69.28" data-end="77.06">have a bit of time to decide if it's not right moment for you. Algorithms impose consequences</span> <span data-start="77.06" data-end="85.039">on people all the time. We're able to extract remarkably precise insights about an individual,</span> <span data-start="85.039" data-end="90.229">but do we have a right to know what they didn't consent to share? Even when they're willingly</span> <span data-start="90.229" data-end="96.85">sharing the data that leads us there. How do we even mitigate against unintended consequences</span> <span data-start="96.85" data-end="103.81">like these? Let's start by just thinking about what is an algorithm, defined step‑by‑step</span> <span data-start="103.81" data-end="112.369">set of operations predictably arriving at an outcome. Predictivefully is pivotal here.</span> </p>
<p><span data-start="112.369" data-end="118.229">We're talking ability algorithm of computer science, patterns of instructions that are</span> <span data-start="118.229" data-end="127.689">articulate in the code or in formulas. But you could also think of algorithms as being</span> <span data-start="127.689" data-end="131.7">something in just ordinary every day life, patterns of instructions that can be articulate</span> <span data-start="131.7" data-end="145.441">in the all sorts of ways such as a map or a recipe or even C\h‑‑ you can Lasly define</span> <span data-start="145.441" data-end="152.53">it as Al governorrisms as fast trainable artificial gnarl networks. A technology been around for</span> <span data-start="152.53" data-end="158.76">a while since '80s in theirretcal scale and confined to academia. In the past few year</span> <span data-start="158.76" data-end="166.37">this is' been big advance in a variety of ways that make deep learning for extracting</span> <span data-start="166.37" data-end="174.26">insights out of Big Data out of construction deployment. Opening up a lot offed possibilities.</span> <span data-start="174.26" data-end="177.87">In particular it's an approach to building and training article official neural networks</span> <span data-start="177.87" data-end="183.8">you can think of them as decision making black boxes. What does that mean, essentially we</span> <span data-start="183.8" data-end="189.86">have some inputs, is this an array might be representing words concepts, Octobers, any</span> <span data-start="189.86" data-end="195.55">number of things, execution running a series of functions repeatedly and layers that get</span> <span data-start="195.55" data-end="201.44">more and more recease in their analysis, output our predictions of properties that might be</span> <span data-start="201.44" data-end="206.12">useful for drawing intuition about future data set as long as they're similar to the</span> <span data-start="206.12" data-end="211.129">original training data set. That allows the us to do some incredible things behavioral</span> <span data-start="211.129" data-end="217.17">prediction, the facial identification, sentiment analysis, and things as extreme as self driving</span> <span data-start="217.17" data-end="222.48">cars which Google is already using this stuff for a number of other companies are as well.</span> </p>
<p><span data-start="222.48" data-end="226.61">So there's a lot of practical applications if that's already intriguing you you can check</span> <span data-start="226.61" data-end="238.159">out C Convnetjs, it's a great opportunity to explore and experiment. So deep learning</span> <span data-start="238.159" data-end="245.269">relies on and ANN's automated discovery. And it applies those discoveries to intuitions</span> <span data-start="245.269" data-end="252.79">about future inputs. There's aquavit, every flaw or assumption in that training data set</span> <span data-start="252.79" data-end="258.159">or original functions is going to have unrecognized influence on the Gordon and Maureen and the</span> <span data-start="258.159" data-end="262.729">outcomes they generate. We're going to take a closer look at that in a minute, I want</span> <span data-start="262.729" data-end="271.28">to give you a neat example of what an ANN is like. This is Mario. It's an ANN that teaches</span> <span data-start="271.28" data-end="277.87">itself how to play super Mario world. It start was no clue whatsoever, all it does is manipulate</span> <span data-start="277.87" data-end="285.29">numbers and notice that sometimes things happen. Over 24 hour period it learns movement and</span> <span data-start="285.29" data-end="291.659">play via a purely self training session in which it engages in those hours of experimentation</span> <span data-start="291.659" data-end="295.719">each time learn ago little bit more about the patterns and identifiable them and using</span> <span data-start="295.719" data-end="303.71">them to make predictions for next layer. And speaking of games, let's play one. It looks</span> <span data-start="303.71" data-end="311.29">a little bit like Bingo, it's called data mining fail. Insightful algorithms are full</span> <span data-start="311.29" data-end="316.17">of pitfalls by looking at case studies it's an opportunity to explore some of the pitfalls</span> <span data-start="316.17" data-end="320.6">on this particular board. So are you ready? Yeah.</span> </p>
<p><span data-start="320.6" data-end="327.03">All right, here we go. In the retail sector the second trimester of pregnancy is known</span> <span data-start="327.03" data-end="333.159">as the holy grail. The reason is that it is one of the few times in life where consumers</span> <span data-start="333.159" data-end="339.38">spending habits product loyalties, brand loyalties are all kind of thrown up in the air, everything</span> <span data-start="339.38" data-end="343.96">is subject for an opportunity to change. And for retailers this is an incredible moment,</span> <span data-start="343.96" data-end="351.779">an opportunity to capture a consumer for potentially the rest of their lives and family. Target</span> <span data-start="351.779" data-end="355.66">managed to come up several years ago with a predictive algorithm that was good at identifying</span> <span data-start="355.66" data-end="362.88">customers that were in the second trimester. They started sending out add seculars to the</span> <span data-start="362.88" data-end="371.12">targeted people full of stuff related pregnancy, babies, a funny thing happened one day a man</span> <span data-start="371.12" data-end="377.93">came into the store and he was really angry. He's yelling at the manager, how dare you</span> <span data-start="377.93" data-end="384.37">send this to my teenage daughter are you trying to tell her to have sex. Manager, you know,</span> <span data-start="384.37" data-end="388.12">like he's not in charge of this, this is a huge national change, he apologizes, the guy</span> <span data-start="388.12" data-end="393.99">goes home he comes back the following day and says, I you an apology, I talked to my</span> <span data-start="393.99" data-end="401.83">daughter it turns out there were things I did not know and she is in fact pregnant.</span> </p>
<p><span data-start="401.83" data-end="410.149">So, target was right. But they were also wrong. What they found were that a lot of women were</span> <span data-start="410.149" data-end="415.18">not okay with having their privacy violate in the this way. And the way they describe</span> <span data-start="415.18" data-end="423.58">od it is, some women React badly. Which is an interesting moral judgment on that. So,</span> <span data-start="423.58" data-end="432.45">they came up with a change in plan. The new one was, now adds still go out to the same</span> <span data-start="432.45" data-end="437.459">people, same adds except they're couched among other adds that seem completely unrelated</span> <span data-start="437.459" data-end="441.96">so that their perception is that you know it's completely random bunch of adds that</span> <span data-start="441.96" data-end="445.43">they just happen to get that have some things that are relevant to their life. And the reason</span> <span data-start="445.43" data-end="451.01">they do this. This is a quote "as long as a pregnant women thinks she hasn't been spied</span> <span data-start="451.01" data-end="460.7">on, as long as we don't spook her, it works.". (Laughing) so algorithms aren't just about</span> <span data-start="460.7" data-end="465.9">the outputs, it's about how we use them and how we abuse them. This is one of the examples</span> <span data-start="465.9" data-end="474.3">of ways that we can have all the math right and still be wrong. Shutterfully likewise</span> <span data-start="474.3" data-end="479.77">was trying to predict things related pregnancy, in this case what they were predicting was</span> <span data-start="479.77" data-end="485.279">recent childbirth. Congratulations on your new bundle of joy, time to write thank you</span> <span data-start="485.279" data-end="491.62">cards to all the people that came to your lovely party. Some of the people who got these</span> <span data-start="491.62" data-end="497.08">said, well, I haven't really been pregnant seeing as how I'm male. (Laughing) and others</span> <span data-start="497.08" data-end="502.77">had different responses. Thanks, shutterfly for the congratulations on my new bundle of</span> <span data-start="502.77" data-end="512.55">joy, I'm horribly infertile, but hey, I'm aadopting a kitten, so .. I lost a baby in</span> </p>
<p><span data-start="512.55" data-end="519.65">November, who would have been due this week, it was like hitting a wall all over again.</span> <span data-start="519.65" data-end="525.3">Shutterfly's response was the intent of the e‑mail was to target customers who recently</span> <span data-start="525.3" data-end="532.93">had a baby. Well, yes, that's true. That's not an apology. That is a statement that that</span> <span data-start="532.93" data-end="543.22">was what they wanted to do. They failed at it. False positives can be very meaningful.</span> <span data-start="543.22" data-end="549.8">Few months ago mark Zuckerberg excitedly announced he's going to be a father soon. He wrote on</span> <span data-start="549.8" data-end="556.3">Facebook about a series of miscarriages that he and his wife had felt with as a couple.</span> <span data-start="556.3" data-end="560.95">This is part of what he had to say. He said, you feel so hopeful when you learn you're</span> <span data-start="560.95" data-end="566.28">going to have a child. You start imagining who they'll become, and dreaming of hopes</span> <span data-start="566.28" data-end="577.76">for their future. You start making plans. And then they're gone. It's a lonely experience.</span> </p>
<p><span data-start="577.76" data-end="583.611">Facebook in review has\h‑‑ Facebook year in review has been around for a while. This</span> <span data-start="583.611" data-end="588.51">past year what they did was much more automated putting the post from the past year that they</span> <span data-start="588.51" data-end="593.37">felt were particularly big and important and memorable for you and throwing them back to</span> <span data-start="593.37" data-end="597.26">you at the end of the year to enjoy all over again. What they failed to take into account</span> <span data-start="597.26" data-end="604.55">is our lives oconstantly changing in the course of a year many of us have job changes, relationship</span> <span data-start="604.55" data-end="609.12">change, our life circumstances. All sorts of things and some of those mean that not</span> <span data-start="609.12" data-end="616.4">every memory stays the joyous one that it once was.Er reck Meyer coined the term inadvertent</span> <span data-start="616.4" data-end="622.79">algorithmic cruelty. The result of code that works in the overwhelming majority of cases</span> <span data-start="622.79" data-end="630.2">but doesn't take other use cases into account. So why does he get to name it? Well because</span> <span data-start="630.2" data-end="637.551">he's one of the people it happened to. This is a picture ofmy daughter who is dead. Who</span> <span data-start="637.551" data-end="644.4">died this year. The year in review add keeps coming up in my feed, rotating through different</span> <span data-start="644.4" data-end="650.52">fun and fabulous backgrounds as if celebrating her death. And there's no obvious way to stop</span> <span data-start="650.52" data-end="659">it. Eric calls on us to increase awareness of and consideration of the failure modes,</span> <span data-start="659" data-end="664.72">the educations, the worst case scenarios, and I hope that we can do some of that today</span> <span data-start="664.72" data-end="669.49">and that you're going to carry it forward to others W that in mind hear's my first recommendation</span> <span data-start="669.49" data-end="679.31">for all of us to think about. Be humble. We cannot actually Intuit inner state, emotions,</span> <span data-start="679.31" data-end="693.23">private subjectivity. Not yet. Any way. (Scenario) when fitbit started out, it had a sex tracker.</span> </p>
<p><span data-start="693.23" data-end="698.18">You know, quantified self, let's quantified everything, it counts as exercise. Right.</span> <span data-start="698.18" data-end="714.65">There was a wrinkle, the wrinkle was that it defaulted to public. (Laughing) you all</span> <span data-start="714.65" data-end="723.53">want a fitbit now don't you?! All right, so first of all I appreciate the vigorous effort.</span> <span data-start="723.53" data-end="730.07">(Laughing) secondly, I also am a certified sex educator and I'm look oing at the four</span> <span data-start="730.07" data-end="742.73">hours and I just tonight know whether to congratulate or be concerned. (Laughing) fitbit users were</span> <span data-start="742.73" data-end="747.01">unwitting libraries sharing details of their sex lives with the whole world, it was on</span> <span data-start="747.01" data-end="753.9">Google. That's because it was set public by default. And this is one of the things that</span> <span data-start="753.9" data-end="759.31">we have to be thinking about an algorithm is not just about crunching numbers our patterns,</span> <span data-start="759.31" data-end="766.3">prepredictable reproducible actions, this was really unthinking decision to not evaluate</span> <span data-start="766.3" data-end="771.351">how different data sets might be differently treated, differently considered. Different</span> <span data-start="771.351" data-end="775.3">amounts of privacy in our lives just because you want to share with all your friends your</span> <span data-start="775.3" data-end="780.59">competition over how many steps you've taken or how many runs you've done doesn't mean</span> <span data-start="780.59" data-end="782.726">that everything in your life is meant to be a public DOM petition as well. This was\h‑‑</span> <span data-start="782.726" data-end="796.79">public competition as this was a algorithm for UX it was really a fail here. Most of</span> <span data-start="796.79" data-end="804.96">us use internal opt tools, it's mandatory right. Performance tuning, business metrics,</span> <span data-start="804.96" data-end="810.64">a lot of something, Uber is called God view. If you're a gamer you're already suspecting</span> <span data-start="810.64" data-end="817.15">what this implies. Uber did not limit access to admins and not restrict it to operational</span> <span data-start="817.15" data-end="823.06">use alone, workers could freely identify had any passenger and monitor the person's movements</span> <span data-start="823.06" data-end="831.88">even drivers were welcome to Bruce through Ubers customer trip records. Meanwhile managers</span> <span data-start="831.88" data-end="837.93">felt free to abuse God view for non‑operational purposes such as stocking celebrity ride in</span> <span data-start="837.93" data-end="844.19">real‑time showing it as party entertainment. To is show you how horrifying God view is,</span> <span data-start="844.19" data-end="856.76">here's code expert. This is so nobly inappropriate. mean, seriously. Auto play true? Okay. And</span> <span data-start="856.76" data-end="861.25">then of course there's the other choice. Background image, that's pretty telling as well as to</span> <span data-start="861.25" data-end="867.66">what their intent was for this. The research group at dating site okay cupid used to Blog</span> <span data-start="867.66" data-end="874.05">all the time things they were learning about aggregating their data and Blog showing insights</span> <span data-start="874.05" data-end="880.94">into simple ways that okay cupid users could use that data site well to date better. Uber</span> <span data-start="880.94" data-end="886.64">used to Blog about its day to too. There's a critical difference in that Uber's approach</span> <span data-start="886.64" data-end="893.88">to it was not about improving customers' experience of a ride service, it was about invading people's</span> <span data-start="893.88" data-end="899.99">privacy for the sake of judging and shaming and stalking them. These are not predictable</span> <span data-start="899.99" data-end="908.82">consequences of signing up for an account to take a ride. Galling add words is an interesting</span> <span data-start="908.82" data-end="915.33">study done at Harvard a few years ago, what they did was took two sets of names, one that</span> <span data-start="915.33" data-end="920.151">is strongly correlated with black people and one that's correlated with white people. So</span> <span data-start="920.151" data-end="924.581">for instance first name like Latonya would be something that's highly correlated lated</span> <span data-start="924.581" data-end="931.07">with black women and something like Jill would be highly correlated with a white woman. And</span> <span data-start="931.07" data-end="934.85">then what they did was they matched up the first names a with the real last names of</span> <span data-start="934.85" data-end="941.83">professors and did some searches on add words for those names. And what they found is that</span> <span data-start="941.83" data-end="948.2">a black identifying name was 25\hpercent more likely to result in the an add that implied</span> <span data-start="948.2" data-end="958.36">that that person had an arrest record. So for example adds like these. And I think it's</span> <span data-start="958.36" data-end="964.22">important to note here, Ad word algorithm is focused on predicting what we'll click</span> <span data-start="964.22" data-end="971.23">on. That's it. It's not interested in whether anyone was arrested. That's not it's point,</span> <span data-start="971.23" data-end="976.64">the real world isn't important. It's whole job is to figure out what motivates us to</span> <span data-start="976.64" data-end="982.61">click. Which Ad template we're going to respond to. Based on what it knows about us individually</span> <span data-start="982.61" data-end="988.149">and collectively what it knows about other users before us, what we're see inning these</span> </p>
<p><span data-start="988.149" data-end="995.37">Ads is our collective bias at work and being reflected back to us and then being reinforced</span> <span data-start="995.37" data-end="1002">every time it's presented again and we click on it again. This is a feedback loop. Data</span> <span data-start="1002" data-end="1008.75">is generated by people. It's not objective. It's constrained by our tunnel vision it replicates</span> <span data-start="1008.75" data-end="1023.08">our flaws, it echos our preconceptions. Image recognition is hard. And you remember it wasn't</span> <span data-start="1023.08" data-end="1032.089">so long ago we had things like this. (Laughing) I photo helpfully helpfully detecting faces</span> <span data-start="1032.089" data-end="1039.659">in baked goods. It's funny, sure. It's a harmless mistake, it's a false positive that's easy</span> <span data-start="1039.659" data-end="1046.1">to chuckle at. Some are less funny, such as in this next photo. Flicker classified it</span> <span data-start="1046.1" data-end="1053.58">as essentially children's playground equipment. For those who are not familiar that's ash</span> <span data-start="1053.58" data-end="1065.38">wits. This was in May\h‑‑\h‑‑ a month later Google photos mistagged this person</span> <span data-start="1065.38" data-end="1075.34">as an animal. Sorry that was actually flicker again, apologize, it also tagged him as an</span> <span data-start="1075.34" data-end="1082.059">ape. Google photos a month after that tagged someone as a gorilla. You'll notice a common</span> <span data-start="1082.059" data-end="1089.18">theme here, black skin. How does that happen? Well, maybe some of it is just like those</span> <span data-start="1089.18" data-end="1094.721">Ad words our bias being reflected back, there's also other answers for one of those you're</span> <span data-start="1094.721" data-end="1103.56">going to have go all the way back to the 1950s when color film stock was first being developed,</span> <span data-start="1103.56" data-end="1110.83">created it was optimized for white skin to get as much detame out of white skin as possible.</span> </p>
<p><span data-start="1110.83" data-end="1117.19">And for decades labs were given these, they were scall called Shirly cards they were used</span> <span data-start="1117.19" data-end="1125.4">to calibrate developers to make sure they were accurately producing details and colors,</span> <span data-start="1125.4" data-end="1131.08">for decades every film stock was designed to optimize for white skin and to ignore black</span> <span data-start="1131.08" data-end="1137.52">skin. And black skin, to this day still has a very hard time getting a nice accurate well</span> <span data-start="1137.52" data-end="1143.42">exposed photo. When we started moving to digital sensors the obvious thing to do is to replicate</span> <span data-start="1143.42" data-end="1151.059">the experience people were already having. If we have sensors that are radically different</span> <span data-start="1151.059" data-end="1156.79">we would all complain about how terrible and faulty our cameras were. What we have here</span> <span data-start="1156.79" data-end="1165.42">is repeatuation is racial an mouse from thed 50s, we have decades of the data sets that</span> <span data-start="1165.42" data-end="1171.35">are contaminated with noise. And so when we have these kind of misclassifications it's</span> <span data-start="1171.35" data-end="1177.651">easy to look at it and say, Hmm mistake or Hmm racism. It goes deeper than that, these</span> <span data-start="1177.651" data-end="1182.39">are hard problems to solve, Big Data if we throw enough data at it any problem can be</span> <span data-start="1182.39" data-end="1185.78">corrected is what we think. Where are you going to find the data that is an easy corrector</span> <span data-start="1185.78" data-end="1198.75">for this? A firm is a rather unusual credit lending company. They focus on lending for</span> <span data-start="1198.75" data-end="1205.1">certain small consumer purchases and make a rather interesting set of criteria, the</span> <span data-start="1205.1" data-end="1210.05">basis for lending. Essentially just provide a few thing, name, e‑mail, mobile phone</span> <span data-start="1210.05" data-end="1216.41">number, birthday and last four digit of identification number and then from there it starts evaluating</span> <span data-start="1216.41" data-end="1221.52">behavioral factors even were you given that much. Things like how long you take to fill</span> <span data-start="1221.52" data-end="1226.88">in that little form. What time\h‑‑ how much time it takes you to remember stuff.</span> </p>
<p><span data-start="1226.88" data-end="1230.26">And then if it needs more information it goes out and looks at your social accounts including</span> <span data-start="1230.26" data-end="1238.31">GitHub. Which is already starting to replicate privilege in the real world because only 2\hpercent</span> <span data-start="1238.31" data-end="1242.84">of women\h‑‑ sorry only 2\hpercent of Open Source cent toes are women. So that means</span> <span data-start="1242.84" data-end="1248.84">GitHub is inevitably going to be biased towards finding men, and if you're making the criteria</span> <span data-start="1248.84" data-end="1254.32">for lending participation on a site like GitHub automatically it's always going to be biased</span> <span data-start="1254.32" data-end="1260.41">against a lot of women. Think about how much time it takes to remember something. Who might</span> <span data-start="1260.41" data-end="1267.54">need more time? Someone with, say a cognitive processing disorder. Someone who's older.</span> <span data-start="1267.54" data-end="1275.39">All sorts of biases built into the supposedly objective algorithm. UK researchers my shopping</span> <span data-start="1275.39" data-end="1282.12">cart abandonment rate is high because my toddler grabs my visa card and runs off screaming,</span> <span data-start="1282.12" data-end="1288.02">mine, mine, mine. All right, sometimes it's not that we're inattentive because we somehow</span> <span data-start="1288.02" data-end="1293.39">are a bad credit risk, sometimes we're inattentive because other things distract us. This is</span> <span data-start="1293.39" data-end="1298.54">a person who's clock is invisibly ticking and losing opportunities that are financial</span> <span data-start="1298.54" data-end="1304.79">as a result of it. A firm analyzes those social media accounts, they're not the only one,</span> <span data-start="1304.79" data-end="1309.68">there are a number of other companies using similar models. In 2012, in fact Germany's</span> <span data-start="1309.68" data-end="1318.929">biggest credit rating agency considered evaluating Facebook relationships. More recently Facebook</span> <span data-start="1318.929" data-end="1325.02">pushes further down that line making credit decisions about you based on the unrelated</span> <span data-start="1325.02" data-end="1337.34">credit history of your Facebook friends. Okay. What? So are they unaware that friends doesn't</span> <span data-start="1337.34" data-end="1344.99">equal Facebook friend? Like we got to tell Facebook about this. Here's an algorithm with</span> <span data-start="1344.99" data-end="1351.01">potential to deeply intrude on and alter personal relationships. To just to prevent that algorithm</span> <span data-start="1351.01" data-end="1359.91">from financially shaming and pun ishing them. This is a huge consequence. Data is not objective.</span> </p>
<p><span data-start="1359.91" data-end="1367.95">It always has bias, it's inherent at minimum from how it was collected and interpreted.</span> <span data-start="1367.95" data-end="1376.25">A firm says that it's algorithm uses 70,000 factors to reach it's conclusions. They say</span> <span data-start="1376.25" data-end="1380.62">they don't even know what all of them are. All right, so how do we know how many have</span> <span data-start="1380.62" data-end="1385.3">potential for discriminatory outcomes then. How would anyone of them now. If thaw don't</span> <span data-start="1385.3" data-end="1393.03">know how would the consumer do anything about mistakes? Forget about bias, just simple error.</span> <span data-start="1393.03" data-end="1398.841">Rationals for the algorithm can only be seen from inside that black box. So let's take</span> <span data-start="1398.841" data-end="1409.78">a look at it. I took a photo from inside a really, really black box. (Laughing) that's</span> <span data-start="1409.78" data-end="1415.95">what we can see. Making lending desessions inside a black box isn't a radical new business</span> <span data-start="1415.95" data-end="1424.65">model, it's a regression. What is disrupting is oversight and regulation. Right now we're</span> <span data-start="1424.65" data-end="1433.559">in an arms race. Facebook, Google, happening, Microsoft, Yahoo. Baidu, IBM, AT&T Twitter,</span> <span data-start="1433.559" data-end="1439.43">so many companies are making big bets on deep learning, some are already deploying, for</span> <span data-start="1439.43" data-end="1445.94">the moment, quality varies but we have to remember that deep learning is all about iteratively</span> <span data-start="1445.94" data-end="1453.91">drawing intuitions at extremely fine grained levels. And what that means is that they're</span> <span data-start="1453.91" data-end="1458.73">continuously getting more precise in their correctness but also more damaging in their</span> <span data-start="1458.73" data-end="1465.12">wrongness. And that's a dilemma that we have to take seriously as developers. Because underlying</span> <span data-start="1465.12" data-end="1471.37">actions, influence, outcomes and influence consequences. They have underlying assumptions</span> <span data-start="1471.37" data-end="1476.66">about meaning, about accuracy, about the world in which data has been generated, about how</span> <span data-start="1476.66" data-end="1487.21">code should assign meaning to to data. We care about getting this stuff right (To Data)</span> <span data-start="1487.21" data-end="1492.86">the question is how do we flip the paradigm? Well, we can do a few things like taking some</span> <span data-start="1492.86" data-end="1498.2">lessons from professional ethicists because it turns out that's a thing. It turns out</span> <span data-start="1498.2" data-end="1503.44">our profession has professional ethicists, who knew. These are a few that I've adapted</span> <span data-start="1503.44" data-end="1510.28">from the association from computer machinery and a few other sources. We need to consider</span> <span data-start="1510.28" data-end="1517.049">decisions impact, potential impacts on others. For instance how might a false positive affect</span> <span data-start="1517.049" data-end="1523.08">someone, like those shutterfly customers, how might a false negative affect someone,</span> <span data-start="1523.08" data-end="1527.63">have we built in resource for someone to easily get our conclusions corrected when we're wrong</span> <span data-start="1527.63" data-end="1534.19">about them. We need to be able to project the likelihood of consequences to others and</span> <span data-start="1534.19" data-end="1540.03">to minimize negative consequences to others, and yes, I keep hammering on two others, we're</span> <span data-start="1540.03" data-end="1545.73">pretty good at taking care of ourselves. We have to be honest and trustworthy. Not just</span> <span data-start="1545.73" data-end="1548.69">because those are the right things to do, but because we need to be able to lean on</span> <span data-start="1548.69" data-end="1553.95">it when we make mistakes, we need to be able to buyback trust because we've earn it, because</span> <span data-start="1553.95" data-end="1559.84">we can say maya cull pa without that destroying us. We need to provide others with the full</span> <span data-start="1559.84" data-end="1566.4">disclosure of limitations and call attention to signs of risk of harm to them. And here's</span> <span data-start="1566.4" data-end="1572.309">a big one, we have to be visionary about counterrerring bias, we have to be visionaries about creating</span> <span data-start="1572.309" data-end="1580.581">more than one way to counteract it. To counteract bias data, bias analysis, bias impacts. And</span> <span data-start="1580.581" data-end="1587.74">here's the really big one. We have to be able to anticipate diverse ways to screw up. When</span> <span data-start="1587.74" data-end="1593.51">teams are charged with defining data collections use and anal circumstance any time those are</span> <span data-start="1593.51" data-end="1597.85">less diverse than the intended user base, we're going to keep on failing them, just</span> <span data-start="1597.85" data-end="1607.12">like this. We have to have decision making authority in the hands of highly diverse teams,</span> <span data-start="1607.12" data-end="1614.17">highly. What does that mean? Culture fit is the antithesis of diversity, it's superficial</span> <span data-start="1614.17" data-end="1620.12">variations being allowed to exist as long as their unique perspective is sure pressed</span> <span data-start="1620.12" data-end="1627.8">the purpose of culture fit is to avoid disruption of group think. UniI did mixal variety is</span> <span data-start="1627.8" data-end="1635.2">not diversity either. Diversity is widely varied on as many areas as possible. Different</span> <span data-start="1635.2" data-end="1641.88">assumptions, different experiences, until you get to the point where there's no such</span> <span data-start="1641.88" data-end="1650.05">thing as a majority you can't find it. We need to cultivate, inform consent. What that</span> <span data-start="1650.05" data-end="1655.82">means is we ask for permission with the default being no and explain the consequences of a</span> <span data-start="1655.82" data-end="1660.9">yes. Focus on the many people that eerily want to share themselves and enthusiastically</span> <span data-start="1660.9" data-end="1669.429">give consent and want to be served better by that. And we have the audit outcomes constantly,</span> <span data-start="1669.429" data-end="1673.76">the reason is going back to the black box, if we can't be sure what's happening inside</span> <span data-start="1673.76" data-end="1679.92">of it. We need to be able to look at the outcomes. This is used a lot in checking for housing</span> <span data-start="1679.92" data-end="1684.41">discrimination and job discrimination. So you put in two inputs that are exactly the</span> <span data-start="1684.41" data-end="1690.08">same on every criteria but one. One that should not have any bias introduced and if the outcome</span> <span data-start="1690.08" data-end="1695.57">on those divers at all, we know we have an problem with the algorithm. So this is something</span> <span data-start="1695.57" data-end="1699.29">we constantly have to be looking for. For instance when Google photos made that mistake</span> <span data-start="1699.29" data-end="1704.63">with classifying people as gorillas, as soon as they saw that problem on flicker a month</span> <span data-start="1704.63" data-end="1717.35">earlier they should of been dog auditing, do we have a the same problem? And why? Because</span> <span data-start="1717.35" data-end="1726.73">photo of a big black box. And that's why we also have to commit to data transparency and</span> <span data-start="1726.73" data-end="1733.87">algorithmic transparency. And I do mean both because I recognize that these are hard decisions</span> <span data-start="1733.87" data-end="1738.94">to have internally. They truly are. But I also think that, you know, it wasn't that</span> <span data-start="1738.94" data-end="1743.46">long ago that we were fighting for legitimacy of Open Source in our professional Toolkit.</span> </p>
<p><span data-start="1743.46" data-end="1749.82">We push back, we were right, we're profession falls, we won because we know what we're doing</span> <span data-start="1749.82" data-end="1754.91">and we made a good argument. We know that transparency is crucial for drawing insights</span> <span data-start="1754.91" data-end="1759.97">that are general when and useful. So argue for increasing transparency because it's for</span> <span data-start="1759.97" data-end="1767.3">a better product. Cleaner features, fewer bugs stronger tests happier users public trust.</span> <span data-start="1767.3" data-end="1774.1">That's the argument. Because we want to build stuff that matters. We're hired for more than</span> <span data-start="1774.1" data-end="1779.72">just to write code, we're hired as professionals that apply expertise and judgment about how</span> <span data-start="1779.72" data-end="1785.15">to solve problems. That's who we really are. We're not code monkeys, we're people that</span> <span data-start="1785.15" data-end="1789.61">think about how to solve problems. Our role is to be opinionuated about how to make code</span> <span data-start="1789.61" data-end="1796.64">serve the problemtion based well. We can advocate. When we're asked to write code that presumed</span> <span data-start="1796.64" data-end="1801.95">to Intuit people as internal life and act on those assumptions as professionals we have</span> <span data-start="1801.95" data-end="1808.15">to be people's proxies, we have to be their advocates, say no on their behalf to using</span> <span data-start="1808.15" data-end="1815.28">their data in ways that they have not enthusiastically and knowingly consented to. Saying no to uncritically</span> <span data-start="1815.28" data-end="1821.47">reproducing systems that were based to begin with. Say no to writing code that imposes</span> <span data-start="1821.47" data-end="1830.43">on authorized consequences on to their lives. In short, refuse to play along. Thank you.</span> </p>
</section>