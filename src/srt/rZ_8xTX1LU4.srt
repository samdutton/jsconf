1
00:00:19,000 --> 00:00:23,090

gosh James talk was so funny it's like

2
00:00:23,090 --> 00:00:25,460
following up Adele and the crew could

3
00:00:25,460 --> 00:00:28,430
borrow something all right um so thanks

4
00:00:28,430 --> 00:00:29,900
for your interest and i'll be talking

5
00:00:29,900 --> 00:00:32,239
about neural networks today how they

6
00:00:32,239 --> 00:00:33,860
work how you can implement in your

7
00:00:33,860 --> 00:00:36,800
network yourself and hopefully also how

8
00:00:36,800 --> 00:00:40,280
you can improve your algorithm so this

9
00:00:40,280 --> 00:00:42,620
is me you can follow me on twitter and

10
00:00:42,620 --> 00:00:45,500
github on google+ although i'm like

11
00:00:45,500 --> 00:00:47,840
rarely on there but it's always nice if

12
00:00:47,840 --> 00:00:51,050
someone still on google+ so yeah i'm a

13
00:00:51,050 --> 00:00:52,880
web developer by day and I basically

14
00:00:52,880 --> 00:00:56,329
turned machine learning enthusiast after

15
00:00:56,329 --> 00:00:59,470
i attended the AI course by and room

16
00:00:59,470 --> 00:01:01,489
that was the one that actually started

17
00:01:01,489 --> 00:01:05,000
Kucera and afterwards i wanted to like

18
00:01:05,000 --> 00:01:07,310
use my new skills for a hands-on project

19
00:01:07,310 --> 00:01:10,070
and at this time I was in a betting pool

20
00:01:10,070 --> 00:01:13,310
in the office for the football league in

21
00:01:13,310 --> 00:01:15,740
Germany and like every week you have to

22
00:01:15,740 --> 00:01:18,290
come up with new predictions and usually

23
00:01:18,290 --> 00:01:19,670
if you're interested in football you

24
00:01:19,670 --> 00:01:21,799
don't you're not very objective about

25
00:01:21,799 --> 00:01:25,100
like teams and so it's you're not using

26
00:01:25,100 --> 00:01:27,620
the scientific method basically so what

27
00:01:27,620 --> 00:01:29,150
I was thinking was that would be a

28
00:01:29,150 --> 00:01:32,330
perfect use case to implement something

29
00:01:32,330 --> 00:01:35,530
like a soccer match tendency predictor I

30
00:01:35,530 --> 00:01:38,540
will show you what i was thinking and

31
00:01:38,540 --> 00:01:41,900
what I meant by that so um let's start

32
00:01:41,900 --> 00:01:44,570
with a funny quote and this one's by

33
00:01:44,570 --> 00:01:46,729
paul gascoigne and he's also known as

34
00:01:46,729 --> 00:01:48,950
gaza he's a famous English football

35
00:01:48,950 --> 00:01:52,490
player and he famously said that I never

36
00:01:52,490 --> 00:01:55,310
predict anything and I never will so

37
00:01:55,310 --> 00:01:59,270
following his lead i will also predict

38
00:01:59,270 --> 00:02:01,159
something i will predict the tendencies

39
00:02:01,159 --> 00:02:02,750
of the mattress for the Premier League

40
00:02:02,750 --> 00:02:05,810
this weekend I think they will start at

41
00:02:05,810 --> 00:02:09,200
like 9pm and then you can just check for

42
00:02:09,200 --> 00:02:10,519
yourself how well the algorithm actually

43
00:02:10,519 --> 00:02:13,040
performs and whether you want to bet

44
00:02:13,040 --> 00:02:14,420
money on it

45
00:02:14,420 --> 00:02:17,970
so um first of all we have to ask

46
00:02:17,970 --> 00:02:20,370
yourself like what is machine learning

47
00:02:20,370 --> 00:02:22,790
like why would we use machine learning

48
00:02:22,790 --> 00:02:26,280
so like consider we were like the

49
00:02:26,280 --> 00:02:30,300
programmers of an AI in like an RPG game

50
00:02:30,300 --> 00:02:33,450
and this blue sword would represent a

51
00:02:33,450 --> 00:02:35,940
player's action so the player would

52
00:02:35,940 --> 00:02:38,520
attack us and then we will maybe react

53
00:02:38,520 --> 00:02:40,290
with the defense action with a blocking

54
00:02:40,290 --> 00:02:43,320
action so you could have some kind of

55
00:02:43,320 --> 00:02:45,390
behavior tree where based on your leg

56
00:02:45,390 --> 00:02:48,030
remaining health points you would also

57
00:02:48,030 --> 00:02:49,770
have the option to launch a

58
00:02:49,770 --> 00:02:52,140
counter-attack or maybe you want to

59
00:02:52,140 --> 00:02:55,140
drink a potion so the problem is and

60
00:02:55,140 --> 00:02:56,970
when you have to cite the appropriate

61
00:02:56,970 --> 00:02:59,790
actions and that's you will decided when

62
00:02:59,790 --> 00:03:02,430
you program this tree so the the inputs

63
00:03:02,430 --> 00:03:04,680
and the weights so how important is the

64
00:03:04,680 --> 00:03:06,209
health in proportion through the play

65
00:03:06,209 --> 00:03:09,270
action for example its deterministic

66
00:03:09,270 --> 00:03:11,390
because you decide on it beforehand and

67
00:03:11,390 --> 00:03:13,709
this also means that the decision making

68
00:03:13,709 --> 00:03:16,380
process is very subjective because it's

69
00:03:16,380 --> 00:03:17,940
implemented by a program or a game

70
00:03:17,940 --> 00:03:21,269
designer and the machine cannot adapt to

71
00:03:21,269 --> 00:03:23,340
individual players does it doesn't it

72
00:03:23,340 --> 00:03:27,180
doesn't learn and let's say if we wanted

73
00:03:27,180 --> 00:03:29,100
to implement this in a deterministic way

74
00:03:29,100 --> 00:03:32,220
might look something like this so if the

75
00:03:32,220 --> 00:03:34,590
player attacks we look at our health bar

76
00:03:34,590 --> 00:03:37,950
and then we say at the health bar like

77
00:03:37,950 --> 00:03:40,530
above 75 percent then we do a

78
00:03:40,530 --> 00:03:42,870
counter-attack if it's between 25 and

79
00:03:42,870 --> 00:03:45,120
seventy-five percent we do a defense

80
00:03:45,120 --> 00:03:47,430
action and we have less than twenty-five

81
00:03:47,430 --> 00:03:49,050
percent of our house left and we will

82
00:03:49,050 --> 00:03:52,350
drink or health potion so these

83
00:03:52,350 --> 00:03:56,190
thresholds they have to be chosen

84
00:03:56,190 --> 00:03:58,310
beforehand and they might seem arbitrary

85
00:03:58,310 --> 00:04:01,350
or like it's like a personal feeling

86
00:04:01,350 --> 00:04:03,780
that what makes sense but in complex

87
00:04:03,780 --> 00:04:05,940
games and it might not be possible to

88
00:04:05,940 --> 00:04:07,680
manually implement all the possibilities

89
00:04:07,680 --> 00:04:09,900
and all the things you want to look at

90
00:04:09,900 --> 00:04:13,910
so we would not want to have this like

91
00:04:13,910 --> 00:04:16,830
the sturdy monistic logic instead we

92
00:04:16,830 --> 00:04:18,660
want to have something that will change

93
00:04:18,660 --> 00:04:21,060
or logic depending on something else

94
00:04:21,060 --> 00:04:23,669
maybe so this entire thing should be

95
00:04:23,669 --> 00:04:25,920
very dynamic

96
00:04:25,920 --> 00:04:29,550
so um the way that you can do this is

97
00:04:29,550 --> 00:04:32,070
with calculus and I'm trying to not go

98
00:04:32,070 --> 00:04:34,020
too deep into math because I'm like

99
00:04:34,020 --> 00:04:36,120
don't have the time for it but let's

100
00:04:36,120 --> 00:04:38,490
just take the scenario that we have the

101
00:04:38,490 --> 00:04:41,790
what the user did input and then we add

102
00:04:41,790 --> 00:04:45,090
the how healthy we are input and then we

103
00:04:45,090 --> 00:04:48,030
will get something that pertains to the

104
00:04:48,030 --> 00:04:51,450
three possible outputs of course like

105
00:04:51,450 --> 00:04:53,370
the two inputs are not equally important

106
00:04:53,370 --> 00:04:55,680
for decision-making so what we need here

107
00:04:55,680 --> 00:04:59,220
is some weights and in this case I just

108
00:04:59,220 --> 00:05:01,470
called them a and B and basically those

109
00:05:01,470 --> 00:05:03,510
weights determine how important those

110
00:05:03,510 --> 00:05:05,840
inputs are in relation to each other and

111
00:05:05,840 --> 00:05:08,760
then in the end we don't want to

112
00:05:08,760 --> 00:05:10,860
directly have like the action that we

113
00:05:10,860 --> 00:05:12,480
want to take instead we want to have

114
00:05:12,480 --> 00:05:15,180
like a probability distribution this

115
00:05:15,180 --> 00:05:17,310
could for example just be like what's

116
00:05:17,310 --> 00:05:19,290
the most probable action that a human

117
00:05:19,290 --> 00:05:22,770
player would take for example and this

118
00:05:22,770 --> 00:05:24,690
way it's called classification because

119
00:05:24,690 --> 00:05:29,610
we try to classify the correct output

120
00:05:29,610 --> 00:05:33,210
for the given inputs and once we have

121
00:05:33,210 --> 00:05:35,520
the correct weights like if we can

122
00:05:35,520 --> 00:05:37,350
calculate the best a and the best be

123
00:05:37,350 --> 00:05:40,380
then we have a model that represents the

124
00:05:40,380 --> 00:05:41,970
logic or the pattern that we want to

125
00:05:41,970 --> 00:05:45,000
make predictions on and the thing about

126
00:05:45,000 --> 00:05:48,300
models is like Georgie keybox said that

127
00:05:48,300 --> 00:05:50,820
all models are wrong but some are useful

128
00:05:50,820 --> 00:05:53,190
and what he means by that is basically

129
00:05:53,190 --> 00:05:56,310
that our model will not give us the

130
00:05:56,310 --> 00:05:59,070
perfect or the correct result but they

131
00:05:59,070 --> 00:06:00,510
will give us one that is the best

132
00:06:00,510 --> 00:06:04,020
approximation to reality basically or to

133
00:06:04,020 --> 00:06:06,740
the data that we already collected and

134
00:06:06,740 --> 00:06:10,500
so this is basically the magic inside a

135
00:06:10,500 --> 00:06:12,900
node but it's not called neural node

136
00:06:12,900 --> 00:06:15,570
it's called neural networks so we have

137
00:06:15,570 --> 00:06:17,250
to like understand what neural networks

138
00:06:17,250 --> 00:06:21,240
are and so the important question to

139
00:06:21,240 --> 00:06:23,490
answer is how does anything learn and

140
00:06:23,490 --> 00:06:25,950
some type of people and took a look at

141
00:06:25,950 --> 00:06:27,750
it like how learning is done in nature

142
00:06:27,750 --> 00:06:31,260
and as you already know probably it's

143
00:06:31,260 --> 00:06:33,240
done by neurons and this would be one

144
00:06:33,240 --> 00:06:34,370
neuron

145
00:06:34,370 --> 00:06:36,620
neuron receives input through its

146
00:06:36,620 --> 00:06:38,419
dendrites that's a fuzzy purple

147
00:06:38,419 --> 00:06:41,210
attentively stuff and then there it has

148
00:06:41,210 --> 00:06:43,460
the soma which is the middle part with

149
00:06:43,460 --> 00:06:45,710
the green coordinate and inside the soma

150
00:06:45,710 --> 00:06:48,620
there's magic happening and the input

151
00:06:48,620 --> 00:06:50,360
gets changed in a deterministic way

152
00:06:50,360 --> 00:06:53,270
inside the soma and then the result of

153
00:06:53,270 --> 00:06:56,360
it is sent through the axon terminals

154
00:06:56,360 --> 00:06:59,990
and in nature of course a decision in

155
00:06:59,990 --> 00:07:01,699
your brain is not made by one single

156
00:07:01,699 --> 00:07:03,889
neuron but by a vast network of neurons

157
00:07:03,889 --> 00:07:06,500
so we can have multiple layers of

158
00:07:06,500 --> 00:07:09,289
neurons in this case for example we have

159
00:07:09,289 --> 00:07:12,590
two layers with two and three neurons so

160
00:07:12,590 --> 00:07:14,630
in all output from the previous layer

161
00:07:14,630 --> 00:07:17,060
will be sent to all nodes in the next

162
00:07:17,060 --> 00:07:20,180
layer so in the end every node will

163
00:07:20,180 --> 00:07:23,350
output a value pertaining to one singer

164
00:07:23,350 --> 00:07:26,150
like one single possibility that you can

165
00:07:26,150 --> 00:07:30,139
take and the thing to take away from the

166
00:07:30,139 --> 00:07:32,419
slide basically is that instead of one

167
00:07:32,419 --> 00:07:35,240
neuron doing the magic ones you have

168
00:07:35,240 --> 00:07:37,580
multiple neurons that do it in parallel

169
00:07:37,580 --> 00:07:41,330
and also sequentially so even though

170
00:07:41,330 --> 00:07:43,130
each neuron changes values

171
00:07:43,130 --> 00:07:45,680
deterministically the whole thing is not

172
00:07:45,680 --> 00:07:49,820
deterministic okay so this is basically

173
00:07:49,820 --> 00:07:51,770
the same representation that we saw

174
00:07:51,770 --> 00:07:55,940
before except now i just changed in the

175
00:07:55,940 --> 00:07:57,650
natural neurons with artificial neurons

176
00:07:57,650 --> 00:08:01,729
and so for the for the math to work its

177
00:08:01,729 --> 00:08:04,250
magic we need numerical representations

178
00:08:04,250 --> 00:08:06,919
of our inputs and outputs so for example

179
00:08:06,919 --> 00:08:08,900
we can represent a health bar in a

180
00:08:08,900 --> 00:08:10,639
percentage which would be ninety-five

181
00:08:10,639 --> 00:08:14,120
percent in this case but so I personally

182
00:08:14,120 --> 00:08:16,460
think it's better to have like the most

183
00:08:16,460 --> 00:08:18,710
information possible so instead of

184
00:08:18,710 --> 00:08:20,930
saying this we have ninety-five percent

185
00:08:20,930 --> 00:08:22,729
over health left we could say that our

186
00:08:22,729 --> 00:08:24,919
maximum health or your current health is

187
00:08:24,919 --> 00:08:28,910
114 and the maximum help is 120 and by

188
00:08:28,910 --> 00:08:32,779
that or algorithm can deduce that it's

189
00:08:32,779 --> 00:08:36,219
ninety-five percent and have left and

190
00:08:36,219 --> 00:08:40,159
then we have the attack so the attack

191
00:08:40,159 --> 00:08:43,099
isn't it could be a string or label but

192
00:08:43,099 --> 00:08:45,900
in this case our neural network

193
00:08:45,900 --> 00:08:48,150
needs a numerical value so it can

194
00:08:48,150 --> 00:08:51,360
calculate on it and we could just give

195
00:08:51,360 --> 00:08:53,310
it like an ID and then just map it

196
00:08:53,310 --> 00:08:56,100
somewhere and but I didn't really like

197
00:08:56,100 --> 00:08:58,920
that idea because I was afraid M that I

198
00:08:58,920 --> 00:09:00,420
would introduce some numerical

199
00:09:00,420 --> 00:09:02,820
implications that I don't want to for

200
00:09:02,820 --> 00:09:05,460
example if attack is one and defense is

201
00:09:05,460 --> 00:09:07,890
to then somehow my neural network could

202
00:09:07,890 --> 00:09:10,290
think that the blocking action is like

203
00:09:10,290 --> 00:09:12,570
twice the attack action so this doesn't

204
00:09:12,570 --> 00:09:15,420
sound very smart one way to counter that

205
00:09:15,420 --> 00:09:18,660
is to instead use a vector or an area in

206
00:09:18,660 --> 00:09:22,320
the JavaScript context so by using this

207
00:09:22,320 --> 00:09:24,480
M airing I basically say that there are

208
00:09:24,480 --> 00:09:26,370
three possible actions that the user

209
00:09:26,370 --> 00:09:29,010
could take and he took the first one so

210
00:09:29,010 --> 00:09:30,930
basically that's like a like a bull

211
00:09:30,930 --> 00:09:34,680
array and so in this case the first

212
00:09:34,680 --> 00:09:36,360
value would be attack and the second

213
00:09:36,360 --> 00:09:37,890
would be defense and the third would be

214
00:09:37,890 --> 00:09:43,770
potion so how do we get our predictions

215
00:09:43,770 --> 00:09:48,030
and the first thing is I'm talking about

216
00:09:48,030 --> 00:09:50,850
is going to call is called forward

217
00:09:50,850 --> 00:09:53,370
propagation and it's called that because

218
00:09:53,370 --> 00:09:56,430
we propagate data for word from our

219
00:09:56,430 --> 00:10:00,180
input nodes to the output nodes so we

220
00:10:00,180 --> 00:10:02,460
start with our inputs that's the one

221
00:10:02,460 --> 00:10:04,800
you've seen before and then we send each

222
00:10:04,800 --> 00:10:08,310
input to each node in the first layer so

223
00:10:08,310 --> 00:10:10,380
let's focus on upper node so it's not so

224
00:10:10,380 --> 00:10:13,680
complicated and in this node we do our

225
00:10:13,680 --> 00:10:17,130
math magic so we have our weights and we

226
00:10:17,130 --> 00:10:19,560
multiply it with our inputs and then we

227
00:10:19,560 --> 00:10:23,850
get a new value which is X 11 because

228
00:10:23,850 --> 00:10:25,440
it's the value we get from the first

229
00:10:25,440 --> 00:10:27,840
node of the first layer and then we send

230
00:10:27,840 --> 00:10:29,900
that new value to the next nodes and

231
00:10:29,900 --> 00:10:33,090
then the lower note is the same thing

232
00:10:33,090 --> 00:10:36,690
and in the next layer all the nodes do

233
00:10:36,690 --> 00:10:38,460
exactly the same thing again of course

234
00:10:38,460 --> 00:10:40,770
the weights are different here I just

235
00:10:40,770 --> 00:10:43,680
call them D and E and then we get a

236
00:10:43,680 --> 00:10:46,770
value in the end so I just I just said

237
00:10:46,770 --> 00:10:51,030
that as 0.67 and because this would be

238
00:10:51,030 --> 00:10:54,150
like the probability of the

239
00:10:54,150 --> 00:10:56,040
action that is like directly linked to

240
00:10:56,040 --> 00:10:57,930
this node because like each output node

241
00:10:57,930 --> 00:11:04,020
is referring to one possible output okay

242
00:11:04,020 --> 00:11:07,590
so now we have basically made

243
00:11:07,590 --> 00:11:09,450
predictions from a training data but the

244
00:11:09,450 --> 00:11:12,540
prediction is not that good because in

245
00:11:12,540 --> 00:11:14,070
the first iteration which shoes are

246
00:11:14,070 --> 00:11:17,700
weights randomly and now we have to like

247
00:11:17,700 --> 00:11:19,890
the machine learns by trying to get

248
00:11:19,890 --> 00:11:24,450
better at predicting stuff and so my

249
00:11:24,450 --> 00:11:26,250
first instinct would be you could just

250
00:11:26,250 --> 00:11:27,900
reverse engineer right because you have

251
00:11:27,900 --> 00:11:30,420
the data and you know what's supposed to

252
00:11:30,420 --> 00:11:32,400
be the output and then you can just like

253
00:11:32,400 --> 00:11:34,650
reverse engineer and this is more or

254
00:11:34,650 --> 00:11:36,000
less basically what the machine also

255
00:11:36,000 --> 00:11:39,300
does this is called back propagation and

256
00:11:39,300 --> 00:11:41,160
might have guessed already it's because

257
00:11:41,160 --> 00:11:43,140
we propagate data back from the output

258
00:11:43,140 --> 00:11:46,380
nodes to the input nodes and let's say

259
00:11:46,380 --> 00:11:48,690
like these are our predictions this is

260
00:11:48,690 --> 00:11:50,520
the probability that like for example a

261
00:11:50,520 --> 00:11:52,320
human player would take this action with

262
00:11:52,320 --> 00:11:54,990
the given inputs and then this is the

263
00:11:54,990 --> 00:11:56,850
actual result this is like the truth

264
00:11:56,850 --> 00:11:59,370
that we know from our data set and then

265
00:11:59,370 --> 00:12:01,650
we need to figure out what the costs are

266
00:12:01,650 --> 00:12:03,900
and the costs are basically just the

267
00:12:03,900 --> 00:12:06,600
difference between the actual result and

268
00:12:06,600 --> 00:12:09,420
what we predicted so in this case it

269
00:12:09,420 --> 00:12:14,370
would be 0.33 0.14 and 0.19 respectively

270
00:12:14,370 --> 00:12:18,810
and now inside the nodes we do not try

271
00:12:18,810 --> 00:12:20,910
to get the right inputs instead we try

272
00:12:20,910 --> 00:12:22,950
to calculate how we would have to change

273
00:12:22,950 --> 00:12:25,950
the wave so the cost is lower next time

274
00:12:25,950 --> 00:12:28,560
like in the next iteration and I'm not

275
00:12:28,560 --> 00:12:30,210
going to go too deeply into that right

276
00:12:30,210 --> 00:12:32,550
now because like it's very mathematical

277
00:12:32,550 --> 00:12:35,940
and but after we've done that we will

278
00:12:35,940 --> 00:12:38,190
back propagate the values the first

279
00:12:38,190 --> 00:12:39,900
layer and we will do the same thing

280
00:12:39,900 --> 00:12:44,640
there okay and so one way that we

281
00:12:44,640 --> 00:12:47,100
calculate how to change the weights it's

282
00:12:47,100 --> 00:12:48,660
called like gradient descent there are

283
00:12:48,660 --> 00:12:50,670
other algorithms that you can use but in

284
00:12:50,670 --> 00:12:52,410
this case I want to show you I'm the way

285
00:12:52,410 --> 00:12:54,600
in descent because it's it's easy to

286
00:12:54,600 --> 00:12:57,510
explain in a graphical representation so

287
00:12:57,510 --> 00:13:02,700
um let's say our data is will be

288
00:13:02,700 --> 00:13:05,190
represented in this 3d am representation

289
00:13:05,190 --> 00:13:07,180
and we'll take a very simple

290
00:13:07,180 --> 00:13:09,190
example would like only two numerical

291
00:13:09,190 --> 00:13:11,290
features like only the max health and

292
00:13:11,290 --> 00:13:15,120
the current health and then we have our

293
00:13:15,120 --> 00:13:18,220
weights would so we do not plot the

294
00:13:18,220 --> 00:13:21,130
actual input data we plot the weights so

295
00:13:21,130 --> 00:13:24,970
that's a and B and then on the z axis we

296
00:13:24,970 --> 00:13:28,900
plot the cost and so the idea is that in

297
00:13:28,900 --> 00:13:32,380
the front you have high cost so the

298
00:13:32,380 --> 00:13:33,940
predictions that you make are very far

299
00:13:33,940 --> 00:13:36,460
from the actual reality and in the back

300
00:13:36,460 --> 00:13:39,250
we have low cost and the way we plot

301
00:13:39,250 --> 00:13:40,410
data in this three-dimensional

302
00:13:40,410 --> 00:13:43,210
representation is we have those circles

303
00:13:43,210 --> 00:13:45,550
the circle means that all the data

304
00:13:45,550 --> 00:13:48,190
points that are on the circle so all the

305
00:13:48,190 --> 00:13:49,870
combinations of a and B that are on the

306
00:13:49,870 --> 00:13:52,960
circle have the same cost and then you

307
00:13:52,960 --> 00:13:55,840
have different circles like this one and

308
00:13:55,840 --> 00:13:57,850
it's the same here like all the

309
00:13:57,850 --> 00:13:59,320
different data points on this circle

310
00:13:59,320 --> 00:14:01,720
have the same cost although this circle

311
00:14:01,720 --> 00:14:03,880
is a little bit darker and I made a

312
00:14:03,880 --> 00:14:04,960
darker because I wanted to represent

313
00:14:04,960 --> 00:14:08,020
that the cost is lower and so they all

314
00:14:08,020 --> 00:14:10,000
have the same cost on the circle but of

315
00:14:10,000 --> 00:14:12,940
course the differs from the from the

316
00:14:12,940 --> 00:14:15,610
previous circle and then we you know

317
00:14:15,610 --> 00:14:17,530
like further plot the data and then we

318
00:14:17,530 --> 00:14:19,150
get like this kind of funnel where you

319
00:14:19,150 --> 00:14:21,490
can just basically you look inside the

320
00:14:21,490 --> 00:14:24,790
funnel and in the middle that's our

321
00:14:24,790 --> 00:14:27,550
global minimum that's the point where

322
00:14:27,550 --> 00:14:29,470
the cost is the lowest that we can ever

323
00:14:29,470 --> 00:14:34,720
get with our with our algorithm so the

324
00:14:34,720 --> 00:14:36,400
way that gradient descent now tries to

325
00:14:36,400 --> 00:14:38,290
get there mathematically to the red dot

326
00:14:38,290 --> 00:14:40,690
is that we have start somewhere randomly

327
00:14:40,690 --> 00:14:42,070
like I said before we choose n be

328
00:14:42,070 --> 00:14:44,470
randomly and then basically great into

329
00:14:44,470 --> 00:14:48,520
the centers like walks steps towards the

330
00:14:48,520 --> 00:14:50,980
global minimum and just like one was

331
00:14:50,980 --> 00:14:53,200
around a little bit and just tries to

332
00:14:53,200 --> 00:14:55,000
try to approximate the global minimum

333
00:14:55,000 --> 00:14:58,420
and at some point hopefully it will get

334
00:14:58,420 --> 00:15:00,430
there doesn't really happen that often

335
00:15:00,430 --> 00:15:02,230
real life because we don't actually know

336
00:15:02,230 --> 00:15:04,060
what the global minimum is we can see it

337
00:15:04,060 --> 00:15:06,340
here because its graphical but if you

338
00:15:06,340 --> 00:15:08,350
have a mathematical represent you don't

339
00:15:08,350 --> 00:15:13,270
actually know and so the idea of this

340
00:15:13,270 --> 00:15:14,820
whole thing is like we iteratively

341
00:15:14,820 --> 00:15:17,970
approximate our model to the truth

342
00:15:17,970 --> 00:15:21,540
okay so i hope you still with me because

343
00:15:21,540 --> 00:15:24,899
this is gonna be a I'm not gonna go

344
00:15:24,899 --> 00:15:27,389
further into it because it's interesting

345
00:15:27,389 --> 00:15:29,579
to know how neural networks work but

346
00:15:29,579 --> 00:15:31,379
when you implement something you want to

347
00:15:31,379 --> 00:15:33,720
use a framework and not be bothered by

348
00:15:33,720 --> 00:15:36,930
all the mathematical stuff and so I'm

349
00:15:36,930 --> 00:15:40,980
gonna like introduce it another smart

350
00:15:40,980 --> 00:15:44,000
guy who said this longer quote thing and

351
00:15:44,000 --> 00:15:46,769
he says an approximate answers the right

352
00:15:46,769 --> 00:15:48,689
problems were the good deal more than an

353
00:15:48,689 --> 00:15:51,329
exact answer to approximate problem so

354
00:15:51,329 --> 00:15:52,769
basically the better you describe your

355
00:15:52,769 --> 00:15:54,959
problem the better your approximated

356
00:15:54,959 --> 00:15:56,639
answer will fill it even though it's not

357
00:15:56,639 --> 00:16:02,100
perfect so okay and let's implement

358
00:16:02,100 --> 00:16:04,470
something I will not do a live demo

359
00:16:04,470 --> 00:16:06,930
because I'm really scared and that's not

360
00:16:06,930 --> 00:16:10,019
gonna work and I have used a node.js

361
00:16:10,019 --> 00:16:12,060
library which is called synaptic and

362
00:16:12,060 --> 00:16:13,829
like I said it implements all the fun

363
00:16:13,829 --> 00:16:16,019
math stuff already and we just have to

364
00:16:16,019 --> 00:16:18,720
like build the application so these are

365
00:16:18,720 --> 00:16:21,449
22 lines of code and it's basically all

366
00:16:21,449 --> 00:16:23,370
you need to predict a tendency with

367
00:16:23,370 --> 00:16:25,079
their artificial network so we're not

368
00:16:25,079 --> 00:16:27,750
doing like AI anymore for RPGs now we're

369
00:16:27,750 --> 00:16:30,930
doing the prediction of soccer mattress

370
00:16:30,930 --> 00:16:34,319
so first we have this historic data with

371
00:16:34,319 --> 00:16:36,240
inputs in this case it's the market

372
00:16:36,240 --> 00:16:38,579
value of the two teams home team and

373
00:16:38,579 --> 00:16:41,339
away team and then the output represents

374
00:16:41,339 --> 00:16:43,980
the result so in this case the first

375
00:16:43,980 --> 00:16:46,139
element would be that the home team won

376
00:16:46,139 --> 00:16:47,879
the second element would be I'm

377
00:16:47,879 --> 00:16:49,649
representing a draw and the third

378
00:16:49,649 --> 00:16:52,050
element would be representing that the

379
00:16:52,050 --> 00:16:55,920
away team won and then we have like

380
00:16:55,920 --> 00:16:57,660
mattress that are that haven't happened

381
00:16:57,660 --> 00:17:00,240
yet they have of course also inputs but

382
00:17:00,240 --> 00:17:01,680
they don't have an output because of

383
00:17:01,680 --> 00:17:04,140
course we don't have a result yet so

384
00:17:04,140 --> 00:17:09,059
that makes two datasets basically and

385
00:17:09,059 --> 00:17:11,819
then we have to build our network and we

386
00:17:11,819 --> 00:17:15,089
use the number of input nodes that is

387
00:17:15,089 --> 00:17:17,159
the same number of inputs we have and

388
00:17:17,159 --> 00:17:21,059
then India we have three output nodes

389
00:17:21,059 --> 00:17:23,309
because we have three different classes

390
00:17:23,309 --> 00:17:25,409
that are possible and inside we have

391
00:17:25,409 --> 00:17:27,689
hidden layers and I just like edges

392
00:17:27,689 --> 00:17:30,850
chose two layers with six nodes

393
00:17:30,850 --> 00:17:32,470
it's not the this is the law or

394
00:17:32,470 --> 00:17:34,960
something and then we have to get a

395
00:17:34,960 --> 00:17:38,530
trainer for a network and then we train

396
00:17:38,530 --> 00:17:40,270
on it we tell them what the learning

397
00:17:40,270 --> 00:17:41,890
rate is the learning rate is basically

398
00:17:41,890 --> 00:17:43,539
the size of the steps that gradient

399
00:17:43,539 --> 00:17:46,120
descent takes and this is also i just

400
00:17:46,120 --> 00:17:49,000
chose that value and because it just

401
00:17:49,000 --> 00:17:51,940
felt like it and also i have to define

402
00:17:51,940 --> 00:17:53,770
the number of iterations which is how

403
00:17:53,770 --> 00:17:55,360
often you go through the entire training

404
00:17:55,360 --> 00:17:58,360
set to train your network and then when

405
00:17:58,360 --> 00:17:59,799
we're done with training we actually

406
00:17:59,799 --> 00:18:03,429
make predictions and if i would run the

407
00:18:03,429 --> 00:18:05,760
script it would look something like this

408
00:18:05,760 --> 00:18:09,309
so um what we can see like if we look at

409
00:18:09,309 --> 00:18:12,309
the first prediction and the the home

410
00:18:12,309 --> 00:18:14,320
team is worth less than half the of the

411
00:18:14,320 --> 00:18:16,120
away team and the probability of winning

412
00:18:16,120 --> 00:18:18,220
the match is also about half of the

413
00:18:18,220 --> 00:18:20,710
probability to lose the match that seems

414
00:18:20,710 --> 00:18:21,909
pretty straightforward and probably

415
00:18:21,909 --> 00:18:24,370
whatever I would have predicted to if it

416
00:18:24,370 --> 00:18:27,250
just only had those given data but when

417
00:18:27,250 --> 00:18:28,830
we look at like the third prediction

418
00:18:28,830 --> 00:18:31,179
although the home team is also worth

419
00:18:31,179 --> 00:18:33,070
about half compared to the way team our

420
00:18:33,070 --> 00:18:35,080
machine predicts that is likely more

421
00:18:35,080 --> 00:18:36,760
likely for the home team to win the game

422
00:18:36,760 --> 00:18:39,460
and this could have a lot of like this

423
00:18:39,460 --> 00:18:40,870
could have a lot of meanings it could

424
00:18:40,870 --> 00:18:42,580
mean that there's something like a home

425
00:18:42,580 --> 00:18:45,130
team advantage or there's like a

426
00:18:45,130 --> 00:18:47,679
different like implication that we don't

427
00:18:47,679 --> 00:18:49,840
know about and the problem with machine

428
00:18:49,840 --> 00:18:52,419
learning and prediction is that we don't

429
00:18:52,419 --> 00:18:54,190
really know how our machine gets there

430
00:18:54,190 --> 00:18:56,590
because it's non deterministic and those

431
00:18:56,590 --> 00:18:58,600
model is purely mathematical and the

432
00:18:58,600 --> 00:19:00,309
weights don't translate into something

433
00:19:00,309 --> 00:19:02,710
that you can understand intuitively so

434
00:19:02,710 --> 00:19:04,780
we can reverse engineer something like

435
00:19:04,780 --> 00:19:06,610
home team advantage unless we actually

436
00:19:06,610 --> 00:19:11,320
implemented it okay so I hope you're

437
00:19:11,320 --> 00:19:14,409
still with me and this is how we

438
00:19:14,409 --> 00:19:16,630
implemented it now we have got like our

439
00:19:16,630 --> 00:19:20,289
predictions and then now how do we know

440
00:19:20,289 --> 00:19:21,970
how well we're actually doing with our

441
00:19:21,970 --> 00:19:24,940
algorithm and if we know how we're doing

442
00:19:24,940 --> 00:19:26,890
how can we implement how can we improve

443
00:19:26,890 --> 00:19:31,570
it so um when we want to figure figure

444
00:19:31,570 --> 00:19:33,159
out how our algorithm performs there's

445
00:19:33,159 --> 00:19:34,510
something called the error like the

446
00:19:34,510 --> 00:19:36,490
errors like I said the difference

447
00:19:36,490 --> 00:19:39,309
between the actual real result and what

448
00:19:39,309 --> 00:19:40,790
we predicted

449
00:19:40,790 --> 00:19:43,910
and so it's an epic already gives

450
00:19:43,910 --> 00:19:45,110
something and has something like that

451
00:19:45,110 --> 00:19:47,660
it's called the data error and all we

452
00:19:47,660 --> 00:19:49,190
have to do is add a schedule to our

453
00:19:49,190 --> 00:19:51,740
trainer and we say basically that every

454
00:19:51,740 --> 00:19:54,470
10,000 iteration do the stuff that I

455
00:19:54,470 --> 00:19:57,140
give you in the function and basically

456
00:19:57,140 --> 00:19:59,780
we just lock the data error rate and if

457
00:19:59,780 --> 00:20:04,610
I run this it will look like this so we

458
00:20:04,610 --> 00:20:06,430
can see that there is an error rate of

459
00:20:06,430 --> 00:20:10,030
0.19 this does not mean that like

460
00:20:10,030 --> 00:20:12,050
nineteen percent of our predictions are

461
00:20:12,050 --> 00:20:14,750
false this is a mathematical error rate

462
00:20:14,750 --> 00:20:16,790
it's the mean squared error and it's

463
00:20:16,790 --> 00:20:19,070
basically just a distance the errors

464
00:20:19,070 --> 00:20:21,020
distant distance between our predictions

465
00:20:21,020 --> 00:20:23,810
and the truth so this doesn't really

466
00:20:23,810 --> 00:20:25,850
translate into anything like if people

467
00:20:25,850 --> 00:20:27,380
ask me how well does it I wouldn't

468
00:20:27,380 --> 00:20:29,900
perform if I same I mean squared error

469
00:20:29,900 --> 00:20:34,100
is like 19 0.19 nobody knows what I'm

470
00:20:34,100 --> 00:20:36,650
talking about right so I wanted to like

471
00:20:36,650 --> 00:20:38,930
try to come up with a metric that is

472
00:20:38,930 --> 00:20:40,430
more straightforward and that would tell

473
00:20:40,430 --> 00:20:41,570
me an error rate that I can actually

474
00:20:41,570 --> 00:20:47,210
understand so I was coming up with

475
00:20:47,210 --> 00:20:48,170
something that's called the

476
00:20:48,170 --> 00:20:49,940
classification error it's basically the

477
00:20:49,940 --> 00:20:54,110
same thing where we in this case we have

478
00:20:54,110 --> 00:20:57,010
an error counter and then we do a

479
00:20:57,010 --> 00:20:59,270
classification actually because now

480
00:20:59,270 --> 00:21:01,070
before you saw that we have a

481
00:21:01,070 --> 00:21:05,750
probability distribution and now we want

482
00:21:05,750 --> 00:21:07,640
to make an actual prediction from the

483
00:21:07,640 --> 00:21:09,920
distribution so basically we say this is

484
00:21:09,920 --> 00:21:11,720
the most likely so I'm going to predict

485
00:21:11,720 --> 00:21:14,180
this and then we just count the numbers

486
00:21:14,180 --> 00:21:17,540
the times that we are wrong and then bye

487
00:21:17,540 --> 00:21:21,680
I'm sorry from that we want to calculate

488
00:21:21,680 --> 00:21:26,600
our error rate and in this case if I run

489
00:21:26,600 --> 00:21:28,250
my algorithm it would love doing

490
00:21:28,250 --> 00:21:29,690
something like that you can see that the

491
00:21:29,690 --> 00:21:32,270
error went up compared to the mean

492
00:21:32,270 --> 00:21:34,370
squared error which is logical because

493
00:21:34,370 --> 00:21:36,260
we actually make predictions and we can

494
00:21:36,260 --> 00:21:39,650
either be wrong or right we don't have

495
00:21:39,650 --> 00:21:43,460
like a distance anymore so we have this

496
00:21:43,460 --> 00:21:46,160
data but it's we use the classification

497
00:21:46,160 --> 00:21:48,620
data we use the same data that we train

498
00:21:48,620 --> 00:21:51,710
or network on which is not very smart

499
00:21:51,710 --> 00:21:53,090
because our

500
00:21:53,090 --> 00:21:55,610
should actually predict something that

501
00:21:55,610 --> 00:21:58,280
it doesn't know about yet so to figure

502
00:21:58,280 --> 00:22:01,010
out how our algorithm performs with data

503
00:22:01,010 --> 00:22:02,930
that it doesn't know about you basically

504
00:22:02,930 --> 00:22:06,080
take our data sets and then split it in

505
00:22:06,080 --> 00:22:08,990
two thirds basically we take two thirds

506
00:22:08,990 --> 00:22:11,510
of the trainings of the data set to

507
00:22:11,510 --> 00:22:13,820
train and then the last third we use to

508
00:22:13,820 --> 00:22:17,000
classify or to Bella date or a measure

509
00:22:17,000 --> 00:22:19,790
of performance so I have to speed up a

510
00:22:19,790 --> 00:22:21,890
little bit and basically we do the same

511
00:22:21,890 --> 00:22:24,440
thing that we did before but in this

512
00:22:24,440 --> 00:22:25,670
case we just use the cross-validation

513
00:22:25,670 --> 00:22:27,650
set to make our predictions instead of

514
00:22:27,650 --> 00:22:30,980
training set and if we run the script it

515
00:22:30,980 --> 00:22:33,230
looks something like this again our

516
00:22:33,230 --> 00:22:34,790
error I'd jumped up a little bit and

517
00:22:34,790 --> 00:22:36,680
also it's just like all over the place

518
00:22:36,680 --> 00:22:38,420
is like super weird because it doesn't

519
00:22:38,420 --> 00:22:40,880
seem to like go down silly but it just

520
00:22:40,880 --> 00:22:45,320
like jumps around and so okay we know

521
00:22:45,320 --> 00:22:47,300
those error rates and I'm going to skip

522
00:22:47,300 --> 00:22:49,370
the slide real quick because it's just

523
00:22:49,370 --> 00:22:52,730
like a summary and and the next question

524
00:22:52,730 --> 00:22:54,710
would be how do we interpret this and

525
00:22:54,710 --> 00:22:57,200
how can we actually improve on it and I

526
00:22:57,200 --> 00:23:03,320
have to skip the sled to I'm sorry ok so

527
00:23:03,320 --> 00:23:05,120
there are like a few things that I want

528
00:23:05,120 --> 00:23:08,540
to try to improve the improve the

529
00:23:08,540 --> 00:23:10,640
algorithm first thing is adjusting the

530
00:23:10,640 --> 00:23:12,320
learning rate so we saw that the error

531
00:23:12,320 --> 00:23:14,210
rate was jumping like up and down and up

532
00:23:14,210 --> 00:23:16,190
and down and this could mean that we

533
00:23:16,190 --> 00:23:17,810
already like reach the global minimum

534
00:23:17,810 --> 00:23:19,940
and are just like wandering around it

535
00:23:19,940 --> 00:23:23,660
and I just wanted to like try what would

536
00:23:23,660 --> 00:23:26,630
happen if I just changed the learning

537
00:23:26,630 --> 00:23:29,030
rate so this is the error rate that we

538
00:23:29,030 --> 00:23:31,990
had before with the am learning rate of

539
00:23:31,990 --> 00:23:35,900
0.003 and then I just changed it to 0 0

540
00:23:35,900 --> 00:23:39,590
to 1 and this is what happened what you

541
00:23:39,590 --> 00:23:41,330
can see is that the error it is a little

542
00:23:41,330 --> 00:23:44,150
bit higher but now it like slowly goes

543
00:23:44,150 --> 00:23:45,530
down and doesn't like walk around

544
00:23:45,530 --> 00:23:48,800
anymore and this could mean that if I do

545
00:23:48,800 --> 00:23:51,290
more iterations I will get a better like

546
00:23:51,290 --> 00:23:53,180
error wait I will be closer to the

547
00:23:53,180 --> 00:23:55,280
global minimum even though my steps are

548
00:23:55,280 --> 00:23:58,580
smaller and in this case I just decided

549
00:23:58,580 --> 00:24:00,260
to leave it at that to just show you

550
00:24:00,260 --> 00:24:02,050
what what can happen

551
00:24:02,050 --> 00:24:04,180
when you change the learning rate and I

552
00:24:04,180 --> 00:24:06,730
wanted to try some other stuff too so

553
00:24:06,730 --> 00:24:08,500
the next thing I wanted to try was to

554
00:24:08,500 --> 00:24:11,590
just simply get more data and i get i

555
00:24:11,590 --> 00:24:14,500
just added in to new seasons which was

556
00:24:14,500 --> 00:24:17,530
100% more data and again this is the

557
00:24:17,530 --> 00:24:19,000
learning rate from before the error

558
00:24:19,000 --> 00:24:21,310
rates from before and these are the

559
00:24:21,310 --> 00:24:23,350
error rates after i added more data and

560
00:24:23,350 --> 00:24:26,190
what you can see is that between the

561
00:24:26,190 --> 00:24:28,900
10,000 iteration in the 100,000th

562
00:24:28,900 --> 00:24:31,120
iteration there is like a bigger

563
00:24:31,120 --> 00:24:34,090
difference with more data then with less

564
00:24:34,090 --> 00:24:36,580
data which means like if you train your

565
00:24:36,580 --> 00:24:38,650
algorithm like a hundred thousand four

566
00:24:38,650 --> 00:24:40,300
hundred thousand integrations but the

567
00:24:40,300 --> 00:24:41,920
error rate doesn't change that much you

568
00:24:41,920 --> 00:24:45,040
don't really have to write so this could

569
00:24:45,040 --> 00:24:46,960
mean that it actually would be worth

570
00:24:46,960 --> 00:24:51,520
your time to get more data and then the

571
00:24:51,520 --> 00:24:53,290
last thing that I tried was to simply

572
00:24:53,290 --> 00:24:55,810
add more features to give the algorithm

573
00:24:55,810 --> 00:24:58,300
or inputs which would also just mean

574
00:24:58,300 --> 00:25:00,130
that I'm describing the problem better

575
00:25:00,130 --> 00:25:04,180
or more detailed so before I had two

576
00:25:04,180 --> 00:25:06,130
features those were the market values of

577
00:25:06,130 --> 00:25:09,580
the two teams and now i just added like

578
00:25:09,580 --> 00:25:12,100
three more features and the positions of

579
00:25:12,100 --> 00:25:14,410
the teams in the table before the match

580
00:25:14,410 --> 00:25:17,830
starts and also the MH day so I'm saying

581
00:25:17,830 --> 00:25:19,840
probably it does have an influence how

582
00:25:19,840 --> 00:25:21,850
far into the season we are and how well

583
00:25:21,850 --> 00:25:24,430
they are compared to other teams and now

584
00:25:24,430 --> 00:25:25,990
if we look at the error rate right now

585
00:25:25,990 --> 00:25:28,540
looks pretty good except that the

586
00:25:28,540 --> 00:25:30,490
cross-validation error seems to go up at

587
00:25:30,490 --> 00:25:32,710
some point but it still is performing

588
00:25:32,710 --> 00:25:34,540
better than having only two features so

589
00:25:34,540 --> 00:25:36,580
we could say from that that it might

590
00:25:36,580 --> 00:25:38,560
make sense to put more effort into

591
00:25:38,560 --> 00:25:43,990
getting more features so yeah those are

592
00:25:43,990 --> 00:25:47,280
the things that I actually tried and

593
00:25:47,280 --> 00:25:49,870
this is basically just prototyping stuff

594
00:25:49,870 --> 00:25:51,700
just trying stuff out and then decide

595
00:25:51,700 --> 00:25:54,040
what would be like worth my time the

596
00:25:54,040 --> 00:25:55,930
most and there's also this thing called

597
00:25:55,930 --> 00:25:57,760
regularization that like real data

598
00:25:57,760 --> 00:26:00,340
scientists use but I unfortunate don't

599
00:26:00,340 --> 00:26:02,020
have the time to really go that deep

600
00:26:02,020 --> 00:26:03,400
into it but we can talk about it later

601
00:26:03,400 --> 00:26:09,210
after the talk and okay so I'm gonna

602
00:26:09,210 --> 00:26:12,070
pull up another quote so you still with

603
00:26:12,070 --> 00:26:12,980
me

604
00:26:12,980 --> 00:26:15,410
so this Court is most famously of

605
00:26:15,410 --> 00:26:17,179
tributed niels bohr but I'm not quite

606
00:26:17,179 --> 00:26:20,390
sure if he actually said that but the

607
00:26:20,390 --> 00:26:21,950
chorus prediction is very difficult

608
00:26:21,950 --> 00:26:24,410
especially about the future and now as

609
00:26:24,410 --> 00:26:26,030
they have seen it's not even that easy

610
00:26:26,030 --> 00:26:28,010
about like predicting stuff in the past

611
00:26:28,010 --> 00:26:32,390
or the present and so what I want to

612
00:26:32,390 --> 00:26:35,419
like talk about now that I'm coming to

613
00:26:35,419 --> 00:26:38,720
the end and is how do you actually work

614
00:26:38,720 --> 00:26:41,660
with machines like how do you actually

615
00:26:41,660 --> 00:26:42,980
work when you're doing machine learning

616
00:26:42,980 --> 00:26:46,370
and what I've learned is that you have

617
00:26:46,370 --> 00:26:49,040
to work incrementally you will get there

618
00:26:49,040 --> 00:26:51,679
eventually but neural networks are just

619
00:26:51,679 --> 00:26:53,570
basically like your brain and practices

620
00:26:53,570 --> 00:26:55,580
what makes perfect so you can't expect

621
00:26:55,580 --> 00:26:57,260
to have the perfect solution like right

622
00:26:57,260 --> 00:27:00,320
out of the box have to slowly get there

623
00:27:00,320 --> 00:27:02,929
and you have to think about the problem

624
00:27:02,929 --> 00:27:05,419
not the solution the reason to work with

625
00:27:05,419 --> 00:27:07,100
neural networks is precisely so you

626
00:27:07,100 --> 00:27:08,390
don't have to come up with a solution

627
00:27:08,390 --> 00:27:10,340
yourself you get them giving this to a

628
00:27:10,340 --> 00:27:13,400
machine and you can put your time and

629
00:27:13,400 --> 00:27:15,169
effort into thinking about how to best

630
00:27:15,169 --> 00:27:19,190
describe your problem and you should try

631
00:27:19,190 --> 00:27:20,630
out different configuration parameters

632
00:27:20,630 --> 00:27:24,110
if you start with a new and problem or

633
00:27:24,110 --> 00:27:26,390
new thing then no one can tell you what

634
00:27:26,390 --> 00:27:28,010
your perfect learning rate will should

635
00:27:28,010 --> 00:27:29,870
be or how many layers you will need or

636
00:27:29,870 --> 00:27:32,809
how to choose like what what kind of

637
00:27:32,809 --> 00:27:34,309
configuration camera parameters you

638
00:27:34,309 --> 00:27:36,620
should use you should just come up with

639
00:27:36,620 --> 00:27:38,120
a metric that is important to you that

640
00:27:38,120 --> 00:27:40,640
you can understand and just like change

641
00:27:40,640 --> 00:27:42,530
stuff and try it out and then basically

642
00:27:42,530 --> 00:27:44,750
see what it does here metric and then

643
00:27:44,750 --> 00:27:47,929
decide which way you want to go and the

644
00:27:47,929 --> 00:27:49,429
most important thing about machine

645
00:27:49,429 --> 00:27:52,010
learning is it's about the data and if

646
00:27:52,010 --> 00:27:54,049
you have data that is biased you will

647
00:27:54,049 --> 00:27:56,450
get biased results I don't know if you

648
00:27:56,450 --> 00:27:58,580
remember this one an incident where like

649
00:27:58,580 --> 00:28:00,440
this face recognition software would

650
00:28:00,440 --> 00:28:03,049
flag like African Americans as like Apes

651
00:28:03,049 --> 00:28:05,480
and that's not because the machine is

652
00:28:05,480 --> 00:28:07,340
like evil or several races it's because

653
00:28:07,340 --> 00:28:10,309
the data was biased and and so you have

654
00:28:10,309 --> 00:28:11,990
to be really careful what you give your

655
00:28:11,990 --> 00:28:13,429
machine because it's going to learn from

656
00:28:13,429 --> 00:28:18,760
this data and not anything else okay and

657
00:28:18,760 --> 00:28:21,320
so I have those recommended reading

658
00:28:21,320 --> 00:28:23,150
section in case you want to read up more

659
00:28:23,150 --> 00:28:24,909
on machine learning

660
00:28:24,909 --> 00:28:27,940
and just dive into it I hope I've like

661
00:28:27,940 --> 00:28:30,099
made it clear that it's not really that

662
00:28:30,099 --> 00:28:32,019
complicated to actually build something

663
00:28:32,019 --> 00:28:33,489
with it even though you're not like

664
00:28:33,489 --> 00:28:36,190
totally into the math part and the first

665
00:28:36,190 --> 00:28:39,220
link is a link to my repository and you

666
00:28:39,220 --> 00:28:41,559
can find the whole thing there like the

667
00:28:41,559 --> 00:28:43,149
whole data retrieval included and how

668
00:28:43,149 --> 00:28:48,099
implemented the whole like error error

669
00:28:48,099 --> 00:28:54,039
recognition of error rate and pop my I'm

670
00:28:54,039 --> 00:28:56,739
sorry so you can just check it out there

671
00:28:56,739 --> 00:29:00,220
and then this is the little link to the

672
00:29:00,220 --> 00:29:03,759
library i use synaptic and i have the i

673
00:29:03,759 --> 00:29:07,029
have also linked to the course I'm think

674
00:29:07,029 --> 00:29:08,259
it's not that interesting now that I'm

675
00:29:08,259 --> 00:29:10,570
going to tell you about like each and

676
00:29:10,570 --> 00:29:12,700
every single link I'm going to put up

677
00:29:12,700 --> 00:29:15,399
the slides later I'm gonna edit to get

678
00:29:15,399 --> 00:29:17,349
her I think yeah get her on Twitter and

679
00:29:17,349 --> 00:29:20,320
so you can check it out there but also

680
00:29:20,320 --> 00:29:22,749
there's this amazing page called coding

681
00:29:22,749 --> 00:29:24,639
game so it's basically just coding for

682
00:29:24,639 --> 00:29:26,320
fun and coding with your friends and

683
00:29:26,320 --> 00:29:28,029
everything and they have an awesome new

684
00:29:28,029 --> 00:29:29,649
machine learning section that uses

685
00:29:29,649 --> 00:29:32,200
tensorflow tender flows the machine

686
00:29:32,200 --> 00:29:34,299
learning library for python by google if

687
00:29:34,299 --> 00:29:36,129
you don't know that and it's like really

688
00:29:36,129 --> 00:29:38,889
easy to use and and you should totally

689
00:29:38,889 --> 00:29:42,639
check it out okay so like I said before

690
00:29:42,639 --> 00:29:45,099
I've done some predictions for the

691
00:29:45,099 --> 00:29:46,809
Premier League those are the predictions

692
00:29:46,809 --> 00:29:48,369
you can like take a picture right now

693
00:29:48,369 --> 00:29:50,769
and then check and then you just bet

694
00:29:50,769 --> 00:29:53,409
money on it and then we can just see who

695
00:29:53,409 --> 00:29:55,539
made the most money tomorrow by the end

696
00:29:55,539 --> 00:29:58,059
of the day or like tomorrow and then who

697
00:29:58,059 --> 00:29:59,769
made the most money you should just buy

698
00:29:59,769 --> 00:30:03,519
us all drinks I guess alright so that

699
00:30:03,519 --> 00:30:07,500
was it thank you

