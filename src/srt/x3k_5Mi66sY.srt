1
00:00:07,460 --> 00:00:13,050
I'm glad you came to hear about the new parser
coming to Node.

2
00:00:13,050 --> 00:00:18,110
About who I am, I'm Fedor Indutny.

3
00:00:18,110 --> 00:00:21,850
Here's my Twitter and GitHub handles which
are the same.

4
00:00:21,850 --> 00:00:24,320
And I write code at PayPal.

5
00:00:24,320 --> 00:00:30,260
You might know me by this dark avatar I use
on GitHub and Twitter and practically everywhere

6
00:00:30,260 --> 00:00:32,140
else.

7
00:00:32,140 --> 00:00:37,100
For today talk, the slides and the presentations
are already up online.

8
00:00:37,100 --> 00:00:42,590
If you would like, you can scan the QR code
and open your browser and follow along as

9
00:00:42,590 --> 00:00:44,540
I'm going to present the topic.

10
00:00:44,540 --> 00:00:45,900
Which is llhttp.

11
00:00:45,900 --> 00:00:51,829
The new HTTP protocol parser for Node.js.

12
00:00:51,829 --> 00:00:57,440
This has deep roots into the history of Node.js.

13
00:00:57,440 --> 00:01:04,320
And it would be hard if not impossible not
to mention the history while describing.

14
00:01:04,320 --> 00:01:07,430
Of course, Node.js is used to load for the
front-end tooling.

15
00:01:07,430 --> 00:01:11,800
But originally historically it started as
the backend platform.

16
00:01:11,800 --> 00:01:18,560
It was exclusively about building asynchronous
HTTP servers.

17
00:01:18,560 --> 00:01:23,790
And the creator of Node, HTTP parser is what
started as node.

18
00:01:23,790 --> 00:01:29,930
There's presentations on the importance and
role and structure.

19
00:01:29,930 --> 00:01:35,880
It's a power Node.js event loop and it's key
ever since they set up the node.

20
00:01:35,880 --> 00:01:40,670
And you might remember if there's a dependency,
however, it is not.

21
00:01:40,670 --> 00:01:46,450
As an HTTP parser, it has all the dependencies
that Node ever had.

22
00:01:46,450 --> 00:01:49,590
It leads all the dependencies in Node.

23
00:01:49,590 --> 00:01:56,759
Initially it was inspired by mongrel, a Ruby
web server with its own parser created by

24
00:01:56,759 --> 00:01:57,990
web show.

25
00:01:57,990 --> 00:02:02,810
And later, parts
Nginx code introduced in HTTP parser, the

26
00:02:02,810 --> 00:02:03,810
original one.

27
00:02:03,810 --> 00:02:07,560
And, of course, the code itself.

28
00:02:07,560 --> 00:02:10,619
The parser has been with us since 2009.

29
00:02:10,619 --> 00:02:12,969
It's been more than ten years.

30
00:02:12,969 --> 00:02:18,730
And in effect, Node itself has been introduced
that the very conference ten years ago by

31
00:02:18,730 --> 00:02:19,730
Ryan.

32
00:02:19,730 --> 00:02:23,139
So, it's kind of a jubilee for both of those
projects.

33
00:02:23,139 --> 00:02:29,370
And I wrote another HTTP parser to replace
the original parser.

34
00:02:29,370 --> 00:02:36,239
So, why would anyone want to get rid of such
a library?

35
00:02:36,239 --> 00:02:37,920
Of course, it's a fantastic library.

36
00:02:37,920 --> 00:02:39,389
It has been with us for ten years.

37
00:02:39,389 --> 00:02:41,939
It should have been worked fine.

38
00:02:41,939 --> 00:02:46,739
And it has many users inside of the Node.js
community as well.

39
00:02:46,739 --> 00:02:49,059
For example, Android proxy by Google.

40
00:02:49,059 --> 00:02:54,930
They use it for parsing HTTP requests and
it's quite a popular project as well.

41
00:02:54,930 --> 00:02:59,849
What makes this parser great and why did it
stay?

42
00:02:59,849 --> 00:03:03,359
First, good enough performance.

43
00:03:03,359 --> 00:03:09,089
It takes quite a bit of time to invoke a C
function, and parser is written in C. It takes

44
00:03:09,089 --> 00:03:11,909
way less time to parse the requests.

45
00:03:11,909 --> 00:03:15,370
I'm going to elaborate on it a bit later in
this presentation.

46
00:03:15,370 --> 00:03:20,319
But for NodeJS purposes, it's very good performance.

47
00:03:20,319 --> 00:03:22,809
Couldn't be better.

48
00:03:22,809 --> 00:03:27,469
It also supports a lot of clients and servers
that violate the HTTP specification.

49
00:03:27,469 --> 00:03:30,999
There are way too many of them out on the
Internet.

50
00:03:30,999 --> 00:03:32,569
You would be surprised how many.

51
00:03:32,569 --> 00:03:37,139
And, of course, it was very important for
early adoption of NodeJS.

52
00:03:37,139 --> 00:03:42,859
Because in 2009 there was even more such clients
and servers out there.

53
00:03:42,859 --> 00:03:45,980
Another point is that original parser has
a lot of test suites.

54
00:03:45,980 --> 00:03:52,749
So, over ten years Ryan, Ben and other maintainers
of the project, including myself, have wrote

55
00:03:52,749 --> 00:03:58,349
quite a comprehensive test suite that covers
almost every aspect of HTTP specification.

56
00:03:58,349 --> 00:04:00,059
So, the parser is welltested.

57
00:04:00,059 --> 00:04:03,219
So, that was the good points of the original
parser.

58
00:04:03,219 --> 00:04:05,709
Now we come to other points.

59
00:04:05,709 --> 00:04:10,319
Unfortunately, with the HTTP library the code
became quite rigid.

60
00:04:10,319 --> 00:04:16,150
It became impossible to move things around,
to make significant changes to it.

61
00:04:16,150 --> 00:04:23,120
And as a consequence of this, it became impossible
to maintain this library efficiently.

62
00:04:23,120 --> 00:04:28,919
Furthermore, as one of the maintainers of
the project, I have to constantly relearn

63
00:04:28,919 --> 00:04:35,120
and get familiar with the parts of the codebase
that I was previously familiar with before.

64
00:04:35,120 --> 00:04:40,870
And I did it on every pull request and still
I wasn't sure if the code is going to run

65
00:04:40,870 --> 00:04:43,940
in the way I expected it to run.

66
00:04:43,940 --> 00:04:47,449
So, it could introduce some unexpected behavior.

67
00:04:47,449 --> 00:04:50,050
Or maybe a security vulnerability as well.

68
00:04:50,050 --> 00:04:52,180
Which is obviously bad.

69
00:04:52,180 --> 00:04:58,569
It doesn't help either that most NodeJS users
and developers are familiar with JavaScript

70
00:04:58,569 --> 00:05:03,650
and are more comfortable with it than they
are with C. So, there was not too many people

71
00:05:03,650 --> 00:05:07,500
interested in working on this HTTP parser.

72
00:05:07,500 --> 00:05:12,560
With all this in mind, several years ago I
set out on a quest it make the library better

73
00:05:12,560 --> 00:05:16,319
and maybe a bit faster in the process.

74
00:05:16,319 --> 00:05:18,730
First attempts were quite conservative.

75
00:05:18,730 --> 00:05:21,560
So, I tried to stay with existing code as
much as possible.

76
00:05:21,560 --> 00:05:23,190
And some of them were successful.

77
00:05:23,190 --> 00:05:28,389
Like replacing the parser state machine with
a cross, and using it consistently not only

78
00:05:28,389 --> 00:05:31,550
improved the code, but also made it faster.

79
00:05:31,550 --> 00:05:33,129
Which was nice.

80
00:05:33,129 --> 00:05:35,190
Other attempts were a complete disaster.

81
00:05:35,190 --> 00:05:39,969
I tried to move those states into a separated
function and just called them from the loop

82
00:05:39,969 --> 00:05:45,020
so each state would return the next state
that was supposed to be executed and then

83
00:05:45,020 --> 00:05:47,050
the loop would run the function for it.

84
00:05:47,050 --> 00:05:52,949
This completely ruins the performance and
I never contributed or sent it to the string.

85
00:05:52,949 --> 00:05:58,990
From this attempt was success or failure,
the conclusion was clear.

86
00:05:58,990 --> 00:06:02,650
It was hard to make an improvement while staying
with the existing codebase.

87
00:06:02,650 --> 00:06:07,810
There was no requirement to use as much code
as possible, it was no longer required to

88
00:06:07,810 --> 00:06:11,380
make it in the same programming language as
before.

89
00:06:11,380 --> 00:06:16,039
Why not develop it in JavaScript or maybe
TypeScript instead?

90
00:06:16,039 --> 00:06:21,310
And, of course, JavaScript performance is
quite great.

91
00:06:21,310 --> 00:06:26,499
But you wouldn't be surprised that it's slower
than C and takes a lot of effort to reach

92
00:06:26,499 --> 00:06:30,550
comparable performances in the C libraries
when you write programs in JavaScript.

93
00:06:30,550 --> 00:06:31,550
Takes a lot of effort.

94
00:06:31,550 --> 00:06:32,650
But it's possible.

95
00:06:32,650 --> 00:06:38,020
So, I wanted to get this performance optimization
out of consideration.

96
00:06:38,020 --> 00:06:44,069
And also, I decided to just define the parser
in TypeScript and still compile it down to

97
00:06:44,069 --> 00:06:45,069
the C library.

98
00:06:45,069 --> 00:06:49,009
So, the end result would be C library that
was used in Node and other projects.

99
00:06:49,009 --> 00:06:55,400
Which was great because existing users of
HTTP parser this way would be able to transition

100
00:06:55,400 --> 00:07:00,400
their code to the new parser and hopefully
the process and the performance would not

101
00:07:00,400 --> 00:07:03,919
degrade so much because in the end it's the
same programming language.

102
00:07:03,919 --> 00:07:09,490
It would have good chances of being the same
speed.

103
00:07:09,490 --> 00:07:15,870
So, llhttp is the next major version of HTTP
parser.

104
00:07:15,870 --> 00:07:20,389
It has the same core principles and similar
API, which is almost identical.

105
00:07:20,389 --> 00:07:27,870
And the way they work, is they scan one character
at a time.

106
00:07:27,870 --> 00:07:34,280
And during the process they change the internal
state and they could add a header fields or

107
00:07:34,280 --> 00:07:39,719
maybe header values and later on body.

108
00:07:39,719 --> 00:07:42,159
I'm not sure if we're going to wait for this.

109
00:07:42,159 --> 00:07:43,159
It's quite slow.

110
00:07:43,159 --> 00:07:44,159
Okay.

111
00:07:44,159 --> 00:07:45,159
Yeah.

112
00:07:45,159 --> 00:07:47,490
I think you probably understand what it means
now.

113
00:07:47,490 --> 00:07:49,189
At least to some extent.

114
00:07:49,189 --> 00:07:57,229
So, this can by the virtue of this one scan
the parser can work without buffering anything

115
00:07:57,229 --> 00:07:58,229
at all.

116
00:07:58,229 --> 00:08:00,889
So, it doesn't allocate memory itself.

117
00:08:00,889 --> 00:08:06,879
And it creates especially for request bodies
because it could just need the slices of original

118
00:08:06,879 --> 00:08:10,990
buffers that came from that work instead of
allocating the coping data.

119
00:08:10,990 --> 00:08:16,770
So, in the core principle of the HTTP parser,
it's not copying.

120
00:08:16,770 --> 00:08:18,370
That's important.

121
00:08:18,370 --> 00:08:24,330
And as soon as any amount of data arrives
via a request or a single byte of request,

122
00:08:24,330 --> 00:08:26,529
HTTP parser is ready to process it.

123
00:08:26,529 --> 00:08:30,319
And it will be possibly partial because it
will be health requests.

124
00:08:30,319 --> 00:08:36,229
And the header names, we are just seeing in
this animation.

125
00:08:36,229 --> 00:08:43,630
In the original version of the parser, this
scan was quite naturally implemented foreloop

126
00:08:43,630 --> 00:08:45,950
over the input.

127
00:08:45,950 --> 00:08:50,610
Just going by the input bytebybyte and doing
some syncs.

128
00:08:50,610 --> 00:08:57,430
What it did, it was described by a huge which
statement or all possible parsing state.

129
00:08:57,430 --> 00:09:02,360
Whether it's a header name, header value,
whether it's value of content lengths header,

130
00:09:02,360 --> 00:09:09,030
it was all described by the switch statement,
and they represented different states of the

131
00:09:09,030 --> 00:09:10,600
state machine.

132
00:09:10,600 --> 00:09:16,709
All of this lived in a single function or
1,000 lines of code which is quite a terrible

133
00:09:16,709 --> 00:09:17,709
idea.

134
00:09:17,709 --> 00:09:24,490
So, an obvious improvement would be to break
this switch into pieces and make it such that

135
00:09:24,490 --> 00:09:26,940
each piece has precise action.

136
00:09:26,940 --> 00:09:30,250
It's sort of a unique philosophy, I guess.

137
00:09:30,250 --> 00:09:35,660
So, it would be just exactly about doing one
small thing at a time.

138
00:09:35,660 --> 00:09:38,570
Go to statements would be used to jump between
states.

139
00:09:38,570 --> 00:09:43,970
There would not be as much need for this foreloop,
at least not as much.

140
00:09:43,970 --> 00:09:49,730
With all this in mind, how do I approach this
process?

141
00:09:49,730 --> 00:09:59,180
I developed a domainspecific language, DSL,
and created a compiler around it, LL parse,

142
00:09:59,180 --> 00:10:07,410
so, again, double L. And this compiler is
used to describe the parsing states in terms

143
00:10:07,410 --> 00:10:09,660
of these actions that they perform.

144
00:10:09,660 --> 00:10:14,259
So, each state would have several actions
assigned to them and they would perform them

145
00:10:14,259 --> 00:10:17,630
and move on to the next state.

146
00:10:17,630 --> 00:10:23,090
Because of this llparse is quite a general
compiler, it can be used for other protocols

147
00:10:23,090 --> 00:10:24,090
as well.

148
00:10:24,090 --> 00:10:29,589
It works better for textual protocols, but
I think it's useful.

149
00:10:29,589 --> 00:10:33,910
Original parser suffered from a surplus of
handwritten code.

150
00:10:33,910 --> 00:10:39,120
I have selected a few actions that were repeated
most in the original library and had DSL around

151
00:10:39,120 --> 00:10:40,120
them.

152
00:10:40,120 --> 00:10:45,670
The idea here is that I wanted the description
of the new parser to be concise.

153
00:10:45,670 --> 00:10:50,430
So, I wanted to write code with less lines
and less signals than possible.

154
00:10:50,430 --> 00:10:56,920
I wanted to move the most common iterations
inside of the compiler so that the rest would

155
00:10:56,920 --> 00:11:01,050
have to do the work all over again and the
original parser.

156
00:11:01,050 --> 00:11:06,220
Here were a few that the compiler supports.

157
00:11:06,220 --> 00:11:08,660
One is match.

158
00:11:08,660 --> 00:11:15,680
It takes a sequence, or a character of bytes
and it tries to match them from the input.

159
00:11:15,680 --> 00:11:20,980
For example, it could be keep alive, which
is the value of the headernamed connection.

160
00:11:20,980 --> 00:11:23,470
It's quite a common header and very important.

161
00:11:23,470 --> 00:11:25,899
So, it could match this sequence.

162
00:11:25,899 --> 00:11:31,160
And when it does, move to the next state by
taking the reference to this state.

163
00:11:31,160 --> 00:11:36,029
And other times the parser needs to check
the next character in the incoming data without

164
00:11:36,029 --> 00:11:37,370
actually consuming it.

165
00:11:37,370 --> 00:11:41,300
And it could be used for this.

166
00:11:41,300 --> 00:11:49,560
Takes a single character and mentions it and
moves on without moving the input stream.

167
00:11:49,560 --> 00:11:56,569
And speaking of headers, headers like lengths,
they have internal values which frankly described

168
00:11:56,569 --> 00:11:59,339
by strings, it's a contextual protocol.

169
00:11:59,339 --> 00:12:03,269
The new parser has to be able to parse the
integer strings.

170
00:12:03,269 --> 00:12:11,180
And the way I decided to do it was to implement
a select method in DSL which takes a map as

171
00:12:11,180 --> 00:12:12,730
an input.

172
00:12:12,730 --> 00:12:17,600
And this map has sequences or characters as
keys.

173
00:12:17,600 --> 00:12:18,839
And the integers as values.

174
00:12:18,839 --> 00:12:25,610
So, it tries to map this sequence to the integers
and just passes values along to the next state.

175
00:12:25,610 --> 00:12:32,940
The next state could be storing integers inside
some property of the structure, or maybe walking

176
00:12:32,940 --> 00:12:35,850
a user code back with them.

177
00:12:35,850 --> 00:12:40,339
Speaking of callbacks, there is one special
type of callback.

178
00:12:40,339 --> 00:12:47,519
It is very important in the life span of both
original and the new HTTP parser.

179
00:12:47,519 --> 00:12:50,940
During their executions they need ranges of
data.

180
00:12:50,940 --> 00:12:55,709
For example, header names, or headers are
in this way.

181
00:12:55,709 --> 00:13:02,310
And begin that we have a stream of data that
comes to the parser, we have to be able to

182
00:13:02,310 --> 00:13:07,330
mark some certain place inside of this stream
as the beginning of this range.

183
00:13:07,330 --> 00:13:12,949
And then at some other point later on we want
to set it as an ending of the range.

184
00:13:12,949 --> 00:13:17,069
So, between those beginning and ending, or
you can see, our beginning and ending.

185
00:13:17,069 --> 00:13:20,649
Between them the callback is going to be invoked
for every byte.

186
00:13:20,649 --> 00:13:26,360
And it's really, really useful for header
names, header values and bodies, and other

187
00:13:26,360 --> 00:13:31,000
things that could be needed that spans the
ranges of input.

188
00:13:31,000 --> 00:13:35,529
Of course, there are a couple of important
actions that I have not needed in previous

189
00:13:35,529 --> 00:13:40,009
slides that are actually mandatory to have
in this state.

190
00:13:40,009 --> 00:13:42,430
They call otherwise and skip to.

191
00:13:42,430 --> 00:13:49,600
And those specify which states of the parser
should be reached next if nothing else matches

192
00:13:49,600 --> 00:13:50,990
inside of the current state.

193
00:13:50,990 --> 00:13:57,730
So, in this example, the input would be A.
The parser would move to the A state, and

194
00:13:57,730 --> 00:14:03,029
for B, move to B and C or D or E or whatever
is later.

195
00:14:03,029 --> 00:14:06,550
It would move to some other state.

196
00:14:06,550 --> 00:14:08,180
Skip to is quite similar.

197
00:14:08,180 --> 00:14:11,850
It's the same thing but consumes the character
from the input stream.

198
00:14:11,850 --> 00:14:14,769
Otherwise, it does not change the input stream
at all.

199
00:14:14,769 --> 00:14:16,140
It just moves on.

200
00:14:16,140 --> 00:14:23,730
So, that was a bit of description maybe too
concise to be useful of DSL.

201
00:14:23,730 --> 00:14:30,329
And with this DSL in mind, llhttp becomes
a type Script program.

202
00:14:30,329 --> 00:14:37,310
This program uses it to describe the actions
and input as said before.

203
00:14:37,310 --> 00:14:41,769
Because it's a TypeScript program, or JavaScript
program, really, I could split it into several

204
00:14:41,769 --> 00:14:44,520
sub modules and use them efficiently.

205
00:14:44,520 --> 00:14:45,870
And each submodule could have the subparser.

206
00:14:45,870 --> 00:14:49,740
This is what I use in HTTP.

207
00:14:49,740 --> 00:14:56,910
I have a separate parser inside of it and
can use it and run it separately and can be

208
00:14:56,910 --> 00:15:02,860
used separately as well as a library if anyone
wants it.

209
00:15:02,860 --> 00:15:12,009
Llparse compile this is TypeScript program
down to C. And that's the main action of it.

210
00:15:12,009 --> 00:15:19,579
Know that because it uses a stable DSL, oh,
sorry, just uses DSL, the parser doesn't need

211
00:15:19,579 --> 00:15:21,259
to do any parsing.

212
00:15:21,259 --> 00:15:24,810
It's done automatically by the JS engine.

213
00:15:24,810 --> 00:15:26,980
So, V8 does it for us.

214
00:15:26,980 --> 00:15:30,649
V8 does this itself internally.

215
00:15:30,649 --> 00:15:37,009
Llparse builds a graph of state which I will
try to show you.

216
00:15:37,009 --> 00:15:38,260
It looks kind of terrible.

217
00:15:38,260 --> 00:15:39,420
But I probably can zoom in.

218
00:15:39,420 --> 00:15:40,420
Yeah.

219
00:15:40,420 --> 00:15:45,509
So, yeah, hear, how it looks like in practice.

220
00:15:45,509 --> 00:15:49,370
I can probably actually show you something
more useful.

221
00:15:49,370 --> 00:15:56,449
So, here on the right you see ACL buy check
out this.

222
00:15:56,449 --> 00:15:58,960
Mobile names supported by parser.

223
00:15:58,960 --> 00:16:01,819
And the name is matched in this of the input.

224
00:16:01,819 --> 00:16:07,400
It will store the integer and coding as a
method inside those internal properties of

225
00:16:07,400 --> 00:16:08,400
parsers.

226
00:16:08,400 --> 00:16:11,310
It works this way more or less.

227
00:16:11,310 --> 00:16:15,139
I guess with a that means is the kind of graph
is looking awesome.

228
00:16:15,139 --> 00:16:18,529
So, that's one of the reasons to have it.

229
00:16:18,529 --> 00:16:23,500
And another reason to have it is that llparse
can do static analysis on this graph.

230
00:16:23,500 --> 00:16:29,339
Before in original parsers there was no way
to reason about the states automatically.

231
00:16:29,339 --> 00:16:33,230
So, it was all described manually inside of
the parser.

232
00:16:33,230 --> 00:16:35,389
There was just a lot of C code.

233
00:16:35,389 --> 00:16:39,050
And there was no way to analyze it and to
do any optimizations for checks.

234
00:16:39,050 --> 00:16:46,910
What I can to in llparse is check the code
for absence of infant loops which is possible

235
00:16:46,910 --> 00:16:50,259
due to otherwise so, they could be combined
together.

236
00:16:50,259 --> 00:16:54,790
Not just making any progress over the input
and just being in indefinitely.

237
00:16:54,790 --> 00:17:00,579
It's important to check this statically because
there might be an array of conditions that

238
00:17:00,579 --> 00:17:01,579
could trigger it.

239
00:17:01,579 --> 00:17:06,860
It might not be immediately verifiable with
the test suite.

240
00:17:06,860 --> 00:17:11,810
Speaking of optimizations, the parser could
do peephole optimizations.

241
00:17:11,810 --> 00:17:17,880
That's a fancy name for just combining similar
states together into one.

242
00:17:17,880 --> 00:17:24,480
This way the amount of code is reduced, and
also the compiler sorry, programmer has a

243
00:17:24,480 --> 00:17:29,640
lot more freedom and development with the
parser because they don't have to think about

244
00:17:29,640 --> 00:17:32,560
doing these optimizations manually in their
code.

245
00:17:32,560 --> 00:17:38,080
So, as I said, the DSL is quite stable for
llparse.

246
00:17:38,080 --> 00:17:42,270
So, same program could be compared to different
outputs.

247
00:17:42,270 --> 00:17:46,670
At this moment, C and the code is wellsupported.

248
00:17:46,670 --> 00:17:54,100
And the code was kind of before, it was supported
before the C. So, that's the reason why both

249
00:17:54,100 --> 00:17:57,060
projects have double L in their names.

250
00:17:57,060 --> 00:17:58,810
Kind of a historical reason.

251
00:17:58,810 --> 00:18:07,390
But in the end when I ran benchmarks, this
tree C compiler worked better than the code

252
00:18:07,390 --> 00:18:10,450
which I spent several weeks on.

253
00:18:10,450 --> 00:18:12,230
It was surprising for me, maybe shocking.

254
00:18:12,230 --> 00:18:16,800
I had a few months to think about it.

255
00:18:16,800 --> 00:18:17,800
Yeah.

256
00:18:17,800 --> 00:18:22,180
And speaking of performance, you might be
wondering how fast this new parser is given

257
00:18:22,180 --> 00:18:24,950
that it is not handwritten at all.

258
00:18:24,950 --> 00:18:30,030
But, of course, despite the maintenance issues,
as I said before, the original parser has

259
00:18:30,030 --> 00:18:31,220
quite a bit of improvements.

260
00:18:31,220 --> 00:18:33,750
They're good enough, still very good.

261
00:18:33,750 --> 00:18:39,450
It would have been very unreasonable to replace
it with something that performed significantly

262
00:18:39,450 --> 00:18:40,450
worse.

263
00:18:40,450 --> 00:18:45,330
So, ll shipping is not handwritten, it's not
hand optimized.

264
00:18:45,330 --> 00:18:53,490
And when I ran benchmarks, I discovered that
it runs twice as fast as the original parser.

265
00:18:53,490 --> 00:19:01,580
[ Applause ]
Thank you.

266
00:19:01,580 --> 00:19:03,620
And here is the actual benchmark numbers.

267
00:19:03,620 --> 00:19:09,440
So, as you can see, both those numbers did
quite well.

268
00:19:09,440 --> 00:19:14,890
As it presents a number of requests per second
that each parser can take.

269
00:19:14,890 --> 00:19:19,190
And this way both parsers run in microseconds.

270
00:19:19,190 --> 00:19:23,470
You wouldn't ever see this on the profile
logs.

271
00:19:23,470 --> 00:19:25,360
Just impossible to see it.

272
00:19:25,360 --> 00:19:29,770
And, of course, it's important to note as
well that llhttp is more than two times faster

273
00:19:29,770 --> 00:19:31,660
than the original parser.

274
00:19:31,660 --> 00:19:35,210
But no one hardly cares about it.

275
00:19:35,210 --> 00:19:39,670
This llhttp parser is a default in Node version
12.

276
00:19:39,670 --> 00:19:46,960
If you are using the latest Node, I hope you
do, you are already running this.

277
00:19:46,960 --> 00:19:52,590
And even more, you have a reason to blame
me for any kinds of HTTP problems that you

278
00:19:52,590 --> 00:19:53,590
have.

279
00:19:53,590 --> 00:19:57,570
So, feel free to do so and it would be rightful.

280
00:19:57,570 --> 00:20:00,010
Please open GitHub.

281
00:20:00,010 --> 00:20:03,560
Don't just brag on Twitter how bad I am.

282
00:20:03,560 --> 00:20:04,560
And tag me on GitHub.

283
00:20:04,560 --> 00:20:09,210
I will be happy to look into it and fix it
as soon as possible.

284
00:20:09,210 --> 00:20:14,570
As I said before, over ten years originally
the parser has accumulated a comprehensive

285
00:20:14,570 --> 00:20:16,050
test suite.

286
00:20:16,050 --> 00:20:20,460
It would be really unwise to get rid of it
and just start it over.

287
00:20:20,460 --> 00:20:23,790
So, I ported all the original tests to mark
down.

288
00:20:23,790 --> 00:20:25,240
And the new ones.

289
00:20:25,240 --> 00:20:28,740
And here they are described by the markdown
files.

290
00:20:28,740 --> 00:20:34,400
So, they completed, and I encourage you to
take a look at them if you want.

291
00:20:34,400 --> 00:20:40,290
Because I find them the most I'm using part
of the project that worked on.

292
00:20:40,290 --> 00:20:41,290
Yes.

293
00:20:41,290 --> 00:20:42,330
They're really, really fun.

294
00:20:42,330 --> 00:20:51,250
I'm going to give a bit more time because
I see that some people scanned

295
00:20:51,250 --> 00:20:52,250
the codes.

296
00:20:52,250 --> 00:20:53,250
Okay.

297
00:20:53,250 --> 00:20:54,250
So, that makes it.

298
00:20:54,250 --> 00:20:57,820
And each markdown file contains several tests.

299
00:20:57,820 --> 00:21:00,010
They are separated by the headings.

300
00:21:00,010 --> 00:21:02,620
So, it's quite easy to read.

301
00:21:02,620 --> 00:21:04,220
And even easier to contribute.

302
00:21:04,220 --> 00:21:09,240
In fact, they had one contributor that submitted
a test without asking a question how to do

303
00:21:09,240 --> 00:21:10,240
so.

304
00:21:10,240 --> 00:21:15,920
And I don't know that many projects that uses
a test system that's easy to contribute.

305
00:21:15,920 --> 00:21:19,920
And furthermore, each test has an actual description
inside of them.

306
00:21:19,920 --> 00:21:26,710
They have code chunks inside of markdown,
code chunk for expected output, and between

307
00:21:26,710 --> 00:21:29,200
those you can put just any text you want.

308
00:21:29,200 --> 00:21:32,260
You can put hyperlinks, you can put images.

309
00:21:32,260 --> 00:21:35,190
You can put GIFs of pets doing stuff.

310
00:21:35,190 --> 00:21:38,990
So, it's quite a nice way of writing tests.

311
00:21:38,990 --> 00:21:43,580
And it especially works well for HTTP because
it's the contextual protocol.

312
00:21:43,580 --> 00:21:50,340
And you can see in C where it's actually inside
the test suite.

313
00:21:50,340 --> 00:21:51,340
Yeah.

314
00:21:51,340 --> 00:21:57,030
So, here's been the presence of the parser
and the history of it.

315
00:21:57,030 --> 00:22:02,340
So, naturally I would like to talk about what's
coming next.

316
00:22:02,340 --> 00:22:06,030
And there is room for future improvements
with regards to doing more static checks in

317
00:22:06,030 --> 00:22:10,830
this graph I'm showing to you and doing more
performance optimizations.

318
00:22:10,830 --> 00:22:16,860
There are forks of original parsers that use
CPUspecific vector instructions which are

319
00:22:16,860 --> 00:22:17,860
really, really, fast.

320
00:22:17,860 --> 00:22:22,200
They perform better than both.

321
00:22:22,200 --> 00:22:24,620
Not much use for this speed bump for Node.

322
00:22:24,620 --> 00:22:28,300
But nevertheless, there's no reason to not
explore it.

323
00:22:28,300 --> 00:22:33,990
I probably should do it, or I would love someone
do it for me to do some.

324
00:22:33,990 --> 00:22:37,970
Quite ashamedly, the project is not well documented.

325
00:22:37,970 --> 00:22:46,290
It has quite a bit of information describing
the API of llparse, but it's scattered through

326
00:22:46,290 --> 00:22:49,900
several dependencies and could be made more
accessible.

327
00:22:49,900 --> 00:22:57,270
I could use help with this and I'm sure some
people might find this quite entertaining

328
00:22:57,270 --> 00:23:01,740
as well because there's a lot of interesting
moments in this parser, in this code.

329
00:23:01,740 --> 00:23:10,020
Finally, it would be fascinating to see different
types of parsers implemented on top of llparse.

330
00:23:10,020 --> 00:23:14,620
Two examples that I have in mind, SMTP and
protocols, they are contextual and could be

331
00:23:14,620 --> 00:23:17,680
implemented in llparse.

332
00:23:17,680 --> 00:23:24,020
I really look forward to either working on
this or helping someone with this.

333
00:23:24,020 --> 00:23:25,480
And, yeah.

334
00:23:25,480 --> 00:23:34,340
Here is a link to the ll repos.

335
00:23:34,340 --> 00:23:37,110
It's quite easy to find on GitHub.

336
00:23:37,110 --> 00:23:40,370
Just under the Node.js organization.

337
00:23:40,370 --> 00:23:43,130
GitHub.com/Node.js/ et cetera /llhttp.

338
00:23:43,130 --> 00:23:45,890
So, I guess that's it.

