1
00:00:04,220 --> 00:00:07,500

oops I am extremely nervous right now I

2
00:00:07,500 --> 00:00:09,450
feel like I can't breathe but I'm

3
00:00:09,450 --> 00:00:13,950
extremely excited but first I have

4
00:00:13,950 --> 00:00:19,529
something to share warning right now

5
00:00:19,529 --> 00:00:23,880
your users are at risk users of the web

6
00:00:23,880 --> 00:00:26,699
everywhere are frustrated in this very

7
00:00:26,699 --> 00:00:28,230
moment with the applications that

8
00:00:28,230 --> 00:00:31,560
they're forced used every day this is a

9
00:00:31,560 --> 00:00:33,809
review from the internet somebody wrote

10
00:00:33,809 --> 00:00:35,510
about their application hey Amelia

11
00:00:35,510 --> 00:00:37,410
somebody wrote about their application

12
00:00:37,410 --> 00:00:39,950
the new version sometimes slows down

13
00:00:39,950 --> 00:00:42,899
this is a real user of a real web app

14
00:00:42,899 --> 00:00:44,820
there's a real review it's from the

15
00:00:44,820 --> 00:00:46,230
Internet so we know we can trust it

16
00:00:46,230 --> 00:00:49,950
and here's another review sometimes it

17
00:00:49,950 --> 00:00:52,199
takes a lot of time for loading the

18
00:00:52,199 --> 00:00:58,140
contents someone else simply wrote it's

19
00:00:58,140 --> 00:01:02,640
too slow this could happen to you and

20
00:01:02,640 --> 00:01:06,210
this could happen to your users but I'm

21
00:01:06,210 --> 00:01:08,280
here today to tell you that there is

22
00:01:08,280 --> 00:01:10,799
hope my name is Wil Klein I'm from

23
00:01:10,799 --> 00:01:12,750
Boulder Colorado where I work at workday

24
00:01:12,750 --> 00:01:14,850
as a full stack engineer this is my

25
00:01:14,850 --> 00:01:18,390
family and I also have a confession to

26
00:01:18,390 --> 00:01:21,299
share I have built apps that have

27
00:01:21,299 --> 00:01:25,140
reviews like these and when approached

28
00:01:25,140 --> 00:01:28,470
with these complaints I will initially

29
00:01:28,470 --> 00:01:31,700
reply well it works fast on my machine

30
00:01:31,700 --> 00:01:35,909
but what about their machine what about

31
00:01:35,909 --> 00:01:39,180
their browser I use Chrome but it turns

32
00:01:39,180 --> 00:01:40,320
out there's this other browser out there

33
00:01:40,320 --> 00:01:45,869
called Internet Explorer 11 and users

34
00:01:45,869 --> 00:01:47,579
everywhere are forced by their IT

35
00:01:47,579 --> 00:01:49,530
departments to use it to use

36
00:01:49,530 --> 00:01:51,570
applications like mine and it makes my

37
00:01:51,570 --> 00:01:53,420
life a living hell

38
00:01:53,420 --> 00:01:55,500
what about their connection I have a

39
00:01:55,500 --> 00:01:57,570
very fast internet connection at home

40
00:01:57,570 --> 00:02:00,659
and at work but not everyone has that

41
00:02:00,659 --> 00:02:03,630
and not everyone has a fast VPN either

42
00:02:03,630 --> 00:02:05,909
sometimes their internet is fast when

43
00:02:05,909 --> 00:02:08,069
they dial into a VPN across the world

44
00:02:08,069 --> 00:02:11,310
everything slows down a little bit and

45
00:02:11,310 --> 00:02:13,930
what about their data have you ever

46
00:02:13,930 --> 00:02:18,189
seen a defect or a bug where the the

47
00:02:18,189 --> 00:02:19,659
complaint is that they're they're rich

48
00:02:19,659 --> 00:02:21,430
text doesn't actually render as rich

49
00:02:21,430 --> 00:02:25,759
text but as HTML in a plain text field

50
00:02:25,769 --> 00:02:28,209
users do interesting things with our app

51
00:02:28,209 --> 00:02:30,099
that we don't quite anticipate all the

52
00:02:30,099 --> 00:02:33,819
time and what about their data some of

53
00:02:33,819 --> 00:02:36,489
our applications are configurable to the

54
00:02:36,489 --> 00:02:38,769
user or their organization where they

55
00:02:38,769 --> 00:02:42,280
can change their data model to have any

56
00:02:42,280 --> 00:02:44,590
type of Ire have different types of

57
00:02:44,590 --> 00:02:47,590
hierarchy and this can lead to lots of

58
00:02:47,590 --> 00:02:49,989
performance woes that we can't very well

59
00:02:49,989 --> 00:02:53,139
anticipate so there are many variables

60
00:02:53,139 --> 00:02:55,900
that work their way into our web app

61
00:02:55,900 --> 00:02:58,419
performance and our user experience and

62
00:02:58,419 --> 00:03:01,060
this is a full-stack problem we can't

63
00:03:01,060 --> 00:03:03,189
just look at the front end or the back

64
00:03:03,189 --> 00:03:04,569
end we need to look at the full picture

65
00:03:04,569 --> 00:03:06,900
and see what's happening throughout the

66
00:03:06,900 --> 00:03:10,409
system to know what we might need to do

67
00:03:10,409 --> 00:03:13,450
and there are tools we can use we can do

68
00:03:13,450 --> 00:03:16,030
performance audits on our application we

69
00:03:16,030 --> 00:03:17,680
can do performance testing on our micro

70
00:03:17,680 --> 00:03:21,069
services we can monitor our services and

71
00:03:21,069 --> 00:03:23,919
look at their response times and we can

72
00:03:23,919 --> 00:03:25,479
even do application profiling on the

73
00:03:25,479 --> 00:03:27,699
front end and the back end to look for

74
00:03:27,699 --> 00:03:29,979
memory leaks and anything that might be

75
00:03:29,979 --> 00:03:33,280
slowing down but none of these things

76
00:03:33,280 --> 00:03:35,439
look at what's actually happening for

77
00:03:35,439 --> 00:03:38,590
our users in the wild so how do we

78
00:03:38,590 --> 00:03:41,199
observe our users applications in the

79
00:03:41,199 --> 00:03:43,540
wild how do we observe their actual user

80
00:03:43,540 --> 00:03:45,549
experience to know what's really

81
00:03:45,549 --> 00:03:47,769
happening in their conditions when they

82
00:03:47,769 --> 00:03:50,709
use our application we're going to talk

83
00:03:50,709 --> 00:03:52,329
about that today and follow the full

84
00:03:52,329 --> 00:03:54,340
stack trace and learn how we can

85
00:03:54,340 --> 00:03:55,810
understand our app with the distributed

86
00:03:55,810 --> 00:03:59,919
tracing my cursor is in the middle

87
00:03:59,919 --> 00:04:02,560
screen I hate that so this is a

88
00:04:02,560 --> 00:04:04,979
daredevil from the Netflix series and

89
00:04:04,979 --> 00:04:07,150
daredevil is a very interesting Marvel

90
00:04:07,150 --> 00:04:11,169
superhero he's blind but he had his

91
00:04:11,169 --> 00:04:12,729
superpowers that he can sense everything

92
00:04:12,729 --> 00:04:15,639
around him with his other senses so much

93
00:04:15,639 --> 00:04:18,759
so that he's able to observe an

94
00:04:18,759 --> 00:04:21,669
unprecedented way despite lacking any

95
00:04:21,669 --> 00:04:24,159
vision so I wonder if there's something

96
00:04:24,159 --> 00:04:26,380
that we can tap into that would give us

97
00:04:26,380 --> 00:04:27,790
Bella / superpower

98
00:04:27,790 --> 00:04:29,110
so we can observe what's actually

99
00:04:29,110 --> 00:04:34,270
happening in the wild I believe we can

100
00:04:34,270 --> 00:04:37,450
get that with distributed tracing zoom

101
00:04:37,450 --> 00:04:40,420
is a little bit so this is a trace we're

102
00:04:40,420 --> 00:04:41,890
gonna jump right into what this looks

103
00:04:41,890 --> 00:04:44,920
like a trace is essentially a series of

104
00:04:44,920 --> 00:04:49,080
timings and each row in this is a

105
00:04:49,080 --> 00:04:51,730
specific timing where a specific thing

106
00:04:51,730 --> 00:04:53,620
happens and each of those things is

107
00:04:53,620 --> 00:04:56,170
called the span in this case the whole

108
00:04:56,170 --> 00:04:59,350
trace is following a user request the

109
00:04:59,350 --> 00:05:02,380
user request is going to hit slash

110
00:05:02,380 --> 00:05:04,510
dispatch with the HTTP GET request and

111
00:05:04,510 --> 00:05:06,150
then a bunch of things happen after that

112
00:05:06,150 --> 00:05:09,160
there's other HTTP requests associated

113
00:05:09,160 --> 00:05:11,620
with it to other endpoints there's

114
00:05:11,620 --> 00:05:13,870
database calls to my sequel there's

115
00:05:13,870 --> 00:05:16,330
access to Redis there's a bunch of

116
00:05:16,330 --> 00:05:18,280
things that we can see happening when

117
00:05:18,280 --> 00:05:22,060
this request processes now some of these

118
00:05:22,060 --> 00:05:23,830
things happen in parallel the the first

119
00:05:23,830 --> 00:05:25,300
four things and the blue and the yellow

120
00:05:25,300 --> 00:05:26,560
on the brown they're happening in

121
00:05:26,560 --> 00:05:28,870
parallel and that's that's good they can

122
00:05:28,870 --> 00:05:31,120
happen at the same time and then you see

123
00:05:31,120 --> 00:05:33,400
the next set of things happen afterwards

124
00:05:33,400 --> 00:05:35,230
so some things are happening in parallel

125
00:05:35,230 --> 00:05:38,100
some things are happening sequentially

126
00:05:38,100 --> 00:05:40,180
and this is interesting because then we

127
00:05:40,180 --> 00:05:42,220
can start to see with this trace at

128
00:05:42,220 --> 00:05:44,020
least in our back in here we can see

129
00:05:44,020 --> 00:05:45,970
what is happening how long is it taking

130
00:05:45,970 --> 00:05:48,040
what can happen at the same time and

131
00:05:48,040 --> 00:05:50,470
what's being blocked and this is where

132
00:05:50,470 --> 00:05:51,790
we can start to see where bottlenecks

133
00:05:51,790 --> 00:05:53,950
are happening it's also where we can

134
00:05:53,950 --> 00:05:56,020
start to see what actually happens when

135
00:05:56,020 --> 00:06:00,640
you use a request happens so this was

136
00:06:00,640 --> 00:06:04,230
shown with Yaeger UI from Yaeger tracing

137
00:06:04,230 --> 00:06:07,510
Iger is a open source project that is

138
00:06:07,510 --> 00:06:09,160
managed by the cloud native computing

139
00:06:09,160 --> 00:06:12,360
foundation there's several members of

140
00:06:12,360 --> 00:06:15,220
the cloud native computing foundation

141
00:06:15,220 --> 00:06:17,200
that are sponsoring and supporting this

142
00:06:17,200 --> 00:06:19,030
project so hopefully it'll be around

143
00:06:19,030 --> 00:06:21,040
awhile they have a number of other

144
00:06:21,040 --> 00:06:22,480
projects like kubernetes so they're

145
00:06:22,480 --> 00:06:23,020
doing pretty well

146
00:06:23,020 --> 00:06:25,990
I was listening in this podcast last

147
00:06:25,990 --> 00:06:27,580
week and was interviewed with Yura

148
00:06:27,580 --> 00:06:28,510
Shakur Oh

149
00:06:28,510 --> 00:06:30,280
one of the main authors behind the Jager

150
00:06:30,280 --> 00:06:36,030
and about 12 minutes in the podcast

151
00:06:36,030 --> 00:06:38,860
interviewer made a statement

152
00:06:38,860 --> 00:06:42,300
everybody wants distributed tracing I

153
00:06:42,300 --> 00:06:44,650
stop right there for a moment and I

154
00:06:44,650 --> 00:06:47,349
started to wonder how many of you have

155
00:06:47,349 --> 00:06:48,849
heard of distributed tracing before this

156
00:06:48,849 --> 00:06:52,210
conference whew that's pretty good

157
00:06:52,210 --> 00:06:55,270
but maybe like maybe half not everyone

158
00:06:55,270 --> 00:06:57,759
and what I've found in my travels

159
00:06:57,759 --> 00:06:59,919
particularly in front-end development is

160
00:06:59,919 --> 00:07:02,919
a lot of people haven't heard of it and

161
00:07:02,919 --> 00:07:04,150
if you don't work in enterprise software

162
00:07:04,150 --> 00:07:06,250
or an organization that maybe already

163
00:07:06,250 --> 00:07:08,500
has this on the back end you might not

164
00:07:08,500 --> 00:07:11,620
have had exposure or the need to look at

165
00:07:11,620 --> 00:07:14,259
this and the other interesting thing

166
00:07:14,259 --> 00:07:16,180
about this podcast is this was about 12

167
00:07:16,180 --> 00:07:17,710
minutes in they talked about micro

168
00:07:17,710 --> 00:07:19,449
servers for the first 12 minutes and

169
00:07:19,449 --> 00:07:20,919
that's actually where I think a lot of

170
00:07:20,919 --> 00:07:22,569
the content around distributed tracing

171
00:07:22,569 --> 00:07:25,060
is focused is on the back end and how we

172
00:07:25,060 --> 00:07:27,250
handle the requests to our micro

173
00:07:27,250 --> 00:07:29,110
services I want to look at that in a

174
00:07:29,110 --> 00:07:31,930
different way today when I look at these

175
00:07:31,930 --> 00:07:35,409
front end spans the the blue that you

176
00:07:35,409 --> 00:07:37,629
see here at the top where it doesn't has

177
00:07:37,629 --> 00:07:39,250
a front end before it these are

178
00:07:39,250 --> 00:07:41,469
basically identifying when the request

179
00:07:41,469 --> 00:07:43,419
came in from the front end there's no

180
00:07:43,419 --> 00:07:45,880
other information about what happened in

181
00:07:45,880 --> 00:07:48,550
the browser to kick off that request I

182
00:07:48,550 --> 00:07:50,110
want to go a little deeper there if we

183
00:07:50,110 --> 00:07:52,990
can so how do we apply this to the front

184
00:07:52,990 --> 00:07:56,440
end the first thing to think about is

185
00:07:56,440 --> 00:07:58,719
well what makes up a trace when do we

186
00:07:58,719 --> 00:08:01,090
have a trace what do we consider a user

187
00:08:01,090 --> 00:08:03,880
request so I think about two things

188
00:08:03,880 --> 00:08:07,029
really when we're loading a page or

189
00:08:07,029 --> 00:08:09,279
doing a route change we're loading a

190
00:08:09,279 --> 00:08:11,529
whole view essentially or when there's

191
00:08:11,529 --> 00:08:13,750
any UI interaction of any kind maybe

192
00:08:13,750 --> 00:08:15,969
they're doing an inline edit or they're

193
00:08:15,969 --> 00:08:18,460
doing a button click basically any time

194
00:08:18,460 --> 00:08:20,319
the user interacts with the application

195
00:08:20,319 --> 00:08:22,000
whether they're pulling it down for the

196
00:08:22,000 --> 00:08:24,400
first time or navigating to another page

197
00:08:24,400 --> 00:08:27,520
or clicking on a button that is when we

198
00:08:27,520 --> 00:08:29,080
want to start thinking about what's

199
00:08:29,080 --> 00:08:33,130
happening and that's a user action the

200
00:08:33,130 --> 00:08:34,779
other way the other side to think about

201
00:08:34,779 --> 00:08:36,550
is the feedback that we're giving to the

202
00:08:36,550 --> 00:08:39,399
user when does the page render when has

203
00:08:39,399 --> 00:08:41,589
your eye state updated when does the

204
00:08:41,589 --> 00:08:43,630
user consider it to have finished when

205
00:08:43,630 --> 00:08:46,660
they did something this comprises the

206
00:08:46,660 --> 00:08:48,699
user experience from page load to the

207
00:08:48,699 --> 00:08:50,589
page rendering from the button being

208
00:08:50,589 --> 00:08:51,520
clicked

209
00:08:51,520 --> 00:08:54,100
to the view updating this is what I want

210
00:08:54,100 --> 00:08:55,480
to measure and what I want to capture

211
00:08:55,480 --> 00:08:59,470
with my distributed traces so I go back

212
00:08:59,470 --> 00:09:03,490
to this I want to take those blue

213
00:09:03,490 --> 00:09:06,130
front-end bars and enrich them with more

214
00:09:06,130 --> 00:09:09,280
child spans more things that comprise

215
00:09:09,280 --> 00:09:12,940
those components so I can know what did

216
00:09:12,940 --> 00:09:14,830
they click what happened in the browser

217
00:09:14,830 --> 00:09:16,660
before the request happened when did it

218
00:09:16,660 --> 00:09:18,910
request it in the browser and not just

219
00:09:18,910 --> 00:09:22,750
when did we get on the back end so how

220
00:09:22,750 --> 00:09:25,360
do we instrument our code we're going to

221
00:09:25,360 --> 00:09:28,180
start with how we time stuff now when I

222
00:09:28,180 --> 00:09:29,740
walk through some code examples here I

223
00:09:29,740 --> 00:09:31,300
don't want you to get too hung up on the

224
00:09:31,300 --> 00:09:34,870
nuances of the Samiha of the code or any

225
00:09:34,870 --> 00:09:36,850
specific semantics it's intentionally

226
00:09:36,850 --> 00:09:39,700
abstracted just to have the main idea of

227
00:09:39,700 --> 00:09:41,800
what is a trace was a span how do we

228
00:09:41,800 --> 00:09:43,420
time things and how we might bring that

229
00:09:43,420 --> 00:09:46,870
into our application so our first

230
00:09:46,870 --> 00:09:48,580
example is how do we start a trace we

231
00:09:48,580 --> 00:09:50,740
need some API that lets us well start a

232
00:09:50,740 --> 00:09:52,840
trace and give it a description did we

233
00:09:52,840 --> 00:09:55,240
load a page or do we navigate to a new

234
00:09:55,240 --> 00:09:58,720
URL it might look something like this

235
00:09:58,720 --> 00:10:00,040
might give a description that we have a

236
00:10:00,040 --> 00:10:01,450
route change and then we give it the

237
00:10:01,450 --> 00:10:03,490
slug where's that window location that

238
00:10:03,490 --> 00:10:08,560
we're navigating to and to record a span

239
00:10:08,560 --> 00:10:11,200
within that trace more specific work

240
00:10:11,200 --> 00:10:14,260
that's happening in the system for any

241
00:10:14,260 --> 00:10:16,540
of work that we do we want to time it

242
00:10:16,540 --> 00:10:20,020
again and here we're starting a span

243
00:10:20,020 --> 00:10:22,420
instead of starting a trace and then we

244
00:10:22,420 --> 00:10:25,390
want to do the work we want to see

245
00:10:25,390 --> 00:10:29,260
whatever it is that we need to do could

246
00:10:29,260 --> 00:10:31,660
be anything right now and then when that

247
00:10:31,660 --> 00:10:35,680
work is done we want to stop the span a

248
00:10:35,680 --> 00:10:37,210
quick example of that is maybe we're

249
00:10:37,210 --> 00:10:39,250
making a network request maybe we're

250
00:10:39,250 --> 00:10:41,380
making a request to a web service and we

251
00:10:41,380 --> 00:10:43,840
need to start a span and record that

252
00:10:43,840 --> 00:10:48,090
it's request and take a specific request

253
00:10:48,090 --> 00:10:50,290
what's behind the API I've start tracing

254
00:10:50,290 --> 00:10:55,390
start span not too much basic idea is

255
00:10:55,390 --> 00:10:56,650
you want to keep track of the trace

256
00:10:56,650 --> 00:10:59,260
that's active so I have a let for the

257
00:10:59,260 --> 00:11:00,970
current trace and then my start trace

258
00:11:00,970 --> 00:11:03,400
function sets that current trace to be a

259
00:11:03,400 --> 00:11:04,760
new object

260
00:11:04,760 --> 00:11:07,100
and then it has a start time and a

261
00:11:07,100 --> 00:11:09,620
unique ID with those two things those

262
00:11:09,620 --> 00:11:11,089
are the main components of the trace we

263
00:11:11,089 --> 00:11:12,949
need to know when it started and what is

264
00:11:12,949 --> 00:11:14,630
that what is its identifier because

265
00:11:14,630 --> 00:11:16,639
we're going to need that later and start

266
00:11:16,639 --> 00:11:18,680
fist ban is very similar we just need to

267
00:11:18,680 --> 00:11:21,110
start the time for a given span and

268
00:11:21,110 --> 00:11:24,380
maintain a reference to it for stopping

269
00:11:24,380 --> 00:11:26,180
the trace we just record the stop time

270
00:11:26,180 --> 00:11:28,790
we're just doing a new date get the time

271
00:11:28,790 --> 00:11:32,839
and putting that on the trace and then

272
00:11:32,839 --> 00:11:34,550
when we're done with that trace when

273
00:11:34,550 --> 00:11:35,510
we've stopped it

274
00:11:35,510 --> 00:11:39,199
we need to persist it in some way this

275
00:11:39,199 --> 00:11:42,260
could be an HTTP request but do have a

276
00:11:42,260 --> 00:11:44,810
warning there initially when you getting

277
00:11:44,810 --> 00:11:46,760
started with this making an HTTP request

278
00:11:46,760 --> 00:11:48,800
is great just to see what's happening

279
00:11:48,800 --> 00:11:50,779
seeing that on the wire making sure you

280
00:11:50,779 --> 00:11:52,430
can thread that through to the eager

281
00:11:52,430 --> 00:11:54,350
back end and that it pulls up in their

282
00:11:54,350 --> 00:11:56,930
UI but eventually you're going to want

283
00:11:56,930 --> 00:11:58,370
to have strategies to not create

284
00:11:58,370 --> 00:12:00,649
additional user web requests every time

285
00:12:00,649 --> 00:12:03,199
the user does something so batching is a

286
00:12:03,199 --> 00:12:04,699
really good strategy to roll those up

287
00:12:04,699 --> 00:12:06,709
somehow and then send them all at once

288
00:12:06,709 --> 00:12:11,720
so what does this look like in a real

289
00:12:11,720 --> 00:12:13,850
application maybe we're using react or

290
00:12:13,850 --> 00:12:17,569
view or angular this gets a little bit

291
00:12:17,569 --> 00:12:20,269
tricky it will vary per application I've

292
00:12:20,269 --> 00:12:22,579
done a lot with react and even with

293
00:12:22,579 --> 00:12:23,120
react

294
00:12:23,120 --> 00:12:25,399
there's react with redux there's react

295
00:12:25,399 --> 00:12:27,589
with state manage by react context I

296
00:12:27,589 --> 00:12:29,899
might even be using Apollo client with

297
00:12:29,899 --> 00:12:32,269
graph QL and what this looks like in

298
00:12:32,269 --> 00:12:34,010
each specific implementation looks a

299
00:12:34,010 --> 00:12:35,540
little bit different so we need to roll

300
00:12:35,540 --> 00:12:37,010
up our sleeves a little bit to see how

301
00:12:37,010 --> 00:12:39,980
we apply those api's I suggested into a

302
00:12:39,980 --> 00:12:41,889
given application

303
00:12:41,889 --> 00:12:44,360
but there's one common strategy that I

304
00:12:44,360 --> 00:12:47,720
advocate for we could approach all of

305
00:12:47,720 --> 00:12:49,610
our UI components and all of our

306
00:12:49,610 --> 00:12:52,370
requests code and instrument each one

307
00:12:52,370 --> 00:12:55,430
specifically but then it's easy to miss

308
00:12:55,430 --> 00:12:58,010
things so I like to opt into middleware

309
00:12:58,010 --> 00:13:00,949
or plugins wherever possible so that way

310
00:13:00,949 --> 00:13:02,810
when I develop a new feature it just

311
00:13:02,810 --> 00:13:04,790
gets picked up by the system and

312
00:13:04,790 --> 00:13:07,060
middleware handles and timings for me

313
00:13:07,060 --> 00:13:09,440
I'll show you a light example and Redux

314
00:13:09,440 --> 00:13:12,110
for this the bit I want to focus on here

315
00:13:12,110 --> 00:13:14,720
is in in redox or really a lot of

316
00:13:14,720 --> 00:13:16,250
middlewares there's this concept of a

317
00:13:16,250 --> 00:13:17,170
next function

318
00:13:17,170 --> 00:13:19,329
and the idea is that you can do things

319
00:13:19,329 --> 00:13:21,850
in your middleware when you're

320
00:13:21,850 --> 00:13:23,230
processing requests when the event has

321
00:13:23,230 --> 00:13:25,380
happened you can do it before actually

322
00:13:25,380 --> 00:13:28,540
acting on that action and you do things

323
00:13:28,540 --> 00:13:31,269
afterwards so in the case of tracing we

324
00:13:31,269 --> 00:13:33,730
want to start a span before say hey we

325
00:13:33,730 --> 00:13:35,560
got a Redux action here's its type and

326
00:13:35,560 --> 00:13:37,930
then we call next and when we call next

327
00:13:37,930 --> 00:13:39,459
it's going to process it it's going to

328
00:13:39,459 --> 00:13:40,839
actually pass it through the system

329
00:13:40,839 --> 00:13:42,850
although middlewares can act and

330
00:13:42,850 --> 00:13:46,089
eventually redux state can update it's

331
00:13:46,089 --> 00:13:47,709
the same for other state management

332
00:13:47,709 --> 00:13:50,560
systems and then after that we can stop

333
00:13:50,560 --> 00:13:52,839
the span and record when we finish that

334
00:13:52,839 --> 00:13:58,810
we also need to make this full stack I

335
00:13:58,810 --> 00:14:00,610
talked about not just having the

336
00:14:00,610 --> 00:14:02,649
back-end spans but connecting it to the

337
00:14:02,649 --> 00:14:05,529
front-end to do that we need to share

338
00:14:05,529 --> 00:14:06,699
the trace that we create on the front

339
00:14:06,699 --> 00:14:10,449
end with the back end I'm gonna use a

340
00:14:10,449 --> 00:14:12,850
plug-in example here I'm using super

341
00:14:12,850 --> 00:14:16,149
agent super agent has an API similar to

342
00:14:16,149 --> 00:14:17,980
I think Redux middleware and Express and

343
00:14:17,980 --> 00:14:19,839
Khoa have something similar when you

344
00:14:19,839 --> 00:14:21,640
plug in a middleware you say hey use

345
00:14:21,640 --> 00:14:23,410
this middleware well with super agent

346
00:14:23,410 --> 00:14:25,839
use a plug-in you can define hey here's

347
00:14:25,839 --> 00:14:29,769
what my get request is and I can say use

348
00:14:29,769 --> 00:14:31,269
for a number of plugins and I will say

349
00:14:31,269 --> 00:14:34,510
use my tracing plug-in and then here's

350
00:14:34,510 --> 00:14:37,390
the response body pass that back now

351
00:14:37,390 --> 00:14:40,000
tracing plugins similar to the Redux

352
00:14:40,000 --> 00:14:41,860
example the middle of our example a

353
00:14:41,860 --> 00:14:44,199
little bit simpler though we take in the

354
00:14:44,199 --> 00:14:46,870
request for it and we can set things on

355
00:14:46,870 --> 00:14:49,779
the request like headers so we can go

356
00:14:49,779 --> 00:14:51,990
and get the trace that we manage and

357
00:14:51,990 --> 00:14:55,209
then get the trace ID and put that on as

358
00:14:55,209 --> 00:14:57,910
a request header for the request so we

359
00:14:57,910 --> 00:14:59,380
send that to the backend our back-end

360
00:14:59,380 --> 00:15:00,850
code can say hey is there already or a

361
00:15:00,850 --> 00:15:03,940
trace ID existing and if it is will

362
00:15:03,940 --> 00:15:05,829
create spans and associate it as

363
00:15:05,829 --> 00:15:11,740
children of that does this work what

364
00:15:11,740 --> 00:15:13,510
does this look like in a full stack

365
00:15:13,510 --> 00:15:16,649
application in a real world example I

366
00:15:16,649 --> 00:15:19,060
have another confession I've been

367
00:15:19,060 --> 00:15:20,170
working really hard to come up with a

368
00:15:20,170 --> 00:15:22,750
deal for this but I wasn't able to do

369
00:15:22,750 --> 00:15:26,370
that in time it's not trivial

370
00:15:26,370 --> 00:15:29,019
but the value is incredibly high I'm

371
00:15:29,019 --> 00:15:30,290
pretty close I'm very

372
00:15:30,290 --> 00:15:34,339
to share this with you soon in fact the

373
00:15:34,339 --> 00:15:36,110
current state of tracing in the front

374
00:15:36,110 --> 00:15:39,380
end doing at full stack is well this

375
00:15:39,380 --> 00:15:42,019
Help Wanted there's a repository called

376
00:15:42,019 --> 00:15:43,850
year client JavaScript that's under the

377
00:15:43,850 --> 00:15:46,310
Jaeger tracing project and there's no

378
00:15:46,310 --> 00:15:49,880
code there's one issue extract the base

379
00:15:49,880 --> 00:15:51,649
JavaScript client from Jaeger client

380
00:15:51,649 --> 00:15:54,529
node so your client node is an existing

381
00:15:54,529 --> 00:15:57,620
NPM module that you can pull in a node

382
00:15:57,620 --> 00:16:00,230
back-end and get a bunch of utilities

383
00:16:00,230 --> 00:16:01,819
for starting traces and starting spans

384
00:16:01,819 --> 00:16:04,790
but it's right now coupled to node and

385
00:16:04,790 --> 00:16:07,819
so there's some help wanted to take out

386
00:16:07,819 --> 00:16:09,259
the node bits and make something that's

387
00:16:09,259 --> 00:16:12,709
browser friendly the current state of

388
00:16:12,709 --> 00:16:14,329
that is that nobody is working on this

389
00:16:14,329 --> 00:16:16,190
at the moment right now but there's

390
00:16:16,190 --> 00:16:17,930
multiple people before this and after

391
00:16:17,930 --> 00:16:20,389
this comment saying hey we need this we

392
00:16:20,389 --> 00:16:23,240
want this so I think is I think this is

393
00:16:23,240 --> 00:16:25,790
gonna come up more and more of very

394
00:16:25,790 --> 00:16:28,250
common cases that you already have this

395
00:16:28,250 --> 00:16:29,779
in your back end or that your back end

396
00:16:29,779 --> 00:16:31,670
developers will bring this into the

397
00:16:31,670 --> 00:16:34,459
application first and you see that

398
00:16:34,459 --> 00:16:35,870
opportunity there already solved on the

399
00:16:35,870 --> 00:16:37,459
infrastructure problem and it's

400
00:16:37,459 --> 00:16:39,199
something to look at bringing into the

401
00:16:39,199 --> 00:16:41,990
front-end there's there's more benefit

402
00:16:41,990 --> 00:16:44,290
that I think is behind this than just

403
00:16:44,290 --> 00:16:47,269
finishing what the back-end developers

404
00:16:47,269 --> 00:16:50,420
might be starting trust me it is

405
00:16:50,420 --> 00:16:54,769
possible so five years ago I was at a

406
00:16:54,769 --> 00:16:56,899
company that had this they had full

407
00:16:56,899 --> 00:17:00,380
stack traces with a pre react legacy

408
00:17:00,380 --> 00:17:02,569
front-end framework and when we migrated

409
00:17:02,569 --> 00:17:04,189
from that framework to react we were

410
00:17:04,189 --> 00:17:06,020
able to look at racism and the old

411
00:17:06,020 --> 00:17:09,470
framework and then react as well and and

412
00:17:09,470 --> 00:17:12,049
see the differences and see what was

413
00:17:12,049 --> 00:17:13,819
improving and even what was taking a

414
00:17:13,819 --> 00:17:16,449
step back so we were able to when we

415
00:17:16,449 --> 00:17:19,339
migrated into flux and eventually redox

416
00:17:19,339 --> 00:17:20,720
were able to look at where our

417
00:17:20,720 --> 00:17:23,089
bottlenecks in the front-end and address

418
00:17:23,089 --> 00:17:26,870
those things it is definitely possible I

419
00:17:26,870 --> 00:17:28,760
know a number of companies have handled

420
00:17:28,760 --> 00:17:30,620
their own but right now we're starting

421
00:17:30,620 --> 00:17:32,150
to see this come out and open source

422
00:17:32,150 --> 00:17:34,940
with Yaeger tracing and now we're gonna

423
00:17:34,940 --> 00:17:37,960
see it soon in the front end I believe

424
00:17:37,960 --> 00:17:40,640
there's another project out there called

425
00:17:40,640 --> 00:17:43,210
real-world i/o and this is

426
00:17:43,210 --> 00:17:46,210
basically it's like a new to MVC it's

427
00:17:46,210 --> 00:17:47,770
been a couple years but they basically

428
00:17:47,770 --> 00:17:50,710
have implemented react examples and

429
00:17:50,710 --> 00:17:52,419
angular examples and view examples they

430
00:17:52,419 --> 00:17:53,830
basically take in any of the frameworks

431
00:17:53,830 --> 00:17:54,820
that are out there and tried to

432
00:17:54,820 --> 00:17:57,570
implement a medium blog clone and

433
00:17:57,570 --> 00:18:00,059
they've not only done the front-end

434
00:18:00,059 --> 00:18:03,340
clones front-end implementation examples

435
00:18:03,340 --> 00:18:06,100
but they've done back in examples so I'm

436
00:18:06,100 --> 00:18:10,240
actually working on a real-world IO fork

437
00:18:10,240 --> 00:18:12,070
right now and trying to create examples

438
00:18:12,070 --> 00:18:17,970
of this with a full stack so stay tuned

439
00:18:17,970 --> 00:18:20,860
so I think again about our users and how

440
00:18:20,860 --> 00:18:22,419
we can observe what's really happening

441
00:18:22,419 --> 00:18:25,899
in the wild I can tell you it's amazing

442
00:18:25,899 --> 00:18:28,750
being able to see an actual trace that

443
00:18:28,750 --> 00:18:30,909
shows like this didn't perform the way I

444
00:18:30,909 --> 00:18:32,890
expected and being able to see things

445
00:18:32,890 --> 00:18:36,450
that happen that I didn't expect as well

446
00:18:36,450 --> 00:18:39,460
because when we look at our traces is

447
00:18:39,460 --> 00:18:41,289
it's actually not just about performance

448
00:18:41,289 --> 00:18:44,559
when I look at this I can see everything

449
00:18:44,559 --> 00:18:47,140
happening in the system and if I include

450
00:18:47,140 --> 00:18:49,179
the front-end activities as well then

451
00:18:49,179 --> 00:18:51,279
everything in a potentially complex

452
00:18:51,279 --> 00:18:53,529
distributed system is apparent in one

453
00:18:53,529 --> 00:18:56,350
view not just what is happening how long

454
00:18:56,350 --> 00:18:58,809
what's blocking what and what can I

455
00:18:58,809 --> 00:19:01,330
improve about this and being able to see

456
00:19:01,330 --> 00:19:03,309
this happen in the wild actually user

457
00:19:03,309 --> 00:19:07,960
requests that is amazing and with that

458
00:19:07,960 --> 00:19:10,179
we can better understand our apps this

459
00:19:10,179 --> 00:19:11,770
can be an incredible tool not just for

460
00:19:11,770 --> 00:19:13,750
debugging performance but for onboarding

461
00:19:13,750 --> 00:19:16,360
new developers for seeing how different

462
00:19:16,360 --> 00:19:17,710
parts of the system that we haven't

463
00:19:17,710 --> 00:19:21,789
worked with yet work so checkout yogurt

464
00:19:21,789 --> 00:19:23,620
racing IO there's a really good place to

465
00:19:23,620 --> 00:19:25,570
start there they have an all-in-one

466
00:19:25,570 --> 00:19:27,640
docker image that you can pull down and

467
00:19:27,640 --> 00:19:30,460
when you run it it runs all the things

468
00:19:30,460 --> 00:19:34,059
you need to to to aggragate and receive

469
00:19:34,059 --> 00:19:36,760
requests for tracing and then see view

470
00:19:36,760 --> 00:19:40,809
them in their UI and I'll share some

471
00:19:40,809 --> 00:19:42,520
updates on Twitter follow me at Wills

472
00:19:42,520 --> 00:19:44,260
lab we're kin hunting that real-world

473
00:19:44,260 --> 00:19:46,539
example to share with you all and I'll

474
00:19:46,539 --> 00:19:48,370
be around for any questions thank you

475
00:19:48,370 --> 00:19:49,870
all for listening it's been a blast to

476
00:19:49,870 --> 00:19:51,159
to share this with you and I hope to

477
00:19:51,159 --> 00:19:52,480
discuss this more with you in the future

478
00:19:52,480 --> 00:19:53,540
thanks

479
00:19:53,540 --> 00:19:56,800
[Applause]

