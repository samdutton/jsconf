1
00:00:05,779 --> 00:00:08,920

good morning hello my name is Kyle Oba

2
00:00:08,920 --> 00:00:10,910
thank you to all the organizers and the

3
00:00:10,910 --> 00:00:12,980
volunteers for you know this has been an

4
00:00:12,980 --> 00:00:14,359
amazing experience so far I'm very

5
00:00:14,359 --> 00:00:16,070
excited to be here so you can probably

6
00:00:16,070 --> 00:00:19,490
tell I'm a little bit nervous so I know

7
00:00:19,490 --> 00:00:21,500
I'm just gonna dive right in alright so

8
00:00:21,500 --> 00:00:23,089
I work at a company called patio Cola we

9
00:00:23,089 --> 00:00:26,089
work on local local problems with local

10
00:00:26,089 --> 00:00:27,529
clients when you try to find local

11
00:00:27,529 --> 00:00:29,329
solutions as much as possible or a

12
00:00:29,329 --> 00:00:30,800
research and design and development

13
00:00:30,800 --> 00:00:32,960
company My partner and I started this

14
00:00:32,960 --> 00:00:35,690
company before moving to Hawaii but

15
00:00:35,690 --> 00:00:39,710
she's actually from Hawaii so that's

16
00:00:39,710 --> 00:00:41,480
where this whole like local little

17
00:00:41,480 --> 00:00:43,700
centered design and research comes from

18
00:00:43,700 --> 00:00:45,710
we partner with other researchers and

19
00:00:45,710 --> 00:00:48,020
designers and programmers but enough

20
00:00:48,020 --> 00:00:49,580
about me

21
00:00:49,580 --> 00:00:55,450
I'm sorry you can't see my slides Oh No

22
00:00:55,450 --> 00:01:06,410
should I just try to restart that okay

23
00:01:06,420 --> 00:01:14,370
okay cool thank you thank you that's my

24
00:01:14,370 --> 00:01:18,450
presentation keynote is the thing it

25
00:01:18,450 --> 00:01:19,080
used to work

26
00:01:19,080 --> 00:01:22,710
okay so cool alright so diving right in

27
00:01:22,710 --> 00:01:25,619
so the unprecedented so Shoshana Zubov

28
00:01:25,619 --> 00:01:26,820
just recently published a book called

29
00:01:26,820 --> 00:01:28,740
the age of surveillance capitalism I'm

30
00:01:28,740 --> 00:01:30,119
not gonna pretend to have read the whole

31
00:01:30,119 --> 00:01:31,590
thing because it's like over 700 pages

32
00:01:31,590 --> 00:01:35,790
and I'm a busy person but yeah so

33
00:01:35,790 --> 00:01:37,409
there's this idea they unprecedented and

34
00:01:37,409 --> 00:01:38,970
in her own words the unprecedent is

35
00:01:38,970 --> 00:01:41,820
necessarily unrecognizable right so when

36
00:01:41,820 --> 00:01:42,690
we encounter something that's

37
00:01:42,690 --> 00:01:44,580
unprecedented we automatically interpret

38
00:01:44,580 --> 00:01:45,630
it through the lenses that we are

39
00:01:45,630 --> 00:01:47,940
familiar with or the familiar categories

40
00:01:47,940 --> 00:01:50,280
thereby rendering invisible precisely

41
00:01:50,280 --> 00:01:52,080
which is unprecedented when I read this

42
00:01:52,080 --> 00:01:53,550
I was thinking wow this is amazing

43
00:01:53,550 --> 00:01:55,830
I admittedly was going to Center this

44
00:01:55,830 --> 00:01:58,770
talk all around context but I really

45
00:01:58,770 --> 00:02:01,950
like her idea here and so if you were

46
00:02:01,950 --> 00:02:05,640
living or visiting Hawaii about a year

47
00:02:05,640 --> 00:02:08,880
ago exactly almost you would have

48
00:02:08,880 --> 00:02:12,150
received this on your phone it's all

49
00:02:12,150 --> 00:02:13,500
caps so you know it's important

50
00:02:13,500 --> 00:02:15,840
ballistic missile threat in bounds of

51
00:02:15,840 --> 00:02:17,730
Hawaii seek immediate shelter and then

52
00:02:17,730 --> 00:02:19,920
if you were you're like is that real it

53
00:02:19,920 --> 00:02:22,829
says this is not a drill which you know

54
00:02:22,829 --> 00:02:24,570
usually I'm people are drilling me at

55
00:02:24,570 --> 00:02:26,070
8:00 in the morning on Saturday but

56
00:02:26,070 --> 00:02:29,370
whatever yeah so from my own experience

57
00:02:29,370 --> 00:02:31,769
you know I I saw this you know it was

58
00:02:31,769 --> 00:02:34,380
Saturday morning I just kind of calmly

59
00:02:34,380 --> 00:02:36,329
like doing stuff in the kitchen look at

60
00:02:36,329 --> 00:02:38,850
my phone and I guess I'm gonna die right

61
00:02:38,850 --> 00:02:44,250
and you know usually when I see you know

62
00:02:44,250 --> 00:02:45,510
we're all gonna die but whatever you

63
00:02:45,510 --> 00:02:48,540
know but when I see this type of message

64
00:02:48,540 --> 00:02:49,769
on my phone and maybe some of you got

65
00:02:49,769 --> 00:02:51,570
this last night but it's like there's a

66
00:02:51,570 --> 00:02:54,360
flood coming maybe you know there's a

67
00:02:54,360 --> 00:02:57,600
hurricane on its way maybe maybe you

68
00:02:57,600 --> 00:02:59,670
should care maybe right and so that's

69
00:02:59,670 --> 00:03:02,040
kind of the lens that I used to

70
00:03:02,040 --> 00:03:04,829
interpret this message which is kind of

71
00:03:04,829 --> 00:03:06,959
like what Zubov is saying it was totally

72
00:03:06,959 --> 00:03:08,940
the wrong lens to use it was just a lens

73
00:03:08,940 --> 00:03:11,160
I was familiar to me so I immediately

74
00:03:11,160 --> 00:03:13,980
started filling my water filter in the

75
00:03:13,980 --> 00:03:16,739
kitchen with water which seems

76
00:03:16,739 --> 00:03:18,780
reasonable but like when you but then

77
00:03:18,780 --> 00:03:19,770
like you know 38

78
00:03:19,770 --> 00:03:21,990
later when they say just kidding just

79
00:03:21,990 --> 00:03:23,610
just you didn't that's not real I really

80
00:03:23,610 --> 00:03:25,980
like had time to evaluate like my own

81
00:03:25,980 --> 00:03:28,860
behavior and and it really didn't make

82
00:03:28,860 --> 00:03:31,560
any sense I mean like if we got hit by a

83
00:03:31,560 --> 00:03:35,220
missile as pouring water I mean I don't

84
00:03:35,220 --> 00:03:38,640
you know didn't really matter okay cool

85
00:03:38,640 --> 00:03:40,830
so that's the idea of the unprecedent

86
00:03:40,830 --> 00:03:43,620
how we require these lenses in order to

87
00:03:43,620 --> 00:03:46,380
interpret new things and so obviously

88
00:03:46,380 --> 00:03:47,520
this talk it's a little bit about

89
00:03:47,520 --> 00:03:49,500
artificial intelligence which is kind of

90
00:03:49,500 --> 00:03:51,870
this weird broad term so like houses

91
00:03:51,870 --> 00:03:54,450
houses relevant to us today

92
00:03:54,450 --> 00:03:56,610
so as builders and designers as a lot of

93
00:03:56,610 --> 00:03:59,790
us are we need to create that new lens

94
00:03:59,790 --> 00:04:03,210
for ourselves in order to interpret that

95
00:04:03,210 --> 00:04:05,220
which is unprecedented to us and to the

96
00:04:05,220 --> 00:04:08,760
community or into society yeah one of

97
00:04:08,760 --> 00:04:10,110
the common themes to a lot of the work

98
00:04:10,110 --> 00:04:11,400
that we do is that we'd like to try to

99
00:04:11,400 --> 00:04:14,070
find the unrelatable things that are

100
00:04:14,070 --> 00:04:16,200
invisible things that are undefined and

101
00:04:16,200 --> 00:04:17,760
try to make them more relatable visible

102
00:04:17,760 --> 00:04:21,299
and articulate them more fully and it's

103
00:04:21,299 --> 00:04:22,260
only through the creation of these new

104
00:04:22,260 --> 00:04:23,880
lenses that we can bend further these

105
00:04:23,880 --> 00:04:26,820
discussions with our communities so as

106
00:04:26,820 --> 00:04:29,520
an example of that I wanted to take you

107
00:04:29,520 --> 00:04:32,220
all through a project that we did with

108
00:04:32,220 --> 00:04:34,260
the Honolulu Museum of Art which is just

109
00:04:34,260 --> 00:04:36,660
down the street and I highly recommend

110
00:04:36,660 --> 00:04:39,270
it so about the time that that alert

111
00:04:39,270 --> 00:04:42,060
came out we had the opportunity to do

112
00:04:42,060 --> 00:04:43,770
this project with the museum and we

113
00:04:43,770 --> 00:04:45,810
called it a design intervention and we

114
00:04:45,810 --> 00:04:47,640
wanted to sort of forward the discussion

115
00:04:47,640 --> 00:04:50,700
of surveillance technologies so at the

116
00:04:50,700 --> 00:04:52,320
time they had this program called

117
00:04:52,320 --> 00:04:54,870
classified that was produced by the

118
00:04:54,870 --> 00:04:56,130
Doris Duke theatre which is in the

119
00:04:56,130 --> 00:04:58,850
museum which was to highlight screening

120
00:04:58,850 --> 00:05:01,050
well highlights of the of the program

121
00:05:01,050 --> 00:05:02,580
were screening of films including lower

122
00:05:02,580 --> 00:05:05,669
Patras citizen for documentary about

123
00:05:05,669 --> 00:05:07,410
Edward Snowden and there was also a

124
00:05:07,410 --> 00:05:10,050
panel discussion so the panel discussion

125
00:05:10,050 --> 00:05:11,580
took place on you know just one

126
00:05:11,580 --> 00:05:13,830
particular day involved Kate Crawford

127
00:05:13,830 --> 00:05:15,900
one of the cofounders of the AI now

128
00:05:15,900 --> 00:05:17,580
Institute revver Paglen and artist who

129
00:05:17,580 --> 00:05:18,840
works with surveillance technologies

130
00:05:18,840 --> 00:05:21,180
Laura Patris the director Edward Snowden

131
00:05:21,180 --> 00:05:24,090
actually Skyped in and Ben Weisner who's

132
00:05:24,090 --> 00:05:26,910
his ACLU attorney and it was moderated

133
00:05:26,910 --> 00:05:28,680
by asan ilahe another artist who works

134
00:05:28,680 --> 00:05:30,300
with surveillance technologies or

135
00:05:30,300 --> 00:05:33,090
surveillance in general and so we were

136
00:05:33,090 --> 00:05:33,960
invited to sort of

137
00:05:33,960 --> 00:05:36,479
come and create an experience and so we

138
00:05:36,479 --> 00:05:39,000
dubbed it a design intervention to

139
00:05:39,000 --> 00:05:40,530
complement what was happening in the

140
00:05:40,530 --> 00:05:43,650
panel so so they the museum called it to

141
00:05:43,650 --> 00:05:46,979
my profile tour I'm not sure how I feel

142
00:05:46,979 --> 00:05:48,270
about that name but you know that it's

143
00:05:48,270 --> 00:05:49,650
stuck so that's what it is it's a my

144
00:05:49,650 --> 00:05:51,509
poster my profile took my profile choice

145
00:05:51,509 --> 00:05:53,910
it's a little it's a little 2004 a name

146
00:05:53,910 --> 00:05:57,350
I think a little bit but it's cool and

147
00:05:57,350 --> 00:06:01,050
so the purpose of our of our design

148
00:06:01,050 --> 00:06:03,030
intervention was to sort of raise raise

149
00:06:03,030 --> 00:06:05,820
awareness about things in Google that

150
00:06:05,820 --> 00:06:07,440
can go wrong so the fal ability of face

151
00:06:07,440 --> 00:06:09,750
detection face recognition technology

152
00:06:09,750 --> 00:06:13,199
and problematic data privacy issues so

153
00:06:13,199 --> 00:06:16,080
this is like about a year ago so we

154
00:06:16,080 --> 00:06:18,030
weren't well I'll just leave it at that

155
00:06:18,030 --> 00:06:19,020
so we were totally sure what was gonna

156
00:06:19,020 --> 00:06:20,190
happen with those issues but we knew

157
00:06:20,190 --> 00:06:22,590
they were problematic anyway so this was

158
00:06:22,590 --> 00:06:23,970
this was mentioned reduce public to

159
00:06:23,970 --> 00:06:26,789
specific technologies and the use cases

160
00:06:26,789 --> 00:06:29,070
of machine learning learning in the same

161
00:06:29,070 --> 00:06:32,460
giant amorphous AI thing and to replace

162
00:06:32,460 --> 00:06:34,650
sort of those marketing buzzwords with

163
00:06:34,650 --> 00:06:36,150
some a little bit more articulate

164
00:06:36,150 --> 00:06:38,430
discussion and specific discussion about

165
00:06:38,430 --> 00:06:41,580
these issues all right so what did we

166
00:06:41,580 --> 00:06:44,010
build so we built individual offices I

167
00:06:44,010 --> 00:06:44,789
don't know

168
00:06:44,789 --> 00:06:46,530
elevator pitch that we built into the

169
00:06:46,530 --> 00:06:49,380
individual eyes tours based on guests

170
00:06:49,380 --> 00:06:52,680
faces match to our currently on display

171
00:06:52,680 --> 00:06:54,930
in a museum okay and I know a lot of you

172
00:06:54,930 --> 00:06:55,470
are thinking

173
00:06:55,470 --> 00:06:58,409
isn't that what Google did in their app

174
00:06:58,409 --> 00:07:01,080
for Google arts and culture and now I'm

175
00:07:01,080 --> 00:07:03,360
not lying when I tell you this and you

176
00:07:03,360 --> 00:07:05,159
know that that's what Liars say but

177
00:07:05,159 --> 00:07:08,729
anyway we they really least there at

178
00:07:08,729 --> 00:07:10,470
like two weeks before we went live and

179
00:07:10,470 --> 00:07:12,120
it was just sort of uncanny I actually

180
00:07:12,120 --> 00:07:13,500
didn't find out about their app until

181
00:07:13,500 --> 00:07:16,380
after we after the panel and I was like

182
00:07:16,380 --> 00:07:18,690
oh wow that that's disappointing but at

183
00:07:18,690 --> 00:07:21,180
the same time it was really interesting

184
00:07:21,180 --> 00:07:22,320
because they were doing something very

185
00:07:22,320 --> 00:07:25,500
very similar I can I'm so I'm gonna kind

186
00:07:25,500 --> 00:07:27,620
of walk you through how we did it and

187
00:07:27,620 --> 00:07:29,849
some of the differences but I think it

188
00:07:29,849 --> 00:07:32,070
was an uncanny coincidence and I think a

189
00:07:32,070 --> 00:07:33,330
lot of it had to do with how good

190
00:07:33,330 --> 00:07:35,250
certain types of Technology were like

191
00:07:35,250 --> 00:07:36,630
face recognition and detection we're

192
00:07:36,630 --> 00:07:39,000
getting at about that time like just and

193
00:07:39,000 --> 00:07:44,159
how easy it was to apply so all right so

194
00:07:44,159 --> 00:07:45,510
cool to my probe out here how did it

195
00:07:45,510 --> 00:07:47,630
work so step one you had to opt in

196
00:07:47,630 --> 00:07:50,030
not everybody had to do this as you can

197
00:07:50,030 --> 00:07:51,890
imagine at a panel discussion where

198
00:07:51,890 --> 00:07:53,660
Edward Snowden is skyping in in the

199
00:07:53,660 --> 00:07:55,130
state of Hawaii where he used to work

200
00:07:55,130 --> 00:07:57,470
it's a little bit weird to have somebody

201
00:07:57,470 --> 00:07:59,540
ask you to take a picture of you before

202
00:07:59,540 --> 00:08:01,340
you go into the panel so you had to opt

203
00:08:01,340 --> 00:08:04,130
in and then if you did opt in we took a

204
00:08:04,130 --> 00:08:06,500
picture of you and it said hey this is

205
00:08:06,500 --> 00:08:07,940
the picture we're taking would you like

206
00:08:07,940 --> 00:08:12,320
to opt in if you did we kind of labeled

207
00:08:12,320 --> 00:08:13,490
you in the wheel world we gave you a

208
00:08:13,490 --> 00:08:15,980
sticker and a number on there it's sort

209
00:08:15,980 --> 00:08:18,110
of like sort of a symbolic like your

210
00:08:18,110 --> 00:08:22,610
this is happening to you yeah I mean you

211
00:08:22,610 --> 00:08:24,740
know let's be fair not every website

212
00:08:24,740 --> 00:08:26,270
does this okay well they don't give you

213
00:08:26,270 --> 00:08:28,010
a sticker well actually the stickers are

214
00:08:28,010 --> 00:08:31,100
a thing but anyway okay oh yeah

215
00:08:31,100 --> 00:08:32,570
incidentally ask me later I asked you

216
00:08:32,570 --> 00:08:35,479
should give up all right cool so the

217
00:08:35,479 --> 00:08:38,090
four-step customized tour so the panel

218
00:08:38,090 --> 00:08:40,490
was an hour long so before you walked in

219
00:08:40,490 --> 00:08:42,289
we took your picture when you walked out

220
00:08:42,289 --> 00:08:44,510
we handed you a customized tour so there

221
00:08:44,510 --> 00:08:45,740
was a lot that went into sort of

222
00:08:45,740 --> 00:08:47,510
printing and formatting and laying these

223
00:08:47,510 --> 00:08:49,670
things out ahead of time so that only

224
00:08:49,670 --> 00:08:51,350
the live customized content would be

225
00:08:51,350 --> 00:08:55,760
applied cool so the process so I know

226
00:08:55,760 --> 00:08:56,990
this is a little small for you to see

227
00:08:56,990 --> 00:08:58,970
I'm sorry about that this is sort of

228
00:08:58,970 --> 00:09:01,700
like a version from the version of what

229
00:09:01,700 --> 00:09:03,920
we put out in a handout and so basically

230
00:09:03,920 --> 00:09:06,260
the top part of it is stuff that

231
00:09:06,260 --> 00:09:08,120
happened ahead of time and the bottom

232
00:09:08,120 --> 00:09:11,330
part is stuff that happened on site that

233
00:09:11,330 --> 00:09:15,010
day and I'll walk you through that so

234
00:09:15,010 --> 00:09:17,900
step one of I think almost every one of

235
00:09:17,900 --> 00:09:19,610
these machine learning slash you know

236
00:09:19,610 --> 00:09:21,140
whatever you want to call it artificial

237
00:09:21,140 --> 00:09:22,970
intelligence projects is data collection

238
00:09:22,970 --> 00:09:24,860
right or getting data from somewhere and

239
00:09:24,860 --> 00:09:26,600
so as you can imagine when you're

240
00:09:26,600 --> 00:09:28,160
working with a museum who hasn't really

241
00:09:28,160 --> 00:09:29,960
done this type of thing before data

242
00:09:29,960 --> 00:09:31,760
collection is hard data collection is

243
00:09:31,760 --> 00:09:34,370
hard I in my experience no matter what

244
00:09:34,370 --> 00:09:37,310
project I'm working on so we had to walk

245
00:09:37,310 --> 00:09:38,990
through the entire museum find out where

246
00:09:38,990 --> 00:09:41,060
all the art was write down all the

247
00:09:41,060 --> 00:09:42,560
numbers associated with that art and

248
00:09:42,560 --> 00:09:44,450
figure out what they were called what

249
00:09:44,450 --> 00:09:46,490
room they were in and then get a photo

250
00:09:46,490 --> 00:09:49,370
of everything that was that was a lot of

251
00:09:49,370 --> 00:09:53,030
work and then we sort of processed the

252
00:09:53,030 --> 00:09:54,380
images of the art as well as the

253
00:09:54,380 --> 00:09:56,330
sculpture so anything that they had that

254
00:09:56,330 --> 00:09:58,010
was going to be on this display at that

255
00:09:58,010 --> 00:09:59,570
time that wasn't in sort of like a

256
00:09:59,570 --> 00:10:00,990
special exhibition where

257
00:10:00,990 --> 00:10:03,930
allowed to photograph the art we pass it

258
00:10:03,930 --> 00:10:07,380
through a face detection neural network

259
00:10:07,380 --> 00:10:09,540
which is essentially just says hey I

260
00:10:09,540 --> 00:10:10,890
think there's a face here and I think

261
00:10:10,890 --> 00:10:13,020
it's inside of this rectangle and then

262
00:10:13,020 --> 00:10:16,680
you can highlight that or crop it out so

263
00:10:16,680 --> 00:10:18,060
in this case we just cropped out the

264
00:10:18,060 --> 00:10:19,800
faces and then we used a second neural

265
00:10:19,800 --> 00:10:22,709
network which was a landmark prediction

266
00:10:22,709 --> 00:10:24,089
neural network which essentially says

267
00:10:24,089 --> 00:10:25,740
hey we're I think the eyebrows are

268
00:10:25,740 --> 00:10:27,330
probably you know based on you telling

269
00:10:27,330 --> 00:10:29,310
me this is a face I think this is where

270
00:10:29,310 --> 00:10:31,410
the eyebrows are the eyes the nose the

271
00:10:31,410 --> 00:10:35,160
mouth the jaw etc and the image on the

272
00:10:35,160 --> 00:10:37,620
bottom there which is me I just wanted

273
00:10:37,620 --> 00:10:39,690
to throw in here that although we did a

274
00:10:39,690 --> 00:10:41,700
lot of this in Python because the

275
00:10:41,700 --> 00:10:45,750
beginning of every web project using

276
00:10:45,750 --> 00:10:48,060
machine learning is to install Python on

277
00:10:48,060 --> 00:10:51,779
your machine this is something that you

278
00:10:51,779 --> 00:10:53,130
can actually do in the web so I wanted

279
00:10:53,130 --> 00:10:54,930
to put this link here this is an example

280
00:10:54,930 --> 00:10:59,010
that runs in ml 5j s and is rendered

281
00:10:59,010 --> 00:11:01,290
with p5.js or you know sort of like put

282
00:11:01,290 --> 00:11:03,810
into the browser with p5.js it's super

283
00:11:03,810 --> 00:11:05,579
cool so if you're like if you if you

284
00:11:05,579 --> 00:11:07,589
love javascript you can do all this

285
00:11:07,589 --> 00:11:08,670
stuff from the comfort of your

286
00:11:08,670 --> 00:11:10,740
JavaScript but just remember you have to

287
00:11:10,740 --> 00:11:12,870
install Python because that's just

288
00:11:12,870 --> 00:11:14,940
required but don't be afraid of Python

289
00:11:14,940 --> 00:11:17,430
it's just executable pseudo code all

290
00:11:17,430 --> 00:11:18,329
right

291
00:11:18,329 --> 00:11:22,860
next let's see that's a joke for the

292
00:11:22,860 --> 00:11:24,959
Python people all right so this prepares

293
00:11:24,959 --> 00:11:27,930
us for numerical comfort comparison so

294
00:11:27,930 --> 00:11:30,839
and we can actually pass that set of

295
00:11:30,839 --> 00:11:32,089
landmarks through a face recognition

296
00:11:32,089 --> 00:11:34,860
neural network weather then essentially

297
00:11:34,860 --> 00:11:36,360
render that image into a bunch of

298
00:11:36,360 --> 00:11:38,430
numbers right like big vector all right

299
00:11:38,430 --> 00:11:40,529
and so now that we have sort of a face

300
00:11:40,529 --> 00:11:42,420
and we know where the landmarks are

301
00:11:42,420 --> 00:11:44,220
we've turned it into a bunch of numbers

302
00:11:44,220 --> 00:11:46,470
we can start matching it to things okay

303
00:11:46,470 --> 00:11:47,910
so like on the so beast a ball that

304
00:11:47,910 --> 00:11:49,740
stuff away and then on the day of the

305
00:11:49,740 --> 00:11:50,279
event

306
00:11:50,279 --> 00:11:52,350
people come in we take their picture

307
00:11:52,350 --> 00:11:55,890
right and then we find the landmarks on

308
00:11:55,890 --> 00:11:59,910
their face and then we can then render

309
00:11:59,910 --> 00:12:02,190
them into numbers and then match them to

310
00:12:02,190 --> 00:12:06,870
the art that they're similar to cool and

311
00:12:06,870 --> 00:12:08,910
then since we have facial scary facial

312
00:12:08,910 --> 00:12:11,339
recognition software we can then say hey

313
00:12:11,339 --> 00:12:12,720
do you want your tor

314
00:12:12,720 --> 00:12:14,430
oh we know who you are so here's

315
00:12:14,430 --> 00:12:16,110
- right so that was another thing we

316
00:12:16,110 --> 00:12:19,440
added so it wasn't just about matching

317
00:12:19,440 --> 00:12:21,540
faces to art we also did a number of

318
00:12:21,540 --> 00:12:25,260
other things so this is the tour folded

319
00:12:25,260 --> 00:12:26,760
up that we handed to them so it has

320
00:12:26,760 --> 00:12:28,470
their face it has their landmarks and it

321
00:12:28,470 --> 00:12:30,589
has a number of super problematic

322
00:12:30,589 --> 00:12:32,730
classifications that we said we're

323
00:12:32,730 --> 00:12:35,450
attributes of you based on your face and

324
00:12:35,450 --> 00:12:38,339
this was not meant to be like true it

325
00:12:38,339 --> 00:12:39,720
was meant to be like super problematic

326
00:12:39,720 --> 00:12:41,370
and something that people should

327
00:12:41,370 --> 00:12:43,500
question so special thanks to Kyle

328
00:12:43,500 --> 00:12:47,250
McDonald who is an artist who trained

329
00:12:47,250 --> 00:12:48,810
the neural network to work with these

330
00:12:48,810 --> 00:12:50,910
classifications on the labeled faces of

331
00:12:50,910 --> 00:12:53,760
the wild data set it's another one of

332
00:12:53,760 --> 00:12:55,380
things where you you can pop that thing

333
00:12:55,380 --> 00:12:59,310
into anyway I won't go into it so these

334
00:12:59,310 --> 00:13:01,380
labels were we're super problematic and

335
00:13:01,380 --> 00:13:03,149
I think in some cases kind of insulting

336
00:13:03,149 --> 00:13:04,470
it might tell you you're not attractive

337
00:13:04,470 --> 00:13:07,140
right and some it might tell you you

338
00:13:07,140 --> 00:13:09,029
look tired you know stuff like that and

339
00:13:09,029 --> 00:13:11,220
you know that's not something you want

340
00:13:11,220 --> 00:13:12,800
to hear from computer or anybody but

341
00:13:12,800 --> 00:13:16,820
nonetheless computers will do that and

342
00:13:16,820 --> 00:13:19,560
um so the next page we actually this is

343
00:13:19,560 --> 00:13:21,480
the stuff that was besides the labels

344
00:13:21,480 --> 00:13:24,360
was custom generated so here we were

345
00:13:24,360 --> 00:13:25,890
able to say okay we think you look like

346
00:13:25,890 --> 00:13:27,390
this painting we think you look like

347
00:13:27,390 --> 00:13:29,160
this sculpture and then based on

348
00:13:29,160 --> 00:13:30,930
everything that was in the frame when

349
00:13:30,930 --> 00:13:32,640
you took your photo we match it we're

350
00:13:32,640 --> 00:13:34,800
matching you using a different neural

351
00:13:34,800 --> 00:13:37,440
network that does object matching and

352
00:13:37,440 --> 00:13:38,910
I'll go into that a little bit later and

353
00:13:38,910 --> 00:13:41,820
then because of your classification that

354
00:13:41,820 --> 00:13:42,330
we gave you

355
00:13:42,330 --> 00:13:44,190
we're gonna say this piece of art is

356
00:13:44,190 --> 00:13:45,300
something you might be interested in

357
00:13:45,300 --> 00:13:47,490
based on what was strongest in your

358
00:13:47,490 --> 00:13:50,040
classifications and then whoop and then

359
00:13:50,040 --> 00:13:52,529
we created a path through other pieces

360
00:13:52,529 --> 00:13:54,630
of art that's sort of like provided this

361
00:13:54,630 --> 00:13:56,130
sort of like trail that you could follow

362
00:13:56,130 --> 00:14:00,170
from one our piece of art to the next

363
00:14:00,170 --> 00:14:02,880
this was an educational project so what

364
00:14:02,880 --> 00:14:04,650
we really wanted to do was to provide

365
00:14:04,650 --> 00:14:06,690
people a way to question the technology

366
00:14:06,690 --> 00:14:09,270
and have it be personal so that people

367
00:14:09,270 --> 00:14:11,850
could have a further more articulate

368
00:14:11,850 --> 00:14:14,100
discussion in the community so we also

369
00:14:14,100 --> 00:14:15,300
wanted to highlight where our

370
00:14:15,300 --> 00:14:17,700
technologies failed I'll go into that a

371
00:14:17,700 --> 00:14:20,850
little bit and then also we provided

372
00:14:20,850 --> 00:14:23,040
details about how the artwork was chosen

373
00:14:23,040 --> 00:14:25,020
a very technical level if people wanted

374
00:14:25,020 --> 00:14:27,510
to get them out as well

375
00:14:27,510 --> 00:14:28,890
so cool so one of the things that we

376
00:14:28,890 --> 00:14:31,170
really wanted to do was to say you know

377
00:14:31,170 --> 00:14:33,120
what are the ways that we can use to

378
00:14:33,120 --> 00:14:36,360
find art that we can match to people and

379
00:14:36,360 --> 00:14:38,310
so one of the techniques that we came

380
00:14:38,310 --> 00:14:39,450
across was something called reverse

381
00:14:39,450 --> 00:14:41,390
image search and so reverse image search

382
00:14:41,390 --> 00:14:44,370
essentially you take an image you use an

383
00:14:44,370 --> 00:14:47,880
object detection neural network and you

384
00:14:47,880 --> 00:14:50,130
kind of short-circuit it to provide you

385
00:14:50,130 --> 00:14:53,460
with numbers instead of names of things

386
00:14:53,460 --> 00:14:55,500
and then with those numbers you can sort

387
00:14:55,500 --> 00:14:57,000
of compare them to other objects and

388
00:14:57,000 --> 00:14:59,730
find in the data set other objects that

389
00:14:59,730 --> 00:15:01,200
look the same so I'll just kind of let

390
00:15:01,200 --> 00:15:05,220
that let that picture clean itself one

391
00:15:05,220 --> 00:15:06,420
of the object neural the neural networks

392
00:15:06,420 --> 00:15:08,550
are used was called vgg 16 it's 16

393
00:15:08,550 --> 00:15:10,740
layers you slice off the last layer that

394
00:15:10,740 --> 00:15:12,180
basically tells you what the thing is

395
00:15:12,180 --> 00:15:14,520
and you're left with it with a giant

396
00:15:14,520 --> 00:15:17,030
vector for every object that's numbers

397
00:15:17,030 --> 00:15:19,890
here's another example of finding stuff

398
00:15:19,890 --> 00:15:21,650
that's similar to the vase on the left

399
00:15:21,650 --> 00:15:24,000
so once you've got these numbers you

400
00:15:24,000 --> 00:15:25,320
basically have coordinates in this

401
00:15:25,320 --> 00:15:27,600
multi-dimensional space and you can use

402
00:15:27,600 --> 00:15:31,410
traditional distance algorithms to see

403
00:15:31,410 --> 00:15:34,290
what's close to what and then once you

404
00:15:34,290 --> 00:15:36,240
do something called PCA analysis or

405
00:15:36,240 --> 00:15:37,680
principal component analysis you can

406
00:15:37,680 --> 00:15:39,900
slam you know four thousand dimensions

407
00:15:39,900 --> 00:15:42,120
down into two dimensions using this

408
00:15:42,120 --> 00:15:45,240
algorithm which essentially maintains

409
00:15:45,240 --> 00:15:47,700
closeness of points in multi-dimensional

410
00:15:47,700 --> 00:15:50,370
space in the two dimensional translation

411
00:15:50,370 --> 00:15:52,230
and then once you're in two dimensions

412
00:15:52,230 --> 00:15:53,550
you can use traditional graphing

413
00:15:53,550 --> 00:15:55,620
algorithm or graph algorithms to find

414
00:15:55,620 --> 00:15:57,810
shortest paths like you would to find a

415
00:15:57,810 --> 00:16:00,900
route through a city so in this case we

416
00:16:00,900 --> 00:16:02,610
have a picture of a person you may have

417
00:16:02,610 --> 00:16:05,280
heard of him and the and a vase on the

418
00:16:05,280 --> 00:16:06,690
right hand side and we tried to find

419
00:16:06,690 --> 00:16:08,700
items in the museum collection that

420
00:16:08,700 --> 00:16:10,140
would sort of like transition from one

421
00:16:10,140 --> 00:16:12,150
to the next I'm not sure how convincing

422
00:16:12,150 --> 00:16:14,450
this is I kind of think it's convincing

423
00:16:14,450 --> 00:16:17,340
maybe it's like bias on me for selecting

424
00:16:17,340 --> 00:16:19,830
this but anyway you kind of get the

425
00:16:19,830 --> 00:16:22,680
picture this is how we selected art so

426
00:16:22,680 --> 00:16:26,490
lessons learned we had to try a lot of

427
00:16:26,490 --> 00:16:29,610
different ways to try to find things

428
00:16:29,610 --> 00:16:31,920
that would work - Matt - convincingly

429
00:16:31,920 --> 00:16:34,020
match you to something that's in the art

430
00:16:34,020 --> 00:16:35,970
right - a piece of art and once we got

431
00:16:35,970 --> 00:16:37,350
to this point we're like yeah that's

432
00:16:37,350 --> 00:16:38,760
pretty good Zuckerberg looks like that

433
00:16:38,760 --> 00:16:41,180
guy so okay we're like

434
00:16:41,180 --> 00:16:44,240
we're done alright but there's also

435
00:16:44,240 --> 00:16:49,880
mistakes that are made and I should have

436
00:16:49,880 --> 00:16:51,950
put like a warning or something on the

437
00:16:51,950 --> 00:16:54,080
previous slide so that we started out

438
00:16:54,080 --> 00:16:55,520
with this thing called the opencv whore

439
00:16:55,520 --> 00:16:57,200
classifier to find faces and it turns

440
00:16:57,200 --> 00:16:59,330
out it's not that good or at least it

441
00:16:59,330 --> 00:17:01,010
was good for a while but then when you

442
00:17:01,010 --> 00:17:02,360
know these convolutional neural networks

443
00:17:02,360 --> 00:17:03,860
came out we ended up using one byte

444
00:17:03,860 --> 00:17:06,110
called D live which hasn't I put that as

445
00:17:06,110 --> 00:17:09,650
a Python API it got much better but we

446
00:17:09,650 --> 00:17:10,940
were getting results like this and I I

447
00:17:10,940 --> 00:17:12,860
just I mean it's like automatic

448
00:17:12,860 --> 00:17:17,120
screenshots save right also privacy

449
00:17:17,120 --> 00:17:19,010
policy this is one of the least the

450
00:17:19,010 --> 00:17:20,810
lesser successful parts of the project

451
00:17:20,810 --> 00:17:22,970
was we put a giant wall sized terms and

452
00:17:22,970 --> 00:17:25,670
conditions on the wall to remind people

453
00:17:25,670 --> 00:17:28,090
that we were taking their images and

454
00:17:28,090 --> 00:17:30,530
making conclusions about them and

455
00:17:30,530 --> 00:17:32,600
recording it on a computer and and

456
00:17:32,600 --> 00:17:34,490
basically saying all the horrible things

457
00:17:34,490 --> 00:17:36,050
we could do with that information and

458
00:17:36,050 --> 00:17:37,640
then at the very end which they liked

459
00:17:37,640 --> 00:17:38,660
but we're not gonna do and we're gonna

460
00:17:38,660 --> 00:17:40,250
believe your data in 30 days but you

461
00:17:40,250 --> 00:17:42,410
should really think about this and I

462
00:17:42,410 --> 00:17:43,700
don't know what it is about putting

463
00:17:43,700 --> 00:17:45,230
terms and conditions in front of people

464
00:17:45,230 --> 00:17:47,030
but they don't want to read them so

465
00:17:47,030 --> 00:17:49,460
almost nobody read this which is a

466
00:17:49,460 --> 00:17:50,630
little disappointing for our graphic

467
00:17:50,630 --> 00:17:53,570
designer that we work with but it did

468
00:17:53,570 --> 00:17:55,220
teach this lesson that it was really

469
00:17:55,220 --> 00:17:56,990
incumbent on us to make this more

470
00:17:56,990 --> 00:18:00,680
approachable and consumable another

471
00:18:00,680 --> 00:18:03,350
super difficult thing to deal with was

472
00:18:03,350 --> 00:18:06,110
using the classifications and labeling

473
00:18:06,110 --> 00:18:08,120
the data that exists in the Y or exists

474
00:18:08,120 --> 00:18:11,810
currently right if you look at this it's

475
00:18:11,810 --> 00:18:13,340
probably too small for you to see but if

476
00:18:13,340 --> 00:18:15,260
you look at this up close you'll see

477
00:18:15,260 --> 00:18:17,270
that there's only four ethnicities

478
00:18:17,270 --> 00:18:20,980
available in the label faces in the wild

479
00:18:20,980 --> 00:18:25,880
attribute classifiers black white Asian

480
00:18:25,880 --> 00:18:27,650
and Indian I thought Asians and Indians

481
00:18:27,650 --> 00:18:30,830
were kind of but whatever and you know

482
00:18:30,830 --> 00:18:32,630
we're in Hawaii we're doing this project

483
00:18:32,630 --> 00:18:34,190
in Hawaii there's a lot of Southeast

484
00:18:34,190 --> 00:18:35,780
Asians right if you just say Asia and

485
00:18:35,780 --> 00:18:36,920
you're like I don't know and there's

486
00:18:36,920 --> 00:18:41,120
like it it's everybody almost and yeah

487
00:18:41,120 --> 00:18:43,460
and there's no Hawaiian right so you

488
00:18:43,460 --> 00:18:44,690
know there's so you kind of like leaving

489
00:18:44,690 --> 00:18:46,520
out a giant portion of the population

490
00:18:46,520 --> 00:18:48,740
and then also I'd probably not need to

491
00:18:48,740 --> 00:18:50,510
go into it but you know art collections

492
00:18:50,510 --> 00:18:52,810
that you're using this for also have a

493
00:18:52,810 --> 00:18:55,530
bias

494
00:18:55,530 --> 00:18:57,990
kind of taking a wider view you know I

495
00:18:57,990 --> 00:18:59,070
found this when we were doing our

496
00:18:59,070 --> 00:19:01,140
research there's obvious bias here I

497
00:19:01,140 --> 00:19:02,700
don't need to go into it but the dataset

498
00:19:02,700 --> 00:19:05,840
has a bias the engineers have a bias

499
00:19:05,840 --> 00:19:08,669
there's bias out there people anyway and

500
00:19:08,669 --> 00:19:11,309
then so this is Hawaii

501
00:19:11,309 --> 00:19:12,990
Hawaii's weird and this is why it's my

502
00:19:12,990 --> 00:19:14,640
concern why is super unique in the

503
00:19:14,640 --> 00:19:16,500
United States we're number one in terms

504
00:19:16,500 --> 00:19:17,730
of the percentage of non-white

505
00:19:17,730 --> 00:19:20,160
population even looking at this chart

506
00:19:20,160 --> 00:19:22,230
there's no category for Hawaiians

507
00:19:22,230 --> 00:19:24,720
there's also no category for mixed mixed

508
00:19:24,720 --> 00:19:28,380
race or ethnicity so so why is that

509
00:19:28,380 --> 00:19:30,780
right because the bar graph tool didn't

510
00:19:30,780 --> 00:19:33,179
really allow for that and then also

511
00:19:33,179 --> 00:19:35,370
locally our Police Department just

512
00:19:35,370 --> 00:19:37,830
bought 1200 axial on body cameras which

513
00:19:37,830 --> 00:19:39,660
sounds a lot like letting my axe on body

514
00:19:39,660 --> 00:19:42,030
cameras and I'm a little worried about

515
00:19:42,030 --> 00:19:44,010
that because you know

516
00:19:44,010 --> 00:19:45,510
excellent has an AI division

517
00:19:45,510 --> 00:19:48,360
headquartered in Scottsdale Arizona and

518
00:19:48,360 --> 00:19:50,160
you know if bias are the thing maybe

519
00:19:50,160 --> 00:19:51,120
this is something we should be concerned

520
00:19:51,120 --> 00:19:53,700
about why looks very different than

521
00:19:53,700 --> 00:19:57,210
Scottsdale Arizona and a worthwhile so I

522
00:19:57,210 --> 00:19:59,490
think in the words of so I'm gonna leave

523
00:19:59,490 --> 00:20:00,660
you with a couple of coats so we're

524
00:20:00,660 --> 00:20:04,140
worthwhile what's what exercise would be

525
00:20:04,140 --> 00:20:05,730
to delete the word technology from

526
00:20:05,730 --> 00:20:07,290
vocabulary in order to see how quickly

527
00:20:07,290 --> 00:20:10,850
capitalism's objectives are exposed okay

528
00:20:10,850 --> 00:20:13,950
marketing is powerful right AI I believe

529
00:20:13,950 --> 00:20:16,530
is one of those terms which if not more

530
00:20:16,530 --> 00:20:18,330
clearly defined it's essentially just

531
00:20:18,330 --> 00:20:21,270
marketing right and AI means anything

532
00:20:21,270 --> 00:20:22,830
that's all powerful and inevitable and

533
00:20:22,830 --> 00:20:26,190
as long as we we allow that term to be

534
00:20:26,190 --> 00:20:27,570
just thrown around without properly

535
00:20:27,570 --> 00:20:29,460
defining it we're basically giving in to

536
00:20:29,460 --> 00:20:31,710
this sort of desire to just say it's

537
00:20:31,710 --> 00:20:33,570
inevitable it's all powerful it's gonna

538
00:20:33,570 --> 00:20:35,520
happen let's just let it right so

539
00:20:35,520 --> 00:20:36,929
where's it so there's an opportunity for

540
00:20:36,929 --> 00:20:38,010
us and I'm gonna just kind of go through

541
00:20:38,010 --> 00:20:40,410
this real quick but this is actually

542
00:20:40,410 --> 00:20:42,299
happening like people are getting

543
00:20:42,299 --> 00:20:45,690
tickets in China because their picture

544
00:20:45,690 --> 00:20:48,059
goes across the intersection right we

545
00:20:48,059 --> 00:20:49,679
don't really have to let that happen

546
00:20:49,679 --> 00:20:54,809
but we do also this quote by having

547
00:20:54,809 --> 00:20:56,370
anymore is also inefficiency is

548
00:20:56,370 --> 00:20:58,410
precisely what shelters us from the APA

549
00:20:58,410 --> 00:21:00,360
inhumanity of Taylorism and market

550
00:21:00,360 --> 00:21:02,640
fundamentalism so when it efficiency is

551
00:21:02,640 --> 00:21:03,720
the result of the deliberative

552
00:21:03,720 --> 00:21:05,520
commitment by a democratically run

553
00:21:05,520 --> 00:21:06,360
community

554
00:21:06,360 --> 00:21:08,220
no need to eliminate it even if the

555
00:21:08,220 --> 00:21:09,600
latest technologies can accomplish that

556
00:21:09,600 --> 00:21:12,290
in no time I love this guy's books I

557
00:21:12,290 --> 00:21:15,480
highly recommend them essentially

558
00:21:15,480 --> 00:21:17,550
sometimes in efficiencies a good thing

559
00:21:17,550 --> 00:21:19,440
we should think about it one think about

560
00:21:19,440 --> 00:21:21,690
it when we eliminate it and then finally

561
00:21:21,690 --> 00:21:23,880
so technology is not and never can be a

562
00:21:23,880 --> 00:21:25,860
thing in itself isolated from economies

563
00:21:25,860 --> 00:21:28,140
and it kind of economics and society

564
00:21:28,140 --> 00:21:29,730
this means that technological

565
00:21:29,730 --> 00:21:33,150
inevitability does not exist and I can't

566
00:21:33,150 --> 00:21:38,460
I love this quote it's it's everything

567
00:21:38,460 --> 00:21:41,670
that that that we love about the work

568
00:21:41,670 --> 00:21:43,530
that we do is learning about the

569
00:21:43,530 --> 00:21:44,670
communities and learning about the

570
00:21:44,670 --> 00:21:46,340
technology that they use and

571
00:21:46,340 --> 00:21:48,480
understanding when it's appropriate to

572
00:21:48,480 --> 00:21:50,010
apply the technology and when it's

573
00:21:50,010 --> 00:21:51,420
appropriate to step back and just sort

574
00:21:51,420 --> 00:21:55,800
of listen so I encourage you all to take

575
00:21:55,800 --> 00:21:57,930
this you know what did I end on a high

576
00:21:57,930 --> 00:22:01,440
note so today to take what I've said

577
00:22:01,440 --> 00:22:03,090
it's like go forth to your local

578
00:22:03,090 --> 00:22:05,220
communities and see how you can create

579
00:22:05,220 --> 00:22:08,970
your own lens and use your lens to shape

580
00:22:08,970 --> 00:22:10,350
the future with these technologies

581
00:22:10,350 --> 00:22:14,340
because none of this is inevitable so

582
00:22:14,340 --> 00:22:15,310
thank you very much

