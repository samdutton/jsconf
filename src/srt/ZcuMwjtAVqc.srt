1
00:00:34,670 --> 00:00:36,980

I don't I don't know if many people in

2
00:00:36,980 --> 00:00:39,589
this room know who I am if you don't get

3
00:00:39,589 --> 00:00:41,300
this reference then that's not good and

4
00:00:41,300 --> 00:00:42,890
you you gotta catch opening Jackie Chan

5
00:00:42,890 --> 00:00:44,019
movies

6
00:00:44,019 --> 00:00:46,219
so let's want to give a brief

7
00:00:46,219 --> 00:00:48,440
introduction to myself Who I am what I

8
00:00:48,440 --> 00:00:51,140
work on again my name is Jared Nichols

9
00:00:51,140 --> 00:00:53,539
and I work at Sencha I work in the

10
00:00:53,539 --> 00:00:57,320
center's web platform team which is like

11
00:00:57,320 --> 00:00:59,149
a corporate name for the web kid team we

12
00:00:59,149 --> 00:01:01,280
just do web Kitty things we work on

13
00:01:01,280 --> 00:01:02,899
WebKit products and we can you should be

14
00:01:02,899 --> 00:01:05,810
back to the WebKit project and I'm a

15
00:01:05,810 --> 00:01:08,360
WebKit committer for those who don't

16
00:01:08,360 --> 00:01:10,310
know what that means it just means I can

17
00:01:10,310 --> 00:01:13,159
push to the repository of WebKit nothing

18
00:01:13,159 --> 00:01:17,479
fancy and I'm also co work co-author of

19
00:01:17,479 --> 00:01:20,509
the w3c web cryptography API this

20
00:01:20,509 --> 00:01:23,750
technically doesn't exist yet it's it's

21
00:01:23,750 --> 00:01:25,940
coming though the the working group is

22
00:01:25,940 --> 00:01:28,250
knew it was recently chartered and it's

23
00:01:28,250 --> 00:01:31,069
in the Advisory Committee stage so once

24
00:01:31,069 --> 00:01:32,869
it gets out of that stage then this will

25
00:01:32,869 --> 00:01:35,810
be will be a you know full steam ahead

26
00:01:35,810 --> 00:01:37,429
on this and I'm working together with

27
00:01:37,429 --> 00:01:41,210
David dolphin Mozilla on this so that's

28
00:01:41,210 --> 00:01:42,920
just briefly who I am when I'm working

29
00:01:42,920 --> 00:01:45,320
on but today I'm not gonna talk about

30
00:01:45,320 --> 00:01:46,640
any of those things I'm talking about

31
00:01:46,640 --> 00:01:49,219
something totally different JavaScript

32
00:01:49,219 --> 00:01:51,530
on the GPU is there something that's

33
00:01:51,530 --> 00:01:54,799
caught my fancy recently it's more or

34
00:01:54,799 --> 00:01:57,979
less just a side secret pet project

35
00:01:57,979 --> 00:01:59,869
experiment that I'm working on with a

36
00:01:59,869 --> 00:02:02,450
couple of my own my friends today I'm

37
00:02:02,450 --> 00:02:04,789
just going to talk about like why job's

38
00:02:04,789 --> 00:02:06,259
getting the GPU why is that interesting

39
00:02:06,259 --> 00:02:10,220
why would we want that if if any of you

40
00:02:10,220 --> 00:02:11,989
were here for the first session on

41
00:02:11,989 --> 00:02:13,549
Monday when you heard Stephan from Intel

42
00:02:13,549 --> 00:02:17,030
talking he was he gave all the reasons

43
00:02:17,030 --> 00:02:19,459
why we should care about JavaScript

44
00:02:19,459 --> 00:02:21,739
running on the GPU doing data parallel

45
00:02:21,739 --> 00:02:24,920
tasks so I will go over that briefly but

46
00:02:24,920 --> 00:02:26,510
I think everybody who attended that has

47
00:02:26,510 --> 00:02:29,239
the gist of it and then we're gonna talk

48
00:02:29,239 --> 00:02:31,010
about getting jobs going to GPU how we

49
00:02:31,010 --> 00:02:33,470
do that and the approach to that I took

50
00:02:33,470 --> 00:02:37,100
it's a insane approach and we'll walk

51
00:02:37,100 --> 00:02:38,600
over that and show you all the issues

52
00:02:38,600 --> 00:02:41,660
that I ran to it's crazy so after you

53
00:02:41,660 --> 00:02:42,440
talk about that then we talk about

54
00:02:42,440 --> 00:02:43,360
what's to come

55
00:02:43,360 --> 00:02:46,760
so why JavaScript the GPU again we

56
00:02:46,760 --> 00:02:47,670
already kind of covered that

57
00:02:47,670 --> 00:02:50,130
but they're really that there's two

58
00:02:50,130 --> 00:02:52,530
answers one is why not and the other

59
00:02:52,530 --> 00:02:54,959
answer is there's a better question and

60
00:02:54,959 --> 00:03:01,080
why the GPU the GPU is fast okay it's

61
00:03:01,080 --> 00:03:02,760
fast it's not faceted everything as fast

62
00:03:02,760 --> 00:03:04,830
as certain types of things and these

63
00:03:04,830 --> 00:03:06,270
things are what we need to target on

64
00:03:06,270 --> 00:03:08,700
GPUs and they're fast because there are

65
00:03:08,700 --> 00:03:10,380
totally different paradigm their

66
00:03:10,380 --> 00:03:11,489
architectures totally different from

67
00:03:11,489 --> 00:03:14,100
CPUs they're geared towards data

68
00:03:14,100 --> 00:03:17,550
parallel tasks and stream processing so

69
00:03:17,550 --> 00:03:19,670
taking a stream or set of data

70
00:03:19,670 --> 00:03:22,560
performing operations on every element

71
00:03:22,560 --> 00:03:25,470
of that that set of data and doing it

72
00:03:25,470 --> 00:03:27,299
all in parallel and it takes a

73
00:03:27,299 --> 00:03:28,860
divide-and-conquer approach it has many

74
00:03:28,860 --> 00:03:32,040
small working stream processing units to

75
00:03:32,040 --> 00:03:35,910
to do this and each of those processing

76
00:03:35,910 --> 00:03:37,769
users you can say that it can run a

77
00:03:37,769 --> 00:03:41,580
thread of general-purpose code and for

78
00:03:41,580 --> 00:03:44,010
example on my on my laptop here my HCI

79
00:03:44,010 --> 00:03:46,769
Radeon has four engines 480 stream

80
00:03:46,769 --> 00:03:48,660
processing unit sources effectively 480

81
00:03:48,660 --> 00:03:50,310
small little cores to do something for

82
00:03:50,310 --> 00:03:53,370
us on my mac pro back to my office that

83
00:03:53,370 --> 00:03:57,570
has like 1600 so you can imagine how

84
00:03:57,570 --> 00:03:59,940
much you can get done at one time on

85
00:03:59,940 --> 00:04:02,549
these on these GPUs in general they have

86
00:04:02,549 --> 00:04:04,530
a high memory bandwidth a lot higher

87
00:04:04,530 --> 00:04:06,630
than system memory

88
00:04:06,630 --> 00:04:08,640
most of the advertised values are

89
00:04:08,640 --> 00:04:10,200
theoretical so you have to take

90
00:04:10,200 --> 00:04:12,000
advantage of the GPU 100% to get to

91
00:04:12,000 --> 00:04:14,340
those values but in general the

92
00:04:14,340 --> 00:04:15,810
bandwidth is much faster than you know

93
00:04:15,810 --> 00:04:18,690
system memory to a CPU and they can

94
00:04:18,690 --> 00:04:20,489
they're specialized you know they were

95
00:04:20,489 --> 00:04:24,060
made for mathematical operations

96
00:04:24,060 --> 00:04:26,400
particularly with you know games and

97
00:04:26,400 --> 00:04:28,710
they had to specialize in processing

98
00:04:28,710 --> 00:04:30,840
floating-point operations really fast

99
00:04:30,840 --> 00:04:34,110
and a lot of them at same time but they

100
00:04:34,110 --> 00:04:36,060
don't solve all problems again they you

101
00:04:36,060 --> 00:04:37,860
can't just throw any task or any any

102
00:04:37,860 --> 00:04:39,630
problem at a GPU and expect it to go

103
00:04:39,630 --> 00:04:42,030
faster it's just a that's that's a false

104
00:04:42,030 --> 00:04:44,880
statement so they have you have to throw

105
00:04:44,880 --> 00:04:47,520
something a problem set that can be run

106
00:04:47,520 --> 00:04:50,160
in parallel homogeneous if you will

107
00:04:50,160 --> 00:04:52,440
side-effect free Stephan cover this well

108
00:04:52,440 --> 00:04:55,289
so I won't go any further so I just

109
00:04:55,289 --> 00:04:57,840
asked myself a question how well would

110
00:04:57,840 --> 00:04:59,660
jobs could run on the GPU if we throw

111
00:04:59,660 --> 00:05:03,200
JavaScript running GPU let's I just want

112
00:05:03,200 --> 00:05:04,430
to know how that would happen all right

113
00:05:04,430 --> 00:05:06,080
how well would that work so we're gonna

114
00:05:06,080 --> 00:05:10,010
find out so a couple buddies of mine who

115
00:05:10,010 --> 00:05:11,780
work Accenture as well we decided to

116
00:05:11,780 --> 00:05:13,100
start a little experiment we codenamed a

117
00:05:13,100 --> 00:05:16,400
lateral Jas and that experiment was to

118
00:05:16,400 --> 00:05:18,320
get JavaScript as a first-class citizen

119
00:05:18,320 --> 00:05:23,810
on GPUs to run 100% compliant and to

120
00:05:23,810 --> 00:05:25,370
take advantage of the GPUs in certain

121
00:05:25,370 --> 00:05:27,680
ways to do data parallelization and

122
00:05:27,680 --> 00:05:31,280
accelerate operations like native native

123
00:05:31,280 --> 00:05:32,900
floating point operations instructions

124
00:05:32,900 --> 00:05:35,840
built right into the hardware so we had

125
00:05:35,840 --> 00:05:38,090
two options to get a general-purpose

126
00:05:38,090 --> 00:05:41,420
you know whatever to run JavaScript on

127
00:05:41,420 --> 00:05:44,810
only GPU those two options were open CL

128
00:05:44,810 --> 00:05:49,160
and Nvidia CUDA and it's it's

129
00:05:49,160 --> 00:05:50,900
interesting how we how we chose what we

130
00:05:50,900 --> 00:05:53,270
did we went over a list and Nvidia CUDA

131
00:05:53,270 --> 00:05:55,790
has a lot of great abilities basically

132
00:05:55,790 --> 00:05:57,260
you can write a lot of general-purpose

133
00:05:57,260 --> 00:06:00,260
code and it will run on these GPUs but

134
00:06:00,260 --> 00:06:01,760
it's only for NVIDIA hardware and we

135
00:06:01,760 --> 00:06:03,500
want to kind of make this stuff run on

136
00:06:03,500 --> 00:06:06,890
all hardware all variable GPUs OpenCL

137
00:06:06,890 --> 00:06:10,610
accomplishes that and it has support and

138
00:06:10,610 --> 00:06:13,520
drivers for eight AMD Harbor and video

139
00:06:13,520 --> 00:06:14,810
hardware and even Intel like a

140
00:06:14,810 --> 00:06:17,930
celebrator processors but everything

141
00:06:17,930 --> 00:06:19,280
else about OpenGL sucks

142
00:06:19,280 --> 00:06:21,980
it's a terrible version of C you can't

143
00:06:21,980 --> 00:06:23,990
have dynamic memory you have no

144
00:06:23,990 --> 00:06:25,580
recursion available all functions are in

145
00:06:25,580 --> 00:06:28,010
line no function pointers there's no

146
00:06:28,010 --> 00:06:30,050
tooling like really hardly any tolling

147
00:06:30,050 --> 00:06:33,020
the Intel XDK is pretty good but I mean

148
00:06:33,020 --> 00:06:34,700
the tolling is just far behind on videos

149
00:06:34,700 --> 00:06:36,950
and it's a little bit mature it's a

150
00:06:36,950 --> 00:06:39,740
newer newer open standard but we went

151
00:06:39,740 --> 00:06:40,760
ahead and chose up and see all the one

152
00:06:40,760 --> 00:06:41,870
that sounded like a complete nightmare

153
00:06:41,870 --> 00:06:45,500
so we really wanted to target all those

154
00:06:45,500 --> 00:06:47,419
different GPUs but really the truth of

155
00:06:47,419 --> 00:06:52,010
it is our Mac books had AMD cards so we

156
00:06:52,010 --> 00:06:56,570
had to work with that so we had a couple

157
00:06:56,570 --> 00:06:57,800
of different routes were gonna take and

158
00:06:57,800 --> 00:06:58,730
the first one was doing a static

159
00:06:58,730 --> 00:07:00,500
compiler which is exactly where River

160
00:07:00,500 --> 00:07:02,450
Trail from Intel does it statically

161
00:07:02,450 --> 00:07:04,510
compiled JavaScript into up and CL code

162
00:07:04,510 --> 00:07:07,110
but we chose not to go that route

163
00:07:07,110 --> 00:07:09,120
for one we wanted full JavaScript

164
00:07:09,120 --> 00:07:11,280
support we wanted objects and prototypes

165
00:07:11,280 --> 00:07:14,610
closures recursion variable typing all

166
00:07:14,610 --> 00:07:16,110
the things you get with JavaScript we

167
00:07:16,110 --> 00:07:17,759
want you know compliant JavaScript to

168
00:07:17,759 --> 00:07:21,900
run on this on the GPUs and to

169
00:07:21,900 --> 00:07:23,849
accomplish a really good stack of holo

170
00:07:23,849 --> 00:07:24,990
you have to do a lot of type inference

171
00:07:24,990 --> 00:07:26,789
which is pretty limiting it can be

172
00:07:26,789 --> 00:07:29,220
solved for some cases but the rabbit

173
00:07:29,220 --> 00:07:30,900
hole gets pretty deep to figure it out

174
00:07:30,900 --> 00:07:33,270
stuff out statically and you know if you

175
00:07:33,270 --> 00:07:35,639
if you have a really good static

176
00:07:35,639 --> 00:07:36,870
compiler can figure stuff out you're

177
00:07:36,870 --> 00:07:38,310
basically at that point interpreting the

178
00:07:38,310 --> 00:07:41,970
code so that compilers are tough to

179
00:07:41,970 --> 00:07:43,560
solve all those problems and get 100%

180
00:07:43,560 --> 00:07:47,159
applying JavaScript running so again

181
00:07:47,159 --> 00:07:48,960
with the sac compiler you're kind of

182
00:07:48,960 --> 00:07:51,210
limited to those kernel size functions

183
00:07:51,210 --> 00:07:53,370
which are perfect for you know doing

184
00:07:53,370 --> 00:07:55,139
these data breaking up these tasks to

185
00:07:55,139 --> 00:07:57,030
homogeneous parts and and running

186
00:07:57,030 --> 00:07:59,430
parallel tasks on this hardware so you

187
00:07:59,430 --> 00:08:01,620
know writing a small kernel function in

188
00:08:01,620 --> 00:08:02,789
JavaScript totally possible to

189
00:08:02,789 --> 00:08:04,319
statically compiled that river turtles

190
00:08:04,319 --> 00:08:06,449
doing it but we just didn't think it was

191
00:08:06,449 --> 00:08:07,740
insane enough we wanted to do something

192
00:08:07,740 --> 00:08:09,539
that is just totally crazy and see how

193
00:08:09,539 --> 00:08:13,139
it would run so what we did was Roberto

194
00:08:13,139 --> 00:08:16,020
J's interpreter and OpenCL seeing which

195
00:08:16,020 --> 00:08:19,530
is really crazy and you know for the

196
00:08:19,530 --> 00:08:21,330
reasons reasons why we did that it's

197
00:08:21,330 --> 00:08:22,349
just the opposite of what I just said

198
00:08:22,349 --> 00:08:24,419
you know we can run full JavaScript it's

199
00:08:24,419 --> 00:08:26,490
it is insane we have no idea how it was

200
00:08:26,490 --> 00:08:27,900
going to perform we know wasn't gonna be

201
00:08:27,900 --> 00:08:29,639
great we just want to see how it work

202
00:08:29,639 --> 00:08:34,020
right and you know it is a challenge it

203
00:08:34,020 --> 00:08:35,339
would be a challenge to make that happen

204
00:08:35,339 --> 00:08:36,930
especially with all the deficiencies in

205
00:08:36,930 --> 00:08:39,810
OpenCL so we thought it'd be fun and

206
00:08:39,810 --> 00:08:41,459
then if you can make it at least work

207
00:08:41,459 --> 00:08:42,750
then we can make it better and actually

208
00:08:42,750 --> 00:08:44,010
make it you know something that is

209
00:08:44,010 --> 00:08:46,829
practical to use to solve real world

210
00:08:46,829 --> 00:08:49,170
problems so first we talk about all the

211
00:08:49,170 --> 00:08:51,240
headaches we ran into just diving into

212
00:08:51,240 --> 00:08:53,279
OpenCL and getting an interpreter

213
00:08:53,279 --> 00:08:57,120
written as we all know the best cure for

214
00:08:57,120 --> 00:08:58,470
headache is decapitation another

215
00:08:58,470 --> 00:08:59,700
insanity well if I love the insanity

216
00:08:59,700 --> 00:09:04,860
wolf so we ran into some issues and

217
00:09:04,860 --> 00:09:08,190
here's a list of them with these

218
00:09:08,190 --> 00:09:09,660
general-purpose

219
00:09:09,660 --> 00:09:14,100
GPU SDKs or specs if you will they they

220
00:09:14,100 --> 00:09:16,260
allow you to really optimize your code

221
00:09:16,260 --> 00:09:18,600
to different memory addresses there's

222
00:09:18,600 --> 00:09:20,579
multiple memory address spaces on these

223
00:09:20,579 --> 00:09:23,489
on this Hong from these devices that you

224
00:09:23,489 --> 00:09:25,230
can target with your code and they kind

225
00:09:25,230 --> 00:09:28,230
of tear down from really fast but

226
00:09:28,230 --> 00:09:30,839
limited amount to you know your entire

227
00:09:30,839 --> 00:09:33,329
available vram but super slow bandwidth

228
00:09:33,329 --> 00:09:35,399
right so you have all these different

229
00:09:35,399 --> 00:09:38,850
options and in dealing with those

230
00:09:38,850 --> 00:09:40,079
different address spaces you have to

231
00:09:40,079 --> 00:09:41,549
know that you know when you're dealing

232
00:09:41,549 --> 00:09:44,220
with pointers to address to addresses in

233
00:09:44,220 --> 00:09:47,970
those spaces they are totally different

234
00:09:47,970 --> 00:09:49,920
they're just autonomous you know sets of

235
00:09:49,920 --> 00:09:51,089
memory and so when you have all these

236
00:09:51,089 --> 00:09:54,299
pointers you have to fully qualify what

237
00:09:54,299 --> 00:09:55,949
the pointer is pointing to so it's tough

238
00:09:55,949 --> 00:09:58,769
it's this really verbose code again no

239
00:09:58,769 --> 00:10:01,980
recursion all inline functions so you

240
00:10:01,980 --> 00:10:02,910
know writing interpreter without

241
00:10:02,910 --> 00:10:04,649
recursion it's certainly possible but

242
00:10:04,649 --> 00:10:08,910
it's hard so we'll get into what we have

243
00:10:08,910 --> 00:10:10,739
to do with that and there's no standard

244
00:10:10,739 --> 00:10:13,799
Lipsy libraries whatsoever I mean you're

245
00:10:13,799 --> 00:10:16,139
stuck with nothing really you don't have

246
00:10:16,139 --> 00:10:18,989
you know mem coffee or string age or and

247
00:10:18,989 --> 00:10:20,629
you know any of that stuff it's not good

248
00:10:20,629 --> 00:10:23,850
no dynamic memory again so what do you

249
00:10:23,850 --> 00:10:25,110
do with no I mean you can't do you can

250
00:10:25,110 --> 00:10:27,449
allocate memory okay so what do you do I

251
00:10:27,449 --> 00:10:31,769
mean and then you know they don't have

252
00:10:31,769 --> 00:10:32,939
any standard data structures they do

253
00:10:32,939 --> 00:10:35,660
have like vector you know for numeric

254
00:10:35,660 --> 00:10:38,610
values that you can do vector operations

255
00:10:38,610 --> 00:10:39,899
which you know harbors tuned for that

256
00:10:39,899 --> 00:10:41,489
but apart from that they don't have like

257
00:10:41,489 --> 00:10:43,410
standard data structures like stacks and

258
00:10:43,410 --> 00:10:45,470
queues and linkless and so like that so

259
00:10:45,470 --> 00:10:48,389
and then in general OpenCL since it's so

260
00:10:48,389 --> 00:10:50,220
fresh you know the compilers with the

261
00:10:50,220 --> 00:10:51,509
drivers are pretty buggy they have

262
00:10:51,509 --> 00:10:53,189
problems they have memory alignment

263
00:10:53,189 --> 00:10:55,199
issues it was a nightmare trying to get

264
00:10:55,199 --> 00:10:57,179
this thing get this thing working so in

265
00:10:57,179 --> 00:10:58,980
general it's bananas there's totally

266
00:10:58,980 --> 00:11:01,919
bananas so real quick the memory space

267
00:11:01,919 --> 00:11:04,259
is you have private which is very fast

268
00:11:04,259 --> 00:11:06,540
it's like cache on each individual

269
00:11:06,540 --> 00:11:08,339
processing core in the in the hardware

270
00:11:08,339 --> 00:11:10,980
effectively it's super fast but you only

271
00:11:10,980 --> 00:11:13,100
get about 64k of the per working onion

272
00:11:13,100 --> 00:11:15,689
then you have local memory which is also

273
00:11:15,689 --> 00:11:17,730
fast it's available to a group but

274
00:11:17,730 --> 00:11:19,589
limited again like 64 K on average

275
00:11:19,589 --> 00:11:21,110
depending on the harbor and the drivers

276
00:11:21,110 --> 00:11:22,980
then you have global memory which is

277
00:11:22,980 --> 00:11:24,809
basically all of your available vrm it's

278
00:11:24,809 --> 00:11:26,999
slow much much much much much lower than

279
00:11:26,999 --> 00:11:30,539
private or local memory but it's

280
00:11:30,539 --> 00:11:32,640
available to you know every available

281
00:11:32,640 --> 00:11:33,840
work item that's running for that

282
00:11:33,840 --> 00:11:38,370
particular kernel on the device so to

283
00:11:38,370 --> 00:11:39,570
talk about let you know to go a little

284
00:11:39,570 --> 00:11:41,850
more detail but the pointer problems we

285
00:11:41,850 --> 00:11:43,880
had with these different address spaces

286
00:11:43,880 --> 00:11:47,640
you have to fully qualify pointers to a

287
00:11:47,640 --> 00:11:49,320
particular address space if you don't

288
00:11:49,320 --> 00:11:50,780
qualify it then it's implied to be

289
00:11:50,780 --> 00:11:53,220
living in the private very pointing to

290
00:11:53,220 --> 00:11:55,950
address in private memory and so when

291
00:11:55,950 --> 00:11:58,410
you write functions you have to fully

292
00:11:58,410 --> 00:11:59,850
qualify the incoming pointer if you're

293
00:11:59,850 --> 00:12:02,990
passing a pointer to a function and that

294
00:12:02,990 --> 00:12:06,510
gets kind of nuts so that you can see

295
00:12:06,510 --> 00:12:07,920
here like if you have an address for K

296
00:12:07,920 --> 00:12:09,510
is pointing to different spots and

297
00:12:09,510 --> 00:12:11,070
global local and private so you have to

298
00:12:11,070 --> 00:12:13,110
keep that in mind you can't just turn a

299
00:12:13,110 --> 00:12:15,390
global pointer into a local pointer and

300
00:12:15,390 --> 00:12:16,800
expect it to work you have to copy the

301
00:12:16,800 --> 00:12:21,000
data over so because you have to fully

302
00:12:21,000 --> 00:12:22,920
qualify all these dress spaces it just

303
00:12:22,920 --> 00:12:24,330
got really redundant so we create some

304
00:12:24,330 --> 00:12:26,310
macros to help us out and keep the code

305
00:12:26,310 --> 00:12:30,270
a little bit shorter now no recursion so

306
00:12:30,270 --> 00:12:32,340
there's no call stack and I don't know

307
00:12:32,340 --> 00:12:33,600
whether it's a chicken and egg omelet

308
00:12:33,600 --> 00:12:35,330
there's no call checkers are in lined or

309
00:12:35,330 --> 00:12:37,320
they're in lining it because there's no

310
00:12:37,320 --> 00:12:38,810
call stack I don't know what it is but

311
00:12:38,810 --> 00:12:41,130
you can't write recursive functions

312
00:12:41,130 --> 00:12:43,530
again no standard Lib C libraries new

313
00:12:43,530 --> 00:12:45,930
mem copy string copy string compare so

314
00:12:45,930 --> 00:12:48,530
we just implemented that ourselves

315
00:12:48,530 --> 00:12:52,890
now we had to do this really strangely

316
00:12:52,890 --> 00:12:55,050
we had to actually write these functions

317
00:12:55,050 --> 00:12:58,230
as macros and then create a whole bunch

318
00:12:58,230 --> 00:13:00,590
of versions of the same function but

319
00:13:00,590 --> 00:13:02,150
using different address spaces

320
00:13:02,150 --> 00:13:04,740
qualifying different address spaces so

321
00:13:04,740 --> 00:13:06,840
you can see that this macro will produce

322
00:13:06,840 --> 00:13:09,210
12 different copies of this M copy

323
00:13:09,210 --> 00:13:11,460
function which is kind of it kind of

324
00:13:11,460 --> 00:13:13,020
sucks because I mean these functions are

325
00:13:13,020 --> 00:13:15,750
all in line when they're used so I was

326
00:13:15,750 --> 00:13:17,940
taking up a lot of space but that's what

327
00:13:17,940 --> 00:13:19,440
you have to do to make this clean and be

328
00:13:19,440 --> 00:13:21,380
able to just cleanly pass in a

329
00:13:21,380 --> 00:13:23,610
destination of a global pointer and a

330
00:13:23,610 --> 00:13:25,380
source of a private pointer and just

331
00:13:25,380 --> 00:13:26,850
have it work I mean I don't at

332
00:13:26,850 --> 00:13:28,860
development I'm you know which what your

333
00:13:28,860 --> 00:13:30,420
source and destination is and so you can

334
00:13:30,420 --> 00:13:33,300
say I want to do mem copy underscore GP

335
00:13:33,300 --> 00:13:35,490
and it'll just work you want to do like

336
00:13:35,490 --> 00:13:39,270
casting and whatnot so so we had to do

337
00:13:39,270 --> 00:13:41,820
this for every single Lib C function

338
00:13:41,820 --> 00:13:43,080
that we implemented which is all a

339
00:13:43,080 --> 00:13:44,200
string age some of

340
00:13:44,200 --> 00:13:47,440
etc so it's kind of nuts no dying

341
00:13:47,440 --> 00:13:49,450
memories a new mouth no free what to do

342
00:13:49,450 --> 00:13:53,139
do it ourselves so we had to create a

343
00:13:53,139 --> 00:13:54,940
large buffle of buffer excuse me of

344
00:13:54,940 --> 00:13:56,709
global memory which would just call our

345
00:13:56,709 --> 00:13:58,389
heap it's our virtual heap if you will

346
00:13:58,389 --> 00:14:00,660
and we inflated our own malloc and free

347
00:14:00,660 --> 00:14:02,740
we had to create our own pointer uh

348
00:14:02,740 --> 00:14:04,630
excuse me uh handle system is like a

349
00:14:04,630 --> 00:14:07,240
smart pointer that kind of points like a

350
00:14:07,240 --> 00:14:09,639
virtual memory right and we had to do

351
00:14:09,639 --> 00:14:11,889
that because as soon as you free data

352
00:14:11,889 --> 00:14:13,510
and we decide we win the kind of

353
00:14:13,510 --> 00:14:16,930
compressed data or rearrange it much

354
00:14:16,930 --> 00:14:20,019
like an OS would do pointers would be

355
00:14:20,019 --> 00:14:22,120
immediately invalidated they wouldn't

356
00:14:22,120 --> 00:14:23,560
point to the right data anymore so we

357
00:14:23,560 --> 00:14:26,260
had to create a handle and every time

358
00:14:26,260 --> 00:14:27,730
you wanted to do something with the

359
00:14:27,730 --> 00:14:30,160
handle put data or read data from it you

360
00:14:30,160 --> 00:14:31,570
had to get the pointer out of the handle

361
00:14:31,570 --> 00:14:33,459
and that pointer always be the right you

362
00:14:33,459 --> 00:14:34,660
know point to the right spot and then

363
00:14:34,660 --> 00:14:37,570
you could do something with it so that's

364
00:14:37,570 --> 00:14:40,990
what we had to do it's interesting but

365
00:14:40,990 --> 00:14:42,399
um I'll tell you what

366
00:14:42,399 --> 00:14:43,990
doing that I got a lot of these screens

367
00:14:43,990 --> 00:14:46,920
I definitely had a lot of memory issues

368
00:14:46,920 --> 00:14:50,260
and infinite loops and things like that

369
00:14:50,260 --> 00:14:53,620
yeah so I saw this I can't remember how

370
00:14:53,620 --> 00:14:54,699
many times out of restart my computer

371
00:14:54,699 --> 00:14:56,529
it's fun so you go I get the point

372
00:14:56,529 --> 00:14:57,579
there's a lot of headaches for doing

373
00:14:57,579 --> 00:15:02,199
this so finally we solved these problems

374
00:15:02,199 --> 00:15:03,670
OpenCL and now we're actually getting to

375
00:15:03,670 --> 00:15:05,800
what we wanted to do so we create out of

376
00:15:05,800 --> 00:15:07,600
a architecture of this host that runs in

377
00:15:07,600 --> 00:15:09,760
a process and the host has an embedded

378
00:15:09,760 --> 00:15:12,070
v8 engine that runs the Escrima parser

379
00:15:12,070 --> 00:15:16,089
everybody here saw Paul Irish talk about

380
00:15:16,089 --> 00:15:18,220
ass prima a little bit already out he

381
00:15:18,220 --> 00:15:19,839
he's a colleague of mine he wrote a

382
00:15:19,839 --> 00:15:22,240
stream into JavaScript parser it's super

383
00:15:22,240 --> 00:15:23,680
fast so we're using that to generate the

384
00:15:23,680 --> 00:15:26,740
ast of incoming JavaScript then we had

385
00:15:26,740 --> 00:15:27,670
like a little module in the host that

386
00:15:27,670 --> 00:15:30,640
does data serialization to and from the

387
00:15:30,640 --> 00:15:33,880
device and then a device manager so you

388
00:15:33,880 --> 00:15:37,510
can actually send JavaScript at the same

389
00:15:37,510 --> 00:15:39,730
time to different available devices on

390
00:15:39,730 --> 00:15:41,769
the system to get multiple GPUs they can

391
00:15:41,769 --> 00:15:44,079
manage that on the GPU side then we have

392
00:15:44,079 --> 00:15:46,269
our data heat that I've talked about a

393
00:15:46,269 --> 00:15:48,550
slow terrible stack based interpreter

394
00:15:48,550 --> 00:15:51,069
well we'll get into that and then a

395
00:15:51,069 --> 00:15:52,720
garbage collector so like the whole

396
00:15:52,720 --> 00:15:55,870
interpreters on the GPU and the host is

397
00:15:55,870 --> 00:15:57,550
basically just sending commands and

398
00:15:57,550 --> 00:16:00,730
things like that so what happens today's

399
00:16:00,730 --> 00:16:02,350
we get some code we're going to evaluate

400
00:16:02,350 --> 00:16:04,899
it it builds a json AST we convert that

401
00:16:04,899 --> 00:16:07,720
to a friendly c structure so we can

402
00:16:07,720 --> 00:16:10,209
easily read it over in the the open CL

403
00:16:10,209 --> 00:16:13,810
sign and we shipped the command say

404
00:16:13,810 --> 00:16:16,329
interpret this ast to the GPU and we get

405
00:16:16,329 --> 00:16:20,860
the result back so AST generation this

406
00:16:20,860 --> 00:16:21,819
is kind of how it works

407
00:16:21,819 --> 00:16:23,829
Java goes in this premium we get the v8

408
00:16:23,829 --> 00:16:25,779
object out we enumerate the v8 object

409
00:16:25,779 --> 00:16:27,790
convert it to see structures and then we

410
00:16:27,790 --> 00:16:30,670
send the C structures over as one big

411
00:16:30,670 --> 00:16:32,529
memory blob to the GPU so we can work

412
00:16:32,529 --> 00:16:34,839
with that we're we already put up with

413
00:16:34,839 --> 00:16:35,980
enough we're not gonna write a JSON

414
00:16:35,980 --> 00:16:37,779
parser and OpenCL see it's not gonna

415
00:16:37,779 --> 00:16:38,110
happen

416
00:16:38,110 --> 00:16:41,769
so so the first thing is embedding the

417
00:16:41,769 --> 00:16:43,540
stream of us so we very like a quick you

418
00:16:43,540 --> 00:16:45,160
know a resource generator all does it

419
00:16:45,160 --> 00:16:47,199
take the file in spits out you know a

420
00:16:47,199 --> 00:16:49,089
string of all the bytes and then we can

421
00:16:49,089 --> 00:16:51,670
use it inside of our code compiling a

422
00:16:51,670 --> 00:16:52,959
stream of running after the first time

423
00:16:52,959 --> 00:16:54,790
which initializes it and now it's ready

424
00:16:54,790 --> 00:16:56,800
to parse something so that's the agency

425
00:16:56,800 --> 00:16:59,199
generator initializing itself then you

426
00:16:59,199 --> 00:17:00,339
can throw anything out you can throw

427
00:17:00,339 --> 00:17:02,410
JavaScript at it so here's an example of

428
00:17:02,410 --> 00:17:06,339
a variable declaration XYZ and it's just

429
00:17:06,339 --> 00:17:08,350
it's a new expression for array of a

430
00:17:08,350 --> 00:17:11,620
size 10 this is the function experiment

431
00:17:11,620 --> 00:17:13,809
parse and if you don't if you never work

432
00:17:13,809 --> 00:17:16,089
the v8 then it all it's doing is calling

433
00:17:16,089 --> 00:17:17,740
a spring MoDOT parse passing in the

434
00:17:17,740 --> 00:17:19,900
JavaScript string getting a v8 object

435
00:17:19,900 --> 00:17:22,329
out and the v8 object holds

436
00:17:22,329 --> 00:17:25,630
json HT that looks just like this so

437
00:17:25,630 --> 00:17:27,429
then we have to take that and convert to

438
00:17:27,429 --> 00:17:29,669
the lateral ast Struck's

439
00:17:29,669 --> 00:17:34,200
so these trucks are made to you know be

440
00:17:34,200 --> 00:17:37,240
compiled and ran on both the host and

441
00:17:37,240 --> 00:17:39,309
the OpenCL run time so they have

442
00:17:39,309 --> 00:17:40,840
compatible types we had to do some

443
00:17:40,840 --> 00:17:42,880
macros to get types working you know

444
00:17:42,880 --> 00:17:44,970
cleanly on both both sides of the fence

445
00:17:44,970 --> 00:17:49,090
but we have an ast node structure for

446
00:17:49,090 --> 00:17:51,880
every single node in that JSON that you

447
00:17:51,880 --> 00:17:56,409
saw if we were to write this by hand

448
00:17:56,409 --> 00:17:59,669
what the v8 object and numerator does it

449
00:17:59,669 --> 00:18:01,980
would look like this it's a bunch of

450
00:18:01,980 --> 00:18:04,330
creation calls passing in different

451
00:18:04,330 --> 00:18:06,159
parts different nodes AFC nodes and

452
00:18:06,159 --> 00:18:08,260
creating blocks of

453
00:18:08,260 --> 00:18:11,650
ASD knows here's an example of creating

454
00:18:11,650 --> 00:18:14,429
identifiers so we had to get the

455
00:18:14,429 --> 00:18:16,929
calculate the size of what this identify

456
00:18:16,929 --> 00:18:19,450
will be in total including the structure

457
00:18:19,450 --> 00:18:20,950
size and then the string of the identify

458
00:18:20,950 --> 00:18:22,960
itself allocate all that memory and then

459
00:18:22,960 --> 00:18:25,330
we put the string into the right spot

460
00:18:25,330 --> 00:18:27,520
just tuck it right after the the

461
00:18:27,520 --> 00:18:30,250
structure so it's all one can take it as

462
00:18:30,250 --> 00:18:32,470
you know blob memory it would look like

463
00:18:32,470 --> 00:18:35,919
this you know size 16 name is a field in

464
00:18:35,919 --> 00:18:36,880
the identifiers

465
00:18:36,880 --> 00:18:38,770
structure and that just officer from the

466
00:18:38,770 --> 00:18:40,809
beginning of the header onion excuse me

467
00:18:40,809 --> 00:18:41,740
the beginning at the beginning of the

468
00:18:41,740 --> 00:18:44,559
shock and and so it's pointing to 12 and

469
00:18:44,559 --> 00:18:45,910
that 12 that's beginning of our string

470
00:18:45,910 --> 00:18:49,620
XYZ in the four bytes another example

471
00:18:49,620 --> 00:18:51,610
new expression is doing the same thing

472
00:18:51,610 --> 00:18:54,820
calculate the size to fit it's solved

473
00:18:54,820 --> 00:18:58,360
nodes into the the new expression blob

474
00:18:58,360 --> 00:19:01,090
and then it's copying all that in and so

475
00:19:01,090 --> 00:19:02,080
this was it would look like this in

476
00:19:02,080 --> 00:19:04,210
memory you know it's a total size of 50

477
00:19:04,210 --> 00:19:07,330
tube lights you have offsets for qwali

478
00:19:07,330 --> 00:19:09,700
20 arguments 40 and then at 20 and 40

479
00:19:09,700 --> 00:19:12,549
you you have those structures there in

480
00:19:12,549 --> 00:19:15,220
place so you can enumerate down if you

481
00:19:15,220 --> 00:19:19,299
will so lateral ast structs there again

482
00:19:19,299 --> 00:19:21,160
they're shared across both the hosts in

483
00:19:21,160 --> 00:19:22,809
the observer one time the host right

484
00:19:22,809 --> 00:19:25,120
stinkin creates them slowly and then the

485
00:19:25,120 --> 00:19:26,830
runtime is strictly reading down

486
00:19:26,830 --> 00:19:30,520
traversing it and it's really important

487
00:19:30,520 --> 00:19:32,260
that we did this as continuous blobs as

488
00:19:32,260 --> 00:19:34,750
you saw so that it was easy to send the

489
00:19:34,750 --> 00:19:36,340
gpo you're basically sending from byte

490
00:19:36,340 --> 00:19:39,220
you know start to bite end or a byte

491
00:19:39,220 --> 00:19:41,520
start this many bytes and it's one

492
00:19:41,520 --> 00:19:43,840
operation the Santa GPS we only have to

493
00:19:43,840 --> 00:19:45,490
go through the drivers and sent it a

494
00:19:45,490 --> 00:19:47,140
device one time the whole entire thing

495
00:19:47,140 --> 00:19:49,720
as opposed to you know following a bunch

496
00:19:49,720 --> 00:19:51,840
of pointers doing a bunch of writing so

497
00:19:51,840 --> 00:19:54,220
and it's still simple a diverse on the

498
00:19:54,220 --> 00:19:55,890
open CL side with a pointer arithmetic

499
00:19:55,890 --> 00:19:57,790
so now we're gonna get the de sac base

500
00:19:57,790 --> 00:20:00,220
interpreter this is where it gets fun

501
00:20:00,220 --> 00:20:03,100
we had some building blocks this is all

502
00:20:03,100 --> 00:20:06,070
stack base and it was the easiest thing

503
00:20:06,070 --> 00:20:07,780
to do at the time because of the fact

504
00:20:07,780 --> 00:20:12,520
that there is no recursion and we wanted

505
00:20:12,520 --> 00:20:14,230
to get done fast we were lazy we didn't

506
00:20:14,230 --> 00:20:16,120
do any compilation or anything so we

507
00:20:16,120 --> 00:20:18,159
just did all stack base so there's a

508
00:20:18,159 --> 00:20:19,780
stack for the ast traversal there's a

509
00:20:19,780 --> 00:20:21,880
stack for call operations

510
00:20:21,880 --> 00:20:24,580
do something with a particular part of

511
00:20:24,580 --> 00:20:27,580
the ASD and then a return stack so after

512
00:20:27,580 --> 00:20:29,950
you run an expression you have some sort

513
00:20:29,950 --> 00:20:32,530
of result after that we push those

514
00:20:32,530 --> 00:20:34,570
results on to the stack so they can be

515
00:20:34,570 --> 00:20:37,300
popped up later there's other parts that

516
00:20:37,300 --> 00:20:40,000
go symbol symbol table is important and

517
00:20:40,000 --> 00:20:41,290
then there's just a loop that goes

518
00:20:41,290 --> 00:20:44,560
through these these or fills up these

519
00:20:44,560 --> 00:20:45,910
stacks of how things off these stacks to

520
00:20:45,910 --> 00:20:47,530
interpret a code we're gonna see how

521
00:20:47,530 --> 00:20:48,280
that works

522
00:20:48,280 --> 00:20:50,170
here's the kernel function that that

523
00:20:50,170 --> 00:20:53,050
does it's the looping we basically

524
00:20:53,050 --> 00:20:54,760
Traverse as far down as we can until

525
00:20:54,760 --> 00:20:56,050
there's nothing left in the diverse

526
00:20:56,050 --> 00:20:58,060
stack and then we start popping things

527
00:20:58,060 --> 00:21:00,040
off the call stack and running them that

528
00:21:00,040 --> 00:21:01,510
things in the call stack could put more

529
00:21:01,510 --> 00:21:03,520
things on Traverse stack like a for loop

530
00:21:03,520 --> 00:21:08,050
for example but uh it once there once

531
00:21:08,050 --> 00:21:09,850
both stacks are empty you're done your

532
00:21:09,850 --> 00:21:11,580
your application knows ran to completion

533
00:21:11,580 --> 00:21:14,440
so let's quickly interpret this far x

534
00:21:14,440 --> 00:21:17,860
equals one plus two so here's the here's

535
00:21:17,860 --> 00:21:20,230
the ast on the Left we start with empty

536
00:21:20,230 --> 00:21:21,550
stacks right so first we're going at the

537
00:21:21,550 --> 00:21:22,900
variable decoration it's going to push

538
00:21:22,900 --> 00:21:26,200
itself onto the ast stack on the next

539
00:21:26,200 --> 00:21:28,360
loop it's gonna be popped off and its

540
00:21:28,360 --> 00:21:30,850
job is to push the variable decorator

541
00:21:30,850 --> 00:21:32,560
ones with this ast stack so traversing

542
00:21:32,560 --> 00:21:34,180
down at this point we're kind of going

543
00:21:34,180 --> 00:21:36,520
down as deeply as we can and then we'll

544
00:21:36,520 --> 00:21:37,930
kind of pull our way back up with the

545
00:21:37,930 --> 00:21:40,480
results and stuff so so it pushes very

546
00:21:40,480 --> 00:21:42,910
well decorator on pebble decorator pops

547
00:21:42,910 --> 00:21:44,740
off and pushes out the identifier and

548
00:21:44,740 --> 00:21:46,540
the binary expression onto the SD stack

549
00:21:46,540 --> 00:21:48,100
and then puts itself in the call stack

550
00:21:48,100 --> 00:21:52,330
to later retrieve results then binary

551
00:21:52,330 --> 00:21:54,520
expression is is popped off puts its

552
00:21:54,520 --> 00:21:56,800
both of its operands onto the ast stack

553
00:21:56,800 --> 00:21:58,900
the left and the right which are just

554
00:21:58,900 --> 00:22:01,450
literals so one literals popped off

555
00:22:01,450 --> 00:22:03,070
putting the call stack the next ones put

556
00:22:03,070 --> 00:22:04,840
in the call stack and then the

557
00:22:04,840 --> 00:22:06,970
identifiers the last thing now our ast

558
00:22:06,970 --> 00:22:08,740
traversals done we've hit every node

559
00:22:08,740 --> 00:22:11,140
that we can we want to at this point

560
00:22:11,140 --> 00:22:13,270
it's now we can actually start popping

561
00:22:13,270 --> 00:22:14,980
off calls from the call stack and doing

562
00:22:14,980 --> 00:22:17,020
something with them so identifier pops

563
00:22:17,020 --> 00:22:18,550
this off off creates a JavaScript string

564
00:22:18,550 --> 00:22:21,040
puts into the resolved stack literal

565
00:22:21,040 --> 00:22:22,780
does the same thing pop self off puts a

566
00:22:22,780 --> 00:22:24,520
JavaScript number and into the returned

567
00:22:24,520 --> 00:22:25,870
stack is you know

568
00:22:25,870 --> 00:22:28,690
and then same thing with two and then

569
00:22:28,690 --> 00:22:31,059
binary pops off it pulls in the right

570
00:22:31,059 --> 00:22:32,740
operand and then the left operand as you

571
00:22:32,740 --> 00:22:35,080
could see right it was two and left was

572
00:22:35,080 --> 00:22:37,990
one and then it does something with them

573
00:22:37,990 --> 00:22:39,789
it wants to perform the binary

574
00:22:39,789 --> 00:22:41,830
expression so it does the and it sees

575
00:22:41,830 --> 00:22:43,419
the operators plus okay I'm gonna go

576
00:22:43,419 --> 00:22:44,950
ahead and add them together the results

577
00:22:44,950 --> 00:22:46,330
three and it pushes that result on to

578
00:22:46,330 --> 00:22:48,760
the return and then the last thing in

579
00:22:48,760 --> 00:22:50,200
the call stack is the variable decorator

580
00:22:50,200 --> 00:22:53,529
so it pops off it pulls off the init

581
00:22:53,529 --> 00:22:57,340
three and then it pulls off the ID X and

582
00:22:57,340 --> 00:22:59,169
it says I'm gonna store into the symbol

583
00:22:59,169 --> 00:23:01,659
table you know a symbol of X with it and

584
00:23:01,659 --> 00:23:05,289
it has a value of three and now we're

585
00:23:05,289 --> 00:23:07,000
done interpreting their code so that's

586
00:23:07,000 --> 00:23:10,600
kind of how it works and anybody who is

587
00:23:10,600 --> 00:23:14,830
a JavaScript interpreter guru maybe like

588
00:23:14,830 --> 00:23:16,750
Andy is probably like this is the worst

589
00:23:16,750 --> 00:23:17,850
thing I've ever seen in my life

590
00:23:17,850 --> 00:23:20,860
because it is it really is but it was

591
00:23:20,860 --> 00:23:22,179
this was all like a perfect concept

592
00:23:22,179 --> 00:23:23,470
experiment to see what we can do with

593
00:23:23,470 --> 00:23:25,510
this right so we wanted to see how it

594
00:23:25,510 --> 00:23:27,309
would work how it would perform so we

595
00:23:27,309 --> 00:23:28,840
just we did as quickly as kind of stack

596
00:23:28,840 --> 00:23:32,260
base benchmark it it's actually to do so

597
00:23:32,260 --> 00:23:34,059
we did a just a really small loop of

598
00:23:34,059 --> 00:23:36,130
flops you know the harbor's really good

599
00:23:36,130 --> 00:23:38,289
at flops we we mapped you know the power

600
00:23:38,289 --> 00:23:39,520
operation to the native power

601
00:23:39,520 --> 00:23:41,830
instruction on the GPU so it run as fast

602
00:23:41,830 --> 00:23:43,840
as possible that's not the slowest part

603
00:23:43,840 --> 00:23:47,230
of this thing though so we ran it the

604
00:23:47,230 --> 00:23:50,950
lateral interpreter on both GPU and on

605
00:23:50,950 --> 00:23:54,010
the CPU since OpenCL can do that it just

606
00:23:54,010 --> 00:23:56,409
compiles with LLVM down to the x86

607
00:23:56,409 --> 00:23:58,120
instructions or whatever process you're

608
00:23:58,120 --> 00:24:00,520
running and and we just want to compare

609
00:24:00,520 --> 00:24:01,840
the two and then we ran the same block

610
00:24:01,840 --> 00:24:04,899
of code in v8 and this the results are

611
00:24:04,899 --> 00:24:08,610
not that surprising GPU incredibly slow

612
00:24:08,610 --> 00:24:10,779
116 milliseconds just to do that little

613
00:24:10,779 --> 00:24:15,399
tiny thing this awful on the cpu is 0.2

614
00:24:15,399 --> 00:24:17,250
2 milliseconds which is interesting

615
00:24:17,250 --> 00:24:20,260
that's not not well it's kind of what it

616
00:24:20,260 --> 00:24:22,480
is what we expected but the difference

617
00:24:22,480 --> 00:24:23,890
is not what we expected is a huge

618
00:24:23,890 --> 00:24:26,020
difference and v8

619
00:24:26,020 --> 00:24:29,320
shocker is like no time at all it's in

620
00:24:29,320 --> 00:24:33,000
the nanoseconds so you don't say

621
00:24:33,000 --> 00:24:37,980
so surprising so like I mean this this

622
00:24:37,980 --> 00:24:40,260
number the numbers in the lateral sigh

623
00:24:40,260 --> 00:24:41,490
I'm giving too much credit I was gonna

624
00:24:41,490 --> 00:24:42,659
say its inflated and a little bit

625
00:24:42,659 --> 00:24:44,700
because it's doing some prep but it's

626
00:24:44,700 --> 00:24:46,140
nothing has nothing to do with that

627
00:24:46,140 --> 00:24:52,620
really the the interesting thing is when

628
00:24:52,620 --> 00:24:54,690
I run this on my Mac Pro which is a much

629
00:24:54,690 --> 00:24:56,070
better video card that numbers in half

630
00:24:56,070 --> 00:24:58,350
so it's still terrible down

631
00:24:58,350 --> 00:25:00,840
so overall the experiment failed but

632
00:25:00,840 --> 00:25:02,730
we're not giving up and we just wanted

633
00:25:02,730 --> 00:25:03,900
to get that done as fast as possible to

634
00:25:03,900 --> 00:25:07,830
see can we do it and I feel free Kotori

635
00:25:07,830 --> 00:25:09,510
us of conquering up and sale to actually

636
00:25:09,510 --> 00:25:11,789
do something useful but it's not what

637
00:25:11,789 --> 00:25:15,419
the harbor is meant to do at all but we

638
00:25:15,419 --> 00:25:16,860
can take it further we can we can do

639
00:25:16,860 --> 00:25:18,840
something with this but we had to recap

640
00:25:18,840 --> 00:25:20,190
in like what we're wrong and the first

641
00:25:20,190 --> 00:25:22,140
thing was everything went wrong I mean

642
00:25:22,140 --> 00:25:23,610
we had to solve all those problems all

643
00:25:23,610 --> 00:25:25,289
those headaches and that took more time

644
00:25:25,289 --> 00:25:26,850
than doing that's that silly little

645
00:25:26,850 --> 00:25:29,580
stack based interpreter so once we got

646
00:25:29,580 --> 00:25:31,530
once we saw those problems we feel like

647
00:25:31,530 --> 00:25:34,409
we can do anything at this point but you

648
00:25:34,409 --> 00:25:35,490
know the sack to deter Birds just

649
00:25:35,490 --> 00:25:37,440
following the yellow brick road of the

650
00:25:37,440 --> 00:25:38,909
ast it was just no optimizations

651
00:25:38,909 --> 00:25:39,960
whatsoever

652
00:25:39,960 --> 00:25:42,299
it wasn't do any compilation or anything

653
00:25:42,299 --> 00:25:44,669
like that so so that was not the right

654
00:25:44,669 --> 00:25:46,830
way to do it or the best way to do it we

655
00:25:46,830 --> 00:25:48,830
are accessing a lot of global memory

656
00:25:48,830 --> 00:25:50,940
because of our dominant dynamic

657
00:25:50,940 --> 00:25:54,150
allocation needs we had to suck that

658
00:25:54,150 --> 00:25:55,890
teat a little bit or so we wanted it

659
00:25:55,890 --> 00:25:59,880
really badly so we everything was done

660
00:25:59,880 --> 00:26:05,220
in global memory and we had a lot of

661
00:26:05,220 --> 00:26:06,720
access global memory that's the slowest

662
00:26:06,720 --> 00:26:09,840
memory available so we we had no

663
00:26:09,840 --> 00:26:11,400
optimizations there whatsoever we could

664
00:26:11,400 --> 00:26:13,049
do a lot of caching and private memory

665
00:26:13,049 --> 00:26:13,470
or whatnot

666
00:26:13,470 --> 00:26:15,620
to speed things up and we never did that

667
00:26:15,620 --> 00:26:17,909
and we never broke things up excuse me

668
00:26:17,909 --> 00:26:20,669
never birth things up into any parallel

669
00:26:20,669 --> 00:26:22,620
tasks for data or even just you know

670
00:26:22,620 --> 00:26:26,970
standard instructions so let's reflect a

671
00:26:26,970 --> 00:26:29,370
little bit stack-based slow it was a

672
00:26:29,370 --> 00:26:30,780
memory halt good use a lot of memory

673
00:26:30,780 --> 00:26:32,760
like it collapsed it I mean it's

674
00:26:32,760 --> 00:26:35,610
terrible and just that just that one

675
00:26:35,610 --> 00:26:39,690
statement hit the sack 30 times and then

676
00:26:39,690 --> 00:26:41,549
in between that did a lot of dynamic

677
00:26:41,549 --> 00:26:44,100
memory allocation and freeing you know

678
00:26:44,100 --> 00:26:45,149
and it's our own software an

679
00:26:45,149 --> 00:26:46,620
implementation of that so

680
00:26:46,620 --> 00:26:50,250
it's really slow and you know again we

681
00:26:50,250 --> 00:26:51,960
didn't know inline optimizations of the

682
00:26:51,960 --> 00:26:54,870
actual code we just interpret it

683
00:26:54,870 --> 00:26:57,540
directly from the AST so we were just

684
00:26:57,540 --> 00:27:00,420
rate up lazy but we can do better I mean

685
00:27:00,420 --> 00:27:01,770
we could do something like compiling

686
00:27:01,770 --> 00:27:03,480
into byte code on the host and then

687
00:27:03,480 --> 00:27:05,370
doing like a register based interpreter

688
00:27:05,370 --> 00:27:09,059
on the on the device along with other

689
00:27:09,059 --> 00:27:11,370
things that would make it worth you know

690
00:27:11,370 --> 00:27:14,280
more a while so global memory access

691
00:27:14,280 --> 00:27:17,610
again just too damn I we we have to

692
00:27:17,610 --> 00:27:19,860
limit that I want to give it a we

693
00:27:19,860 --> 00:27:22,370
conduct a little experiment to just see

694
00:27:22,370 --> 00:27:25,260
what the difference really is I mean

695
00:27:25,260 --> 00:27:26,610
there are theoretical bandwidth numbers

696
00:27:26,610 --> 00:27:31,260
out there but so we we went ahead and

697
00:27:31,260 --> 00:27:33,210
created like two little kernel functions

698
00:27:33,210 --> 00:27:36,679
one that was going through a large loop

699
00:27:36,679 --> 00:27:39,450
that acts as nothing but data or excuse

700
00:27:39,450 --> 00:27:41,040
me actually stuff from a global memory

701
00:27:41,040 --> 00:27:42,570
and then create another one that created

702
00:27:42,570 --> 00:27:44,960
temp temporary private variables

703
00:27:44,960 --> 00:27:46,890
incremented and touched them throughout

704
00:27:46,890 --> 00:27:48,360
the loop when every loop iteration and

705
00:27:48,360 --> 00:27:49,679
then just touch global memory one other

706
00:27:49,679 --> 00:27:51,570
time at the end the difference is

707
00:27:51,570 --> 00:27:54,360
astounding the first one ran in 11 point

708
00:27:54,360 --> 00:27:56,580
1 2 seconds in the second one ran in

709
00:27:56,580 --> 00:28:01,320
point 0 for 4 seconds so with the proper

710
00:28:01,320 --> 00:28:03,120
optimizations on memory access I think

711
00:28:03,120 --> 00:28:06,870
we can get pretty far with our speed but

712
00:28:06,870 --> 00:28:09,059
that's not the only thing we need to do

713
00:28:09,059 --> 00:28:12,000
we need to do some magic and that's try

714
00:28:12,000 --> 00:28:14,309
to figure out a way to break up do here

715
00:28:14,309 --> 00:28:15,929
your sticks on code and break things

716
00:28:15,929 --> 00:28:18,480
into parallel tasks not even with the

717
00:28:18,480 --> 00:28:22,050
developer explicitly asking for it there

718
00:28:22,050 --> 00:28:24,270
are times where it's possible to do

719
00:28:24,270 --> 00:28:28,440
detection on what's you know side-effect

720
00:28:28,440 --> 00:28:30,059
free what is homogeneous what can be

721
00:28:30,059 --> 00:28:33,210
homogeneous especially if you're doing

722
00:28:33,210 --> 00:28:35,970
an interpreter you could actually find

723
00:28:35,970 --> 00:28:37,500
things at runtime leakage it would and

724
00:28:37,500 --> 00:28:39,120
then we can make it faster at that point

725
00:28:39,120 --> 00:28:42,720
so things like this loop you know we

726
00:28:42,720 --> 00:28:44,730
could've done heuristics and say well

727
00:28:44,730 --> 00:28:46,880
you know what nothing's being changed

728
00:28:46,880 --> 00:28:48,929
outside of each individual element of

729
00:28:48,929 --> 00:28:50,280
this input array so we could break that

730
00:28:50,280 --> 00:28:52,400
up into ten different operations

731
00:28:52,400 --> 00:28:55,380
interpret them in at the same time and

732
00:28:55,380 --> 00:28:57,090
tended from cores in the GPU and speed

733
00:28:57,090 --> 00:29:00,510
things up in general

734
00:29:00,510 --> 00:29:02,790
if the majority of your application

735
00:29:02,790 --> 00:29:04,920
can't be sped up or accelerated in this

736
00:29:04,920 --> 00:29:06,720
way then you're going to be limited by

737
00:29:06,720 --> 00:29:08,880
indels wall eventually if you don't that

738
00:29:08,880 --> 00:29:11,970
is you can look it up on Google but you

739
00:29:11,970 --> 00:29:14,820
know the this can only go so far to be

740
00:29:14,820 --> 00:29:17,760
practical but you know there's a lot of

741
00:29:17,760 --> 00:29:19,590
experimentation to be done and we wanted

742
00:29:19,590 --> 00:29:20,910
to see how far we can take it so we're

743
00:29:20,910 --> 00:29:23,300
going to continue you know experimenting

744
00:29:23,300 --> 00:29:26,040
we want to see if we can get the

745
00:29:26,040 --> 00:29:27,510
performance of this interpreter all and

746
00:29:27,510 --> 00:29:29,070
Cl devices to an acceptable state where

747
00:29:29,070 --> 00:29:31,800
you can actually go ahead and send tasks

748
00:29:31,800 --> 00:29:33,780
to a stateless you know no share memory

749
00:29:33,780 --> 00:29:35,670
tasks but you can send remember you can

750
00:29:35,670 --> 00:29:37,200
send parameter values to it they'll be

751
00:29:37,200 --> 00:29:39,120
serialized over and then you can pull

752
00:29:39,120 --> 00:29:43,650
that memory back and you know do high

753
00:29:43,650 --> 00:29:45,810
level things like map map reduction and

754
00:29:45,810 --> 00:29:47,880
whatnot these are things that River

755
00:29:47,880 --> 00:29:48,900
Trail is doing very well

756
00:29:48,900 --> 00:29:54,420
and you know there's there are

757
00:29:54,420 --> 00:29:55,890
limitations there so we can get this

758
00:29:55,890 --> 00:29:57,840
interpreter going then we can actually

759
00:29:57,840 --> 00:30:00,090
have full compliant JavaScript on all

760
00:30:00,090 --> 00:30:03,150
these you know fast GPU devices

761
00:30:03,150 --> 00:30:04,980
accelerator processors and see if we can

762
00:30:04,980 --> 00:30:07,920
get JavaScript up to the next level you

763
00:30:07,920 --> 00:30:11,070
can even you know think further and set

764
00:30:11,070 --> 00:30:12,300
up like a clustering system and actually

765
00:30:12,300 --> 00:30:13,440
do these things on a bunch of different

766
00:30:13,440 --> 00:30:15,600
systems and orchestrate them which are

767
00:30:15,600 --> 00:30:19,770
pretty neat so so that's there's a those

768
00:30:19,770 --> 00:30:21,720
are the things that we ran into and we

769
00:30:21,720 --> 00:30:23,280
came out with and we're still working on

770
00:30:23,280 --> 00:30:24,240
it these all this stuff's gonna be

771
00:30:24,240 --> 00:30:26,910
open-source we solved like legal things

772
00:30:26,910 --> 00:30:28,410
to take care of like copyrights and

773
00:30:28,410 --> 00:30:29,760
whatnot but it's gonna be open source

774
00:30:29,760 --> 00:30:31,050
just people to play around with and see

775
00:30:31,050 --> 00:30:33,960
what it looks like it's a mess but we're

776
00:30:33,960 --> 00:30:36,030
gonna clean it up it'll be it's fun so

777
00:30:36,030 --> 00:30:37,020
if anybody wants to just play around

778
00:30:37,020 --> 00:30:39,140
with it see if they can make it faster

779
00:30:39,140 --> 00:30:43,310
you can I'll be posting and tweeting

780
00:30:43,310 --> 00:30:46,710
about it and my Twitter's at your

781
00:30:46,710 --> 00:30:47,940
Nichols so if you can follow me I'll

782
00:30:47,940 --> 00:30:49,890
I'll be talking about this quite a bit

783
00:30:49,890 --> 00:30:52,800
and you can stay up to date it's on my

784
00:30:52,800 --> 00:30:54,060
github account I didn't put the link in

785
00:30:54,060 --> 00:30:55,050
there I don't what the hell I was

786
00:30:55,050 --> 00:30:58,020
thinking but it will be live soon it's

787
00:30:58,020 --> 00:30:58,800
probably right now because they've

788
00:30:58,800 --> 00:31:00,990
copyright stuff but it'll be live soon

789
00:31:00,990 --> 00:31:03,260
but that's it that's my talk so

