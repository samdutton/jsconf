1
00:00:09,760 --> 00:00:11,080
Thanks so much.

2
00:00:11,090 --> 00:00:15,350
I'm incredibly honoured to be here.

3
00:00:15,350 --> 00:00:20,280
Today I'm talking about formalising former
right on the web.

4
00:00:20,280 --> 00:00:24,170
Let me give context who I am.

5
00:00:24,170 --> 00:00:27,700
I'm in Austin Texas, a JavaScript developer.

6
00:00:27,700 --> 00:00:33,570
I've been working with Node.js for five years,
making websites and applications for just

7
00:00:33,570 --> 00:00:35,249
about all my life.

8
00:00:35,249 --> 00:00:42,030
I have an enormous amount of passion for distributed
systems and peer-to-peer technology.

9
00:00:42,030 --> 00:00:46,960
I think they are technically fascinating but
there's an incredible potential in these kind

10
00:00:46,960 --> 00:00:52,069
of technologies that haven't been leveraged
in the web, so that is what I pursue a lot

11
00:00:52,069 --> 00:00:53,579
in my daily life.

12
00:00:53,579 --> 00:01:00,299
I was one of the people who helped start the
secure scuttlebutt project which is a secure

13
00:01:00,299 --> 00:01:04,589
peer-to-peer network.

14
00:01:04,589 --> 00:01:07,940
I spend my days now working on the Beaker
browser.

15
00:01:07,940 --> 00:01:13,580
It is an experimental peer-to-peer web browser.

16
00:01:13,580 --> 00:01:19,180
We want to see if it is possible to let users
publish websites without having to use servers

17
00:01:19,180 --> 00:01:20,720
at all.

18
00:01:20,720 --> 00:01:25,600
We want to see if you could have a button
perhaps if the browser, you can click that,

19
00:01:25,600 --> 00:01:30,421
then public the site from your laptop or a
mobile device, and then you don't have to

20
00:01:30,421 --> 00:01:34,680
worry about operations and things are much
easier for you.

21
00:01:34,680 --> 00:01:44,980
Curious to hear how that works, you should
listen to Tara Vancil's talk tonight.

22
00:01:44,980 --> 00:01:50,220
What I'm going to be talking about is a little
bit about animates us to work on this project,

23
00:01:50,220 --> 00:01:55,170
why we care so much about this idea, and we
think it can have a positive effect on the

24
00:01:55,170 --> 00:01:56,450
web.

25
00:01:56,450 --> 00:02:00,280
Now, we are huge advocate for the open web.

26
00:02:00,280 --> 00:02:04,320
I think it's incredible that we have this
shared platform that's not encumbered by patents

27
00:02:04,320 --> 00:02:11,379
or licences, and it isn't owned by any one
corps ratings, but lately the web has been

28
00:02:11,379 --> 00:02:13,579
struggling with systemic problems.

29
00:02:13,579 --> 00:02:19,409
Issues with things like bullying, harassment
online, misinformation campaigns that affect

30
00:02:19,409 --> 00:02:25,440
our elections, and infringement of personal
privacy, and honestly, the list goes on.

31
00:02:25,440 --> 00:02:31,150
Now, I think in a way, all of these systemic
problems stem or have some kind of relationship

32
00:02:31,150 --> 00:02:38,620
to one basic question, and that question is:
who is in charge?

33
00:02:38,620 --> 00:02:43,319
I don't mean this in a petty sense like who
happens to be the market leader from one moment

34
00:02:43,319 --> 00:02:49,359
to another, but in a profound sense: who has
the authority to govern or communities and

35
00:02:49,359 --> 00:02:52,290
our applications, and our online lives?

36
00:02:52,290 --> 00:02:56,200
More importantly than that, perhaps, what
gives them that right to be the people that

37
00:02:56,200 --> 00:02:59,209
govern our experiences?

38
00:02:59,209 --> 00:03:03,810
On top of that, I think we also should understand
what kind of rights we have as users.

39
00:03:03,810 --> 00:03:06,249
What rights do we have to control the software
we use?

40
00:03:06,249 --> 00:03:10,620
What rights do we have to control the algorithms
that affect our perception of the world.

41
00:03:10,620 --> 00:03:14,840
What rights do we have to control the moderation
policies that affect these issues that affect

42
00:03:14,840 --> 00:03:16,599
us every day?

43
00:03:16,599 --> 00:03:20,639
And so, you can talk about political rights.

44
00:03:20,639 --> 00:03:26,939
In fact, there's been amazing work with the
GDPR, but there's something else, a kind of

45
00:03:26,939 --> 00:03:31,499
right that emerges, I believe, specifically
from the technical design of the web, and

46
00:03:31,499 --> 00:03:34,330
the architectures of networks in general.

47
00:03:34,330 --> 00:03:39,269
And this technical right is derived from what
everybody is able to do.

48
00:03:39,269 --> 00:03:43,010
So that is the right that we are going to
be talking about here today.

49
00:03:43,010 --> 00:03:46,930
Now, I think it is important that we go through
some of the stuff that is the problem right

50
00:03:46,930 --> 00:03:51,769
now which means we are going to have to go
through some offensive content — I tried

51
00:03:51,769 --> 00:03:52,889
to censor it a little bit.

52
00:03:52,889 --> 00:03:56,030
It's kind of annoying.

53
00:03:56,030 --> 00:03:57,830
Let's talk about harassment.

54
00:03:57,830 --> 00:04:01,840
Well, mostly talk about Twitter, but Twitter
of course is not the only community that has

55
00:04:01,840 --> 00:04:02,870
this problem.

56
00:04:02,870 --> 00:04:06,989
Here is Susan Fowler talking about anti-Semitism
filling her notifications.

57
00:04:06,989 --> 00:04:10,500
Lately, Jessica had a death threat.

58
00:04:10,500 --> 00:04:17,730
She had to struggle a lit bit to get Twitter's
moderation teams to take it seriously.

59
00:04:17,730 --> 00:04:22,530
You don't have to go far to find this kind
of stuff.

60
00:04:22,530 --> 00:04:23,830
I don't think this is news to anybody.

61
00:04:23,830 --> 00:04:26,890
The internet is full of trolls, right?

62
00:04:26,890 --> 00:04:31,340
The running joke at this point is that Twitter
is a cesspool.

63
00:04:31,340 --> 00:04:35,690
Well, you could say that this is just how
it goes.

64
00:04:35,690 --> 00:04:39,900
We should develop a thick skin, and perhaps
this kind of behaviour is just the cost of

65
00:04:39,900 --> 00:04:42,420
free speech.

66
00:04:42,420 --> 00:04:45,950
Perhaps that's the case, except that I'm beginning
to believe that this kind of behaviour is

67
00:04:45,950 --> 00:04:48,690
affecting our culture, and our political systems.

68
00:04:48,690 --> 00:04:51,280
I don't think I'm the only one to think that.

69
00:04:51,280 --> 00:04:56,220
At the end of last year, Reid Hoffman weighed
in on this issue, how he would save the problems

70
00:04:56,220 --> 00:05:01,620
of hate speech, abuse on our social media
platforms.

71
00:05:01,620 --> 00:05:05,840
Reid Hoffman is the co-founder of LinkedIn.

72
00:05:05,840 --> 00:05:12,070
In this interview, he gave his prescription,
and it was this: these are private businesses.

73
00:05:12,070 --> 00:05:15,670
All these social media platforms are private
businesses, and they can set policies about

74
00:05:15,670 --> 00:05:21,290
what kind of behaviour they expect from their
users, from their participants on the platform.

75
00:05:21,290 --> 00:05:25,850
The metaphor he uses it's like a hotel or
restaurant.

76
00:05:25,850 --> 00:05:29,000
You can set a policy, no shirt, no service.

77
00:05:29,000 --> 00:05:31,240
The same thing here.

78
00:05:31,240 --> 00:05:37,650
Project a more opinionated view about what
kind of speech is permissible on your platform.

79
00:05:37,650 --> 00:05:39,070
That's what he is putting out.

80
00:05:39,070 --> 00:05:43,750
Now, to some degree, I think he has a fair
point.

81
00:05:43,750 --> 00:05:50,440
But what he is suggesting really highlights
what I think is kind of a constant probably

82
00:05:50,440 --> 00:05:51,750
with how the web works.

83
00:05:51,750 --> 00:05:56,920
It kind of highlights how we are stuck between
a rock and a hard place on this matter.

84
00:05:56,920 --> 00:06:02,490
Because, on the one hand, I'm not the sort
of person who is animated by concerns about

85
00:06:02,490 --> 00:06:04,270
censorship.

86
00:06:04,270 --> 00:06:05,300
That's not my day-to-day.

87
00:06:05,300 --> 00:06:10,520
My concern is more about bullying or death
threats to somebody I love, or misinformation

88
00:06:10,520 --> 00:06:13,990
campaigns that might affect the elections
in my country.

89
00:06:13,990 --> 00:06:16,000
That bothers me a lot more.

90
00:06:16,000 --> 00:06:21,810
At the same time, I think you can't ignore
the fact that we had a very serious conversation

91
00:06:21,810 --> 00:06:25,350
about the possibility that Mark Zuckerberg
could run for president.

92
00:06:25,350 --> 00:06:30,260
This guy runs one of the most powerful information-sharing
platforms in the world — over 2 billion

93
00:06:30,260 --> 00:06:34,290
users use Facebook to get their daily news.

94
00:06:34,290 --> 00:06:39,160
So the idea that we at this juncture would
start to ask corporations more proactively

95
00:06:39,160 --> 00:06:45,210
to police our speech is I think a slightly
bad idea.

96
00:06:45,210 --> 00:06:48,020
So it seems like we're stuck between these
two options.

97
00:06:48,020 --> 00:06:52,560
On the one hand, you have trolltopia where
everything is permissible, and, on the other

98
00:06:52,560 --> 00:06:59,490
hand, you have a corporate hegemony where
speech is being policed by big businesses.

99
00:06:59,490 --> 00:07:05,020
There ought to be something in between this,
something driven perhaps by users.

100
00:07:05,020 --> 00:07:06,620
Yet it's not there.

101
00:07:06,620 --> 00:07:13,080
Assess it happens, Mark Zuckerberg is not
particularly interested in Reid Hoffman's

102
00:07:13,080 --> 00:07:14,080
suggestion.

103
00:07:14,080 --> 00:07:17,960
He's extremely adamant that Facebook is not
a media company.

104
00:07:17,960 --> 00:07:20,000
They're just a tools company.

105
00:07:20,000 --> 00:07:23,900
If they were a media company, they would control
what kind of media is put on Facebook.

106
00:07:23,900 --> 00:07:24,900
That's his point.

107
00:07:24,900 --> 00:07:26,150
That's not their job.

108
00:07:26,150 --> 00:07:30,730
He says this because, to be honest, he want
Facebook to be popular.

109
00:07:30,730 --> 00:07:34,000
As soon as they start getting into these hard
decisions about what sort of behaviour is

110
00:07:34,000 --> 00:07:42,260
per missable, they get into partisan fights
and using losers because they are seen as

111
00:07:42,260 --> 00:07:43,260
biased.

112
00:07:43,260 --> 00:07:45,720
This sort of dove-tails nicely into a conversation
about misinformation.

113
00:07:45,720 --> 00:07:50,610
We are still in our systemic problems of the
talk here.

114
00:07:50,610 --> 00:07:56,420
Let's talk a little bit what happens in the
2016 American election.

115
00:07:56,420 --> 00:08:00,720
This is a Washington Post article and we will
go through some of the ads that were run illegally

116
00:08:00,720 --> 00:08:06,950
by a Russian propaganda arm using Facebook's
ad-targeting platform.

117
00:08:06,950 --> 00:08:11,250
If you were opposed to Muslim immigration,
you get this law from this Russian propaganda

118
00:08:11,250 --> 00:08:15,590
organisation saying Shari'ah law should the
not be debatable.

119
00:08:15,590 --> 00:08:19,360
If you were a Christian Conservative, you
got Jesus arm wrestling the devil, and if

120
00:08:19,360 --> 00:08:26,610
Clinton won, the devil won the election.

121
00:08:26,610 --> 00:08:30,180
If you were a southern conservative, you got
a fake tea-party endorsement for trump.

122
00:08:30,180 --> 00:08:37,060
If you're an LGBT supporter, you got this
ad against the west borough Baptist church.

123
00:08:37,060 --> 00:08:45,560
If you are were a Hillary Clinton supporter,
you got — the strategy they were pursuing

124
00:08:45,560 --> 00:08:49,900
is getting to you click like, because then
they could push more propaganda to you.

125
00:08:49,900 --> 00:08:53,930
The strategy was to strengthen trump's base
and divide Clinton's.

126
00:08:53,930 --> 00:09:00,790
There is a lot of examples of what happened
and what went wrong in the 2016 election with

127
00:09:00,790 --> 00:09:01,880
misinformation.

128
00:09:01,880 --> 00:09:05,860
If you want more, look being at Reddit, and
Twitter has its own problems.

129
00:09:05,860 --> 00:09:11,890
The next to fit in with the time I have was
important to illustrate because it cuts to

130
00:09:11,890 --> 00:09:14,380
the heart of how this sort of stuff happens.

131
00:09:14,380 --> 00:09:20,130
That's this one: this is an article published
by ProPublica last year.

132
00:09:20,130 --> 00:09:25,750
There's an advertising demographic on Facebook
of Jew-haters.

133
00:09:25,750 --> 00:09:27,900
You could target them with your ads.

134
00:09:27,900 --> 00:09:32,990
It was apparently 2,274 people who put this
as their field of study.

135
00:09:32,990 --> 00:09:36,740
Now, I don't know if they thought they were
being funny or being serious — it doesn't

136
00:09:36,740 --> 00:09:38,170
really matter.

137
00:09:38,170 --> 00:09:43,270
But, somehow, Facebook's algorithms picked
up on this and made it a group you could advertise

138
00:09:43,270 --> 00:09:44,270
to.

139
00:09:44,270 --> 00:09:46,990
I want to point out the UI element underneath
there.

140
00:09:46,990 --> 00:09:49,470
Yes, I think so.

141
00:09:49,470 --> 00:09:53,120
Okay, why is this happening?

142
00:09:53,120 --> 00:09:59,600
Is Facebook intentionally setting out to collude
with the Russians, to mess with our elections

143
00:09:59,600 --> 00:10:01,120
in America?

144
00:10:01,120 --> 00:10:05,310
Is there some Facebook employee that is adding
that Jew-hater entry into the database?

145
00:10:05,310 --> 00:10:06,810
I don't think so.

146
00:10:06,810 --> 00:10:07,810
I don't think that is what happened.

147
00:10:07,810 --> 00:10:11,490
I don't know, but I doubt it.

148
00:10:11,490 --> 00:10:14,420
What I think is happening here is the same
thing that happens with every Silicon Valley

149
00:10:14,420 --> 00:10:20,480
company trying to achieve enormous amounts
of scale: they're just using algorithms.

150
00:10:20,480 --> 00:10:28,690
They're accepting user data without considering
just how problematic that user data can be.

151
00:10:28,690 --> 00:10:30,980
This is a screen shot of YouTube.

152
00:10:30,980 --> 00:10:33,192
David Hogg is one of the Parkland Shoot be
survivors.

153
00:10:33,192 --> 00:10:38,130
He survived a high school shooting.

154
00:10:38,130 --> 00:10:45,920
He decided to become vocal about his opposition,
or his support, rather, for gun control.

155
00:10:45,920 --> 00:10:49,430
People who didn't like his politics decided
to spread a conspiracy theory that he's a

156
00:10:49,430 --> 00:10:53,360
paid political actor, a crisis actor.

157
00:10:53,360 --> 00:10:57,482
And so I guess enough people searched for
that on YouTube because that started to show

158
00:10:57,482 --> 00:11:01,680
up as the only thing when you type into his
names that you should look into him being

159
00:11:01,680 --> 00:11:02,870
a crisis actor.

160
00:11:02,870 --> 00:11:09,620
It is a combination of these algorithms, and
then, what I could only describe as I suppose

161
00:11:09,620 --> 00:11:14,740
the political weaponisation that is occurring
on the web, and will continue to occur, because

162
00:11:14,740 --> 00:11:16,930
these platforms have the power to push an
agenda.

163
00:11:16,930 --> 00:11:22,800
And every time you have one of these algorithms,
that blindly trust user input, that's another

164
00:11:22,800 --> 00:11:23,800
vector.

165
00:11:23,800 --> 00:11:27,580
It's another opportunity to push propaganda.

166
00:11:27,580 --> 00:11:34,050
Okay, these are problems.

167
00:11:34,050 --> 00:11:38,710
They're problems in how we govern our communities
online.

168
00:11:38,710 --> 00:11:45,230
And, when you see problems like this, you
naturally have to ask who is in charge?

169
00:11:45,230 --> 00:11:48,830
Whose job is it to solve these kinds of problems?

170
00:11:48,830 --> 00:11:54,930
And I think this is where we see technology
and civics collide in an incredibly specific

171
00:11:54,930 --> 00:11:55,930
way.

172
00:11:55,930 --> 00:12:00,850
Because, we are talking about the system of
authority, and the system of governance.

173
00:12:00,850 --> 00:12:07,440
Whose job is it to maintain these communities
online?

174
00:12:07,440 --> 00:12:11,080
If you look at Reddit, it's ostensibly designed
to be a democracy.

175
00:12:11,080 --> 00:12:14,589
In fact, it's probably one of the most democratic
websites online.

176
00:12:14,589 --> 00:12:18,430
The users submit stories and vote what shows
up on the front page.

177
00:12:18,430 --> 00:12:20,320
It is great.

178
00:12:20,320 --> 00:12:24,760
But if you actually look at the civic structure
of Reddit, it is not actually a democracy.

179
00:12:24,760 --> 00:12:29,270
It is actually more like a monarch can I because
you have the — monarchy, because you have

180
00:12:29,270 --> 00:12:35,940
users submitting on comments, and above that,
you have moderator users, and they have the

181
00:12:35,940 --> 00:12:40,710
power to remove content and users, and things
like that, and on top, you have the Reddit

182
00:12:40,710 --> 00:12:44,960
staff who are basically the kings of this
community.

183
00:12:44,960 --> 00:12:46,830
They have total control.

184
00:12:46,830 --> 00:12:49,380
They can change the code, they can change
the data, they can do anything.

185
00:12:49,380 --> 00:12:56,030
And, in fact, they highlighted this about
a year ago when the CEO of Reddit decided

186
00:12:56,030 --> 00:13:00,220
to jump into TheDonald and manually edit some
of the users.

187
00:13:00,220 --> 00:13:02,290
He trolled the trolls, right?

188
00:13:02,290 --> 00:13:07,060
He figured it would be funny.

189
00:13:07,060 --> 00:13:11,090
If you don't know how websites work, you might
be shocked to realise that somebody on the

190
00:13:11,090 --> 00:13:14,310
Reddit staff can change people's comments.

191
00:13:14,310 --> 00:13:19,330
But I think probably most of us here are technologists,
and intuitively aware of course they can do

192
00:13:19,330 --> 00:13:23,390
that — they run the server, right?

193
00:13:23,390 --> 00:13:29,000
That dove-tails into this next question: what
is it about the web that makes it like this?

194
00:13:29,000 --> 00:13:33,580
Why do the Reddit staff act as the king and
have total authority?

195
00:13:33,580 --> 00:13:38,399
I think it flows directly from this thick
server design, the architecture of applications

196
00:13:38,399 --> 00:13:39,399
on the web.

197
00:13:39,399 --> 00:13:46,290
Fixed server is a technical term meaning we
put the business logic into the server, and,

198
00:13:46,290 --> 00:13:48,790
as a result, all the authority.

199
00:13:48,790 --> 00:13:51,420
If you diagram it, it looks like this.

200
00:13:51,420 --> 00:13:55,649
You got the thick server up at the to be,
and you have the database in there.

201
00:13:55,649 --> 00:13:57,360
You have all the code.

202
00:13:57,360 --> 00:14:00,480
And you have all the authority placed in the
server.

203
00:14:00,480 --> 00:14:06,620
And then you have the web browsers, the clients,
and you actually call them a thin client.

204
00:14:06,620 --> 00:14:08,360
Thick server, thin client.

205
00:14:08,360 --> 00:14:13,090
And the thin client is just a few of this
data, just a rendering of what is occurring

206
00:14:13,090 --> 00:14:14,150
on the server.

207
00:14:14,150 --> 00:14:17,690
Any time you want to do something as one of
the clients, you actually have to ask the

208
00:14:17,690 --> 00:14:19,920
server to do it for you.

209
00:14:19,920 --> 00:14:23,600
So all the authority lives in the server,
and, if you have any authority as a user,

210
00:14:23,600 --> 00:14:28,680
you're borrowing it from the server in a way.

211
00:14:28,680 --> 00:14:31,500
What is it about the web that makes it like
that?

212
00:14:31,500 --> 00:14:33,140
Why are the servers king?

213
00:14:33,140 --> 00:14:36,760
There is nothing in the nature of computers
that make it this way.

214
00:14:36,760 --> 00:14:42,070
If you look at computers in a state of nature,
hanging out next to each other, look at a

215
00:14:42,070 --> 00:14:49,140
server, you look at a normal desktop computer,
or a laptop, sure, the server is more powerful,

216
00:14:49,140 --> 00:14:52,750
but that doesn't necessarily meaning that
the server ought to be king.

217
00:14:52,750 --> 00:14:56,700
Server doesn't have to be in charge but that
is what it is.

218
00:14:56,700 --> 00:15:00,300
Why is it that if it is not in the hardware?

219
00:15:00,300 --> 00:15:02,890
The answer has to do with this.

220
00:15:02,890 --> 00:15:08,490
It has to do with the specifications and the
standards that define the web — HTTP, HTML,

221
00:15:08,490 --> 00:15:11,220
all the web APIs.

222
00:15:11,220 --> 00:15:17,760
They encode this set of behaviours.

223
00:15:17,760 --> 00:15:24,240
This is a very clear example of how technology
doesn't just interact with civics, but it

224
00:15:24,240 --> 00:15:27,250
actually drives civics.

225
00:15:27,250 --> 00:15:32,380
It defines what the civic structure of a community
is going to be.

226
00:15:32,380 --> 00:15:36,331
In a way you could say that these specifications
are like a shared contract between us, or

227
00:15:36,331 --> 00:15:40,580
perhaps even like a constitution.

228
00:15:40,580 --> 00:15:46,560
Because they define how our online society
of computers are going to work with each other.

229
00:15:46,560 --> 00:15:49,200
There's nothing in the hardware that does
this.

230
00:15:49,200 --> 00:15:50,200
It's in the specification.

231
00:15:50,200 --> 00:15:55,050
It's in the shared agreement, these rules
that bind us together and define how our computers

232
00:15:55,050 --> 00:15:56,960
relate to each other.

233
00:15:56,960 --> 00:16:03,200
It is a contract or constitution because it
is just an agreement between the devices to

234
00:16:03,200 --> 00:16:06,100
follow these rules.

235
00:16:06,100 --> 00:16:11,330
It is in the constitution of the kind that
these people made but the kind made by people

236
00:16:11,330 --> 00:16:14,920
like this, the hackers that set the web in
motion.

237
00:16:14,920 --> 00:16:20,720
They produce documents that look like this
but it produce specs like this.

238
00:16:20,720 --> 00:16:26,020
There is a parallel there, because all of
our computers, everybody here, we use the

239
00:16:26,020 --> 00:16:28,490
image tag.

240
00:16:28,490 --> 00:16:30,450
That's how that happens.

241
00:16:30,450 --> 00:16:36,149
So, when we ask what gives the server the
right to be king over our application, well,

242
00:16:36,149 --> 00:16:38,100
the answer is that it's in the architecture.

243
00:16:38,100 --> 00:16:40,450
It is how the web is designed.

244
00:16:40,450 --> 00:16:46,110
Now, it is not just the authority model that
is encoded in these architectures, it is also

245
00:16:46,110 --> 00:16:49,840
the individual capabilities of everybody in
the network.

246
00:16:49,840 --> 00:16:53,170
What can my computer do on the web?

247
00:16:53,170 --> 00:16:59,160
Those questions are answered in the specifications,
and this gets us back to that idea of a right.

248
00:16:59,160 --> 00:17:00,660
What rights does my machine have?

249
00:17:00,660 --> 00:17:02,430
What rights do the server have?

250
00:17:02,430 --> 00:17:07,959
I'm going to try to give us a term here — an
ark technical architectural right, a right

251
00:17:07,959 --> 00:17:14,770
that gives me on my device encoded in the
web, or in any network.

252
00:17:14,770 --> 00:17:17,220
Let's go through examples to make it intuitive.

253
00:17:17,220 --> 00:17:19,390
Here we have a local area network.

254
00:17:19,390 --> 00:17:22,880
We will go with the natural design.

255
00:17:22,880 --> 00:17:24,270
Everybody can connect to everybody else.

256
00:17:24,270 --> 00:17:26,620
So we have Alice, Bob, and Carla.

257
00:17:26,620 --> 00:17:29,360
Their machines can talk to each other.

258
00:17:29,360 --> 00:17:34,309
You might technology there's a architectural
right in this design, a right for everybody

259
00:17:34,309 --> 00:17:39,799
to connect to everybody else.

260
00:17:39,799 --> 00:17:44,630
You might decide that Alice is more important
and you maybe can't trust Bob and Carla in

261
00:17:44,630 --> 00:17:48,260
your architecture, so you could do it like
this where only Al-shortlist allowed to create

262
00:17:48,260 --> 00:17:52,430
new connections, and Bob and Carla just have
to listen.

263
00:17:52,430 --> 00:17:58,090
You have to do it this way but then you would
have two kinds of citizens — Alice who has

264
00:17:58,090 --> 00:18:03,310
the right to connect, and Bob and Carla who
can't.

265
00:18:03,310 --> 00:18:04,310
Let's look at another example of the internet.

266
00:18:04,310 --> 00:18:09,110
The internet is like our land because the
internet has the same basic principle: everybody

267
00:18:09,110 --> 00:18:11,090
should be able to connect to everybody else.

268
00:18:11,090 --> 00:18:13,040
Should be able to connect to everybody else.

269
00:18:13,040 --> 00:18:17,750
You could say that there is a right to connect
globally encoded in the design of the internet,

270
00:18:17,750 --> 00:18:20,350
in the architecture of the internet.

271
00:18:20,350 --> 00:18:23,980
Again, you didn't have to do it this way.

272
00:18:23,980 --> 00:18:28,260
You could do it like China has done it — excuse
me, I just want to point out, sometimes, the

273
00:18:28,260 --> 00:18:31,760
internet doesn't work quite so well because
there aren't enough IP addresses in their

274
00:18:31,760 --> 00:18:33,150
firewalls.

275
00:18:33,150 --> 00:18:36,110
That's what that slide is about.

276
00:18:36,110 --> 00:18:37,200
You don't have to do it this way.

277
00:18:37,200 --> 00:18:42,830
You could do it like China, set up a global
government firewall, or you could set up something

278
00:18:42,830 --> 00:18:46,930
like a municipal server somewhere that you
have to talk to and ask permission to make

279
00:18:46,930 --> 00:18:48,770
a connection.

280
00:18:48,770 --> 00:18:51,760
That is how you could do the internet.

281
00:18:51,760 --> 00:18:53,420
We chose not to.

282
00:18:53,420 --> 00:18:56,710
We chose to make it so that everybody can
connect to everybody else, and I think that

283
00:18:56,710 --> 00:18:57,850
is important.

284
00:18:57,850 --> 00:19:03,290
It means there is a value set encoded in that
standard in all the standards that define

285
00:19:03,290 --> 00:19:04,290
the web.

286
00:19:04,290 --> 00:19:06,220
A right to connect globally.

287
00:19:06,220 --> 00:19:13,100
It's not a neutral decision.

288
00:19:13,100 --> 00:19:19,640
So we have an idea about how architectural
rights work.

289
00:19:19,640 --> 00:19:21,280
Let's take a look at the web.

290
00:19:21,280 --> 00:19:25,750
You might say there are two kinds of establishes
on the web, like we were talking about before:

291
00:19:25,750 --> 00:19:27,650
the client and the server.

292
00:19:27,650 --> 00:19:31,870
The client is your browser or user agent,
so let's step through some of the rights that

293
00:19:31,870 --> 00:19:34,280
each of these citizens on the web has.

294
00:19:34,280 --> 00:19:39,710
The client of course has the right to browse,
go from one website to another and visit content.

295
00:19:39,710 --> 00:19:41,450
Of course they can do that.

296
00:19:41,450 --> 00:19:43,380
Clients have the right to filter as well.

297
00:19:43,380 --> 00:19:44,970
You can run an ad blocker.

298
00:19:44,970 --> 00:19:48,770
You might call this a right to mutate because
you can run extensions and change things once

299
00:19:48,770 --> 00:19:51,179
you receive them.

300
00:19:51,179 --> 00:19:53,870
This is open to interpretation, but I would
say those are the two.

301
00:19:53,870 --> 00:19:57,530
This is what a client is allowed to do on
the web.

302
00:19:57,530 --> 00:20:00,810
Let's look at a server.

303
00:20:00,810 --> 00:20:02,230
Servers have the right to an identity.

304
00:20:02,230 --> 00:20:05,230
An accuracy, a .com.

305
00:20:05,230 --> 00:20:07,700
Only servers have that on the web.

306
00:20:07,700 --> 00:20:15,500
Browsers don't have addresses 
or identified — you need to ask a server

307
00:20:15,500 --> 00:20:19,441
to make an identity for you because they are
the only ones with the right to do that, that's

308
00:20:19,441 --> 00:20:22,030
why I'm twitter.com/username.

309
00:20:22,030 --> 00:20:27,570
A right to publish.

310
00:20:27,570 --> 00:20:31,760
This is what a server is designed to do on
the web.

311
00:20:31,760 --> 00:20:34,020
They're publishing that content.

312
00:20:34,020 --> 00:20:35,990
That's a right that only the server has.

313
00:20:35,990 --> 00:20:37,220
The client can't do that.

314
00:20:37,220 --> 00:20:41,960
If I want to publish something, I either need
to be a server, or I need to ask a server

315
00:20:41,960 --> 00:20:47,380
to do something, and that's why I do my tweets
on twitter.com.

316
00:20:47,380 --> 00:20:52,200
Because they control the publishing, servers
have a right to moderate as well.

317
00:20:52,200 --> 00:20:54,470
They can choose what they publish.

318
00:20:54,470 --> 00:20:58,680
Sort of falls naturally out from having been
dominate right to publishing, and then servers

319
00:20:58,680 --> 00:21:01,330
can also choose what they had they deploy.

320
00:21:01,330 --> 00:21:11,280
They get to choose the data model, where the
data goes been when you look at this citizenship

321
00:21:11,280 --> 00:21:18,400
on the web it's unsurprising that there is
an asymmetrical power here, not only do servers

322
00:21:18,400 --> 00:21:22,090
have more rights but way better rights.

323
00:21:22,090 --> 00:21:24,620
That's the hurry to describe how the web applications
work.

324
00:21:24,620 --> 00:21:26,750
The clients are passive.

325
00:21:26,750 --> 00:21:31,610
The best they can do is make a choice about
where they go.

326
00:21:31,610 --> 00:21:35,120
When you're talking about these problems of
governance online, how do we solve these tough

327
00:21:35,120 --> 00:21:41,480
questions about moderation policies and the
truth of information?

328
00:21:41,480 --> 00:21:44,280
How can we make governance better?

329
00:21:44,280 --> 00:21:49,790
How can we give new rights to clients so that
the civic structure is no longer being constrained

330
00:21:49,790 --> 00:21:55,950
by the design of the web, and the architecture
can have a more perhaps even democratic design

331
00:21:55,950 --> 00:21:57,460
in how it is governed?

332
00:21:57,460 --> 00:22:01,850
Can we make it so that the client has the
right to publish instead of always depending

333
00:22:01,850 --> 00:22:03,350
on a server to do it for them?

334
00:22:03,350 --> 00:22:08,270
Can we make it even so that the client has
the right to having an identity so that my

335
00:22:08,270 --> 00:22:12,990
personal identity is no longer tied to whatever
happens to Twitter?

336
00:22:12,990 --> 00:22:17,550
Could we even give clients the right to deploy
the code so they can decide how their application

337
00:22:17,550 --> 00:22:19,700
should work?

338
00:22:19,700 --> 00:22:28,940
Now I mentioned at the beginning of that talk
that I work on peer-to-peer networks.

339
00:22:28,940 --> 00:22:33,460
In this context, peer-to-peer networks really
fascinate me, because, unlike client server

340
00:22:33,460 --> 00:22:39,360
networks, they connect nodes in a way such
that they have the same capabilities.

341
00:22:39,360 --> 00:22:43,130
The rights are completely evenly distributed
in a peer-to-peer network.

342
00:22:43,130 --> 00:22:48,600
That's implicit in the name — we're all
just peers.

343
00:22:48,600 --> 00:22:52,980
I think that has an equalising force across
the network.

344
00:22:52,980 --> 00:23:00,640
It would be easy in a way to make this talk
largely about free software because in a lot

345
00:23:00,640 --> 00:23:05,600
of ways, it is deeply connected, this ability
to control our right to modify how the experience

346
00:23:05,600 --> 00:23:08,740
works, but I actually think it is a little
bit bigger than that.

347
00:23:08,740 --> 00:23:13,580
I think it's about our ability to decide how
code works as a community.

348
00:23:13,580 --> 00:23:21,960
That makes it a question of civics, not just
free software.

349
00:23:21,960 --> 00:23:31,240
Every time we ask Facebook to make a change
to their interfaces, it's kind of a big deal.

350
00:23:31,240 --> 00:23:35,440
It requires those companies to take a risk
to potentially loose users, or change something

351
00:23:35,440 --> 00:23:38,680
that's fundamental to their success in the
past, and, as a result, they might not be

352
00:23:38,680 --> 00:23:42,179
able to make those kind of risks.

353
00:23:42,179 --> 00:23:46,990
When users have the option to develop the
software on their own, to pursue their own

354
00:23:46,990 --> 00:23:50,470
needs, problems, and idea, they don't need
to be afraid that it might hurt their bottom

355
00:23:50,470 --> 00:23:55,700
line, don't need to think in terms of maximising
engagement numbers but can think about solve

356
00:23:55,700 --> 00:23:59,289
their own problems.

357
00:23:59,289 --> 00:24:03,150
As technologists, it is our job not to solve
problems for people but to give them the tools

358
00:24:03,150 --> 00:24:08,000
to solve those problems so they can decide
what is best for them, especially in these

359
00:24:08,000 --> 00:24:12,730
contexts of these global society the like
the web is.

360
00:24:12,730 --> 00:24:16,590
I think perhaps it's easy to think of the
web as being fixed and a stable place where

361
00:24:16,590 --> 00:24:20,630
we've experienced the full history of the
web but the web has only been around for 30

362
00:24:20,630 --> 00:24:21,630
years.

363
00:24:21,630 --> 00:24:23,980
What will the next 30 years be like?

364
00:24:23,980 --> 00:24:28,350
Will we continue to use Facebook and Twitter?

365
00:24:28,350 --> 00:24:30,040
Is it going to be the same governance model?

366
00:24:30,040 --> 00:24:32,140
Still have servers as king?

367
00:24:32,140 --> 00:24:36,600
Or are we as users going to be defining much
more of our experience in the future?

368
00:24:36,600 --> 00:24:41,190
Think about it, 30 years from now, is it going
to be like this?

369
00:24:41,190 --> 00:24:45,110
I believe in civic engagement.

370
00:24:45,110 --> 00:24:50,260
I believe in all kinds — legal rights and
regulations are powerful, and I'm extremely

371
00:24:50,260 --> 00:24:54,800
excited about what the GDPR will do for our
industry.

372
00:24:54,800 --> 00:24:57,980
But the legal system is not our own option.

373
00:24:57,980 --> 00:25:05,340
As people who shape technology, and shape
the web, we have powerful tools at our disposal.

374
00:25:05,340 --> 00:25:07,730
Technology is not neutral.

375
00:25:07,730 --> 00:25:12,380
It encodes a set of values, and, as a political
system, it encodes a set of rights, so it

376
00:25:12,380 --> 00:25:17,280
will be up to us to decide what our online
civic structures will be like.

377
00:25:17,280 --> 00:25:22,710
I hope you take this time to consider which
structures of power and which rights you're

378
00:25:22,710 --> 00:25:24,650
enabling in the architectures that you build.

379
00:25:24,650 --> 00:25:26,030
Thank you all very much.

