1
00:00:10,889 --> 00:00:11,889
Thank you.

2
00:00:11,889 --> 00:00:12,940
Thank you, everyone.

3
00:00:12,940 --> 00:00:17,460
Well, there's one thing I've learned working
with my team that I would like to share and

4
00:00:17,460 --> 00:00:27,019
that I will never forget is that we know that
writing fast applications makes our users

5
00:00:27,019 --> 00:00:29,250
and our customers happy.

6
00:00:29,250 --> 00:00:31,269
So, who doesn't want to write fast code?

7
00:00:31,269 --> 00:00:32,509
Raise your hand.

8
00:00:32,509 --> 00:00:33,509
Naw.

9
00:00:33,509 --> 00:00:35,059
That's interesting.

10
00:00:35,059 --> 00:00:39,840
So, before we start, I have a couple of questions
that I need to ask.

11
00:00:39,840 --> 00:00:44,230
And then I'll see what the Internet tells
us.

12
00:00:44,230 --> 00:00:49,570
So, the first question is, if you go on your
favorite web browser and your favorite search

13
00:00:49,570 --> 00:00:53,149
engine and you type "Is JavaScript fast?

14
00:00:53,149 --> 00:00:55,150
How fast is JavaScript?"

15
00:00:55,150 --> 00:01:00,890
Probably get something like this that says,
and I'm just quoting," Under the right circumstances

16
00:01:00,890 --> 00:01:01,960
it is very fast.

17
00:01:01,960 --> 00:01:05,780
Actually, as fast as C."

18
00:01:05,780 --> 00:01:11,160
If you search again, another result would
be, "Why is it so fast?

19
00:01:11,160 --> 00:01:17,030
It is because as soon as you understand event
loop and how it processes requests, you realize

20
00:01:17,030 --> 00:01:18,680
it's so fast."

21
00:01:18,680 --> 00:01:23,750
You start to see a pattern, because fast is
because it's fast.

22
00:01:23,750 --> 00:01:29,960
And you keep going on and you get stuff like,
"How can it be so fast since it's a single

23
00:01:29,960 --> 00:01:31,570
thread?"

24
00:01:31,570 --> 00:01:38,049
And the answer, like in this example is because
it's lightweight.

25
00:01:38,049 --> 00:01:43,850
We keep going and then you find this interesting
question."

26
00:01:43,850 --> 00:01:46,340
How fast is it compared to Java?"

27
00:01:46,340 --> 00:01:52,241
Well, because most recruiters think that Java
and JavaScript is the same thing, which is

28
00:01:52,241 --> 00:01:53,360
kind of interesting.

29
00:01:53,360 --> 00:02:00,570
So, if you look around on the Internet, you
see JS is and shines when it comes to a huge

30
00:02:00,570 --> 00:02:05,159
amount of short connections.

31
00:02:05,159 --> 00:02:11,220
And finally, I could be all day showing Google
results.

32
00:02:11,220 --> 00:02:13,230
But what does it make faster than Java?

33
00:02:13,230 --> 00:02:20,510
Well, and the answer is because the sync ecosystem
is more than 50,000 modules written in asynchronous

34
00:02:20,510 --> 00:02:21,510
style.

35
00:02:21,510 --> 00:02:24,040
It's kind of a strange answer to the question.

36
00:02:24,040 --> 00:02:33,170
But giving all these questions, we need to
ask, do we trust the Internet?

37
00:02:33,170 --> 00:02:37,660
Like the Internet is full of stories, and
like some Game of Thrones characters said

38
00:02:37,660 --> 00:02:40,519
a few weeks ago, stories connect people.

39
00:02:40,519 --> 00:02:44,030
However, stories are not exact science.

40
00:02:44,030 --> 00:02:51,150
And above all, they should not drive us as
a software engineer.

41
00:02:51,150 --> 00:02:56,349
So, my interpretation is, do I trust the Internet?

42
00:02:56,349 --> 00:02:57,349
No.

43
00:02:57,349 --> 00:02:58,349
I don't.

44
00:02:58,349 --> 00:02:59,530
And why?

45
00:02:59,530 --> 00:03:05,800
Because I am a software engineer, as you can
if you don't know who invented who coined

46
00:03:05,800 --> 00:03:12,230
term you can go in our exhibition hall and
there's an explanation there who did it.

47
00:03:12,230 --> 00:03:19,909
And you see that if you look on the dictionary
for software engineering, it says engineer

48
00:03:19,909 --> 00:03:24,450
is the application of science and mathematics
by which the properties of matter and the

49
00:03:24,450 --> 00:03:28,370
sources of energy and nature are made useful
to people.

50
00:03:28,370 --> 00:03:35,900
So, as a software engineer, we should apply
science and mathematics to solve our problems.

51
00:03:35,900 --> 00:03:40,720
So, going back to the question, is JavaScript
fast?

52
00:03:40,720 --> 00:03:43,379
We need we must be able to reproduce a problem.

53
00:03:43,379 --> 00:03:46,560
We must be able to explain the results.

54
00:03:46,560 --> 00:03:48,400
And reproduce the results.

55
00:03:48,400 --> 00:03:53,450
So, I think the right answer is, is JavaScript
fast?

56
00:03:53,450 --> 00:03:54,450
I don't know.

57
00:03:54,450 --> 00:03:57,599
From these results, it's not clear.

58
00:03:57,599 --> 00:04:01,430
So, starting now with the main topic.

59
00:04:01,430 --> 00:04:04,440
Like when I was planning the talk, I needed
a title.

60
00:04:04,440 --> 00:04:09,020
So, I ended up with so things I learned make
the fastest JavaScript server runtime in the

61
00:04:09,020 --> 00:04:10,020
world.

62
00:04:10,020 --> 00:04:14,150
I carefully decided to pick the word "Server."

63
00:04:14,150 --> 00:04:19,739
Going to Wikipedia for a definition, a server
is a computer in the network of users that

64
00:04:19,739 --> 00:04:23,940
is used to provide services to other computers
in the network.

65
00:04:23,940 --> 00:04:31,950
So, what I'm about to tell you is not about
command line applications or lambdas.

66
00:04:31,950 --> 00:04:33,850
It's about long running processes.

67
00:04:33,850 --> 00:04:37,080
So, we need to also define what is fast.

68
00:04:37,080 --> 00:04:43,700
So, because when I say fast, I don't mean
I'm fast because I put my server on a race

69
00:04:43,700 --> 00:04:46,410
car and the car running around.

70
00:04:46,410 --> 00:04:47,410
No.

71
00:04:47,410 --> 00:04:51,200
What I mean by fast is we need to obtain a
common set of metrics.

72
00:04:51,200 --> 00:04:59,599
And for this, I'm using what the site reliability
engineering has found out.

73
00:04:59,599 --> 00:05:04,550
So, if don't know anything about site reliability
engineering, there's this interesting link

74
00:05:04,550 --> 00:05:06,159
with nice books from Google.

75
00:05:06,159 --> 00:05:08,589
And Google has one of the biggest teams on
SRE.

76
00:05:08,589 --> 00:05:13,720
And SRE has identified five golden signals.

77
00:05:13,720 --> 00:05:22,420
So, golden signals are critical to the monitoring
teams to monitor their systems and identify

78
00:05:22,420 --> 00:05:27,750
problems before they become really big problems.

79
00:05:27,750 --> 00:05:31,080
So, there are many metrics to monitor.

80
00:05:31,080 --> 00:05:40,410
But this team this team this SRE team showed
that rate errors and latency, saturation utilization

81
00:05:40,410 --> 00:05:46,710
contain virtually everything you need to know
about what's going on and where.

82
00:05:46,710 --> 00:05:51,860
Getting the signals is quite challenging and
relies on a lot of the tools and services

83
00:05:51,860 --> 00:05:54,180
you have at your disposal.

84
00:05:54,180 --> 00:05:58,480
But for now, I'm just considering rate as
in request per second.

85
00:05:58,480 --> 00:06:01,190
Errors like in errors per second, of course.

86
00:06:01,190 --> 00:06:05,159
And latency as in like response time including
waiting and queuing.

87
00:06:05,159 --> 00:06:08,330
So, focusing on wait, errors and latency.

88
00:06:08,330 --> 00:06:10,209
I'm focusing on the software.

89
00:06:10,209 --> 00:06:14,849
I'm not focusing on the hardware or in the
operating system.

90
00:06:14,849 --> 00:06:25,020
So, a typical server application has a wellset
wellknown set of characteristics.

91
00:06:25,020 --> 00:06:33,910
We need to know how the application behaves
and only once we understand that, we can talk

92
00:06:33,910 --> 00:06:34,910
about it.

93
00:06:34,910 --> 00:06:36,120
So, what is a server application?

94
00:06:36,120 --> 00:06:41,820
So, my definition of server application is
a long running process that should be deployed

95
00:06:41,820 --> 00:06:45,409
on a cloud or in bare metal.

96
00:06:45,409 --> 00:06:47,450
And it should be attached to a fast network.

97
00:06:47,450 --> 00:06:49,750
Otherwise the network becomes your bottleneck.

98
00:06:49,750 --> 00:06:54,140
And, of course, should have enough CPU and
memory.

99
00:06:54,140 --> 00:06:58,990
So, your application is not strained by your
hardware.

100
00:06:58,990 --> 00:07:04,909
So, a longrunning process has different characteristics
from a shortrunning process, of course.

101
00:07:04,909 --> 00:07:12,330
So, in a longrunning process, the startup
and warming up is not really relevant in the

102
00:07:12,330 --> 00:07:16,650
fullspan life cycle of the server because
it's a very tiny moment.

103
00:07:16,650 --> 00:07:20,890
Again, this isn't true if you're talking about
web applications on your browser.

104
00:07:20,890 --> 00:07:25,310
Because you want to be as fast as possible
because that's what's drives the happiness

105
00:07:25,310 --> 00:07:26,990
of your users.

106
00:07:26,990 --> 00:07:31,680
So, now we need to define our two major things.

107
00:07:31,680 --> 00:07:34,250
Our two benchmark things.

108
00:07:34,250 --> 00:07:38,479
Most Internet articles will tell you how fast
something is.

109
00:07:38,479 --> 00:07:43,730
But most of the time when you read the whole
article, you see some graphs, really nice

110
00:07:43,730 --> 00:07:44,730
graphs.

111
00:07:44,730 --> 00:07:49,529
But the information about how the tests will
perform and how the results were obtained

112
00:07:49,529 --> 00:07:51,110
is needed.

113
00:07:51,110 --> 00:07:54,260
From an engineering perspective, this is incorrect.

114
00:07:54,260 --> 00:07:57,969
We should be able to reproduce the test and
the results.

115
00:07:57,969 --> 00:08:03,870
In a lab that gives you more or less exactly
the same results of course.

116
00:08:03,870 --> 00:08:13,019
On top of that, the experiment was we need
to confirm that the results are not biased.

117
00:08:13,019 --> 00:08:22,140
So, when I write a benchmark, I don't want
to make it be my friend and enemy of the others.

118
00:08:22,140 --> 00:08:24,430
It needs to be fair.

119
00:08:24,430 --> 00:08:26,919
And writing benchmarks, of course, is hard.

120
00:08:26,919 --> 00:08:33,840
Because first every benchmark you write will
never represent a real-world use case.

121
00:08:33,840 --> 00:08:37,760
It's always like a tiny subset that doesn't
really represent your application.

122
00:08:37,760 --> 00:08:42,900
So, you need to get into conclusions from
just looking at the tiny bit of your life

123
00:08:42,900 --> 00:08:44,060
cycle.

124
00:08:44,060 --> 00:08:50,370
So, getting peers to review your code can
be really hard to find.

125
00:08:50,370 --> 00:08:59,580
And getting peers to that are willing to review
what you wrote is even harder.

126
00:08:59,580 --> 00:09:07,070
So, what I'm trying to tell is that benchmarking
is hard.

127
00:09:07,070 --> 00:09:17,700
And, however, there is a very popular benchmark
out there that is called the tech and power

128
00:09:17,700 --> 00:09:19,820
frameworks benchmark.

129
00:09:19,820 --> 00:09:23,710
Why is this benchmark so interesting to me?

130
00:09:23,710 --> 00:09:26,380
Well, to me it's like taking power.

131
00:09:26,380 --> 00:09:32,410
A benchmark shows you the true nature of open
source.

132
00:09:32,410 --> 00:09:34,260
It has more than 500 contributors.

133
00:09:34,260 --> 00:09:41,570
So, more than 500 different people have contributed
to tests and reviewed the tests.

134
00:09:41,570 --> 00:09:45,000
There are more than 3,000 merged pull requests.

135
00:09:45,000 --> 00:09:54,670
So, lots of people spend time reviewing or
adding new tests to the framework.

136
00:09:54,670 --> 00:09:57,340
And they already have more than 10,000 commits.

137
00:09:57,340 --> 00:10:01,460
So, it shows that it's kind of a big project.

138
00:10:01,460 --> 00:10:05,130
It's not something that someone just planned
in the weekend.

139
00:10:05,130 --> 00:10:08,520
Oh, I want to check on my framework, how it
works.

140
00:10:08,520 --> 00:10:13,610
No, it's something that has been growing steadily
for the last couple of years.

141
00:10:13,610 --> 00:10:19,050
And it already tests more than 630 different
frameworks.

142
00:10:19,050 --> 00:10:22,350
And these frameworks are written in different
languages.

143
00:10:22,350 --> 00:10:29,200
So, this makes my life easier because I don't
need to invent my own benchmark.

144
00:10:29,200 --> 00:10:30,430
I don't need to explain it.

145
00:10:30,430 --> 00:10:35,550
I can just use it to prove what I want to
say.

146
00:10:35,550 --> 00:10:40,700
So, if you want to have the link, this is
like their GitHub repo.

147
00:10:40,700 --> 00:10:45,370
And from the GitHub repo you can get to the
main website, of course.

148
00:10:45,370 --> 00:10:49,770
And as I said, there are like 630 different
frameworks.

149
00:10:49,770 --> 00:10:57,930
So, if I would try to print on the screen
how it looks right now, well, it wouldn't

150
00:10:57,930 --> 00:10:58,930
fit on the screen.

151
00:10:58,930 --> 00:11:01,470
So, what I did, I just rotated my screen.

152
00:11:01,470 --> 00:11:03,610
I took a screenshot.

153
00:11:03,610 --> 00:11:05,820
And don't worry about the size.

154
00:11:05,820 --> 00:11:07,570
It's not really relevant.

155
00:11:07,570 --> 00:11:15,700
What I'm trying to say is that there are lots
of frameworks that are already being tested.

156
00:11:15,700 --> 00:11:21,650
And the quick question I want to ask the audience
is, like, can you spot the best result for

157
00:11:21,650 --> 00:11:25,290
the JavaScript framework on this graph?

158
00:11:25,290 --> 00:11:27,520
So, probably you cannot because it's very
small.

159
00:11:27,520 --> 00:11:29,640
So, I have here a helper.

160
00:11:29,640 --> 00:11:35,660
You'll find that as shocking as it can be,
the first entry for JavaScript ranks at number

161
00:11:35,660 --> 00:11:37,560
89.

162
00:11:37,560 --> 00:11:45,530
Which performs at about 22.7% of the performance
of the best result.

163
00:11:45,530 --> 00:11:55,970
So, if you look at this, and think, well,
we all have this idea that JavaScript is fast,

164
00:11:55,970 --> 00:12:00,550
but results prove things wrong.

165
00:12:00,550 --> 00:12:03,560
That it's not as fast as we think it is.

166
00:12:03,560 --> 00:12:08,210
So, what we need to do is that we need to
look under the hood.

167
00:12:08,210 --> 00:12:12,470
So, before we can do any optimization, we
need to understand what's going on.

168
00:12:12,470 --> 00:12:16,970
And we shouldn't jump into conclusions and
start tweaking the code of the benchmark.

169
00:12:16,970 --> 00:12:19,540
Because otherwise we are just yak shaving.

170
00:12:19,540 --> 00:12:21,650
And you're not really looking into the problem.

171
00:12:21,650 --> 00:12:25,300
You're just trying to mitigate what could
be the cause.

172
00:12:25,300 --> 00:12:29,070
So, instead of this, we need to take a scientific
approach.

173
00:12:29,070 --> 00:12:33,210
And if you haven't learned anything about
profiling in other applications, I would recommend

174
00:12:33,210 --> 00:12:38,310
for you to look at the tutorial on the NodeJS
website on profiling.

175
00:12:38,310 --> 00:12:46,910
So, just to give you like in a nutshell the
information from the from this tutorial.

176
00:12:46,910 --> 00:12:53,610
That if you look at one of the tests of the
benchmark, which is a very simple return,

177
00:12:53,610 --> 00:12:57,540
hello world string from an HTTP server.

178
00:12:57,540 --> 00:13:03,320
The best result that you could that you saw
on the benchmark was implemented like this.

179
00:13:03,320 --> 00:13:05,720
So, it uses the cluster module.

180
00:13:05,720 --> 00:13:12,290
The cluster module will fork the node process
for the number of CPUs that the environment

181
00:13:12,290 --> 00:13:13,290
has.

182
00:13:13,290 --> 00:13:20,650
And then it uses the express server to set
the content type and send the response.

183
00:13:20,650 --> 00:13:21,820
Okay.

184
00:13:21,820 --> 00:13:27,670
Probably the express is not the most performant
library out there.

185
00:13:27,670 --> 00:13:30,120
But this is just for illustration.

186
00:13:30,120 --> 00:13:37,440
So, once we do this and we do profiling, we
get a flame graph.

187
00:13:37,440 --> 00:13:42,020
So, flame graphs are really interesting too
when we're talking about performance because

188
00:13:42,020 --> 00:13:50,550
they give you a visual explanation on where
your CPU time is spent.

189
00:13:50,550 --> 00:13:55,690
The width of the bars or the coloring doesn't
really matter.

190
00:13:55,690 --> 00:14:01,170
The coloring is just to give it make it nice
and it's called flame graphs because usually

191
00:14:01,170 --> 00:14:04,440
we paint it from red to yellow like a flame.

192
00:14:04,440 --> 00:14:11,360
But what is important to notice is that as
you go from bottom up, you see where the code

193
00:14:11,360 --> 00:14:16,400
is spending most time on your CPU.

194
00:14:16,400 --> 00:14:23,131
So, if you observe this, you basically what
the flame graph is telling you is that there

195
00:14:23,131 --> 00:14:31,860
is a very tiny piece on the top where JavaScript
code is being spent on.

196
00:14:31,860 --> 00:14:35,870
And then there's lots of time where it's spent
on native.

197
00:14:35,870 --> 00:14:43,430
And native means the Node bindings, V8 will
leave for the sync IO and also for the event

198
00:14:43,430 --> 00:14:44,870
loop.

199
00:14:44,870 --> 00:14:53,050
So, once we start trying to optimize this,
the code, we end up like trying to optimize

200
00:14:53,050 --> 00:14:54,770
just the tip of the iceberg.

201
00:14:54,770 --> 00:14:56,350
You cannot optimize everything.

202
00:14:56,350 --> 00:15:04,680
Because most of the time and if I would go
back most of the time here is spent on native

203
00:15:04,680 --> 00:15:05,680
code.

204
00:15:05,680 --> 00:15:07,880
So, you're just optimizing the tip of the
iceberg.

205
00:15:07,880 --> 00:15:11,860
So, this makes you think, right?

206
00:15:11,860 --> 00:15:12,860
This is interesting.

207
00:15:12,860 --> 00:15:14,920
What can we do about this?

208
00:15:14,920 --> 00:15:23,580
If you ask yourself, what is the first thing
that comes on your mind when I say, JavaScript

209
00:15:23,580 --> 00:15:24,920
engine?

210
00:15:24,920 --> 00:15:26,970
Most of you will say V8.

211
00:15:26,970 --> 00:15:33,470
So, if you look at the mission statement of
the V8 project, it reads something like speed

212
00:15:33,470 --> 00:15:38,630
up real world performance for more than JavaScript
and enable developers to build a faster future

213
00:15:38,630 --> 00:15:39,630
web.

214
00:15:39,630 --> 00:15:42,920
So, performance on V8 is great.

215
00:15:42,920 --> 00:15:45,000
But there are more engines out there.

216
00:15:45,000 --> 00:15:51,190
So, if you look at the table, not an authority
on JavaScript engines.

217
00:15:51,190 --> 00:15:54,620
Just lists the compatibility of ES6 across
many.

218
00:15:54,620 --> 00:16:01,300
There you can see engines like ChakraCore,
SpiderMonkey, Safari.

219
00:16:01,300 --> 00:16:07,910
And there was a new one added last year, crowdjs.

220
00:16:07,910 --> 00:16:14,920
So, what my experiment was all about is that,
well, I should try other engines.

221
00:16:14,920 --> 00:16:20,560
Because if most of the CPU is spent on native,
probably I should look into engines that handle

222
00:16:20,560 --> 00:16:24,020
this JavaScript runtime in a different way.

223
00:16:24,020 --> 00:16:26,470
So, I decided to look into rawjs.

224
00:16:26,470 --> 00:16:35,000
So, raw JS is an extension of the Java machine
that supports more languages and execution

225
00:16:35,000 --> 00:16:36,000
models.

226
00:16:36,000 --> 00:16:41,839
So, the project includes a new hey performance
compiler called Raw because as you know the

227
00:16:41,839 --> 00:16:47,010
most difficult thing in computer science and
science is naming things.

228
00:16:47,010 --> 00:16:50,750
You all it also Graal because it is interesting.

229
00:16:50,750 --> 00:16:58,430
And the objective of Graal is to improve the
performance of the machine on any language.

230
00:16:58,430 --> 00:17:04,730
And another goal is to allow free form mixing
of any programming language in a single program.

231
00:17:04,730 --> 00:17:07,380
So, it allows you to do polyglot programming.

232
00:17:07,380 --> 00:17:16,900
So, on the same program you can use Java,
Scala, Ruby, Rust, C++.

233
00:17:16,900 --> 00:17:21,890
And what's interesting about this is that
because it's a new project and it's all up

234
00:17:21,890 --> 00:17:29,040
to date, they offer a modern JavaScript runtime
based on ES2019, ES2020, which isn't released

235
00:17:29,040 --> 00:17:32,340
yet but they already implemented most of the
features.

236
00:17:32,340 --> 00:17:35,610
And the ultimate goal is a very fast server.

237
00:17:35,610 --> 00:17:38,190
But I don't want to change my programming
language.

238
00:17:38,190 --> 00:17:39,970
I want to stay on JavaScript.

239
00:17:39,970 --> 00:17:47,530
So, if I look at the definition of rawjs on
their website, their goals are to execute

240
00:17:47,530 --> 00:17:50,120
JavaScript code with the best possible performance.

241
00:17:50,120 --> 00:17:54,860
They have full support for the latest ES specification.

242
00:17:54,860 --> 00:18:02,920
And the fast interoperability with all the
languages on either on the JVM or the language

243
00:18:02,920 --> 00:18:12,050
supported by Graal like Ruby, Python and R.
There is research around this because this

244
00:18:12,050 --> 00:18:17,750
project, although it was open sourced last
year, it's been running for more than eight

245
00:18:17,750 --> 00:18:20,820
years behind closed doors.

246
00:18:20,820 --> 00:18:28,130
It's just been opened now because now they
feel that it's like in a real stable mature

247
00:18:28,130 --> 00:18:29,560
project.

248
00:18:29,560 --> 00:18:38,060
So, the people working and researching on
this have already shown that the engine is

249
00:18:38,060 --> 00:18:44,000
slightly better or on par with V8 for just
pure language benchmarks.

250
00:18:44,000 --> 00:18:46,450
And you can read more about the paper there.

251
00:18:46,450 --> 00:18:52,970
So, and although you can even run like unmodified
Node applications on it because it just allows

252
00:18:52,970 --> 00:19:00,419
you to just replace V8 from Node, I need to
formulate a hypothesis.

253
00:19:00,419 --> 00:19:09,020
What if we create a project that I would call
agnostic for X that first will replace V8

254
00:19:09,020 --> 00:19:10,390
with a project.

255
00:19:10,390 --> 00:19:15,460
Second, will replace the Eclipse vortex.

256
00:19:15,460 --> 00:19:21,000
Will replace the V8 with a Graal compiler.

257
00:19:21,000 --> 00:19:23,020
Will not have Node bindings.

258
00:19:23,020 --> 00:19:25,180
It will have text definitions.

259
00:19:25,180 --> 00:19:28,530
This will be discarded at runtime.

260
00:19:28,530 --> 00:19:32,230
The code that you don't run is the best code,
it's the fastest.

261
00:19:32,230 --> 00:19:33,960
You don't need to run it.

262
00:19:33,960 --> 00:19:41,270
And offer a basic JS and loader.

263
00:19:41,270 --> 00:19:45,680
And basic compatibility and allows you to
develop and profile the application with the

264
00:19:45,680 --> 00:19:49,360
tools you already know like the Chrome DevTools.

265
00:19:49,360 --> 00:19:59,640
So, if we were going to implement the previous
example that I showed with Node and express

266
00:19:59,640 --> 00:20:07,520
using this new style, this is how the old
express code would look like.

267
00:20:07,520 --> 00:20:10,770
I guess it's not that hard to understand what's
happening here.

268
00:20:10,770 --> 00:20:17,030
The important thing here to notice is that
the library I chose, vortex, by default uses

269
00:20:17,030 --> 00:20:21,710
all the available cores on your machine so
you don't need to use a cluster module to

270
00:20:21,710 --> 00:20:22,880
do forks.

271
00:20:22,880 --> 00:20:25,470
This is all handled behind the scenes for
you.

272
00:20:25,470 --> 00:20:34,179
And Vortex provides us an optimized sync IO
build on to have of an open source project

273
00:20:34,179 --> 00:20:37,930
used by big names like Google, Twitter, Netflix
just to name a few.

274
00:20:37,930 --> 00:20:45,280
If you want to test this, first thing, well,
you need to install a very simple application

275
00:20:45,280 --> 00:20:50,559
called ES4XPM short for project manager.

276
00:20:50,559 --> 00:20:52,410
We cannot run Node directly.

277
00:20:52,410 --> 00:20:54,640
Need to run through ES first.

278
00:20:54,640 --> 00:20:57,510
If I show you, this is how it looks.

279
00:20:57,510 --> 00:21:01,670
If I create a project.

280
00:21:01,670 --> 00:21:05,710
I can make it like with a new module syntax.

281
00:21:05,710 --> 00:21:11,120
And I recorded this so because I'm afraid
that I wouldn't have enough time.

282
00:21:11,120 --> 00:21:12,880
So, just have a couple of dependencies.

283
00:21:12,880 --> 00:21:15,980
This is pure npm stuff.

284
00:21:15,980 --> 00:21:21,670
I just use Vortex and web because I want to
do a web application.

285
00:21:21,670 --> 00:21:25,670
So, I create and you can even do like the
ES6 modules.

286
00:21:25,670 --> 00:21:26,670
I can say, okay.

287
00:21:26,670 --> 00:21:33,790
My home page is a function that I will export
that will just say, hello.

288
00:21:33,790 --> 00:21:37,179
Hello from Vortex Plus ES4X.

289
00:21:37,179 --> 00:21:40,780
And, of course, now I need to bootstrap a
server.

290
00:21:40,780 --> 00:21:44,850
I get my index, which is like my main application.

291
00:21:44,850 --> 00:21:51,940
And again, just import some code from the
vortex library.

292
00:21:51,940 --> 00:21:58,610
I now import my route from the module I just
created.

293
00:21:58,610 --> 00:22:00,160
Route.

294
00:22:00,160 --> 00:22:05,040
And now I just bootstrap the bootstrap my
application.

295
00:22:05,040 --> 00:22:07,830
So, I create the router.

296
00:22:07,830 --> 00:22:10,000
It's kind of the same idea as the express
server.

297
00:22:10,000 --> 00:22:15,940
So, I now create the router a route on home.

298
00:22:15,940 --> 00:22:20,450
And I just paste my callback.

299
00:22:20,450 --> 00:22:23,640
And now I create the server.

300
00:22:23,640 --> 00:22:28,400
I specify who will handle my server request.

301
00:22:28,400 --> 00:22:30,120
Who will be my router?

302
00:22:30,120 --> 00:22:33,080
And I start listening on port 8080.

303
00:22:33,080 --> 00:22:37,220
Same hello message.

304
00:22:37,220 --> 00:22:41,360
So, I'm running.

305
00:22:41,360 --> 00:22:50,929
So, now I can just install starting to make
npm and doesn't really matter.

306
00:22:50,929 --> 00:22:52,990
There are a couple of utilities.

307
00:22:52,990 --> 00:22:57,790
I can quickly get all of my application running
on VSCode.

308
00:22:57,790 --> 00:23:00,590
You can see it's already bugging.

309
00:23:00,590 --> 00:23:01,640
I can put a break point.

310
00:23:01,640 --> 00:23:07,820
And if I put a break point and now make an
HTTP request, you see that the request there

311
00:23:07,820 --> 00:23:08,820
is stopped.

312
00:23:08,820 --> 00:23:15,640
And what's interesting here to see is that
due to the nature of GraalVM, you can see

313
00:23:15,640 --> 00:23:22,340
on the debugger, the code from the Java side
and the code that you wrote.

314
00:23:22,340 --> 00:23:23,850
Everything is optimized.

315
00:23:23,850 --> 00:23:32,100
So, the expectation is that once you write
code in this way, your user code plus your

316
00:23:32,100 --> 00:23:38,350
runtime plus your interop plus your engine
plus your IO libraries plus the whole world

317
00:23:38,350 --> 00:23:39,420
that runs your application.

318
00:23:39,420 --> 00:23:42,220
In this case, the Graal JDK.

319
00:23:42,220 --> 00:23:45,690
It will all be optimized by Graal.

320
00:23:45,690 --> 00:23:46,950
Not just the script itself.

321
00:23:46,950 --> 00:23:52,070
Not just optimizing the tip of the iceberg,
you're optimizing everything.

322
00:23:52,070 --> 00:23:59,810
To test it, I submitted to the tech and power
implementation using this project.

323
00:23:59,810 --> 00:24:04,670
It was reviewed and got accepted and this
is how things are.

324
00:24:04,670 --> 00:24:07,210
This is like the CI builds.

325
00:24:07,210 --> 00:24:14,730
You see now ES4X is ranking on number five
which brings JavaScript from number 86 if

326
00:24:14,730 --> 00:24:24,250
I'm not mistaken to number five in simple
database query test that gets results.

327
00:24:24,250 --> 00:24:27,810
And ranked number six when doing multiple
queries.

328
00:24:27,810 --> 00:24:32,419
So, you see the parallel loading and testing.

329
00:24:32,419 --> 00:24:39,260
So, if I have to compare now this experiment
with all the frameworks that were already

330
00:24:39,260 --> 00:24:42,350
on the benchmark, this is how it compares.

331
00:24:42,350 --> 00:24:51,049
So, when working with JSON we see that the
results give you like two times better results

332
00:24:51,049 --> 00:24:53,490
than the previous best result.

333
00:24:53,490 --> 00:24:57,980
When going on a post base, doing one query,
it's three and a halftimes better.

334
00:24:57,980 --> 00:25:03,210
But if you have to be fair, testing for the
best previous one running on Postpress, it's

335
00:25:03,210 --> 00:25:07,760
six times better doing multiple queries.

336
00:25:07,760 --> 00:25:09,870
There's lots of concurrency going on.

337
00:25:09,870 --> 00:25:13,390
It's still two and a halftimes better than
the previous one.

338
00:25:13,390 --> 00:25:21,010
And doing data updates where the query is
really the issue, it's like five times better

339
00:25:21,010 --> 00:25:22,120
than the previous one.

340
00:25:22,120 --> 00:25:30,679
To put this in numbers if you think about
request response, you see that IO is better,

341
00:25:30,679 --> 00:25:32,090
of course.

342
00:25:32,090 --> 00:25:35,300
I'm not talking about a very small improvement,
tiny improvements.

343
00:25:35,300 --> 00:25:38,640
I'm talking about huge numbers.

344
00:25:38,640 --> 00:25:45,060
So, the final tip is that optimization is
like a neverending job.

345
00:25:45,060 --> 00:25:51,799
So, for example, we could get better results
if we used an enterprise edition of Graal

346
00:25:51,799 --> 00:25:54,980
instead of the open source edition.

347
00:25:54,980 --> 00:25:58,070
That gives you like 20% better performance.

348
00:25:58,070 --> 00:26:01,380
And because it's optimization, it's a neverending
job.

349
00:26:01,380 --> 00:26:07,860
You need to rinse and repeat and go just like
that.

350
00:26:07,860 --> 00:26:14,590
So, the key points I want to give is that
there's nothing wrong with JavaScript.

351
00:26:14,590 --> 00:26:16,780
JavaScript can be fast.

352
00:26:16,780 --> 00:26:21,680
And probably you don't need to switch to Go,
Rust, whatever, because you're having performance

353
00:26:21,680 --> 00:26:22,680
issues.

354
00:26:22,680 --> 00:26:27,929
You can still if you dare to experiment, you
can still remain on JavaScript.

355
00:26:27,929 --> 00:26:33,720
So, if you want to learn more you can.

356
00:26:33,720 --> 00:26:41,400
Either find me on Twitter, GitHub, the source
code forum on GitHub.

357
00:26:41,400 --> 00:26:45,490
And if there are any questions, you can catch
me later.

358
00:26:45,490 --> 00:26:51,000
Thank you.

