1
00:00:00,140 --> 00:00:02,730

good morning thank you for coming out to

2
00:00:02,730 --> 00:00:05,520
my session on elegant pacing patterns

3
00:00:05,520 --> 00:00:07,200
and different functional programming

4
00:00:07,200 --> 00:00:09,540
techniques you guys can use right now to

5
00:00:09,540 --> 00:00:12,179
help scale your JavaScript up to

6
00:00:12,179 --> 00:00:14,070
multiple cores if that sounds a little

7
00:00:14,070 --> 00:00:15,299
bit crazy and you're thinking wait a

8
00:00:15,299 --> 00:00:16,770
minute javascript can't even do this

9
00:00:16,770 --> 00:00:17,699
hang tight

10
00:00:17,699 --> 00:00:19,980
we'll get there so I'm Jonathan Martin

11
00:00:19,980 --> 00:00:23,369
or you can find me at nibbler on the web

12
00:00:23,369 --> 00:00:25,470
one of the awesome calligraphy artists

13
00:00:25,470 --> 00:00:28,109
do this and spell this out so if you

14
00:00:28,109 --> 00:00:30,179
haven't already checked out their booth

15
00:00:30,179 --> 00:00:31,529
by the way you should check it out

16
00:00:31,529 --> 00:00:33,149
they're really really good at what they

17
00:00:33,149 --> 00:00:35,910
do and I'm an instructor in web

18
00:00:35,910 --> 00:00:38,100
developer for a consultancy in the USA

19
00:00:38,100 --> 00:00:41,010
it's called big nerd ranch big nerd

20
00:00:41,010 --> 00:00:43,950
ranch develops web and mobile apps for

21
00:00:43,950 --> 00:00:46,379
our clients and we also teach developers

22
00:00:46,379 --> 00:00:47,969
to do the same through intensive

23
00:00:47,969 --> 00:00:50,280
five-day Bute camps mostly in the US and

24
00:00:50,280 --> 00:00:52,829
then also we fly out to many of our

25
00:00:52,829 --> 00:00:55,320
clients around the globe we also teach

26
00:00:55,320 --> 00:00:56,699
developers to our best-selling

27
00:00:56,699 --> 00:00:58,710
programming guides so maybe you've seen

28
00:00:58,710 --> 00:01:00,300
some of these before especially in the

29
00:01:00,300 --> 00:01:02,010
iOS and Android space and we have a

30
00:01:02,010 --> 00:01:04,700
front-end web development guide as well

31
00:01:04,700 --> 00:01:06,930
outside big nerd ranch I'm also a

32
00:01:06,930 --> 00:01:08,760
digital nomad which really just means

33
00:01:08,760 --> 00:01:10,920
that I leverage technology to work from

34
00:01:10,920 --> 00:01:11,760
anywhere in the globe

35
00:01:11,760 --> 00:01:14,610
so some of these areas might be where I

36
00:01:14,610 --> 00:01:17,340
might be working any given day this

37
00:01:17,340 --> 00:01:19,530
isn't quite the norm yet I'm working up

38
00:01:19,530 --> 00:01:21,810
towards this so over the last three

39
00:01:21,810 --> 00:01:23,610
years this lifestyle in particular has

40
00:01:23,610 --> 00:01:25,049
really helped me to nurture my love for

41
00:01:25,049 --> 00:01:27,119
landscape photography so if you don't

42
00:01:27,119 --> 00:01:29,460
like JavaScript or multi-threading which

43
00:01:29,460 --> 00:01:31,380
seems unusual since you came to a Jay s

44
00:01:31,380 --> 00:01:33,630
comp you can go look at pretty pictures

45
00:01:33,630 --> 00:01:35,759
instead for now I'll assume that's not

46
00:01:35,759 --> 00:01:39,240
the case since it is a Escom so when I

47
00:01:39,240 --> 00:01:40,650
was accepted it comes to speak here at

48
00:01:40,650 --> 00:01:42,630
Budapest I was pretty excited so I

49
00:01:42,630 --> 00:01:44,369
started to piece together my travel

50
00:01:44,369 --> 00:01:46,380
plans for speaking here in Budapest I'm

51
00:01:46,380 --> 00:01:48,329
slightly obsessed with the two to-do

52
00:01:48,329 --> 00:01:50,159
lists so I started listening out the

53
00:01:50,159 --> 00:01:51,869
things I need to complete before I could

54
00:01:51,869 --> 00:01:54,360
give this talk in Budapest of course I

55
00:01:54,360 --> 00:01:56,310
need to fly out here be a little bit

56
00:01:56,310 --> 00:01:57,990
hard to give it over hangouts internet

57
00:01:57,990 --> 00:01:59,729
connections in Alabama are the slowest

58
00:01:59,729 --> 00:02:02,250
in the u.s. also I'd need to put

59
00:02:02,250 --> 00:02:03,840
together a slide deck so I need to work

60
00:02:03,840 --> 00:02:06,030
on those I'd probably need to get packed

61
00:02:06,030 --> 00:02:08,940
for the trip I just some phone calls I

62
00:02:08,940 --> 00:02:10,470
need to make before that true

63
00:02:10,470 --> 00:02:12,330
and probably on the flight I should read

64
00:02:12,330 --> 00:02:15,300
a book and at least some time before my

65
00:02:15,300 --> 00:02:18,200
session I needed to take a shower so

66
00:02:18,200 --> 00:02:21,690
lists are great and but to really start

67
00:02:21,690 --> 00:02:23,370
knocking out leads to dues of course you

68
00:02:23,370 --> 00:02:25,050
need to figure out well what order am I

69
00:02:25,050 --> 00:02:26,610
gonna do these in what's gonna be my

70
00:02:26,610 --> 00:02:29,550
plan for completing these so I could

71
00:02:29,550 --> 00:02:31,530
just naively go from top to bottom and

72
00:02:31,530 --> 00:02:34,410
complete them one by one in that case I

73
00:02:34,410 --> 00:02:35,790
probably would have never made it out

74
00:02:35,790 --> 00:02:37,470
here since I didn't actually have the

75
00:02:37,470 --> 00:02:39,330
slide deck finished until a few minutes

76
00:02:39,330 --> 00:02:41,370
ago so I probably would never have flown

77
00:02:41,370 --> 00:02:43,080
out here and so I wouldn't be here so

78
00:02:43,080 --> 00:02:45,540
that's one strategy I could use I could

79
00:02:45,540 --> 00:02:47,130
go from top to bottom finish these one

80
00:02:47,130 --> 00:02:50,070
by one but we're human we don't actually

81
00:02:50,070 --> 00:02:53,250
finish things this way we tend to do

82
00:02:53,250 --> 00:02:55,980
more than one thing at a time so for

83
00:02:55,980 --> 00:02:58,560
example some of these things could

84
00:02:58,560 --> 00:03:00,180
happen at the same time you know maybe

85
00:03:00,180 --> 00:03:02,550
on my flight I could work on my slide

86
00:03:02,550 --> 00:03:04,650
deck if I was able to stay awake for

87
00:03:04,650 --> 00:03:06,630
that flight so if I were smarter when

88
00:03:06,630 --> 00:03:08,640
writing my to-do lists maybe I could

89
00:03:08,640 --> 00:03:11,130
encode constraints and preferences so I

90
00:03:11,130 --> 00:03:13,350
could better plan how to tackle this

91
00:03:13,350 --> 00:03:17,340
really onerous to-do list for example I

92
00:03:17,340 --> 00:03:20,130
could encode my constraints as arrows

93
00:03:20,130 --> 00:03:22,020
which show that some things logically

94
00:03:22,020 --> 00:03:24,360
have to come before others for example I

95
00:03:24,360 --> 00:03:26,130
have to pack before my flight and I have

96
00:03:26,130 --> 00:03:28,830
to fly before I can speak I also have to

97
00:03:28,830 --> 00:03:30,420
work on my slide deck but really that

98
00:03:30,420 --> 00:03:32,310
can happen any time before I get my talk

99
00:03:32,310 --> 00:03:34,170
so long as it happens before then I

100
00:03:34,170 --> 00:03:35,670
could work on it before or after my

101
00:03:35,670 --> 00:03:37,830
flight now some of these things also

102
00:03:37,830 --> 00:03:39,750
can't happen at the same time for

103
00:03:39,750 --> 00:03:41,340
example I can't make a phone call while

104
00:03:41,340 --> 00:03:43,380
I'm on the plane and I can't read a book

105
00:03:43,380 --> 00:03:45,209
while I'm in the shower as awesome as

106
00:03:45,209 --> 00:03:48,000
that sounds together these describe my

107
00:03:48,000 --> 00:03:50,370
constraints and preferences for how I'm

108
00:03:50,370 --> 00:03:53,600
going to get ready for my Jas comp talk

109
00:03:53,600 --> 00:03:55,980
software also deals with to-do lists of

110
00:03:55,980 --> 00:03:58,410
its own and the problem is twofold we

111
00:03:58,410 --> 00:04:00,660
need a way to model constraints and

112
00:04:00,660 --> 00:04:03,090
preferences for how work gets done and

113
00:04:03,090 --> 00:04:05,160
we need to figure out the optimal

114
00:04:05,160 --> 00:04:07,410
solution that satisfies all those

115
00:04:07,410 --> 00:04:09,450
constraints and preferences and the way

116
00:04:09,450 --> 00:04:11,040
we solve these two problems is a

117
00:04:11,040 --> 00:04:13,830
defining characteristic of many

118
00:04:13,830 --> 00:04:15,000
different programming languages

119
00:04:15,000 --> 00:04:18,359
including Java Script now before I hop

120
00:04:18,359 --> 00:04:19,739
into the body of this session I want to

121
00:04:19,739 --> 00:04:21,370
recap some terminology briefly

122
00:04:21,370 --> 00:04:23,199
in particular we're going to toss around

123
00:04:23,199 --> 00:04:26,669
the terms concurrency and parallelism

124
00:04:26,669 --> 00:04:28,720
parallelism excuse me

125
00:04:28,720 --> 00:04:30,729
concurrency just means that two or more

126
00:04:30,729 --> 00:04:33,370
computations have overlapping timelines

127
00:04:33,370 --> 00:04:36,160
with each other in terms of execution so

128
00:04:36,160 --> 00:04:38,919
for example task 3 begins before task

129
00:04:38,919 --> 00:04:41,410
two and task 1 but before task 3

130
00:04:41,410 --> 00:04:44,169
completes task 1 and task 2 will already

131
00:04:44,169 --> 00:04:46,210
begin computing so that's what I mean by

132
00:04:46,210 --> 00:04:48,669
overlapping timelines now how you

133
00:04:48,669 --> 00:04:50,860
achieve that concurrency is really up to

134
00:04:50,860 --> 00:04:52,000
you there's a lot of different

135
00:04:52,000 --> 00:04:54,550
strategies you could use one example is

136
00:04:54,550 --> 00:04:56,320
you could switch really quickly between

137
00:04:56,320 --> 00:04:59,169
working on these three tasks so in

138
00:04:59,169 --> 00:05:00,789
particular and software we could use

139
00:05:00,789 --> 00:05:04,060
multi-threading to do this a single CPU

140
00:05:04,060 --> 00:05:06,130
core can really only do one thing at a

141
00:05:06,130 --> 00:05:08,260
time but by quickly switching we could

142
00:05:08,260 --> 00:05:10,419
have these overlapping execution

143
00:05:10,419 --> 00:05:12,669
timelines context switching makes it

144
00:05:12,669 --> 00:05:14,169
seem like we're doing three things at

145
00:05:14,169 --> 00:05:16,110
the same time even though we aren't

146
00:05:16,110 --> 00:05:18,400
there's another way we can do this we

147
00:05:18,400 --> 00:05:20,229
could have three separate machines or

148
00:05:20,229 --> 00:05:23,650
CPU cores and dedicate one core per task

149
00:05:23,650 --> 00:05:26,650
this specific form of concurrency is

150
00:05:26,650 --> 00:05:28,539
often called parallelism

151
00:05:28,539 --> 00:05:31,090
so to summarize concurrent programs can

152
00:05:31,090 --> 00:05:32,340
run multiple pieces of code

153
00:05:32,340 --> 00:05:34,080
independently of each other and

154
00:05:34,080 --> 00:05:36,820
multi-threading and parallelism are just

155
00:05:36,820 --> 00:05:39,639
two execution strategies for running

156
00:05:39,639 --> 00:05:42,250
code concurrently so how we write our

157
00:05:42,250 --> 00:05:44,500
code our choice of style isn't really

158
00:05:44,500 --> 00:05:46,479
going to very much based on our choice

159
00:05:46,479 --> 00:05:49,270
of do we write it in parallel or

160
00:05:49,270 --> 00:05:51,580
multi-threaded so for this talk

161
00:05:51,580 --> 00:05:52,750
I'm not going to distinguish between

162
00:05:52,750 --> 00:05:54,639
them I'm just going to collectively

163
00:05:54,639 --> 00:05:59,199
refer to it as concurrency so after this

164
00:05:59,199 --> 00:06:00,970
point you don't have to remember any of

165
00:06:00,970 --> 00:06:02,289
those crazy things we're just always

166
00:06:02,289 --> 00:06:03,580
going to talk about code being

167
00:06:03,580 --> 00:06:05,440
concurrent which just means two or more

168
00:06:05,440 --> 00:06:08,199
things to our more functions perhaps are

169
00:06:08,199 --> 00:06:11,889
running at the same time now some of you

170
00:06:11,889 --> 00:06:15,070
gave me a funny little wink when I said

171
00:06:15,070 --> 00:06:16,240
something about multi-threading in

172
00:06:16,240 --> 00:06:17,740
JavaScript in the same sentence

173
00:06:17,740 --> 00:06:19,870
so note in front-end developers alike

174
00:06:19,870 --> 00:06:21,699
are commonly trolled by the classic

175
00:06:21,699 --> 00:06:24,070
question how do you scale a JavaScript

176
00:06:24,070 --> 00:06:26,080
code base since it's single threaded a

177
00:06:26,080 --> 00:06:29,169
little bit of a loaded question but in

178
00:06:29,169 --> 00:06:31,450
fact not only is it multi-threaded

179
00:06:31,450 --> 00:06:33,789
javascript is highly concurrent by

180
00:06:33,789 --> 00:06:34,930
default Thanks

181
00:06:34,930 --> 00:06:37,539
to the event loop but it shields us at

182
00:06:37,539 --> 00:06:38,710
the same time from many of them

183
00:06:38,710 --> 00:06:40,570
multi-threading woes and synchronization

184
00:06:40,570 --> 00:06:42,460
primitives you might be familiar with in

185
00:06:42,460 --> 00:06:45,220
other languages like semaphores mutexes

186
00:06:45,220 --> 00:06:48,970
locks etc so for example each of these

187
00:06:48,970 --> 00:06:51,610
web api calls seamlessly fires up a

188
00:06:51,610 --> 00:06:53,979
separate thread for a total of four

189
00:06:53,979 --> 00:06:55,870
threads you have the main Orchestrator

190
00:06:55,870 --> 00:06:57,250
thread which is where you write this

191
00:06:57,250 --> 00:06:59,650
code and then you also get these three

192
00:06:59,650 --> 00:07:01,479
others in the background for free that

193
00:07:01,479 --> 00:07:04,600
are powering these different api's so

194
00:07:04,600 --> 00:07:06,880
how on earth does that actually work if

195
00:07:06,880 --> 00:07:09,490
javascript is multi-threaded how is it

196
00:07:09,490 --> 00:07:11,259
that everything seemed like you is

197
00:07:11,259 --> 00:07:13,449
running on one thread which means that

198
00:07:13,449 --> 00:07:14,949
there's only one call stack and there's

199
00:07:14,949 --> 00:07:17,169
one thing happening at a time so how can

200
00:07:17,169 --> 00:07:18,729
you write your code in such a way that

201
00:07:18,729 --> 00:07:20,650
it looks like it's singles write it but

202
00:07:20,650 --> 00:07:22,060
it's actually taking advantage of

203
00:07:22,060 --> 00:07:24,099
multiple cores well that's where the

204
00:07:24,099 --> 00:07:26,979
event loop comes in now in 30 minutes I

205
00:07:26,979 --> 00:07:28,419
can't actually do full justice and

206
00:07:28,419 --> 00:07:30,460
explaining the event loop so let me just

207
00:07:30,460 --> 00:07:32,199
give you a quick recap and just keep in

208
00:07:32,199 --> 00:07:34,300
mind that I'm lying to you quite a bit

209
00:07:34,300 --> 00:07:36,310
so it's grossly inaccurate I'll forward

210
00:07:36,310 --> 00:07:38,820
you guys to a slightly better

211
00:07:38,820 --> 00:07:40,630
examination of the event loop near the

212
00:07:40,630 --> 00:07:43,180
end so in the middle of this slide we

213
00:07:43,180 --> 00:07:45,340
have the call stack and the call stack

214
00:07:45,340 --> 00:07:47,050
just helps us keep track of what is

215
00:07:47,050 --> 00:07:49,539
currently executing you might think of

216
00:07:49,539 --> 00:07:52,180
this and if this is your main javascript

217
00:07:52,180 --> 00:07:53,919
file and the pages just started up you

218
00:07:53,919 --> 00:07:56,229
might think of this as the main function

219
00:07:56,229 --> 00:07:58,720
if you have a callback executing then

220
00:07:58,720 --> 00:08:00,340
you could imagine that callback is on

221
00:08:00,340 --> 00:08:03,490
the call stack so on the far left we

222
00:08:03,490 --> 00:08:05,080
have the built-in web api's

223
00:08:05,080 --> 00:08:07,720
and these are natively implemented for

224
00:08:07,720 --> 00:08:09,430
equivalency this could also be the node

225
00:08:09,430 --> 00:08:11,590
api's node works the same way it also

226
00:08:11,590 --> 00:08:13,900
uses the event loop and then finally on

227
00:08:13,900 --> 00:08:15,370
the far left we have our source code

228
00:08:15,370 --> 00:08:17,800
that we've written we've loaded into the

229
00:08:17,800 --> 00:08:18,970
browser and now we're going to start

230
00:08:18,970 --> 00:08:21,159
executing it so the first line is

231
00:08:21,159 --> 00:08:23,650
performing an ajax request and it

232
00:08:23,650 --> 00:08:25,900
executes a function called parse once we

233
00:08:25,900 --> 00:08:30,280
receive an ajax response second we're

234
00:08:30,280 --> 00:08:32,979
using the set timeout api to schedule a

235
00:08:32,979 --> 00:08:35,200
refresh function to run in about five

236
00:08:35,200 --> 00:08:37,510
seconds or so and finally we use the

237
00:08:37,510 --> 00:08:40,839
indexdb api to make a database query and

238
00:08:40,839 --> 00:08:43,120
invoke a function called render once

239
00:08:43,120 --> 00:08:45,730
that query has completed so how is the

240
00:08:45,730 --> 00:08:47,350
JavaScript runtime actually going to go

241
00:08:47,350 --> 00:08:48,380
about eval

242
00:08:48,380 --> 00:08:50,000
awaiting this code some of these

243
00:08:50,000 --> 00:08:51,680
operations for example will take a while

244
00:08:51,680 --> 00:08:54,050
in Ajax requests might take a few

245
00:08:54,050 --> 00:08:55,610
hundred milliseconds or it might take

246
00:08:55,610 --> 00:08:57,380
several seconds depending on the

247
00:08:57,380 --> 00:08:59,840
connection yarn so javascript is going

248
00:08:59,840 --> 00:09:01,810
to evaluate these in a very specific

249
00:09:01,810 --> 00:09:04,820
order and so let's just to build up our

250
00:09:04,820 --> 00:09:05,840
understanding of the event loop we're

251
00:09:05,840 --> 00:09:08,240
going to walk through this ourselves so

252
00:09:08,240 --> 00:09:09,590
as soon as that fetch function is

253
00:09:09,590 --> 00:09:11,120
invoked you can imagine that that's

254
00:09:11,120 --> 00:09:13,760
currently on the call stack and it fires

255
00:09:13,760 --> 00:09:16,730
up a natively implemented web api in the

256
00:09:16,730 --> 00:09:19,880
backgrounds but it doesn't just fire up

257
00:09:19,880 --> 00:09:22,190
the fetch API it also passes along a

258
00:09:22,190 --> 00:09:25,100
function or callback to invoke once that

259
00:09:25,100 --> 00:09:28,490
fetch API receives the Ajax response now

260
00:09:28,490 --> 00:09:30,500
while that fetch Web API is running in

261
00:09:30,500 --> 00:09:31,370
the background

262
00:09:31,370 --> 00:09:33,350
the runtime will advance to the next

263
00:09:33,350 --> 00:09:35,390
line and go ahead and execute it without

264
00:09:35,390 --> 00:09:37,190
waiting for the Ajax request to finish

265
00:09:37,190 --> 00:09:39,530
this is how we think of asynchronous

266
00:09:39,530 --> 00:09:42,800
coding in JavaScript the set timeout API

267
00:09:42,800 --> 00:09:45,020
also fires up a native web the API and

268
00:09:45,020 --> 00:09:46,880
passes along a callback to execute once

269
00:09:46,880 --> 00:09:48,590
the time is up it's a very similar

270
00:09:48,590 --> 00:09:53,150
behavior so indexdb works exactly the

271
00:09:53,150 --> 00:09:54,830
same way it fires up a native web api

272
00:09:54,830 --> 00:09:57,440
and it passes a callback to execute - in

273
00:09:57,440 --> 00:10:02,060
the indexdb web api so now what we're

274
00:10:02,060 --> 00:10:03,710
out of source code to execute there's

275
00:10:03,710 --> 00:10:05,540
nothing on the call stack in most

276
00:10:05,540 --> 00:10:06,740
languages this would mean that your

277
00:10:06,740 --> 00:10:08,480
program is dead it's not running

278
00:10:08,480 --> 00:10:11,060
anything however we do have those native

279
00:10:11,060 --> 00:10:13,070
web api is still crunching some code for

280
00:10:13,070 --> 00:10:15,560
us in the background and so let's say

281
00:10:15,560 --> 00:10:18,800
that when the index DB query finishes it

282
00:10:18,800 --> 00:10:21,110
will alert the JavaScript runtime by

283
00:10:21,110 --> 00:10:22,970
pushing that render callback we gave it

284
00:10:22,970 --> 00:10:25,520
on to a queue it's very imaginatively

285
00:10:25,520 --> 00:10:28,400
named the callback queue now this

286
00:10:28,400 --> 00:10:31,820
doesn't yet run our render function so

287
00:10:31,820 --> 00:10:33,380
the event loop is actually just a

288
00:10:33,380 --> 00:10:35,210
mechanism that checks to see if there's

289
00:10:35,210 --> 00:10:37,970
anything currently running in other

290
00:10:37,970 --> 00:10:39,110
words is there something in the call

291
00:10:39,110 --> 00:10:40,910
stack and if there is something in the

292
00:10:40,910 --> 00:10:43,280
callback queue if there's nothing in the

293
00:10:43,280 --> 00:10:44,900
call stack and there's at least

294
00:10:44,900 --> 00:10:47,540
something on the combat queue the event

295
00:10:47,540 --> 00:10:49,790
loop will pop off that first callback

296
00:10:49,790 --> 00:10:52,310
off the queue and push it onto the call

297
00:10:52,310 --> 00:10:54,620
stack which means that now our render

298
00:10:54,620 --> 00:10:58,760
function is executing now while that

299
00:10:58,760 --> 00:11:00,350
render function is executing it could

300
00:11:00,350 --> 00:11:02,490
take a while another way

301
00:11:02,490 --> 00:11:04,170
I might finish its background work

302
00:11:04,170 --> 00:11:06,840
perhaps our Ajax request so that web api

303
00:11:06,840 --> 00:11:09,300
will immediately push the parse function

304
00:11:09,300 --> 00:11:12,690
onto the callback queue however this

305
00:11:12,690 --> 00:11:14,820
time there is code already on call stack

306
00:11:14,820 --> 00:11:15,720
being executed

307
00:11:15,720 --> 00:11:17,580
so that parse function is actually just

308
00:11:17,580 --> 00:11:20,220
going to stay in the callback queue this

309
00:11:20,220 --> 00:11:23,100
behavior is called run to completion it

310
00:11:23,100 --> 00:11:24,960
guarantees that the currently executing

311
00:11:24,960 --> 00:11:27,510
function will not be interrupted by

312
00:11:27,510 --> 00:11:29,670
another callback which in a nutshell

313
00:11:29,670 --> 00:11:30,810
means you don't have to worry about

314
00:11:30,810 --> 00:11:34,710
thread safety now when that current

315
00:11:34,710 --> 00:11:37,260
function on the call set takes a long

316
00:11:37,260 --> 00:11:39,120
time to finish this is what we call

317
00:11:39,120 --> 00:11:41,550
blocking the event loop you can just

318
00:11:41,550 --> 00:11:43,290
imagine that if the event loop keeps

319
00:11:43,290 --> 00:11:45,090
trying to figure out hey can I push

320
00:11:45,090 --> 00:11:46,620
something can I push something yet can i

321
00:11:46,620 --> 00:11:48,450
grab one of these callbacks and start

322
00:11:48,450 --> 00:11:51,030
executing it it's blocked until the call

323
00:11:51,030 --> 00:11:55,350
stack is empty now during this time our

324
00:11:55,350 --> 00:11:57,960
timer API might also finish and it just

325
00:11:57,960 --> 00:11:59,760
pushes the refresh function onto that

326
00:11:59,760 --> 00:12:01,410
callback queue and waits to be executed

327
00:12:01,410 --> 00:12:04,050
once that render function finally

328
00:12:04,050 --> 00:12:06,030
finishes executing the call stack is now

329
00:12:06,030 --> 00:12:08,190
empty which means that the event loop

330
00:12:08,190 --> 00:12:10,500
can pop the first callback off the

331
00:12:10,500 --> 00:12:13,320
callback queue and push it onto the call

332
00:12:13,320 --> 00:12:15,660
stack which means it's being executed

333
00:12:15,660 --> 00:12:17,040
that's what's currently being executed

334
00:12:17,040 --> 00:12:19,680
and of course once the parse function

335
00:12:19,680 --> 00:12:21,390
finishes the call SEC will again be

336
00:12:21,390 --> 00:12:23,550
empty so we can push that final refresh

337
00:12:23,550 --> 00:12:26,640
callback and then execute that to

338
00:12:26,640 --> 00:12:30,480
completion so in summary while our own

339
00:12:30,480 --> 00:12:32,580
JavaScript code looks like it's single

340
00:12:32,580 --> 00:12:34,110
threaded and in a way it is actually

341
00:12:34,110 --> 00:12:35,670
single threaded meaning there is only

342
00:12:35,670 --> 00:12:37,770
one call stack and only one function

343
00:12:37,770 --> 00:12:40,830
running at a time the native background

344
00:12:40,830 --> 00:12:43,920
Web API is that powered JavaScript can

345
00:12:43,920 --> 00:12:45,630
be executed on separate background

346
00:12:45,630 --> 00:12:47,730
threads seamlessly it's not even

347
00:12:47,730 --> 00:12:49,710
something we have to think about now not

348
00:12:49,710 --> 00:12:52,200
all of the async Web API s use separate

349
00:12:52,200 --> 00:12:54,690
threads but the mental model holds and

350
00:12:54,690 --> 00:12:56,430
it helps explain why no js' and

351
00:12:56,430 --> 00:12:58,350
javascript in the browser can perform so

352
00:12:58,350 --> 00:13:00,960
much work concurrently while appearing

353
00:13:00,960 --> 00:13:02,880
single threaded makes it very easy to

354
00:13:02,880 --> 00:13:05,640
reason about again this was a highly

355
00:13:05,640 --> 00:13:07,530
inaccurate version of this I hope that

356
00:13:07,530 --> 00:13:09,030
sets the stage at least for the rest of

357
00:13:09,030 --> 00:13:10,680
the session but you owe it to yourself

358
00:13:10,680 --> 00:13:11,940
to watch Phillip Roberts

359
00:13:11,940 --> 00:13:14,190
talk on the subject it's called help I'm

360
00:13:14,190 --> 00:13:15,670
stuck in an event loop

361
00:13:15,670 --> 00:13:17,980
you can check out this link bitly event

362
00:13:17,980 --> 00:13:20,230
loop help really great talk and it's

363
00:13:20,230 --> 00:13:23,200
only 20 minutes so the event loop is

364
00:13:23,200 --> 00:13:25,420
great but in nodejs you can pretty soon

365
00:13:25,420 --> 00:13:27,460
hit a scaling limit with a single

366
00:13:27,460 --> 00:13:29,350
process despite the many background

367
00:13:29,350 --> 00:13:31,660
threads so at this point many developers

368
00:13:31,660 --> 00:13:33,580
typically turn to something like nodes

369
00:13:33,580 --> 00:13:37,060
cluster module or PM 2 but turning to

370
00:13:37,060 --> 00:13:38,770
multi-processing 2 soon

371
00:13:38,770 --> 00:13:40,480
negates many of the single process

372
00:13:40,480 --> 00:13:42,280
benefits we enjoy and the predictability

373
00:13:42,280 --> 00:13:45,160
of having a single call stack in

374
00:13:45,160 --> 00:13:47,410
JavaScript now luckily a single

375
00:13:47,410 --> 00:13:49,150
JavaScript runtime thread can actually

376
00:13:49,150 --> 00:13:51,670
orchestrate an amazing amount of work

377
00:13:51,670 --> 00:13:54,190
but to write code that all that will

378
00:13:54,190 --> 00:13:55,600
scale easily and doesn't look like a

379
00:13:55,600 --> 00:13:58,300
bunch of promise dot all spaghetti will

380
00:13:58,300 --> 00:14:00,310
need to exercise a few patents so in the

381
00:14:00,310 --> 00:14:01,720
remainder of this session we're going to

382
00:14:01,720 --> 00:14:03,430
cover these three different patterns and

383
00:14:03,430 --> 00:14:05,140
recipes that you can use both in your

384
00:14:05,140 --> 00:14:07,240
node.js and your front-end web

385
00:14:07,240 --> 00:14:09,040
applications to write scalable

386
00:14:09,040 --> 00:14:10,930
performant code that remains elegant and

387
00:14:10,930 --> 00:14:13,660
actually scales to multiple cores we're

388
00:14:13,660 --> 00:14:14,890
gonna do that also without any

389
00:14:14,890 --> 00:14:16,930
third-party libraries no frameworks or

390
00:14:16,930 --> 00:14:19,530
fads just plain old JavaScript yes

391
00:14:19,530 --> 00:14:23,260
2017 specifically so the first pattern

392
00:14:23,260 --> 00:14:26,320
is coordinating concurrency with async

393
00:14:26,320 --> 00:14:28,330
if ease you probably haven't all heard

394
00:14:28,330 --> 00:14:31,680
of and seeing if ease so async if ease

395
00:14:31,680 --> 00:14:34,360
should bring up some interesting ideas

396
00:14:34,360 --> 00:14:36,340
so when you do more than one thing at a

397
00:14:36,340 --> 00:14:37,900
time you usually need some ugly

398
00:14:37,900 --> 00:14:39,700
pipelining to describe how those

399
00:14:39,700 --> 00:14:41,740
different tasks are related to each

400
00:14:41,740 --> 00:14:44,170
other so here's a concrete example let's

401
00:14:44,170 --> 00:14:46,360
say we're building iTunes in the browser

402
00:14:46,360 --> 00:14:48,580
and we're beginning to write the code

403
00:14:48,580 --> 00:14:50,800
for importing mp3 files into our music

404
00:14:50,800 --> 00:14:53,260
library in the browser the user might

405
00:14:53,260 --> 00:14:54,850
import these files by dragging and

406
00:14:54,850 --> 00:14:56,470
dropping them into the browser this is

407
00:14:56,470 --> 00:14:58,510
not a theoretical app by the way all the

408
00:14:58,510 --> 00:15:01,150
technology for this exists if you're

409
00:15:01,150 --> 00:15:03,690
interested I'll show you guys a demo of

410
00:15:03,690 --> 00:15:05,770
basically iTunes in the browser and

411
00:15:05,770 --> 00:15:07,780
working with mp3s some cool blog posts

412
00:15:07,780 --> 00:15:10,450
and stuff so we might imagine if we're

413
00:15:10,450 --> 00:15:12,340
writing this mp3 importer there are five

414
00:15:12,340 --> 00:15:15,220
steps to import a song first we need to

415
00:15:15,220 --> 00:15:17,950
read in the mp3 files contents we might

416
00:15:17,950 --> 00:15:20,140
have a file object and so we might need

417
00:15:20,140 --> 00:15:22,090
to read that in to some sort of binary

418
00:15:22,090 --> 00:15:23,100
data type enjoy

419
00:15:23,100 --> 00:15:25,680
script then from that we might want to

420
00:15:25,680 --> 00:15:27,870
parse out the song's title the album

421
00:15:27,870 --> 00:15:29,700
name and some other useful metadata in

422
00:15:29,700 --> 00:15:32,340
most mp3s this information is encoded in

423
00:15:32,340 --> 00:15:35,010
the beginning of the file it's a format

424
00:15:35,010 --> 00:15:37,770
called ID 3 if you're interested in how

425
00:15:37,770 --> 00:15:39,300
to parse that data and working with

426
00:15:39,300 --> 00:15:41,580
binary data in JavaScript check out the

427
00:15:41,580 --> 00:15:45,380
blog post it's bitly slash mp3 - parser

428
00:15:45,380 --> 00:15:48,240
now unfortunately id3 metadata doesn't

429
00:15:48,240 --> 00:15:52,050
usually include the songs duration so

430
00:15:52,050 --> 00:15:53,100
we'll actually need to calculate

431
00:15:53,100 --> 00:15:55,020
ourselves and we can do that using the

432
00:15:55,020 --> 00:15:58,680
web's audio api and once all that

433
00:15:58,680 --> 00:16:00,900
metadata is extracted we're going to

434
00:16:00,900 --> 00:16:03,330
auto create a new album in the database

435
00:16:03,330 --> 00:16:05,400
if one doesn't already exist by that

436
00:16:05,400 --> 00:16:07,410
name and then we'll finally create a new

437
00:16:07,410 --> 00:16:09,870
song entry in our music library using

438
00:16:09,870 --> 00:16:11,040
all the information from those previous

439
00:16:11,040 --> 00:16:14,400
four steps so my first solution when I

440
00:16:14,400 --> 00:16:15,990
was coding this up looked roughly like

441
00:16:15,990 --> 00:16:18,570
this very much the code corresponds

442
00:16:18,570 --> 00:16:20,580
exactly with those steps we read in the

443
00:16:20,580 --> 00:16:22,680
file in this case we're reading it in as

444
00:16:22,680 --> 00:16:24,420
an array buffer which is JavaScript

445
00:16:24,420 --> 00:16:28,350
binary data type and then we parse out

446
00:16:28,350 --> 00:16:30,360
ID 3 metadata this is a library of god

447
00:16:30,360 --> 00:16:31,980
on github you guys can check out and

448
00:16:31,980 --> 00:16:34,050
it's just using a lot of those binary

449
00:16:34,050 --> 00:16:37,050
files and then we're calculating the

450
00:16:37,050 --> 00:16:39,930
duration using some audio api's in

451
00:16:39,930 --> 00:16:42,530
particular this is audio context and

452
00:16:42,530 --> 00:16:44,880
then we're creating entries in the

453
00:16:44,880 --> 00:16:47,100
database for the album and then for the

454
00:16:47,100 --> 00:16:50,160
song now you'll notice that async and

455
00:16:50,160 --> 00:16:52,200
await makes this code really nice we've

456
00:16:52,200 --> 00:16:53,490
got a lot of asynchronous stuff

457
00:16:53,490 --> 00:16:55,500
happening here and all we have to do is

458
00:16:55,500 --> 00:16:57,960
put in a weight in front of every line

459
00:16:57,960 --> 00:17:00,660
that would return a promise this gets

460
00:17:00,660 --> 00:17:02,250
rid of all the dot then callback so this

461
00:17:02,250 --> 00:17:04,620
looks really nice there's a problem

462
00:17:04,620 --> 00:17:07,770
however we're actually blocking too much

463
00:17:07,770 --> 00:17:10,170
anytime you see a weight just realize

464
00:17:10,170 --> 00:17:12,120
that no code below that away will

465
00:17:12,120 --> 00:17:13,950
execute in other words we're kind of

466
00:17:13,950 --> 00:17:17,220
hamstringing JavaScript's pattern of

467
00:17:17,220 --> 00:17:19,650
just going line by line by line without

468
00:17:19,650 --> 00:17:22,440
pausing for a breath so unfortunately

469
00:17:22,440 --> 00:17:24,540
we're actually forcing more things than

470
00:17:24,540 --> 00:17:26,400
necessary to execute one after another

471
00:17:26,400 --> 00:17:29,340
when in reality they could be executing

472
00:17:29,340 --> 00:17:32,030
in parallel or I should say concurrently

473
00:17:32,030 --> 00:17:34,590
but if we wanted to execute some of this

474
00:17:34,590 --> 00:17:36,030
code concurrently you know

475
00:17:36,030 --> 00:17:37,950
squint at this and try to figure out hmm

476
00:17:37,950 --> 00:17:39,390
some of these things yeah they can run

477
00:17:39,390 --> 00:17:42,690
in concurrently but to do that you have

478
00:17:42,690 --> 00:17:44,940
to sacrifice those really elegant awaits

479
00:17:44,940 --> 00:17:47,400
here's one way we might do that we could

480
00:17:47,400 --> 00:17:49,860
use promised doll to block further code

481
00:17:49,860 --> 00:17:51,840
until the file reader and the parser

482
00:17:51,840 --> 00:17:54,660
have finished before computing the

483
00:17:54,660 --> 00:17:57,030
song's duration or importing in album

484
00:17:57,030 --> 00:17:59,370
not only does this uglify the solution

485
00:17:59,370 --> 00:18:01,320
quite a bit but more disturbingly it's

486
00:18:01,320 --> 00:18:04,230
still a suboptimal solution if the file

487
00:18:04,230 --> 00:18:06,600
reader for example finishes before the

488
00:18:06,600 --> 00:18:08,940
parser there's no reason the import

489
00:18:08,940 --> 00:18:11,430
album couldn't already begin doing its

490
00:18:11,430 --> 00:18:14,370
work the problem is it takes a fair

491
00:18:14,370 --> 00:18:16,350
amount of work to figure out the optimal

492
00:18:16,350 --> 00:18:19,350
grouping of which tasks can be run in

493
00:18:19,350 --> 00:18:22,170
parallel and any time you switch any one

494
00:18:22,170 --> 00:18:24,660
of these steps from asynchronous API to

495
00:18:24,660 --> 00:18:28,020
an async one it completely changes that

496
00:18:28,020 --> 00:18:29,880
optimal solution which means you're

497
00:18:29,880 --> 00:18:30,870
going to have a lot of code sharing

498
00:18:30,870 --> 00:18:32,280
you're gonna have very large get discs

499
00:18:32,280 --> 00:18:35,160
so luckily there's another way that we

500
00:18:35,160 --> 00:18:37,020
can model these kinds of concurrency

501
00:18:37,020 --> 00:18:40,410
relationships so what if we modeled each

502
00:18:40,410 --> 00:18:44,100
chunk of code as a dependency graph for

503
00:18:44,100 --> 00:18:46,350
the runtime to evaluate just like we did

504
00:18:46,350 --> 00:18:48,480
with my to-do list for coming to speak

505
00:18:48,480 --> 00:18:52,200
at J's conf to accomplish this we're

506
00:18:52,200 --> 00:18:54,060
going to use a pattern called the async

507
00:18:54,060 --> 00:18:56,040
immediately invoked function expression

508
00:18:56,040 --> 00:18:58,110
it's an elegant pattern for managing

509
00:18:58,110 --> 00:19:01,410
concurrency on a single thread now most

510
00:19:01,410 --> 00:19:02,970
of you have probably already seen async

511
00:19:02,970 --> 00:19:05,370
functions something to keep in mind is

512
00:19:05,370 --> 00:19:08,010
that in async function when invoked

513
00:19:08,010 --> 00:19:10,910
always returns a promise no exception

514
00:19:10,910 --> 00:19:13,500
even if there's an error it's just

515
00:19:13,500 --> 00:19:15,750
returns a promise that rejects so the

516
00:19:15,750 --> 00:19:18,330
return value from an async function

517
00:19:18,330 --> 00:19:21,540
invoked is always a promise so in async

518
00:19:21,540 --> 00:19:23,130
if e is just you creating an async

519
00:19:23,130 --> 00:19:25,530
function an anonymous one and you invoke

520
00:19:25,530 --> 00:19:29,160
it so the async Afiya allows us to group

521
00:19:29,160 --> 00:19:31,890
together sequential code into a single

522
00:19:31,890 --> 00:19:34,110
unit we might call a task and then

523
00:19:34,110 --> 00:19:36,930
immediately invokes it a task can depend

524
00:19:36,930 --> 00:19:39,900
on other tasks as a source of input but

525
00:19:39,900 --> 00:19:43,170
it produces a single return value as its

526
00:19:43,170 --> 00:19:45,600
output which means that this async if e

527
00:19:45,600 --> 00:19:47,220
is going to return a promise that

528
00:19:47,220 --> 00:19:49,080
resolves to the results

529
00:19:49,080 --> 00:19:51,419
now the task local variable that you see

530
00:19:51,419 --> 00:19:54,749
is also going to be a promise so if

531
00:19:54,749 --> 00:19:55,619
there's one thing you should take away

532
00:19:55,619 --> 00:19:58,080
from this talk it should be the async if

533
00:19:58,080 --> 00:20:00,450
you design pattern it kind of resembles

534
00:20:00,450 --> 00:20:05,580
a task in a task runner like a gulp like

535
00:20:05,580 --> 00:20:06,960
gulp or a makefile

536
00:20:06,960 --> 00:20:08,879
so if it helps you can think of async

537
00:20:08,879 --> 00:20:10,230
appeases sort of like those different

538
00:20:10,230 --> 00:20:13,019
tasks in a task runner now if we

539
00:20:13,019 --> 00:20:15,210
refactor our mp3 importer code into

540
00:20:15,210 --> 00:20:17,159
multiple tasks here's one way we might

541
00:20:17,159 --> 00:20:19,710
break it down so first when we read in

542
00:20:19,710 --> 00:20:21,690
that file this just returns a promise

543
00:20:21,690 --> 00:20:23,669
just for naming conventions I might call

544
00:20:23,669 --> 00:20:26,970
this the read task and then the meta

545
00:20:26,970 --> 00:20:29,129
task would just run that parsing code

546
00:20:29,129 --> 00:20:31,529
now you notice in every single one of

547
00:20:31,529 --> 00:20:34,919
these tasks all these operations depend

548
00:20:34,919 --> 00:20:37,769
on the very previous line in other words

549
00:20:37,769 --> 00:20:40,710
there's no line in any of these tasks

550
00:20:40,710 --> 00:20:43,559
that doesn't depend on everything before

551
00:20:43,559 --> 00:20:45,419
it we've tried to separate that out into

552
00:20:45,419 --> 00:20:47,940
these small chunks now each task is an

553
00:20:47,940 --> 00:20:50,220
async iffy so it returns a promise which

554
00:20:50,220 --> 00:20:52,919
evaluates to the functions return value

555
00:20:52,919 --> 00:20:55,649
at the very end the thing that kind of

556
00:20:55,649 --> 00:20:57,809
kick starts this process is when we're

557
00:20:57,809 --> 00:21:00,600
awaiting the song import task which is

558
00:21:00,600 --> 00:21:03,269
sort of the top level task that calls

559
00:21:03,269 --> 00:21:08,129
all these others so with multiple tasks

560
00:21:08,129 --> 00:21:09,690
we're just leveraging local variables

561
00:21:09,690 --> 00:21:11,730
and concurrency by default to

562
00:21:11,730 --> 00:21:13,230
essentially create a dependency graph

563
00:21:13,230 --> 00:21:14,759
which the JavaScript runtime will

564
00:21:14,759 --> 00:21:16,889
optimally evaluate for us no matter how

565
00:21:16,889 --> 00:21:19,289
complex it is so if we were to break

566
00:21:19,289 --> 00:21:21,179
these down you could imagine that this

567
00:21:21,179 --> 00:21:22,980
is the dependency graph that we've just

568
00:21:22,980 --> 00:21:24,509
modeled but we didn't actually have to

569
00:21:24,509 --> 00:21:26,309
type this out ourselves we didn't have

570
00:21:26,309 --> 00:21:28,049
to explicitly define that execution

571
00:21:28,049 --> 00:21:30,330
order just by wrapping sequential chunks

572
00:21:30,330 --> 00:21:32,609
of code into a sink if ease we modeled

573
00:21:32,609 --> 00:21:34,289
the constraints and let JavaScript

574
00:21:34,289 --> 00:21:36,809
figure out how to satisfy those

575
00:21:36,809 --> 00:21:39,869
constraints again there's tons more to

576
00:21:39,869 --> 00:21:41,460
the async if you pattern so definitely

577
00:21:41,460 --> 00:21:42,809
check out this blog post to learn more

578
00:21:42,809 --> 00:21:47,820
bitly slash async - if II leave that up

579
00:21:47,820 --> 00:21:51,480
just for a moment so our second step to

580
00:21:51,480 --> 00:21:53,759
creating elegant scalable code is to

581
00:21:53,759 --> 00:21:56,549
define execution preferences async

582
00:21:56,549 --> 00:21:58,019
ephese allow us to define those

583
00:21:58,019 --> 00:22:00,210
constraints how things have to execute

584
00:22:00,210 --> 00:22:02,310
but a lot of times you

585
00:22:02,310 --> 00:22:05,010
to say how would we like these things to

586
00:22:05,010 --> 00:22:06,270
be executed how would we like to

587
00:22:06,270 --> 00:22:08,760
prioritize them in particular how could

588
00:22:08,760 --> 00:22:10,560
we throttle how many things are allowed

589
00:22:10,560 --> 00:22:12,840
to run concurrently with functional

590
00:22:12,840 --> 00:22:15,210
programming so our mp3 importer right

591
00:22:15,210 --> 00:22:17,100
now runs as fast as possible which is

592
00:22:17,100 --> 00:22:17,760
fabulous

593
00:22:17,760 --> 00:22:19,770
but this is a browser so we need to be

594
00:22:19,770 --> 00:22:21,750
considerate of the CPU which is after

595
00:22:21,750 --> 00:22:25,110
all a limited resource so a syncope has

596
00:22:25,110 --> 00:22:26,370
led us to find those execution

597
00:22:26,370 --> 00:22:28,920
constraints how could we declaratively

598
00:22:28,920 --> 00:22:31,830
define our preferences for how that work

599
00:22:31,830 --> 00:22:34,500
gets executed on the CPU for example in

600
00:22:34,500 --> 00:22:36,600
our application if a user drops in a

601
00:22:36,600 --> 00:22:40,730
very large collection of mp3s by default

602
00:22:40,730 --> 00:22:43,530
we might either import all these songs

603
00:22:43,530 --> 00:22:46,110
one by one which is not so cool or we

604
00:22:46,110 --> 00:22:49,200
might import them all at once now your

605
00:22:49,200 --> 00:22:50,760
solution is great in particular if we

606
00:22:50,760 --> 00:22:52,470
started importing all of them at once

607
00:22:52,470 --> 00:22:54,150
we might get this really irritating

608
00:22:54,150 --> 00:22:56,880
progress bar behavior like this where it

609
00:22:56,880 --> 00:22:58,740
jumps from oh I'm importing the first

610
00:22:58,740 --> 00:23:01,800
one and then 20 seconds later it jumps

611
00:23:01,800 --> 00:23:03,750
all the way to the hand since all those

612
00:23:03,750 --> 00:23:05,490
songs started importing at the same time

613
00:23:05,490 --> 00:23:06,810
the progress bar is basically

614
00:23:06,810 --> 00:23:08,910
meaningless to the user and it will

615
00:23:08,910 --> 00:23:11,270
often lock up the browser also not great

616
00:23:11,270 --> 00:23:14,400
so instead what if we said well we only

617
00:23:14,400 --> 00:23:16,860
want to import a few songs at a time and

618
00:23:16,860 --> 00:23:18,750
then we'll queue up the others for

619
00:23:18,750 --> 00:23:20,910
import once another song finishes

620
00:23:20,910 --> 00:23:23,760
importing so only importing a few at a

621
00:23:23,760 --> 00:23:29,070
time so in many threaded languages you

622
00:23:29,070 --> 00:23:31,140
can accomplish something like this with

623
00:23:31,140 --> 00:23:34,170
semaphores semaphores are an object that

624
00:23:34,170 --> 00:23:37,320
represent a limited resource and you can

625
00:23:37,320 --> 00:23:41,100
acquire and release access to it to

626
00:23:41,100 --> 00:23:43,740
basically throttle how many times or how

627
00:23:43,740 --> 00:23:44,820
many people are trying to use that

628
00:23:44,820 --> 00:23:48,600
semaphore so for example the CPU is an

629
00:23:48,600 --> 00:23:50,010
example of something a semaphore might

630
00:23:50,010 --> 00:23:52,020
represent it could be a database or even

631
00:23:52,020 --> 00:23:55,260
network i/o at their extreme we could

632
00:23:55,260 --> 00:23:57,090
limit it to one client at a time which

633
00:23:57,090 --> 00:23:59,370
we would call a mutex now in an

634
00:23:59,370 --> 00:24:00,960
object-oriented paradigm we could

635
00:24:00,960 --> 00:24:02,940
initialize a semaphore object with the

636
00:24:02,940 --> 00:24:05,040
maximum number of concurrent clients and

637
00:24:05,040 --> 00:24:07,800
use a wait to acquire a spot in the

638
00:24:07,800 --> 00:24:09,630
queue before we execute our code and

639
00:24:09,630 --> 00:24:11,760
then once a spot opens up we do some

640
00:24:11,760 --> 00:24:12,450
things

641
00:24:12,450 --> 00:24:14,970
and we release our spot so another

642
00:24:14,970 --> 00:24:18,630
client can execute some code so here's a

643
00:24:18,630 --> 00:24:20,910
sample object-oriented solution to

644
00:24:20,910 --> 00:24:23,010
creating a semaphore and it just tracks

645
00:24:23,010 --> 00:24:24,300
functions that are waiting to be

646
00:24:24,300 --> 00:24:26,880
executed and whenever a spot opens up it

647
00:24:26,880 --> 00:24:28,410
executes the next function in the queue

648
00:24:28,410 --> 00:24:34,590
so this is very standard cs20 101 type

649
00:24:34,590 --> 00:24:36,000
solution you would probably write for

650
00:24:36,000 --> 00:24:38,550
semaphore unfortunately there's some

651
00:24:38,550 --> 00:24:40,230
really brittle boilerplate with an

652
00:24:40,230 --> 00:24:41,840
object-oriented solution for a semaphore

653
00:24:41,840 --> 00:24:44,490
in particular we could easily write code

654
00:24:44,490 --> 00:24:47,160
that will acquire a semaphore but never

655
00:24:47,160 --> 00:24:48,030
release it

656
00:24:48,030 --> 00:24:49,860
perhaps we throw an exception which will

657
00:24:49,860 --> 00:24:51,690
blow up the rest of the function so now

658
00:24:51,690 --> 00:24:54,320
that some before will never be released

659
00:24:54,320 --> 00:24:57,420
so instead here's a functional

660
00:24:57,420 --> 00:24:58,890
programming version of that same

661
00:24:58,890 --> 00:25:00,660
semaphore and instead of returning an

662
00:25:00,660 --> 00:25:02,640
object it's going to return a

663
00:25:02,640 --> 00:25:05,220
higher-order function that wraps up

664
00:25:05,220 --> 00:25:07,140
other functions with a call to acquire

665
00:25:07,140 --> 00:25:08,970
and release so you can almost think of

666
00:25:08,970 --> 00:25:11,340
it as it I can take any function and

667
00:25:11,340 --> 00:25:14,180
I'll prepend it with a choir and then

668
00:25:14,180 --> 00:25:18,810
suffix it with dot release so use this

669
00:25:18,810 --> 00:25:20,460
functional sum before we can invoke it

670
00:25:20,460 --> 00:25:22,590
with an async function now there's no

671
00:25:22,590 --> 00:25:25,260
way a semaphore can be acquired but not

672
00:25:25,260 --> 00:25:27,960
released now we're actually only one

673
00:25:27,960 --> 00:25:29,280
step away from turning this into a

674
00:25:29,280 --> 00:25:30,960
really elegant higher-order function

675
00:25:30,960 --> 00:25:33,000
that doesn't even force us to think

676
00:25:33,000 --> 00:25:35,400
about semaphores at all so let's suppose

677
00:25:35,400 --> 00:25:37,680
that we want to limit how many times our

678
00:25:37,680 --> 00:25:41,250
import mp3 function is called and we

679
00:25:41,250 --> 00:25:43,140
want to limit how many times it can be

680
00:25:43,140 --> 00:25:45,270
run concurrently so in other words if

681
00:25:45,270 --> 00:25:48,270
you call import mp3 four times right

682
00:25:48,270 --> 00:25:50,250
after each other say we only want to

683
00:25:50,250 --> 00:25:52,470
allow two instances of that function to

684
00:25:52,470 --> 00:25:55,620
run at a time and then it would delay

685
00:25:55,620 --> 00:25:57,930
the third and fourth invocations until

686
00:25:57,930 --> 00:26:00,210
there's a slot left until one of those

687
00:26:00,210 --> 00:26:03,060
first two invocations is finished so we

688
00:26:03,060 --> 00:26:04,770
could think of this function we might

689
00:26:04,770 --> 00:26:06,870
call it limit we could think of it as a

690
00:26:06,870 --> 00:26:08,850
decorator or higher-order function and

691
00:26:08,850 --> 00:26:11,370
it takes an async function that usually

692
00:26:11,370 --> 00:26:14,130
runs with unlimited concurrency and it

693
00:26:14,130 --> 00:26:15,570
returns the same function but now

694
00:26:15,570 --> 00:26:17,910
composed with throttling behavior so

695
00:26:17,910 --> 00:26:19,950
this example would take our mp3 importer

696
00:26:19,950 --> 00:26:21,810
function and return a new function that

697
00:26:21,810 --> 00:26:24,570
looks exactly the same but only allows

698
00:26:24,570 --> 00:26:25,690
two instances

699
00:26:25,690 --> 00:26:28,420
function to run concurrently so in this

700
00:26:28,420 --> 00:26:31,090
example song 1 and song 2 will

701
00:26:31,090 --> 00:26:33,970
immediately begin importing but song 3

702
00:26:33,970 --> 00:26:35,950
won't even begin importing until song 1

703
00:26:35,950 --> 00:26:38,260
or song 2 finishes meaning there's a

704
00:26:38,260 --> 00:26:41,650
slot in the semaphore the limit function

705
00:26:41,650 --> 00:26:43,480
it turns out is really easy to write

706
00:26:43,480 --> 00:26:45,040
with a semaphore we built it's just

707
00:26:45,040 --> 00:26:47,260
three or four lines of code but the key

708
00:26:47,260 --> 00:26:48,970
takeaway from this is that instead of

709
00:26:48,970 --> 00:26:51,580
focusing now on managing this abstract

710
00:26:51,580 --> 00:26:54,130
semaphore object we're focusing on

711
00:26:54,130 --> 00:26:56,770
creating functions with new throttling

712
00:26:56,770 --> 00:26:58,570
behavior it's really elegant and cuts

713
00:26:58,570 --> 00:27:00,520
down on potential bugs from trying to

714
00:27:00,520 --> 00:27:02,290
share a similar object throughout your

715
00:27:02,290 --> 00:27:04,900
codebase and it preserves your existing

716
00:27:04,900 --> 00:27:07,210
API so that way if you want to throttle

717
00:27:07,210 --> 00:27:09,100
concurrency in your codebase you don't

718
00:27:09,100 --> 00:27:10,960
have to refactor your code or change any

719
00:27:10,960 --> 00:27:13,930
of your api's again there's a whole lot

720
00:27:13,930 --> 00:27:15,700
more we could dive into here so feel

721
00:27:15,700 --> 00:27:17,110
free to check out the source code in

722
00:27:17,110 --> 00:27:19,330
particular for the semaphore if you want

723
00:27:19,330 --> 00:27:20,860
to play around without a bit on github

724
00:27:20,860 --> 00:27:24,540
but the final component of this talk is

725
00:27:24,540 --> 00:27:27,640
how can we create our own long-lived

726
00:27:27,640 --> 00:27:31,450
async tasks with a web worker cluster so

727
00:27:31,450 --> 00:27:32,230
what do I mean by this

728
00:27:32,230 --> 00:27:34,090
so the browser comes with a huge

729
00:27:34,090 --> 00:27:36,340
selection of async api's that we use all

730
00:27:36,340 --> 00:27:36,910
the time

731
00:27:36,910 --> 00:27:39,310
these api's are natively implemented

732
00:27:39,310 --> 00:27:41,440
there's not JavaScript code behind in

733
00:27:41,440 --> 00:27:44,200
Ajax requests so for example the fetch

734
00:27:44,200 --> 00:27:46,780
on index DB abis are all natively

735
00:27:46,780 --> 00:27:49,360
implemented and they use promises and

736
00:27:49,360 --> 00:27:50,830
other asynchronous mechanisms like

737
00:27:50,830 --> 00:27:53,800
callbacks now under the hood the browser

738
00:27:53,800 --> 00:27:55,930
handles this by managing a dedicated

739
00:27:55,930 --> 00:27:58,090
thread pool that's ready to crunch those

740
00:27:58,090 --> 00:28:00,940
async api's for you whenever you try to

741
00:28:00,940 --> 00:28:04,300
use one of these async api's but what if

742
00:28:04,300 --> 00:28:06,250
you could create your own how would you

743
00:28:06,250 --> 00:28:08,740
create your own native async api's for

744
00:28:08,740 --> 00:28:11,050
your own long-lived async operations

745
00:28:11,050 --> 00:28:13,000
that maybe they take up a lot of time

746
00:28:13,000 --> 00:28:14,440
and you don't want to block the main

747
00:28:14,440 --> 00:28:14,770
thread

748
00:28:14,770 --> 00:28:16,990
for example maybe we want to move our

749
00:28:16,990 --> 00:28:19,570
mp3 importer off the main thread which

750
00:28:19,570 --> 00:28:22,300
is also rendering the UI maybe we want

751
00:28:22,300 --> 00:28:24,400
to move it to the background so that way

752
00:28:24,400 --> 00:28:26,710
it won't lock up the UI if it takes a

753
00:28:26,710 --> 00:28:28,660
particularly long time to import some of

754
00:28:28,660 --> 00:28:29,320
these mp3s

755
00:28:29,320 --> 00:28:31,630
well web workers are essentially that

756
00:28:31,630 --> 00:28:34,180
there are standard web api for creating

757
00:28:34,180 --> 00:28:36,760
background threads so to create a web

758
00:28:36,760 --> 00:28:38,680
worker we just invoke the worker

759
00:28:38,680 --> 00:28:39,320
construct

760
00:28:39,320 --> 00:28:41,210
and give it the path to the JavaScript

761
00:28:41,210 --> 00:28:42,710
code that will execute with its own

762
00:28:42,710 --> 00:28:45,200
dedicated scope and with its own event

763
00:28:45,200 --> 00:28:47,150
loop it's completely isolated from your

764
00:28:47,150 --> 00:28:49,400
main thread now to communicate with a

765
00:28:49,400 --> 00:28:52,100
worker you can only exchange messages

766
00:28:52,100 --> 00:28:54,350
this is a really important concept those

767
00:28:54,350 --> 00:28:56,510
of you have maybe tried elixir or some

768
00:28:56,510 --> 00:28:58,310
of these high concurrency high fault

769
00:28:58,310 --> 00:28:59,690
tolerance type languages are probably

770
00:28:59,690 --> 00:29:01,400
already familiar with this concept of

771
00:29:01,400 --> 00:29:04,010
exchanging messages basically it means

772
00:29:04,010 --> 00:29:06,080
the worker must be listening for that

773
00:29:06,080 --> 00:29:08,240
message and handle it as part of its own

774
00:29:08,240 --> 00:29:10,880
event loop cycle so in other words

775
00:29:10,880 --> 00:29:14,030
messages are received asynchronously now

776
00:29:14,030 --> 00:29:15,590
the main thread and the worker thread

777
00:29:15,590 --> 00:29:17,990
don't have to both block to exchange

778
00:29:17,990 --> 00:29:19,760
that message they just send and check

779
00:29:19,760 --> 00:29:21,370
for messages whenever they're ready to

780
00:29:21,370 --> 00:29:23,870
now the basic web worker API is not

781
00:29:23,870 --> 00:29:26,150
exceptionally elegant if you want to

782
00:29:26,150 --> 00:29:27,830
have a two-way conversation between the

783
00:29:27,830 --> 00:29:29,270
worker main thread it can really quickly

784
00:29:29,270 --> 00:29:31,840
turn into this really ugly callbacks OOP

785
00:29:31,840 --> 00:29:34,610
so what if web workers looked more like

786
00:29:34,610 --> 00:29:37,760
an async web api call where we invoke it

787
00:29:37,760 --> 00:29:39,710
and we get a promise in return that

788
00:29:39,710 --> 00:29:43,130
resolves to the workers end result that

789
00:29:43,130 --> 00:29:45,050
would make it really trivial to move CPU

790
00:29:45,050 --> 00:29:47,240
intensive computations to a separate

791
00:29:47,240 --> 00:29:49,040
thread so we don't end up walking the

792
00:29:49,040 --> 00:29:50,600
main thread so you can imagine there's

793
00:29:50,600 --> 00:29:52,460
probably a lot of use cases for this up

794
00:29:52,460 --> 00:29:54,410
until cryptography was added to the

795
00:29:54,410 --> 00:29:56,210
browser standards cryptography would

796
00:29:56,210 --> 00:29:58,280
have been a really common use case same

797
00:29:58,280 --> 00:30:00,560
for doing any sort of 3d graphics maybe

798
00:30:00,560 --> 00:30:02,600
game rendering maybe you'd like to move

799
00:30:02,600 --> 00:30:04,010
these to the background off the main

800
00:30:04,010 --> 00:30:05,600
thread but you don't have to completely

801
00:30:05,600 --> 00:30:07,730
rewrite your code base to take advantage

802
00:30:07,730 --> 00:30:11,360
of it so in particular we're going to

803
00:30:11,360 --> 00:30:13,310
take our mp3 importer and move it into a

804
00:30:13,310 --> 00:30:15,380
worker and treat it as though it were a

805
00:30:15,380 --> 00:30:18,950
natively implemented async web api to do

806
00:30:18,950 --> 00:30:19,970
this we're going to create this

807
00:30:19,970 --> 00:30:22,160
mysterious cluster function to make the

808
00:30:22,160 --> 00:30:24,080
web worker API a little bit more elegant

809
00:30:24,080 --> 00:30:26,780
for our use case and cluster is just

810
00:30:26,780 --> 00:30:29,240
going to spin up a bunch of web workers

811
00:30:29,240 --> 00:30:32,390
in the background for us and these web

812
00:30:32,390 --> 00:30:34,160
workers will handle the task of

813
00:30:34,160 --> 00:30:36,380
importing mp3s so a functional

814
00:30:36,380 --> 00:30:37,670
programming the implementation for this

815
00:30:37,670 --> 00:30:40,160
cluster is actually really terse so this

816
00:30:40,160 --> 00:30:41,870
code has a lot of stuff at the beginning

817
00:30:41,870 --> 00:30:43,640
basically it figures out what's the best

818
00:30:43,640 --> 00:30:45,530
number of web workers to use usually

819
00:30:45,530 --> 00:30:48,430
that's how many virtual cores you have

820
00:30:48,430 --> 00:30:51,320
so it creates these different workers

821
00:30:51,320 --> 00:30:52,070
and it put

822
00:30:52,070 --> 00:30:53,660
some in an array to keep track of it's

823
00:30:53,660 --> 00:30:55,340
basically a pool of workers and each

824
00:30:55,340 --> 00:30:58,430
time we try to invoke that cluster it

825
00:30:58,430 --> 00:31:00,200
grabs a worker from the pool that's

826
00:31:00,200 --> 00:31:02,210
currently unused and it forwards along

827
00:31:02,210 --> 00:31:04,160
some data so this would be us invoking

828
00:31:04,160 --> 00:31:05,840
cluster we pass some argument those

829
00:31:05,840 --> 00:31:07,610
arguments get forwarded to the worker

830
00:31:07,610 --> 00:31:10,400
once the worker finishes and replies

831
00:31:10,400 --> 00:31:11,480
with the result

832
00:31:11,480 --> 00:31:14,150
it adds itself back to the pool to say

833
00:31:14,150 --> 00:31:15,380
hey I'm not currently working on

834
00:31:15,380 --> 00:31:17,030
anything you can use me for a different

835
00:31:17,030 --> 00:31:19,490
computation and the overall promise will

836
00:31:19,490 --> 00:31:22,760
evaluate to that result the code for the

837
00:31:22,760 --> 00:31:25,670
web worker itself is really short it's

838
00:31:25,670 --> 00:31:27,590
an infinite loop that just receives data

839
00:31:27,590 --> 00:31:29,360
from the main thread it does some work

840
00:31:29,360 --> 00:31:31,130
and then it notifies the main thread

841
00:31:31,130 --> 00:31:33,530
when it's done with that computation by

842
00:31:33,530 --> 00:31:34,970
the way this isn't just for the browser

843
00:31:34,970 --> 00:31:38,120
you can use a popular facade library to

844
00:31:38,120 --> 00:31:40,520
write web workers in node as well with

845
00:31:40,520 --> 00:31:42,650
the same API and under the hood it uses

846
00:31:42,650 --> 00:31:44,510
native multi-threading so this isn't

847
00:31:44,510 --> 00:31:47,000
just for the front-end browser so you

848
00:31:47,000 --> 00:31:49,970
could imagine moving all kinds of CPU

849
00:31:49,970 --> 00:31:52,610
intensive operations with just a few

850
00:31:52,610 --> 00:31:53,990
lines of code you can actually get with

851
00:31:53,990 --> 00:31:55,610
fewer than this if you write a little

852
00:31:55,610 --> 00:31:57,620
utility function you can imagine moving

853
00:31:57,620 --> 00:32:00,650
all of these into web workers so a

854
00:32:00,650 --> 00:32:03,140
little bit long time so the TLDR from

855
00:32:03,140 --> 00:32:04,790
this really is that javascript in the

856
00:32:04,790 --> 00:32:07,850
browser and node.js is highly concurrent

857
00:32:07,850 --> 00:32:10,280
out-of-the-box so things like async

858
00:32:10,280 --> 00:32:12,140
appease can help us define those

859
00:32:12,140 --> 00:32:15,260
execution constraints thanks to the

860
00:32:15,260 --> 00:32:16,610
event loop we don't have to even worry

861
00:32:16,610 --> 00:32:18,830
about thread safety or re-entrance e or

862
00:32:18,830 --> 00:32:20,090
a lot of these other things you might be

863
00:32:20,090 --> 00:32:22,130
familiar with with language like C or

864
00:32:22,130 --> 00:32:24,890
Java and functional programming patterns

865
00:32:24,890 --> 00:32:26,660
keep us from making a mess of things

866
00:32:26,660 --> 00:32:28,580
just for the sake of that threading it

867
00:32:28,580 --> 00:32:30,380
all happens pretty seamlessly for us and

868
00:32:30,380 --> 00:32:32,780
if there isn't an async Web API for

869
00:32:32,780 --> 00:32:35,420
something you need maybe its 3d graphics

870
00:32:35,420 --> 00:32:37,550
related or cryptography related just

871
00:32:37,550 --> 00:32:39,470
write your own web worker and treat it

872
00:32:39,470 --> 00:32:41,180
like a native async web api

873
00:32:41,180 --> 00:32:43,580
so next time you're told just remember

874
00:32:43,580 --> 00:32:45,740
you can always bet on JavaScript to help

875
00:32:45,740 --> 00:32:47,510
you leverage multi-core machines and

876
00:32:47,510 --> 00:32:49,430
crunch there to do loops through to-do

877
00:32:49,430 --> 00:32:51,770
lists so you won't soak your favorite

878
00:32:51,770 --> 00:33:02,700
book in the shower like I did so

879
00:33:02,710 --> 00:33:05,290
my timeshare on this room CPU is up so

880
00:33:05,290 --> 00:33:06,910
if you like pretty pictures and travel

881
00:33:06,910 --> 00:33:08,380
stories you can hop to my landscape

882
00:33:08,380 --> 00:33:11,410
photography site yellow scale.com or you

883
00:33:11,410 --> 00:33:13,630
can find me on twitter as at nibbler

