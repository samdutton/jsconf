1
00:00:14,330 --> 00:00:17,760

hi everyone and welcome to my talk on

2
00:00:17,760 --> 00:00:20,099
how your brain is conspiring against you

3
00:00:20,099 --> 00:00:24,300
making good software so uh as was

4
00:00:24,300 --> 00:00:25,980
already mentioned I'm an engineering

5
00:00:25,980 --> 00:00:28,800
manager at digital ocean which is a new

6
00:00:28,800 --> 00:00:30,359
york-based company that tries to take

7
00:00:30,359 --> 00:00:32,160
the cognitive load out of managing your

8
00:00:32,160 --> 00:00:36,449
infrastructure i'm also an organizer at

9
00:00:36,449 --> 00:00:40,760
a vampire j/s which is a jazz family

10
00:00:40,760 --> 00:00:44,720
conference in manhattan and that's uh

11
00:00:44,720 --> 00:00:46,890
organizing a conference is a lot of work

12
00:00:46,890 --> 00:00:50,519
a lot of things go into it so just take

13
00:00:50,519 --> 00:00:52,860
a few minutes or a few seconds to give

14
00:00:52,860 --> 00:00:54,180
round of applause to all the organizers

15
00:00:54,180 --> 00:01:02,619
and volunteers cuz yeah they're awesome

16
00:01:02,629 --> 00:01:05,820
so yeah I'm also zeigen vector on

17
00:01:05,820 --> 00:01:08,100
Twitter so if you want to tweet

18
00:01:08,100 --> 00:01:10,140
questions at me while I'm up here try to

19
00:01:10,140 --> 00:01:11,909
answer them as best as I can once I'm

20
00:01:11,909 --> 00:01:14,159
not up here anymore I've also tweeted

21
00:01:14,159 --> 00:01:16,350
out the link to my slides that interests

22
00:01:16,350 --> 00:01:19,500
you right now so before I was a

23
00:01:19,500 --> 00:01:22,140
JavaScript engineer and way before I was

24
00:01:22,140 --> 00:01:23,939
an engineering manager I studied

25
00:01:23,939 --> 00:01:25,979
cognitive science in University

26
00:01:25,979 --> 00:01:29,159
cognitive science of talks about a lot

27
00:01:29,159 --> 00:01:31,619
of things like thinking decision-making

28
00:01:31,619 --> 00:01:34,259
attention vision consciousness and my

29
00:01:34,259 --> 00:01:36,299
personal specialty human language

30
00:01:36,299 --> 00:01:38,369
processing but if you were to ask you to

31
00:01:38,369 --> 00:01:40,679
sum up what I learned in all those four

32
00:01:40,679 --> 00:01:43,409
years into one concise sentence it would

33
00:01:43,409 --> 00:01:46,109
be that humans are predictably

34
00:01:46,109 --> 00:01:48,240
irrational this predictably irrational

35
00:01:48,240 --> 00:01:49,979
phrase was coined by a psychologist

36
00:01:49,979 --> 00:01:52,259
named Dan Ariely who in fact has a book

37
00:01:52,259 --> 00:01:54,240
by that title but what does this mean

38
00:01:54,240 --> 00:01:57,119
that we are predictably irrational it

39
00:01:57,119 --> 00:01:58,920
means that we employ predictable tricks

40
00:01:58,920 --> 00:02:01,200
patterns and shortcuts that allow us to

41
00:02:01,200 --> 00:02:03,210
make more efficient decisions to have

42
00:02:03,210 --> 00:02:05,819
what's called cognitive economy but this

43
00:02:05,819 --> 00:02:08,640
fast thinking often causes us to deviate

44
00:02:08,640 --> 00:02:10,979
from rationality in our judgments to

45
00:02:10,979 --> 00:02:13,740
make what to other eminent scientists in

46
00:02:13,740 --> 00:02:15,390
the field Amos Tversky and Daniel

47
00:02:15,390 --> 00:02:17,610
Kahneman have have called severe and

48
00:02:17,610 --> 00:02:20,790
systematic errors and these errors are

49
00:02:20,790 --> 00:02:22,709
called cognitive biases which is a

50
00:02:22,709 --> 00:02:23,370
phrase that you

51
00:02:23,370 --> 00:02:26,430
might have heard of a few times but this

52
00:02:26,430 --> 00:02:29,099
is a JavaScript conference and not a

53
00:02:29,099 --> 00:02:31,500
cognitive science conference so what

54
00:02:31,500 --> 00:02:32,790
does this have to do with code right

55
00:02:32,790 --> 00:02:35,640
well my job as an engineering manager is

56
00:02:35,640 --> 00:02:38,659
to make sure that my team which is

57
00:02:38,659 --> 00:02:42,989
comprised of humans is happy getting

58
00:02:42,989 --> 00:02:45,720
their work done getting along with each

59
00:02:45,720 --> 00:02:48,930
other growing as individuals and as

60
00:02:48,930 --> 00:02:51,510
programmers and it's also my job to grow

61
00:02:51,510 --> 00:02:53,599
my team to make it the most successful

62
00:02:53,599 --> 00:02:57,209
my team is like my product so I've

63
00:02:57,209 --> 00:03:00,629
started to think back to my cognitive

64
00:03:00,629 --> 00:03:03,090
science years and I'm trying to figure

65
00:03:03,090 --> 00:03:04,829
out especially how these cognitive

66
00:03:04,829 --> 00:03:07,950
biases and other quicksilver mushy human

67
00:03:07,950 --> 00:03:10,409
brains affect us as we're making

68
00:03:10,409 --> 00:03:12,810
software in the environment that were

69
00:03:12,810 --> 00:03:15,209
making the software in because software

70
00:03:15,209 --> 00:03:17,730
isn't just about code it's also about

71
00:03:17,730 --> 00:03:21,480
humans software isn't software if

72
00:03:21,480 --> 00:03:25,349
there's no one using it I think so yeah

73
00:03:25,349 --> 00:03:26,970
I try to think about these cognitive

74
00:03:26,970 --> 00:03:29,459
biases because even the most calculating

75
00:03:29,459 --> 00:03:31,680
software engineers is a human and

76
00:03:31,680 --> 00:03:33,419
therefore subject to these cognitive

77
00:03:33,419 --> 00:03:35,579
biases no matter how much they think

78
00:03:35,579 --> 00:03:36,630
that they are immune to the

79
00:03:36,630 --> 00:03:40,440
rationalities of humankind so I'm going

80
00:03:40,440 --> 00:03:44,910
to talk about these things and first I'm

81
00:03:44,910 --> 00:03:47,579
going to talk about logic so one of the

82
00:03:47,579 --> 00:03:49,530
fundamental underpinnings of programming

83
00:03:49,530 --> 00:03:52,859
is logic in programming we have f

84
00:03:52,859 --> 00:03:54,510
statements all statements bullion's

85
00:03:54,510 --> 00:03:57,060
ternary operators but computers can only

86
00:03:57,060 --> 00:04:00,150
do what humans tell them to do and it

87
00:04:00,150 --> 00:04:02,280
turns out that humans are not very good

88
00:04:02,280 --> 00:04:05,730
logical thinkers what are the tools that

89
00:04:05,730 --> 00:04:08,040
psychologists use to test this is called

90
00:04:08,040 --> 00:04:10,440
the categorical syllogism we have one

91
00:04:10,440 --> 00:04:13,620
right up here on the screen so a

92
00:04:13,620 --> 00:04:15,540
categorical syllogism is a logical

93
00:04:15,540 --> 00:04:17,760
argument with two premises and a

94
00:04:17,760 --> 00:04:19,889
conclusion and scientists will ask

95
00:04:19,889 --> 00:04:22,349
humans hey does this conclusion follow

96
00:04:22,349 --> 00:04:24,570
from the premises so I'll give you a few

97
00:04:24,570 --> 00:04:26,940
seconds to answer that question for

98
00:04:26,940 --> 00:04:31,620
yourself

99
00:04:31,630 --> 00:04:34,240
so when this was presented to

100
00:04:34,240 --> 00:04:36,250
participants eighty-one percent of them

101
00:04:36,250 --> 00:04:38,800
said yep the conclusion follows from the

102
00:04:38,800 --> 00:04:41,290
premises ten percent said something else

103
00:04:41,290 --> 00:04:43,600
wrong and only nine percent of people

104
00:04:43,600 --> 00:04:47,820
got it right um so that's not great and

105
00:04:47,820 --> 00:04:50,260
reasoning about complex if-else

106
00:04:50,260 --> 00:04:52,570
statements isn't much better so a

107
00:04:52,570 --> 00:04:55,270
psychologist damn place in came up with

108
00:04:55,270 --> 00:04:57,700
the task involving four cards in which

109
00:04:57,700 --> 00:05:00,130
every card has a letter on one side and

110
00:05:00,130 --> 00:05:01,540
a number on the other side and

111
00:05:01,540 --> 00:05:03,460
participants were asked to evaluate this

112
00:05:03,460 --> 00:05:05,830
rule if a card has a vowel on one side

113
00:05:05,830 --> 00:05:08,020
it has an even number on the other and

114
00:05:08,020 --> 00:05:10,390
then asked the participants what cards

115
00:05:10,390 --> 00:05:11,920
need to be flipped over to make sure

116
00:05:11,920 --> 00:05:15,970
that this real checks out so formulate

117
00:05:15,970 --> 00:05:21,310
your own answer so only four percent of

118
00:05:21,310 --> 00:05:24,160
people got the right answer four percent

119
00:05:24,160 --> 00:05:27,280
which is to flip only the a and the

120
00:05:27,280 --> 00:05:29,470
seven over if you're stumped about why

121
00:05:29,470 --> 00:05:31,150
this is right remember that the rule

122
00:05:31,150 --> 00:05:33,250
says nothing about what has to be on the

123
00:05:33,250 --> 00:05:36,940
other side of consonants so what does

124
00:05:36,940 --> 00:05:39,370
this mean for testing our code properly

125
00:05:39,370 --> 00:05:41,380
right if we can't come up with questions

126
00:05:41,380 --> 00:05:44,650
to test rules that we hold to be true

127
00:05:44,650 --> 00:05:46,720
how are you going to test our code and

128
00:05:46,720 --> 00:05:48,640
what type of bugs are gonna arise from

129
00:05:48,640 --> 00:05:52,300
this right but luckily there's some hope

130
00:05:52,300 --> 00:05:54,330
which is that we get much better about

131
00:05:54,330 --> 00:05:57,100
reasoning about concrete examples so

132
00:05:57,100 --> 00:05:58,990
some other scientists adapted way since

133
00:05:58,990 --> 00:06:01,930
for card task to test a concrete rule

134
00:06:01,930 --> 00:06:04,510
which was that if a person is drinking

135
00:06:04,510 --> 00:06:06,850
beer they must be over 19 years old and

136
00:06:06,850 --> 00:06:08,650
in this case seventy-three percent of

137
00:06:08,650 --> 00:06:10,480
people got the right answer so an

138
00:06:10,480 --> 00:06:15,520
improvement but like still not great so

139
00:06:15,520 --> 00:06:18,370
when we inevitably make a mistake in our

140
00:06:18,370 --> 00:06:20,950
code logical or otherwise because after

141
00:06:20,950 --> 00:06:23,770
all we are humans we're gonna have to

142
00:06:23,770 --> 00:06:25,390
end up debugging our code and as

143
00:06:25,390 --> 00:06:27,250
computer science elaborate e brian

144
00:06:27,250 --> 00:06:29,260
kernighan said debugging is twice as

145
00:06:29,260 --> 00:06:31,360
hard as writing the program in the first

146
00:06:31,360 --> 00:06:34,360
place so why exactly is debugging so

147
00:06:34,360 --> 00:06:37,030
hard I think there's some cognitive bias

148
00:06:37,030 --> 00:06:39,820
ezel will help or not helping us to

149
00:06:39,820 --> 00:06:42,370
debug well one of them is a confirmation

150
00:06:42,370 --> 00:06:44,900
bias which is that we have a tendency

151
00:06:44,900 --> 00:06:47,419
to search for interpret favor and

152
00:06:47,419 --> 00:06:49,100
remember information in a way that

153
00:06:49,100 --> 00:06:51,380
confirms our pre-existing beliefs or

154
00:06:51,380 --> 00:06:53,060
hypotheses we also give

155
00:06:53,060 --> 00:06:55,460
disproportionately less consideration to

156
00:06:55,460 --> 00:06:58,490
alternative possibilities so an

157
00:06:58,490 --> 00:07:01,400
experiment to test this Wayson did it

158
00:07:01,400 --> 00:07:06,410
again and so for instance they gave a

159
00:07:06,410 --> 00:07:08,270
trio participants a trade-off numbers

160
00:07:08,270 --> 00:07:11,000
like 246 and told the participants that

161
00:07:11,000 --> 00:07:12,560
the trio couldn't form to a specific

162
00:07:12,560 --> 00:07:14,479
rule and their job was to figure out

163
00:07:14,479 --> 00:07:16,430
what the rule was by asking if other

164
00:07:16,430 --> 00:07:18,740
trios also informed the rule in this

165
00:07:18,740 --> 00:07:20,449
case is actually pretty simple that the

166
00:07:20,449 --> 00:07:21,979
numbers just have to be in a sending

167
00:07:21,979 --> 00:07:24,320
order but people ended up having trouble

168
00:07:24,320 --> 00:07:26,000
especially when they asked only

169
00:07:26,000 --> 00:07:27,560
confirming questions and not

170
00:07:27,560 --> 00:07:29,539
disconfirming questions if you were to

171
00:07:29,539 --> 00:07:31,940
say like oh I got the rule it's like

172
00:07:31,940 --> 00:07:36,830
does 6 8 10 apply like yep you would

173
00:07:36,830 --> 00:07:38,000
probably just keep going down the same

174
00:07:38,000 --> 00:07:39,320
path but if you're like I'm gonna try

175
00:07:39,320 --> 00:07:42,050
something different one to a million and

176
00:07:42,050 --> 00:07:44,180
they said yeah that also it works then

177
00:07:44,180 --> 00:07:46,039
you have more insight into what the rule

178
00:07:46,039 --> 00:07:50,930
actually is but we tend to scrutinize

179
00:07:50,930 --> 00:07:52,910
disconfirming evidence we try to find

180
00:07:52,910 --> 00:07:55,639
flaws or ambiguities in in this evidence

181
00:07:55,639 --> 00:07:58,490
blaming say when you're like when it

182
00:07:58,490 --> 00:08:00,800
relates to code a bug in the library or

183
00:08:00,800 --> 00:08:02,449
it was someone else's code that has the

184
00:08:02,449 --> 00:08:04,280
bug in it and even when the facts are

185
00:08:04,280 --> 00:08:06,710
clearly stacked up against the belief

186
00:08:06,710 --> 00:08:08,630
that we are holding true we often throw

187
00:08:08,630 --> 00:08:10,789
out those disconfirming facts especially

188
00:08:10,789 --> 00:08:13,729
when the issue is emotionally charged

189
00:08:13,729 --> 00:08:16,360
such as when your code has a bug in it

190
00:08:16,360 --> 00:08:19,610
we also tend to be rigid in how we

191
00:08:19,610 --> 00:08:22,729
approach problems so if you write the

192
00:08:22,729 --> 00:08:24,440
wrote the code you're going to be rigid

193
00:08:24,440 --> 00:08:27,199
and stinking thinking through the the

194
00:08:27,199 --> 00:08:28,610
problem and it's going to be hard to

195
00:08:28,610 --> 00:08:30,440
think outside the box and squash the bug

196
00:08:30,440 --> 00:08:32,479
especially if it's on a conceptual level

197
00:08:32,479 --> 00:08:35,000
I know I'm guilty of substituting the

198
00:08:35,000 --> 00:08:36,650
single equals four triple equals and

199
00:08:36,650 --> 00:08:38,690
even that type of bug is hard to find so

200
00:08:38,690 --> 00:08:40,580
when the bug is on a more conceptual

201
00:08:40,580 --> 00:08:43,820
level it's that much harder to find and

202
00:08:43,820 --> 00:08:46,610
squash and we even sometimes tend to

203
00:08:46,610 --> 00:08:48,770
block problem solutions based on past

204
00:08:48,770 --> 00:08:51,470
experiences because we have an inability

205
00:08:51,470 --> 00:08:53,060
to see problems from a fresh perspective

206
00:08:53,060 --> 00:08:55,459
I think a great way to get around this

207
00:08:55,459 --> 00:08:57,900
is to pair on squishing bugs so

208
00:08:57,900 --> 00:09:00,840
you get that extra set of eyes when

209
00:09:00,840 --> 00:09:04,680
you're particularly stuck another thing

210
00:09:04,680 --> 00:09:06,420
that's so frustrating about debugging is

211
00:09:06,420 --> 00:09:08,520
that sometimes it feels like there's no

212
00:09:08,520 --> 00:09:10,410
end in sight but you're just searching

213
00:09:10,410 --> 00:09:12,030
and searching like why is this not

214
00:09:12,030 --> 00:09:14,670
working it's frustrating then there's no

215
00:09:14,670 --> 00:09:16,950
light at the end of the tunnel and this

216
00:09:16,950 --> 00:09:18,840
is because we often have no idea when

217
00:09:18,840 --> 00:09:20,850
we're going to solve a problem even the

218
00:09:20,850 --> 00:09:22,830
30 seconds before we end up solving it

219
00:09:22,830 --> 00:09:25,500
and so to test the scientists give

220
00:09:25,500 --> 00:09:27,450
subjects in sight problems kind of like

221
00:09:27,450 --> 00:09:29,610
word problem brain teaser type things

222
00:09:29,610 --> 00:09:33,270
and as they solve the problem the

223
00:09:33,270 --> 00:09:35,550
scientists ask them as the participants

224
00:09:35,550 --> 00:09:37,470
to rate their progress in terms of

225
00:09:37,470 --> 00:09:38,970
warmth so how close do you think you are

226
00:09:38,970 --> 00:09:41,460
solving this initially they gave ratings

227
00:09:41,460 --> 00:09:45,300
of one to two and then their warmest

228
00:09:45,300 --> 00:09:47,550
reading abruptly spiked when they got an

229
00:09:47,550 --> 00:09:49,380
answer whether or not it was correct or

230
00:09:49,380 --> 00:09:53,280
incorrect breaks are also more important

231
00:09:53,280 --> 00:09:54,600
than you think when you're trying to

232
00:09:54,600 --> 00:09:56,700
solve a problem and I know when I'm

233
00:09:56,700 --> 00:09:59,670
trying to squash a bug i'm like dead set

234
00:09:59,670 --> 00:10:01,500
on trying to solve that no breaks until

235
00:10:01,500 --> 00:10:03,270
i finish it but breaks are actually

236
00:10:03,270 --> 00:10:04,890
really good and scientists think that

237
00:10:04,890 --> 00:10:06,420
this is because it helps you forget

238
00:10:06,420 --> 00:10:09,030
misleading hints so to test this like

239
00:10:09,030 --> 00:10:10,680
how it just gave participants some

240
00:10:10,680 --> 00:10:12,570
puzzles to solve as well as misleading

241
00:10:12,570 --> 00:10:16,050
hints the control group had a minute

242
00:10:16,050 --> 00:10:17,400
without breaks to try and solve the

243
00:10:17,400 --> 00:10:19,320
problem and the experimental group had

244
00:10:19,320 --> 00:10:21,480
30 seconds or interrupted for a short

245
00:10:21,480 --> 00:10:24,240
bit and then had another 30 seconds the

246
00:10:24,240 --> 00:10:25,800
interrupted group actually did better

247
00:10:25,800 --> 00:10:27,750
and it was found as a group were

248
00:10:27,750 --> 00:10:29,430
actually less likely to remember the

249
00:10:29,430 --> 00:10:31,470
misleading clues suggesting that maybe

250
00:10:31,470 --> 00:10:35,430
these two things were correlated a

251
00:10:35,430 --> 00:10:39,180
creativity is also a kind of you know

252
00:10:39,180 --> 00:10:41,010
kind of like feels like it's involved in

253
00:10:41,010 --> 00:10:43,860
squashing a bug or in problem solving

254
00:10:43,860 --> 00:10:46,890
but what exactly is creativity well

255
00:10:46,890 --> 00:10:48,360
scientists think it's really actually

256
00:10:48,360 --> 00:10:50,820
nothing special it's just when the sum

257
00:10:50,820 --> 00:10:52,610
of all your experiences memories

258
00:10:52,610 --> 00:10:55,230
training and motivation come together in

259
00:10:55,230 --> 00:10:56,520
the right way to give you the right

260
00:10:56,520 --> 00:11:00,600
tools to solve the problem all right so

261
00:11:00,600 --> 00:11:02,430
now that we are writing our own code and

262
00:11:02,430 --> 00:11:04,530
finding the bugs in it and maybe there's

263
00:11:04,530 --> 00:11:07,110
some people helping us we've entered

264
00:11:07,110 --> 00:11:08,940
into this realm of working with other

265
00:11:08,940 --> 00:11:11,790
humans and maybe even trying to read and

266
00:11:11,790 --> 00:11:14,250
other people's code but this is hard

267
00:11:14,250 --> 00:11:16,260
because again we tend to think about

268
00:11:16,260 --> 00:11:18,660
problems in fixed ways when you're

269
00:11:18,660 --> 00:11:20,370
reading someone's code kind of like

270
00:11:20,370 --> 00:11:21,630
you're getting into their head right

271
00:11:21,630 --> 00:11:23,580
you're like you're seeing how they solve

272
00:11:23,580 --> 00:11:26,220
the problem and that is unlikely to be

273
00:11:26,220 --> 00:11:27,720
exactly the same way that you would have

274
00:11:27,720 --> 00:11:30,090
solved the problem therefore it's harder

275
00:11:30,090 --> 00:11:32,220
to understand what they're doing nefer

276
00:11:32,220 --> 00:11:33,690
makes it that much harder to read the

277
00:11:33,690 --> 00:11:37,800
code um also we tend to use other

278
00:11:37,800 --> 00:11:40,130
people's code when we're using libraries

279
00:11:40,130 --> 00:11:43,350
but y'all might have heard of the not

280
00:11:43,350 --> 00:11:45,390
invented here syndrome which is that

281
00:11:45,390 --> 00:11:46,980
we're kind of averse to using things

282
00:11:46,980 --> 00:11:51,570
that we didn't write and cognitive

283
00:11:51,570 --> 00:11:54,000
scientists have called this the IKEA

284
00:11:54,000 --> 00:11:57,530
effect it's a fairly new phenomenon so

285
00:11:57,530 --> 00:11:59,970
scientists ask participants to assemble

286
00:11:59,970 --> 00:12:02,520
ikea furniture build lego contraptions

287
00:12:02,520 --> 00:12:05,580
and fold origami and then they were

288
00:12:05,580 --> 00:12:07,500
asked how much money they would pay for

289
00:12:07,500 --> 00:12:09,630
their creations as well as for experts

290
00:12:09,630 --> 00:12:12,390
creations participants were willing to

291
00:12:12,390 --> 00:12:15,540
pay the reasonably safe amount of money

292
00:12:15,540 --> 00:12:17,970
for their finished amateurish

293
00:12:17,970 --> 00:12:20,520
dilapidated paper cranes as they were

294
00:12:20,520 --> 00:12:23,070
for beautifully folded professionally

295
00:12:23,070 --> 00:12:27,750
folded origami cranes and while this

296
00:12:27,750 --> 00:12:30,030
particular experiment was mainly about

297
00:12:30,030 --> 00:12:34,410
money I think it's it's very to

298
00:12:34,410 --> 00:12:36,990
extrapolate to look value in general

299
00:12:36,990 --> 00:12:39,590
like how much we value other people's

300
00:12:39,590 --> 00:12:44,100
code versus how much we value our own so

301
00:12:44,100 --> 00:12:45,420
like that's why we don't want to use

302
00:12:45,420 --> 00:12:47,700
that library that has been battle tested

303
00:12:47,700 --> 00:12:51,720
and seeing the bugs have been fixed

304
00:12:51,720 --> 00:12:53,790
through lovely open-source processes

305
00:12:53,790 --> 00:12:55,950
that have been used in in ways that may

306
00:12:55,950 --> 00:12:57,360
be similar or different from the way

307
00:12:57,360 --> 00:13:01,350
that you're going to use it so working

308
00:13:01,350 --> 00:13:02,850
with other people maybe you're on a

309
00:13:02,850 --> 00:13:05,190
software team and therefore you probably

310
00:13:05,190 --> 00:13:07,470
have to do sprint planning or something

311
00:13:07,470 --> 00:13:09,450
or like tell someone how long it's going

312
00:13:09,450 --> 00:13:10,890
to take you to finish that bit of the

313
00:13:10,890 --> 00:13:13,170
project you know my job as an

314
00:13:13,170 --> 00:13:14,880
engineering manager is to make sure that

315
00:13:14,880 --> 00:13:16,410
my people get their work done in a

316
00:13:16,410 --> 00:13:18,420
reasonable amount of time but there's

317
00:13:18,420 --> 00:13:19,950
something working against me which is

318
00:13:19,950 --> 00:13:21,720
that we're really bad at making

319
00:13:21,720 --> 00:13:23,340
predictions about how much time it's

320
00:13:23,340 --> 00:13:25,080
going to take to do something

321
00:13:25,080 --> 00:13:26,510
and this is called the planning fallacy

322
00:13:26,510 --> 00:13:29,400
so an example of this was some

323
00:13:29,400 --> 00:13:32,130
psychologists asked 37's like students

324
00:13:32,130 --> 00:13:33,960
how long they thought it was going to

325
00:13:33,960 --> 00:13:35,670
take them to finish their senior theses

326
00:13:35,670 --> 00:13:38,640
and the average estimate was about 34

327
00:13:38,640 --> 00:13:40,950
days but the actual average time that it

328
00:13:40,950 --> 00:13:42,930
took these people to finish their papers

329
00:13:42,930 --> 00:13:46,410
was about 56 days with only about thirty

330
00:13:46,410 --> 00:13:48,150
percent of people finishing in the time

331
00:13:48,150 --> 00:13:50,820
that they predicted this phenomenon

332
00:13:50,820 --> 00:13:53,450
occurs regardless of if people know that

333
00:13:53,450 --> 00:13:56,070
past tasks that were similar also took

334
00:13:56,070 --> 00:13:58,350
them longer than they expected didn't

335
00:13:58,350 --> 00:14:00,150
really matter and this also really only

336
00:14:00,150 --> 00:14:02,790
happens for our own tasks whether we're

337
00:14:02,790 --> 00:14:05,280
working by ourselves or in a group for

338
00:14:05,280 --> 00:14:07,230
other other tasks to other people's

339
00:14:07,230 --> 00:14:09,030
tasks we show a pessimistic bias we

340
00:14:09,030 --> 00:14:09,990
think it's going to take them longer

341
00:14:09,990 --> 00:14:13,170
than they say and this is part of a

342
00:14:13,170 --> 00:14:15,570
larger bias called the optimism bias

343
00:14:15,570 --> 00:14:18,210
which is that we think that bad things

344
00:14:18,210 --> 00:14:19,680
are more likely to happen to other

345
00:14:19,680 --> 00:14:23,190
people than to us this is seen in 00

346
00:14:23,190 --> 00:14:25,620
wide array of situations not just

347
00:14:25,620 --> 00:14:28,230
planning our software projects so people

348
00:14:28,230 --> 00:14:30,690
tend to think that there are like less

349
00:14:30,690 --> 00:14:32,550
susceptible to crime than other people

350
00:14:32,550 --> 00:14:35,280
or less susceptible to the whims of the

351
00:14:35,280 --> 00:14:39,360
stock market all sorts of things so yeah

352
00:14:39,360 --> 00:14:43,020
we're not really great at that we're

353
00:14:43,020 --> 00:14:45,690
also often so worried about wasting time

354
00:14:45,690 --> 00:14:49,200
that we've already spent and invested

355
00:14:49,200 --> 00:14:52,050
resources in that we don't consider like

356
00:14:52,050 --> 00:14:53,520
the cost that it's going to take to

357
00:14:53,520 --> 00:14:55,680
continue doing something that's like

358
00:14:55,680 --> 00:14:58,950
slogging so this is called the sunk cost

359
00:14:58,950 --> 00:15:02,040
fallacy and I think it's contributing to

360
00:15:02,040 --> 00:15:03,900
us wasting a lot of time and things that

361
00:15:03,900 --> 00:15:07,530
are just taking a really long time so

362
00:15:07,530 --> 00:15:09,480
once you've been through that sprint

363
00:15:09,480 --> 00:15:10,950
planning meeting that took like three

364
00:15:10,950 --> 00:15:12,480
hours you probably have to go back to

365
00:15:12,480 --> 00:15:15,180
your desk and start working maybe in an

366
00:15:15,180 --> 00:15:16,860
open office so the person like right

367
00:15:16,860 --> 00:15:18,450
next to you is on a Google hangout with

368
00:15:18,450 --> 00:15:21,090
a person right next to them so there's a

369
00:15:21,090 --> 00:15:24,360
lot of noise and you know this isn't

370
00:15:24,360 --> 00:15:26,610
really the best for productivity but in

371
00:15:26,610 --> 00:15:28,200
the grand scheme of things we're

372
00:15:28,200 --> 00:15:29,790
actually pretty good at filtering out

373
00:15:29,790 --> 00:15:31,890
unwanted stimuli and this is called

374
00:15:31,890 --> 00:15:35,970
selective attention scientists like to

375
00:15:35,970 --> 00:15:37,830
study selective attention by doing

376
00:15:37,830 --> 00:15:38,940
what's called a dicot

377
00:15:38,940 --> 00:15:41,430
listing task with shadowing so

378
00:15:41,430 --> 00:15:45,030
participants have to to speech dreams or

379
00:15:45,030 --> 00:15:47,640
sound streams going into into both of

380
00:15:47,640 --> 00:15:50,490
their ears so in one ear participants

381
00:15:50,490 --> 00:15:52,530
will will get a stream of speech that

382
00:15:52,530 --> 00:15:54,510
they're supposed to repeat back and in

383
00:15:54,510 --> 00:15:57,060
the other ear they get speech music

384
00:15:57,060 --> 00:15:59,070
something they're not supposed to pay

385
00:15:59,070 --> 00:16:02,280
attention to that and when questioned

386
00:16:02,280 --> 00:16:03,960
afterwards participants generally have

387
00:16:03,960 --> 00:16:07,500
very little recollection of any semantic

388
00:16:07,500 --> 00:16:08,820
content that though they weren't

389
00:16:08,820 --> 00:16:11,850
shadowing so the purple well that

390
00:16:11,850 --> 00:16:15,570
contrast is off so yeah like a switch

391
00:16:15,570 --> 00:16:17,730
from English to German goes unnoticed

392
00:16:17,730 --> 00:16:21,060
like you could tell them things that

393
00:16:21,060 --> 00:16:22,980
they don't want to hear they won't

394
00:16:22,980 --> 00:16:26,430
remember but physical attributes of

395
00:16:26,430 --> 00:16:28,920
sound are are remembered so people

396
00:16:28,920 --> 00:16:31,110
generally are able to recall if the

397
00:16:31,110 --> 00:16:34,710
unattended channel is speech or not so

398
00:16:34,710 --> 00:16:36,420
like they're in your office there could

399
00:16:36,420 --> 00:16:37,770
be like music playing you'll know that

400
00:16:37,770 --> 00:16:39,540
there's music playing but maybe not

401
00:16:39,540 --> 00:16:40,710
listen to the lyrics but when you're

402
00:16:40,710 --> 00:16:42,270
listening to the lyrics you're probably

403
00:16:42,270 --> 00:16:43,860
not going to be able to focus that much

404
00:16:43,860 --> 00:16:47,600
on writing code but if there's something

405
00:16:47,600 --> 00:16:50,550
salient in the and the speedstream that

406
00:16:50,550 --> 00:16:52,470
they're not listening to like their name

407
00:16:52,470 --> 00:16:54,510
or some like not safe for work words

408
00:16:54,510 --> 00:16:56,310
people usually notice them and this is

409
00:16:56,310 --> 00:16:59,940
called the cocktail party effect so this

410
00:16:59,940 --> 00:17:01,710
suggests that selective attention

411
00:17:01,710 --> 00:17:04,079
requires both ignoring like active

412
00:17:04,079 --> 00:17:06,180
ignoring and active paying attention and

413
00:17:06,180 --> 00:17:09,120
so just because we're good at selective

414
00:17:09,120 --> 00:17:10,890
attention doesn't mean it's good for us

415
00:17:10,890 --> 00:17:14,010
we're putting in like active mental

416
00:17:14,010 --> 00:17:16,079
effort to blocking out things that we

417
00:17:16,079 --> 00:17:17,280
don't want to be paying attention to

418
00:17:17,280 --> 00:17:19,500
which means that there are less mental

419
00:17:19,500 --> 00:17:22,079
resources going towards the stuff that

420
00:17:22,079 --> 00:17:24,540
we actually need to be doing so we can

421
00:17:24,540 --> 00:17:26,400
only pay attention to so many things at

422
00:17:26,400 --> 00:17:29,280
once mostly one thing and we have a

423
00:17:29,280 --> 00:17:31,110
limited supply of mental resources and

424
00:17:31,110 --> 00:17:32,580
we often don't have the budget to do

425
00:17:32,580 --> 00:17:34,380
more than one thing at once so you're

426
00:17:34,380 --> 00:17:35,970
unlikely going to be able to keep

427
00:17:35,970 --> 00:17:37,620
writing that difficult algorithm if

428
00:17:37,620 --> 00:17:39,090
you're trying to listen in to that

429
00:17:39,090 --> 00:17:41,190
conversation happening 10 feet away

430
00:17:41,190 --> 00:17:43,020
between your engineering manager and

431
00:17:43,020 --> 00:17:45,120
your product manager that if the project

432
00:17:45,120 --> 00:17:47,520
you're working on that with that

433
00:17:47,520 --> 00:17:48,780
algorithm is going to get scrapped

434
00:17:48,780 --> 00:17:50,700
tomorrow not going to be able to

435
00:17:50,700 --> 00:17:51,440
concentrate

436
00:17:51,440 --> 00:17:54,610
and this is because we are sometimes

437
00:17:54,610 --> 00:17:57,049
helpless to the processing power of our

438
00:17:57,049 --> 00:17:58,850
brain because our brain just does things

439
00:17:58,850 --> 00:18:01,039
automatically in an attempt to be

440
00:18:01,039 --> 00:18:04,009
efficient so if you had an email account

441
00:18:04,009 --> 00:18:06,710
any time around the early 2000s this

442
00:18:06,710 --> 00:18:09,350
might look familiar and this is actually

443
00:18:09,350 --> 00:18:11,330
real science it's called the Stroop task

444
00:18:11,330 --> 00:18:13,879
and if you're not familiar with it the

445
00:18:13,879 --> 00:18:17,480
idea is that you're supposed to say the

446
00:18:17,480 --> 00:18:20,000
color that the word is written in not

447
00:18:20,000 --> 00:18:22,759
the color not the word itself and the

448
00:18:22,759 --> 00:18:24,440
leading theory about why this occurs is

449
00:18:24,440 --> 00:18:27,679
called automaticity so all reading is an

450
00:18:27,679 --> 00:18:29,389
automatic committable process that we

451
00:18:29,389 --> 00:18:30,590
don't really have to think about very

452
00:18:30,590 --> 00:18:34,940
much but recognizing a color isn't

453
00:18:34,940 --> 00:18:37,820
automatic process so while reading

454
00:18:37,820 --> 00:18:39,409
doesn't need controlled attention it

455
00:18:39,409 --> 00:18:41,870
uses enough resources to reduce the

456
00:18:41,870 --> 00:18:43,990
amount that we can then dedicate to

457
00:18:43,990 --> 00:18:49,909
saying what what color the ink is all

458
00:18:49,909 --> 00:18:53,809
right so as I said before software is

459
00:18:53,809 --> 00:18:55,340
actually about people and this lovely

460
00:18:55,340 --> 00:18:57,559
phrase comes from the amazing people at

461
00:18:57,559 --> 00:19:01,370
and yet and so when I heard this it kind

462
00:19:01,370 --> 00:19:02,860
of like changed the way I thought about

463
00:19:02,860 --> 00:19:04,700
software and about engineering

464
00:19:04,700 --> 00:19:06,740
management like it's not just about the

465
00:19:06,740 --> 00:19:08,090
code again I said this in the beginning

466
00:19:08,090 --> 00:19:10,190
it's also about the people and without

467
00:19:10,190 --> 00:19:13,480
humans was supported trading software um

468
00:19:13,480 --> 00:19:16,309
so now we're gonna start to get to

469
00:19:16,309 --> 00:19:22,080
villach human side of all this right so

470
00:19:22,090 --> 00:19:23,929
something that's getting in the way of

471
00:19:23,929 --> 00:19:25,940
us being productive on our teams I think

472
00:19:25,940 --> 00:19:28,730
is that relatively unskilled people

473
00:19:28,730 --> 00:19:31,279
think that they are better at tasks than

474
00:19:31,279 --> 00:19:33,289
they actually are this is called the

475
00:19:33,289 --> 00:19:36,169
dunning-kruger effect and a funny story

476
00:19:36,169 --> 00:19:38,600
it was inspired by the case of a dude

477
00:19:38,600 --> 00:19:40,909
who robbed two banks after covering his

478
00:19:40,909 --> 00:19:43,129
face with lemon juice since lemon juice

479
00:19:43,129 --> 00:19:45,620
can can be used as invisible ink he

480
00:19:45,620 --> 00:19:47,029
thought it would cause his face to be

481
00:19:47,029 --> 00:19:49,700
invisible on the security cameras which

482
00:19:49,700 --> 00:19:54,529
is like unfortunate i guess um and this

483
00:19:54,529 --> 00:19:56,750
is part of a larger phenomenon called

484
00:19:56,750 --> 00:19:59,059
blue Sri superiority which is that we

485
00:19:59,059 --> 00:20:01,159
tend to overestimate our own skills and

486
00:20:01,159 --> 00:20:04,190
abilities so we think that were like

487
00:20:04,190 --> 00:20:05,309
higher

488
00:20:05,309 --> 00:20:06,690
elegance we're going to be better at

489
00:20:06,690 --> 00:20:08,759
performing tasks and tests we think that

490
00:20:08,759 --> 00:20:11,610
we have like more desirable traits and

491
00:20:11,610 --> 00:20:14,220
characteristics than other people but

492
00:20:14,220 --> 00:20:16,860
sort of example of this was in a survey

493
00:20:16,860 --> 00:20:18,990
of faculty of the University of Nebraska

494
00:20:18,990 --> 00:20:22,409
sixty-eight percent of these teachers

495
00:20:22,409 --> 00:20:25,289
rated themselves within the top 25% for

496
00:20:25,289 --> 00:20:27,509
teaching ability and more than ninety

497
00:20:27,509 --> 00:20:28,950
percent or you to themselves as above

498
00:20:28,950 --> 00:20:32,690
average but like that doesn't math uh

499
00:20:32,690 --> 00:20:35,879
like fifty percent of people have to be

500
00:20:35,879 --> 00:20:37,590
below average that's just how it works

501
00:20:37,590 --> 00:20:41,429
and like well I'm like all of you are

502
00:20:41,429 --> 00:20:43,529
below average in something like I'm

503
00:20:43,529 --> 00:20:49,470
below average in height uh like doesn't

504
00:20:49,470 --> 00:20:50,309
mean that you're bad at what you're

505
00:20:50,309 --> 00:20:52,679
doing just below average so like how is

506
00:20:52,679 --> 00:20:54,480
this getting in our way right so you're

507
00:20:54,480 --> 00:20:57,960
not gonna make good software if you

508
00:20:57,960 --> 00:20:59,429
don't realize how much more you have to

509
00:20:59,429 --> 00:21:01,470
learn if there's ways you can make your

510
00:21:01,470 --> 00:21:03,360
software better but you're not really

511
00:21:03,360 --> 00:21:04,980
open to learning them because you think

512
00:21:04,980 --> 00:21:07,080
you're the best your software isn't

513
00:21:07,080 --> 00:21:11,159
going to be good um and there so there's

514
00:21:11,159 --> 00:21:12,690
the flip side of this which is that

515
00:21:12,690 --> 00:21:15,210
skilled people often underestimate their

516
00:21:15,210 --> 00:21:17,220
abilities and think that tasks that are

517
00:21:17,220 --> 00:21:20,369
easy for them are easy for others so if

518
00:21:20,369 --> 00:21:22,169
you've been doing this for a while you

519
00:21:22,169 --> 00:21:23,639
might forget what it was like to be a

520
00:21:23,639 --> 00:21:25,740
beginner you're not gonna have empathy

521
00:21:25,740 --> 00:21:28,499
for the beginners on your team that are

522
00:21:28,499 --> 00:21:30,509
actually integral to your team they're

523
00:21:30,509 --> 00:21:31,860
going to ask questions that are

524
00:21:31,860 --> 00:21:34,200
important to making good software going

525
00:21:34,200 --> 00:21:35,460
to ask things that you're not really

526
00:21:35,460 --> 00:21:39,570
thinking about anymore so if you if you

527
00:21:39,570 --> 00:21:41,610
dismiss their questions they're not

528
00:21:41,610 --> 00:21:42,869
going to ask them any more and then your

529
00:21:42,869 --> 00:21:44,700
software isn't going to be as good as it

530
00:21:44,700 --> 00:21:47,190
could be but this this can also manifest

531
00:21:47,190 --> 00:21:49,139
in a different way and if you attended

532
00:21:49,139 --> 00:21:51,690
the last talk an imposter syndrome you

533
00:21:51,690 --> 00:21:53,399
know what impostor syndrome is the the

534
00:21:53,399 --> 00:21:56,759
short of it is that people sometimes

535
00:21:56,759 --> 00:21:59,100
think that their accomplishments and

536
00:21:59,100 --> 00:22:01,080
their achievements are the result of

537
00:22:01,080 --> 00:22:03,600
luck timing deception like they pulled

538
00:22:03,600 --> 00:22:05,009
the wool over someone's eyes they don't

539
00:22:05,009 --> 00:22:07,740
deserve what they have when in fact they

540
00:22:07,740 --> 00:22:10,049
probably do and some studies suggest

541
00:22:10,049 --> 00:22:12,029
that this is particularly common among

542
00:22:12,029 --> 00:22:14,519
high-achieving women but across the

543
00:22:14,519 --> 00:22:15,360
board even

544
00:22:15,360 --> 00:22:18,059
of the best programmers I know suffer

545
00:22:18,059 --> 00:22:24,870
from imposter syndrome so we're working

546
00:22:24,870 --> 00:22:26,520
with people and we're working with the

547
00:22:26,520 --> 00:22:28,710
team so how do we assemble the best team

548
00:22:28,710 --> 00:22:30,120
and how are these cognitive biases

549
00:22:30,120 --> 00:22:32,250
getting in the way of us assembling the

550
00:22:32,250 --> 00:22:34,230
best team possible I think one of the

551
00:22:34,230 --> 00:22:35,670
things getting in the way is that we

552
00:22:35,670 --> 00:22:37,470
tend to favor members of our own in

553
00:22:37,470 --> 00:22:41,280
group so and this is getting in the way

554
00:22:41,280 --> 00:22:42,750
especially with those like referral

555
00:22:42,750 --> 00:22:45,990
bonuses right you you get a lot of money

556
00:22:45,990 --> 00:22:48,059
for referring people in your social

557
00:22:48,059 --> 00:22:49,290
circles that you think you're good

558
00:22:49,290 --> 00:22:52,679
programmers but if our social social

559
00:22:52,679 --> 00:22:54,900
circles tend to look like us you're just

560
00:22:54,900 --> 00:22:56,700
going to refer them so if i were to

561
00:22:56,700 --> 00:22:59,070
refer people who looked like me my team

562
00:22:59,070 --> 00:23:00,480
would just be a bunch of white women and

563
00:23:00,480 --> 00:23:04,110
that's not good either so we want to not

564
00:23:04,110 --> 00:23:08,400
do that so another thing getting in our

565
00:23:08,400 --> 00:23:09,750
way is called the fundamental

566
00:23:09,750 --> 00:23:12,480
attribution error so people have a

567
00:23:12,480 --> 00:23:14,700
tendency to attribute situations to

568
00:23:14,700 --> 00:23:16,860
other people's character rather than to

569
00:23:16,860 --> 00:23:19,080
external factors so a classic example of

570
00:23:19,080 --> 00:23:21,630
this is like you're driving down the

571
00:23:21,630 --> 00:23:23,970
street being a law abiding and driving

572
00:23:23,970 --> 00:23:25,559
the right speed limit and then all of a

573
00:23:25,559 --> 00:23:27,150
sudden someone like rushes past you and

574
00:23:27,150 --> 00:23:29,429
you're like ah what a jerk they're like

575
00:23:29,429 --> 00:23:31,049
breaking all the laws and they're

576
00:23:31,049 --> 00:23:32,640
causing a dangerous situation on the

577
00:23:32,640 --> 00:23:36,030
road but maybe in fact they're driving a

578
00:23:36,030 --> 00:23:37,320
loved one to the hospital and they're

579
00:23:37,320 --> 00:23:39,210
they're not really thinking about laws

580
00:23:39,210 --> 00:23:40,950
they're just thinking about their loved

581
00:23:40,950 --> 00:23:43,290
one in the back seats so if you were in

582
00:23:43,290 --> 00:23:44,640
that case you would know you would know

583
00:23:44,640 --> 00:23:47,340
to have empathy for that person and it

584
00:23:47,340 --> 00:23:48,600
has nothing to do with they're not like

585
00:23:48,600 --> 00:23:54,630
a jerk actually so this also happens on

586
00:23:54,630 --> 00:23:56,669
a larger scale something called the

587
00:23:56,669 --> 00:23:58,710
group attribution error so people have a

588
00:23:58,710 --> 00:24:01,500
tendency to believe that attributes of a

589
00:24:01,500 --> 00:24:03,419
group member reflects the entire group

590
00:24:03,419 --> 00:24:06,630
so I thought this was well explained by

591
00:24:06,630 --> 00:24:11,070
this XKCD cartoon so unloved on the

592
00:24:11,070 --> 00:24:17,040
right you see two dudes and it's

593
00:24:17,040 --> 00:24:19,260
actually on the left nah I'm below

594
00:24:19,260 --> 00:24:22,620
average in which direction is which so

595
00:24:22,620 --> 00:24:26,520
on one side you see two dudes one who

596
00:24:26,520 --> 00:24:28,290
apparently is not great at math

597
00:24:28,290 --> 00:24:31,110
and his friend is saying why do you suck

598
00:24:31,110 --> 00:24:35,460
at math on the right we see a dude and a

599
00:24:35,460 --> 00:24:38,430
woman and the woman apparently is not

600
00:24:38,430 --> 00:24:42,000
good at math and the guy is saying wow

601
00:24:42,000 --> 00:24:46,050
girls suck at math so why does this why

602
00:24:46,050 --> 00:24:49,200
is this kind of true um but studies have

603
00:24:49,200 --> 00:24:51,780
shown that the the group attribution

604
00:24:51,780 --> 00:24:53,970
error is stronger and perceptions of

605
00:24:53,970 --> 00:24:55,560
groups that are viewed as more too

606
00:24:55,560 --> 00:24:58,860
similar to once owned and this doesn't

607
00:24:58,860 --> 00:25:00,330
really happen with perceptions of our

608
00:25:00,330 --> 00:25:03,690
own groups so decisions made by people

609
00:25:03,690 --> 00:25:06,030
in our own group are the result of

610
00:25:06,030 --> 00:25:08,540
structural constraints but decisions of

611
00:25:08,540 --> 00:25:11,040
other groups are the result of their

612
00:25:11,040 --> 00:25:15,420
attitudes so intact perhaps it's not

613
00:25:15,420 --> 00:25:17,670
that certain groups of people don't want

614
00:25:17,670 --> 00:25:20,550
to be programmers maybe just maybe there

615
00:25:20,550 --> 00:25:22,560
are structural forces making it harder

616
00:25:22,560 --> 00:25:28,080
for them to do so something else that I

617
00:25:28,080 --> 00:25:29,670
think is getting in our way is called

618
00:25:29,670 --> 00:25:32,520
the availability heuristic and this like

619
00:25:32,520 --> 00:25:34,740
the popular example of this is that like

620
00:25:34,740 --> 00:25:36,270
why people are so afraid of plane

621
00:25:36,270 --> 00:25:39,390
crashes which is like we hear only about

622
00:25:39,390 --> 00:25:42,450
plane crashes and not successful plane

623
00:25:42,450 --> 00:25:46,080
trips so there are those examples of

624
00:25:46,080 --> 00:25:47,910
unsuccessful plane trips are more

625
00:25:47,910 --> 00:25:49,380
salient in our mind and therefore like

626
00:25:49,380 --> 00:25:52,830
the plane is going to crash so I think

627
00:25:52,830 --> 00:25:55,500
this applies to to our program and

628
00:25:55,500 --> 00:25:57,480
communities and that like if we are

629
00:25:57,480 --> 00:25:59,550
surrounded by people who all look a

630
00:25:59,550 --> 00:26:01,830
certain way and if the the prominent

631
00:26:01,830 --> 00:26:03,600
members of our community the main

632
00:26:03,600 --> 00:26:05,310
contributors to open source and the

633
00:26:05,310 --> 00:26:07,620
people who we see on stage I'll look a

634
00:26:07,620 --> 00:26:08,670
certain way we're going to start to

635
00:26:08,670 --> 00:26:10,680
think that there's the people in our

636
00:26:10,680 --> 00:26:12,150
community and those are the only people

637
00:26:12,150 --> 00:26:14,100
in our community and those are the only

638
00:26:14,100 --> 00:26:15,660
people who can contribute to open source

639
00:26:15,660 --> 00:26:17,570
and the only people who have good ideas

640
00:26:17,570 --> 00:26:20,220
to talk about on stage which is not

641
00:26:20,220 --> 00:26:24,390
necessarily true something else that's

642
00:26:24,390 --> 00:26:26,400
also getting in our way is called the

643
00:26:26,400 --> 00:26:28,290
representativeness heuristic which is

644
00:26:28,290 --> 00:26:30,990
that essentially that we find we think

645
00:26:30,990 --> 00:26:32,550
that categories are relatively

646
00:26:32,550 --> 00:26:34,560
homogenous so if someone is a software

647
00:26:34,560 --> 00:26:36,360
engineer and expect them to have the

648
00:26:36,360 --> 00:26:37,650
traits that we associate with the

649
00:26:37,650 --> 00:26:39,690
software engineer and vice versa and

650
00:26:39,690 --> 00:26:42,130
this heuristic leads to several by

651
00:26:42,130 --> 00:26:44,440
sees such as something called base rate

652
00:26:44,440 --> 00:26:48,340
neglect so diversity in kahana man ran

653
00:26:48,340 --> 00:26:49,840
an experiment in which they gave

654
00:26:49,840 --> 00:26:52,930
descriptions of a group of people so 100

655
00:26:52,930 --> 00:26:55,630
people and 70 are lawyers and thirty

656
00:26:55,630 --> 00:26:58,060
percent are 30-year engineers and they

657
00:26:58,060 --> 00:27:00,220
found that participants often said that

658
00:27:00,220 --> 00:27:02,590
someone who sounded like an engineer was

659
00:27:02,590 --> 00:27:04,630
more likely to be an engineer even

660
00:27:04,630 --> 00:27:06,460
though the probability was against that

661
00:27:06,460 --> 00:27:08,530
because there were 70 lawyers and 30

662
00:27:08,530 --> 00:27:12,670
engineers I've seen this come true at

663
00:27:12,670 --> 00:27:14,620
programming meetups both it's built

664
00:27:14,620 --> 00:27:16,360
happened to me and to my friends where

665
00:27:16,360 --> 00:27:18,490
we're at a programming meet up it's very

666
00:27:18,490 --> 00:27:20,170
likely that people at programming

667
00:27:20,170 --> 00:27:22,810
meetups are programmers but people have

668
00:27:22,810 --> 00:27:23,770
come up to him in like are you a

669
00:27:23,770 --> 00:27:27,670
designer are you a recruiter like no I'm

670
00:27:27,670 --> 00:27:29,320
at a programming meetup of a programmer

671
00:27:29,320 --> 00:27:36,130
it's like not good Oh so um might it be

672
00:27:36,130 --> 00:27:37,210
able to tell them kind of talking about

673
00:27:37,210 --> 00:27:39,820
diversity here um so like why is

674
00:27:39,820 --> 00:27:42,520
diversity important for assembling good

675
00:27:42,520 --> 00:27:45,880
team and creating good software well so

676
00:27:45,880 --> 00:27:47,710
i mentioned that creativity is all about

677
00:27:47,710 --> 00:27:49,810
collective is about associative memory

678
00:27:49,810 --> 00:27:53,170
so when you have a diverse team you're

679
00:27:53,170 --> 00:27:56,670
going to have a wider array of of

680
00:27:56,670 --> 00:28:00,180
experiences of backgrounds of interests

681
00:28:00,180 --> 00:28:03,070
and therefore you're going to have

682
00:28:03,070 --> 00:28:05,620
better collective associative memory and

683
00:28:05,620 --> 00:28:06,550
therefore you're going to be more

684
00:28:06,550 --> 00:28:07,840
creative you're going to find better

685
00:28:07,840 --> 00:28:09,610
solutions to problems that's going to

686
00:28:09,610 --> 00:28:12,550
lead to better software so what can we

687
00:28:12,550 --> 00:28:15,940
do about all of this right so first off

688
00:28:15,940 --> 00:28:18,130
like don't feel bad your brains are like

689
00:28:18,130 --> 00:28:21,060
literally programmed to do this because

690
00:28:21,060 --> 00:28:25,030
like back in the day we were just

691
00:28:25,030 --> 00:28:27,850
supposed to like escape predators but

692
00:28:27,850 --> 00:28:30,760
now we are sitting at computers thinking

693
00:28:30,760 --> 00:28:33,460
all day so it's a little different so

694
00:28:33,460 --> 00:28:35,520
like the quicker that you can think the

695
00:28:35,520 --> 00:28:37,240
quicker you're going to get away from

696
00:28:37,240 --> 00:28:40,330
that tiger that's chasing you and you're

697
00:28:40,330 --> 00:28:43,090
going to have more cognitive economy so

698
00:28:43,090 --> 00:28:45,490
this thinking fast system is called

699
00:28:45,490 --> 00:28:48,460
system one in the literature and the

700
00:28:48,460 --> 00:28:50,830
thinking slow system is called system to

701
00:28:50,830 --> 00:28:52,150
in the literature and if you might have

702
00:28:52,150 --> 00:28:55,210
read a book or heard of a book by this

703
00:28:55,210 --> 00:28:55,690
title

704
00:28:55,690 --> 00:28:57,549
making fast and slow by Daniel Kahneman

705
00:28:57,549 --> 00:29:00,639
so like what can we do about this right

706
00:29:00,639 --> 00:29:02,860
like we're as I said we are literally

707
00:29:02,860 --> 00:29:05,169
sitting there and thinking our job is to

708
00:29:05,169 --> 00:29:07,299
think and we usually take a really long

709
00:29:07,299 --> 00:29:09,549
time to think through very hard problems

710
00:29:09,549 --> 00:29:12,340
so if we just take that same amount of

711
00:29:12,340 --> 00:29:14,049
time and apply them to things that we

712
00:29:14,049 --> 00:29:16,330
might not think about as much just take

713
00:29:16,330 --> 00:29:17,889
another hour to make those hard

714
00:29:17,889 --> 00:29:20,649
decisions then we're probably going to

715
00:29:20,649 --> 00:29:23,080
end up making better software that more

716
00:29:23,080 --> 00:29:24,580
humans can use and we're going to end up

717
00:29:24,580 --> 00:29:28,470
making these things with happier humans

718
00:29:28,470 --> 00:29:32,110
so thanks for listening that's me and

719
00:29:32,110 --> 00:29:34,149
all my emoji friends you can find my

720
00:29:34,149 --> 00:29:36,700
slides at that link tweet at me it's

