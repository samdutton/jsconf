1
00:00:09,040 --> 00:00:13,360
Hi everybody ! Thank you again for the introduction

2
00:00:13,660 --> 00:00:18,740
I'm Shelley, a software engineer at GitHub
working on open source.

3
00:00:18,980 --> 00:00:24,000
Today, I would like to do a deep dive into
the mechanics of asynchronous programming

4
00:00:24,009 --> 00:00:25,939
in JavaScript.

5
00:00:25,939 --> 00:00:31,610
To make sure we're all on the same page, before
I get started, I will go over basic principles

6
00:00:31,610 --> 00:00:37,680
of asynch, and then we will launch into the
different methodologies and nuances of what

7
00:00:37,680 --> 00:00:43,680
exactly differentiates them, and, finally,
we will compare over the spectrum of options

8
00:00:43,680 --> 00:00:48,949
to discuss which situations require which
approaches.

9
00:00:48,949 --> 00:00:53,399
Let's say you have a programme detained within
a contained within a final file.

10
00:00:53,399 --> 00:00:54,969
It's mate up of functions.

11
00:00:54,969 --> 00:01:00,609
At any given time, only one of these is going
to be executing now.

12
00:01:00,609 --> 00:01:04,629
The rest will execute later at some point
in the future.

13
00:01:04,629 --> 00:01:08,360
That, there, is the crux of asynch.

14
00:01:08,360 --> 00:01:13,770
It's the relationship between now and later,
and the way in which you manage this relationship

15
00:01:13,770 --> 00:01:15,520
with your code.

16
00:01:15,520 --> 00:01:20,970
What is key here, however, and what causes
some of the most difficulties for developers

17
00:01:20,970 --> 00:01:26,750
when they're just starting out, is that later
does not mean strictly and immediately after

18
00:01:26,750 --> 00:01:28,330
now.

19
00:01:28,330 --> 00:01:32,120
It could be at any point in the future, and
you don't necessarily know when that will

20
00:01:32,120 --> 00:01:33,120
be.

21
00:01:33,120 --> 00:01:38,750
Now, let's move on to some of the technical
underpinnings of how code is executed in the

22
00:01:38,750 --> 00:01:40,970
JavaScript environment.

23
00:01:40,970 --> 00:01:45,000
In pursuit of this understanding, it's best
to start with the event loop.

24
00:01:45,000 --> 00:01:51,360
The event loop can best be conceptualised
as an endlessly running singly threaded loop

25
00:01:51,360 --> 00:01:56,280
where each iteration runs a small chunk of
code in the programme.

26
00:01:56,280 --> 00:02:01,890
If you want to run a chunk of code at a later
time, that chunk would simply be added to

27
00:02:01,890 --> 00:02:04,390
the queue for the event loop.

28
00:02:04,390 --> 00:02:10,340
When the time came that you desired it to
execute, it would be dequeued and executed.

29
00:02:10,340 --> 00:02:15,580
With ES6 came a new concept called the microtasks
queue, but we will save that for a little

30
00:02:15,580 --> 00:02:16,770
bit later.

31
00:02:16,770 --> 00:02:24,330
It is also important to mention that JavaScript
has what is known as run-to-completion semantics.

32
00:02:24,330 --> 00:02:30,780
This means that the current task always finishes
before the next task begins.

33
00:02:30,780 --> 00:02:35,420
Or until it explicitly yields control back
to the event loop.

34
00:02:35,420 --> 00:02:41,360
As a result of this, each task has complete
control over all current states, and does

35
00:02:41,360 --> 00:02:47,050
not need to worry about another task modifying
things at the exact same time.

36
00:02:47,050 --> 00:02:52,910
Looking at the code here, running this will
always print first and then second, because

37
00:02:52,910 --> 00:03:00,170
the function, starting in setTimeout is added
to the task queue immediately but only executed

38
00:03:00,170 --> 00:03:04,740
after the current piece of code is down since
it yielded control.

39
00:03:04,740 --> 00:03:07,480
Now let's look at the call stack.

40
00:03:07,480 --> 00:03:15,770
When a function foo calls a function bar,
bar needs to know where inside foo to return

41
00:03:15,770 --> 00:03:18,319
to after it's done.

42
00:03:18,319 --> 00:03:21,900
This information is managed with the call
stack.

43
00:03:21,900 --> 00:03:26,910
Take a look at the set of three functions
on the left-hand side of the slide.

44
00:03:26,910 --> 00:03:30,970
Let's walk through how the stack will look
as the programme executes.

45
00:03:30,970 --> 00:03:37,160
Initially, when the programme above has started,
the call stack is empty.

46
00:03:37,160 --> 00:03:42,590
After foo is called, the stack has one entry:
location and global scope.

47
00:03:42,590 --> 00:03:47,690
As I mentioned before, foo knows where to
return to when it has finished.

48
00:03:47,690 --> 00:03:52,030
Next, after bar is called, the stack has two
entries.

49
00:03:52,030 --> 00:03:56,690
It's now stored at the location that bar needs
to return to when it has finished executing

50
00:03:56,690 --> 00:03:59,690
in addition to global scope.

51
00:03:59,690 --> 00:04:05,800
The trend continues as bas is called, containing
the previous return address and the previous

52
00:04:05,800 --> 00:04:09,690
return addresses from previous calls.

53
00:04:09,690 --> 00:04:15,210
When console.log is called in bas, the call
stack is... the console.

54
00:04:15,210 --> 00:04:21,000
Next, each of the functions terminates, and,
each time, the top entry is removed from the

55
00:04:21,000 --> 00:04:22,400
stack.

56
00:04:22,400 --> 00:04:27,849
After foo is done, we're back in global scope
and the call stack is empty.

57
00:04:27,849 --> 00:04:34,820
At the end, we return, and the programme is
terminated.

58
00:04:34,820 --> 00:04:40,430
In looking at this, you can see a handful
of the things I previously mentioned.

59
00:04:40,430 --> 00:04:44,560
The event loop, the task queue, and the stack.

60
00:04:44,560 --> 00:04:50,810
The current task comes off of the event queue
and its location is stored in memory while

61
00:04:50,810 --> 00:04:54,200
irrelevant variables populate the heap.

62
00:04:54,200 --> 00:05:00,620
The task queue is populated by task sources,
any one of which would be a particular chunk

63
00:05:00,620 --> 00:05:04,050
of code in an executing programme.

64
00:05:04,050 --> 00:05:09,560
This snapshot would represent the moment after
the all functions in the previous slide had

65
00:05:09,560 --> 00:05:15,910
executed and before locations had begun to
pop off of the stack.

66
00:05:15,910 --> 00:05:21,600
Most of you have likely encountered callbacks,
so I'm going to focus more on how they fit

67
00:05:21,600 --> 00:05:24,110
into the asynch landscape as a whole.

68
00:05:24,110 --> 00:05:29,470
Let's start by looking at some functions and
discussing them in context.

69
00:05:29,470 --> 00:05:35,080
Here, you can see I have two programmes side
by side.

70
00:05:35,080 --> 00:05:41,180
On the left, the function names are alphabetical
from top down, and, on the right side, I've

71
00:05:41,180 --> 00:05:45,870
mapped the functions to the order in which
they run.

72
00:05:45,870 --> 00:05:52,300
Most likely, your eyes have to do a significant
amount of jumping around in order to discern

73
00:05:52,300 --> 00:05:57,320
the order in which the functions are executing
for the programme on the left.

74
00:05:57,320 --> 00:06:01,730
Since they're not running in the top-down
sequential order you might expect.

75
00:06:01,730 --> 00:06:07,280
By following the Cardinal number of words
on the right side, you probably had an easier

76
00:06:07,280 --> 00:06:08,450
time.

77
00:06:08,450 --> 00:06:11,040
Let's talk about why that is.

78
00:06:11,040 --> 00:06:13,810
Your brain operates sequentially.

79
00:06:13,810 --> 00:06:19,290
It places it at odds with the inherent functionality
of callbacks.

80
00:06:19,290 --> 00:06:24,419
This is a comparatively simpler example, but
when callbacks start to next significantly,

81
00:06:24,419 --> 00:06:30,020
you enter what is known colloquially as callback
hell which becomes more difficult for your

82
00:06:30,020 --> 00:06:32,750
brain to reason of through.

83
00:06:32,750 --> 00:06:38,630
What is happening here in terms of the call
stack, and, by extension, the event loop?

84
00:06:38,630 --> 00:06:43,729
Assuming all these functions are asynch, first
we will begin, and then immediately yield

85
00:06:43,729 --> 00:06:46,490
control, and, then second, execute.

86
00:06:46,490 --> 00:06:52,820
A callback was registered by first so the
next available task will be that callback.

87
00:06:52,820 --> 00:06:56,700
Next, third will execute, followed by fourth.

88
00:06:56,700 --> 00:07:01,350
Fourth registers a callback, at then returns
control, so that fifth executes.

89
00:07:01,350 --> 00:07:05,340
The callback registered by fourth will come
off the Q and execute, and — the queue and

90
00:07:05,340 --> 00:07:09,410
execute, and finally, six will execute.

91
00:07:09,410 --> 00:07:15,759
For each of these functions taking a callback,
the callback itself is a black box for the

92
00:07:15,759 --> 00:07:16,889
function.

93
00:07:16,889 --> 00:07:23,230
The continuation of the programme is dependent
on our handing that callback off to another

94
00:07:23,230 --> 00:07:27,560
part of the code and then essentially just
praying that it will do the correct thing

95
00:07:27,560 --> 00:07:30,370
whether the callback is invoked.

96
00:07:30,370 --> 00:07:38,100
This paradigm is known as inversion of control,
and can create significant trust issues.

97
00:07:38,100 --> 00:07:44,229
In the previous code snippet I had up, you
could see that your eyes had to skip around,

98
00:07:44,229 --> 00:07:49,199
even though they most likely wanted to read
the code in a top-down fashion.

99
00:07:49,199 --> 00:07:53,979
When you sometimes struggle to understand
how and when each part of a piece of code

100
00:07:53,979 --> 00:08:00,020
is working, it's undoubtedly hard to deal
with errors in that code been within the callback

101
00:08:00,020 --> 00:08:06,419
landscape, there are two ways in which errors
are reported: via callbacks and via exceptions.

102
00:08:06,419 --> 00:08:09,660
You need to combine both properly.

103
00:08:09,660 --> 00:08:14,410
This is because the most obvious, but occasionally
overlooked aspect of dealing with errors in

104
00:08:14,410 --> 00:08:18,440
callbacks, is to make sure that they've actually
all been handled.

105
00:08:18,440 --> 00:08:23,850
However, there's a caveat to this advice,
and it lies specifically in how errors are

106
00:08:23,850 --> 00:08:29,650
caught: can you see how, in the snippet above,
I returned and didn't throw an error.

107
00:08:29,650 --> 00:08:35,630
That is intentional.

108
00:08:35,630 --> 00:08:40,899
In an asynchronous environment, the exception
could be thrown, and, when the lock is out

109
00:08:40,899 --> 00:08:45,430
of scope, the error would be rendered meaningless.

110
00:08:45,430 --> 00:08:52,820
The next big innovation in asynchronous programming
promises hit JavaScript with ES6.

111
00:08:52,820 --> 00:08:57,820
Before this, there was no direct notion of
asynch built directly into the JavaScript

112
00:08:57,820 --> 00:08:59,310
engine.

113
00:08:59,310 --> 00:09:04,890
All it ever did was execute a single chunk
of your programme at any given moment when

114
00:09:04,890 --> 00:09:06,040
asked to.

115
00:09:06,040 --> 00:09:12,330
You, the developer, asked it to by means of
callbacks or timeouts, in order to shuffle

116
00:09:12,330 --> 00:09:15,170
its place in the event loop.

117
00:09:15,170 --> 00:09:20,510
With promises came a change to the JS engine
which took a form of the queue that I mentioned

118
00:09:20,510 --> 00:09:24,970
briefly at the beginning — the microtask
queue.

119
00:09:24,970 --> 00:09:30,510
Before I delve into how exactly this changes
the form of the stack queue event loop diagram

120
00:09:30,510 --> 00:09:36,230
I showed you a few slides ago, let's look
at an example of a programme utilising promises

121
00:09:36,230 --> 00:09:41,160
and then discuss what is happening and why.

122
00:09:41,160 --> 00:09:44,060
Promises act as placeholders.

123
00:09:44,060 --> 00:09:49,550
They allow us to reason about future values
without necessarily knowing their outcomes,

124
00:09:49,550 --> 00:09:52,620
making them functionally extemporaneous.

125
00:09:52,620 --> 00:09:56,500
When the future value is settled, it might
succeed or fail.

126
00:09:56,500 --> 00:10:02,680
Then, at that point, the promise is no longer
a placeholder and becomes an immutable value.

127
00:10:02,680 --> 00:10:11,730
A few slides ago, I referenced the paradigm,
the version of control.

128
00:10:11,730 --> 00:10:23,180
Promises confer to us a capability to know
when a given task finishes.

129
00:10:23,180 --> 00:10:28,580
Promises may seem like an entirely different
paradigm, but they don't get rid of callbacks

130
00:10:28,580 --> 00:10:29,830
at all.

131
00:10:29,830 --> 00:10:35,230
They just change with the callback has passed
to, and remove the black box effect we saw

132
00:10:35,230 --> 00:10:36,820
previously.

133
00:10:36,820 --> 00:10:42,330
We get back from a function when it is completed,
and then perform new passes from there, as

134
00:10:42,330 --> 00:10:44,050
I said.

135
00:10:44,050 --> 00:10:53,760
Promises are not just the mechanism for single-step
operations that follow with this then that

136
00:10:53,760 --> 00:11:01,630
flow.

137
00:11:01,630 --> 00:11:17,360
[Sound distorted].

138
00:11:17,360 --> 00:11:40,230
From the — calls for

139
00:11:40,230 --> 00:11:47,529
the second then would create then another
promise.

140
00:11:47,529 --> 00:11:51,840
So, how does this look under the hood?

141
00:11:51,840 --> 00:11:58,260
Promises utilise the microtask queue by allows
us to say, "Here is this thing that I need

142
00:11:58,260 --> 00:12:06,060
to do later but I need to ensure it happens
immediately later from the — the microtask

143
00:12:06,060 --> 00:12:11,870
queue can best be thought of as attached to
each tech in the event loop.

144
00:12:11,870 --> 00:12:17,050
Some asynch actions will be added to the end
of the current microtask queue instead of

145
00:12:17,050 --> 00:12:19,390
creating a whole new tick as a whole.

146
00:12:19,390 --> 00:12:27,880
When a promise is resolved or rejected, the
associated handlers will be called asynchronously

147
00:12:27,880 --> 00:12:33,329
as microtasks, and then added to the queue
for the current tick.

148
00:12:33,329 --> 00:12:38,430
This diagram looks nearly identical to the
diagram I showed you a few slides back.

149
00:12:38,430 --> 00:12:41,750
One key difference from the microtask queue.

150
00:12:41,750 --> 00:12:48,920
Once a promise settles or already settling,
it queues a microtask.

151
00:12:48,920 --> 00:12:55,020
This ensures promise callbacks are asynch
even if the promise has already settled, so

152
00:12:55,020 --> 00:13:01,860
calling it then would resolve a reject against
the settled promise immediately queues a microtask.

153
00:13:01,860 --> 00:13:07,399
Any additional microtasks queued during a
given microtask are added to the end of the

154
00:13:07,399 --> 00:13:09,100
queue and also processed.

155
00:13:09,100 --> 00:13:15,660
So, in looking at the diagram, you see that
the current task can come off the task queue

156
00:13:15,660 --> 00:13:18,000
or the microtask queue.

157
00:13:18,000 --> 00:13:21,720
All promised callbacks are queued as microtasks.

158
00:13:21,720 --> 00:13:27,450
A microtask can also cause one or more microtasks
to be added to the end of the same queue.

159
00:13:27,450 --> 00:13:32,600
So it's theoretically possible that a microtask
loop could spin indefinitely thus starving

160
00:13:32,600 --> 00:13:37,550
the programme of its ability to move on to
the next event loop tick.

161
00:13:37,550 --> 00:13:44,290
This would conceptually be almost the same
as expressing an infinite loop in your code.

162
00:13:44,290 --> 00:13:46,769
What happens if something goes wrong in a
promise.

163
00:13:46,769 --> 00:13:48,150
How do we deal with those errors?

164
00:13:48,150 --> 00:13:53,889
By default, it turns out, promises are swallowed
if unhandled.

165
00:13:53,889 --> 00:14:01,510
More specifically, any exception which is
thrown inside a dot.then handler, or within

166
00:14:01,510 --> 00:14:08,209
a function path, a new promise will be soundly
disposed of unless manually handled.

167
00:14:08,209 --> 00:14:13,350
The standard way to handle errors from promises
is to add a catch handler at the end of your

168
00:14:13,350 --> 00:14:15,440
promise chain.

169
00:14:15,440 --> 00:14:19,580
You can also chain these handlers so that
you can throw errors into progressively more

170
00:14:19,580 --> 00:14:21,430
outer level scopes.

171
00:14:21,430 --> 00:14:27,130
Catching and rethrowing errors in this way
will tell you what led to the error more effectively

172
00:14:27,130 --> 00:14:31,100
so that you can later debug the issue more
efficiently.

173
00:14:31,100 --> 00:14:37,990
If exceptions are thrown inside the callbacks
of dot then and dot catch, it's not a method

174
00:14:37,990 --> 00:14:41,560
because these two can revert them to rejections.

175
00:14:41,560 --> 00:14:46,019
Let's look at an example and talk about what
would work and what wouldn't in more concrete

176
00:14:46,019 --> 00:14:47,800
terms.

177
00:14:47,800 --> 00:14:50,200
This is a simple promise example.

178
00:14:50,200 --> 00:14:56,209
From looking, you can see that from is going
to reject with an error, no matter what.

179
00:14:56,209 --> 00:15:00,180
So, what happens in the first example versus
the second?

180
00:15:00,180 --> 00:15:02,060
The first has a catch.

181
00:15:02,060 --> 00:15:05,850
So it's going to print the error followed
by the error message which in this case is

182
00:15:05,850 --> 00:15:07,360
rejected.

183
00:15:07,360 --> 00:15:11,800
You can also see the associated call stack
by printing error.stack.

184
00:15:11,800 --> 00:15:13,850
The second one doesn't have a catch.

185
00:15:13,850 --> 00:15:19,070
So even though we threw an error, it will
simply fail silently.

186
00:15:19,070 --> 00:15:24,790
This next type of asynch approach — generators
— sits a little on the edge of the overall

187
00:15:24,790 --> 00:15:29,140
asynch landscape but is nevertheless important
to touch on.

188
00:15:29,140 --> 00:15:34,240
The first thing to observe as we talk about
generators, is how they differ from normal

189
00:15:34,240 --> 00:15:35,620
functions.

190
00:15:35,620 --> 00:15:40,110
There are several notable differences but
key to generators is their behaviour with

191
00:15:40,110 --> 00:15:44,170
respect to the run to completion expectation.

192
00:15:44,170 --> 00:15:48,899
With generators, we have a different kind
of function which can be paused in the middle

193
00:15:48,899 --> 00:15:51,990
either once or several times.

194
00:15:51,990 --> 00:15:57,360
It is resumed later which allows other code
to run during these pause periods between

195
00:15:57,360 --> 00:15:59,260
runs.

196
00:15:59,260 --> 00:16:03,980
The main strength of generators is that they
provide a single threaded synchronous-looking

197
00:16:03,980 --> 00:16:11,130
code style but allow us to hide the asynchrony
away as an implementation detail.

198
00:16:11,130 --> 00:16:17,080
This lets us express naturally what a programme
step and statement flow is without navigating

199
00:16:17,080 --> 00:16:22,070
the asynchronous gotchas and syntax at the
same time.

200
00:16:22,070 --> 00:16:27,110
To get an idea of how this looks in practice,
let's see a function.

201
00:16:27,110 --> 00:16:32,699
Here, you will see immediately that there's
a little star next to the function in the

202
00:16:32,699 --> 00:16:33,820
signature.

203
00:16:33,820 --> 00:16:38,089
This is the syntactical indicator that you're
looking at a generator function.

204
00:16:38,089 --> 00:16:42,899
The key word "yield" will send out a value
whenever the function is run.

205
00:16:42,899 --> 00:16:49,410
So, here, the yield index plus plus expression
will send the index value out when pausing

206
00:16:49,410 --> 00:16:51,750
the generator function at that point.

207
00:16:51,750 --> 00:16:57,779
If ever the generator is restarted, whatever
value it was sent in will be the result of

208
00:16:57,779 --> 00:16:58,779
that expression.

209
00:16:58,779 --> 00:17:03,140
It will then get added to one and assigned
to the index variable.

210
00:17:03,140 --> 00:17:06,709
When we start, index is zero.

211
00:17:06,709 --> 00:17:10,889
So this will be yielded and then 1 will be
added to the index as a result of the plus

212
00:17:10,889 --> 00:17:12,309
plus.

213
00:17:12,309 --> 00:17:18,110
This will occur each time as the value of
index is passed out and then in again, and

214
00:17:18,110 --> 00:17:21,100
so that it increments by one every time.

215
00:17:21,100 --> 00:17:26,069
To see this a little more clearly, let's look
at a diagrammatical representation.

216
00:17:26,069 --> 00:17:29,269
On the left, you will see a traditional non-generator
function.

217
00:17:29,269 --> 00:17:34,470
It adheres to the run to completion behaviour
we expect from functions with no interruptions

218
00:17:34,470 --> 00:17:36,760
from beginning to end.

219
00:17:36,760 --> 00:17:39,190
On the right is the generator function.

220
00:17:39,190 --> 00:17:43,369
With multiple stops and starts between beginning
and end.

221
00:17:43,369 --> 00:17:48,470
It's important to note that there is no real
official end per se in the generator function.

222
00:17:48,470 --> 00:17:53,460
The end in this case will be the last time
that that yield is called.

223
00:17:53,460 --> 00:17:58,720
When the generator function is initialised,
an iterator is returned, and then the generator

224
00:17:58,720 --> 00:18:02,690
starts with the first call to next on the
function.

225
00:18:02,690 --> 00:18:07,370
This function pauses when yield is called,
and then would restart with the next call

226
00:18:07,370 --> 00:18:10,029
to next, and so on, and so forth.

227
00:18:10,029 --> 00:18:14,690
To recap, with normal functions, you get parameters
at the beginning, and a return value at the

228
00:18:14,690 --> 00:18:20,029
end, but generator functions, you send messages
out with yield, and you send messages back

229
00:18:20,029 --> 00:18:22,500
in with each restart.

230
00:18:22,500 --> 00:18:28,730
One of the most powerful parts of ES6 generator
design is that the semantics of the code inside

231
00:18:28,730 --> 00:18:30,979
the generator are synchronous.

232
00:18:30,979 --> 00:18:34,129
Even if the external iteration control proceeds
asynchronously.

233
00:18:34,129 --> 00:18:38,549
That's a fancy way of saying that you can
use a very simple error-handling technique

234
00:18:38,549 --> 00:18:41,269
you're probably familiar with — the tri
catch mechanism.

235
00:18:41,269 --> 00:18:49,690
If even if the function will pause at the
yield expression, the tri catch with catch

236
00:18:49,690 --> 00:18:50,830
it.

237
00:18:50,830 --> 00:18:55,739
With normal asynch capabilities like callbacks,
that's almost impossible to do.

238
00:18:55,739 --> 00:19:01,440
The generator itself has a throw function
to throw an error into the generator at its

239
00:19:01,440 --> 00:19:08,090
pause position which of course can also be
caught by a try catch inside the generator.

240
00:19:08,090 --> 00:19:11,870
Asynch await is a new way to write asynchronous
code.

241
00:19:11,870 --> 00:19:14,450
Previous options are callbacks and promises.

242
00:19:14,450 --> 00:19:21,539
Asynch await was created to simplify the process
of working with and writing chained promises.

243
00:19:21,539 --> 00:19:25,109
And so asynch await functions themselves return
promises.

244
00:19:25,109 --> 00:19:27,179
They cannot be used with plain callbacks.

245
00:19:27,179 --> 00:19:34,289
Asynch await is thus like promises non-blocking,
and makes asynchronous code look and behave

246
00:19:34,289 --> 00:19:36,399
more like synchronous code.

247
00:19:36,399 --> 00:19:39,009
This is where all the power lies.

248
00:19:39,009 --> 00:19:44,989
Since any asynch await function returns a
promise implicitly, the resolve value of the

249
00:19:44,989 --> 00:19:50,440
promise will be whatever you return from the
function to ill straight, let's look at.

250
00:19:50,440 --> 00:19:57,149
Here, we are returning a string that returns
several components of a street address.

251
00:19:57,149 --> 00:20:03,450
The function has the asynch key word before
it and the await key word can only be used

252
00:20:03,450 --> 00:20:06,980
in function s defined with asynch.

253
00:20:06,980 --> 00:20:12,720
All four variables must be resolved before
the function will return the desired string.

254
00:20:12,720 --> 00:20:17,460
Also important to note here is that if we
did not use the await key cord before each

255
00:20:17,460 --> 00:20:22,090
of the address component functions, this would
not necessarily fail.

256
00:20:22,090 --> 00:20:26,119
It would just mean that the variables would
be set to promises and from the values returned

257
00:20:26,119 --> 00:20:27,119
from them.

258
00:20:27,119 --> 00:20:34,399
There is it also an oft overlooked gotcha.

259
00:20:34,399 --> 00:20:37,509
Await calls operate sequentially.

260
00:20:37,509 --> 00:20:44,720
What this means is that the call to get.city
won't kick off until we have a value for get.street

261
00:20:44,720 --> 00:20:45,720
address.

262
00:20:45,720 --> 00:20:53,520
In some, this depends on a call from results
of a previous call.

263
00:20:53,520 --> 00:20:59,929
Here, we want to get the address components
simultaneously, so we should not be blocking

264
00:20:59,929 --> 00:21:02,029
each on the previous one.

265
00:21:02,029 --> 00:21:06,519
Instead, we should rewrite it like this.

266
00:21:06,519 --> 00:21:12,279
Under the hood, asynch await works almost
exactly the same as promises, utilising the

267
00:21:12,279 --> 00:21:16,710
new microtask queue introduced to handle asynch
operations.

268
00:21:16,710 --> 00:21:23,489
If you're familiar with promises, you know
that, if a promise is rejected, you need to

269
00:21:23,489 --> 00:21:26,440
handle that error inside a catch.

270
00:21:26,440 --> 00:21:31,539
If a handle be errors for synchronous and
asynchronous code, you will likely have to

271
00:21:31,539 --> 00:21:33,080
duplicate your error-handler.

272
00:21:33,080 --> 00:21:40,190
In the above snippet, we can see there is
duplicate code on lines 6 and 8.

273
00:21:40,190 --> 00:21:45,099
The catch statement on line 7 will handle
any errors that the synchronous function do

274
00:21:45,099 --> 00:21:50,879
synchronous things may throw, but it won't
handle any errors thrown by do something since

275
00:21:50,879 --> 00:21:54,909
it's asynchronous.

276
00:21:54,909 --> 00:22:00,509
This example may seem palatable, since all
it's doing is printing the error to console,

277
00:22:00,509 --> 00:22:06,899
but if there is any kind of complex error-handle
be logic, we want to avoid duplicating it.

278
00:22:06,899 --> 00:22:10,769
Asynch await let's us do exactly that.

279
00:22:10,769 --> 00:22:16,460
But looking at the code snippet on the top
right, you will see that we only catch once.

280
00:22:16,460 --> 00:22:24,210
When we use asynch await, we can catch errors
in a single handler.

281
00:22:24,210 --> 00:22:29,760
Here, we can both minimise the total amount
of code that we write and catch errors in

282
00:22:29,760 --> 00:22:32,669
a more readable and clear way.

283
00:22:32,669 --> 00:22:43,909
So, wrapping up: our brains plan things out
in sequential blocking singly threaded semantic

284
00:22:43,909 --> 00:22:44,909
ways.

285
00:22:44,909 --> 00:22:52,479
But callbacks express asynchronous flow in
a rather non-linear and non-sequential way.

286
00:22:52,479 --> 00:22:57,809
Which makes reasoning properly about such
code much more difficult.

287
00:22:57,809 --> 00:23:03,019
Callbacks suffer from lack of sequentiality
and lack of trustability, but they're good

288
00:23:03,019 --> 00:23:09,359
in situations where you may just be performing
a simple request that is always asynchronous.

289
00:23:09,359 --> 00:23:14,450
They're just plain functions, so they also
don't require any additional understanding

290
00:23:14,450 --> 00:23:17,929
beyond knowing how asynchronous operations
work.

291
00:23:17,929 --> 00:23:22,629
They also at the end to be more verbose, so
co-ordinating multiple asynchronous requests

292
00:23:22,629 --> 00:23:28,340
with them concurrently can lead to callback
hell if you're not actively modularising your

293
00:23:28,340 --> 00:23:29,770
functions.

294
00:23:29,770 --> 00:23:34,519
Dealing with errors also tends to be more
confusing, since there could be many error

295
00:23:34,519 --> 00:23:40,320
objects that all go back to a single error
further down the call stack.

296
00:23:40,320 --> 00:23:43,690
Promises are easier to reason of about.

297
00:23:43,690 --> 00:23:45,200
Although they still have their downsides.

298
00:23:45,200 --> 00:23:52,599
There are they are especially useful for co-ordinating
multiple asynchronous operations, propagating

299
00:23:52,599 --> 00:23:59,039
errors from nested asynch operations, and
dynamically chaining asynchronous operation

300
00:23:59,039 --> 00:24:04,639
s, i.e., those where you would do something
asynch, examine output, and then do something

301
00:24:04,639 --> 00:24:08,450
else asynch, based on the intermediate values.

302
00:24:08,450 --> 00:24:15,559
Errors and error stacks in promises can also
be a challenge, because they behave unintuitively

303
00:24:15,559 --> 00:24:20,200
in the way that they print errors when those
errors are thrown.

304
00:24:20,200 --> 00:24:24,799
They brought new changes to the JavaScript
engine and paved the way for later innovations

305
00:24:24,799 --> 00:24:27,380
like asynch await.

306
00:24:27,380 --> 00:24:33,759
This latest asynch pattern is basically syntactical
sugar on promises, but it allows for more

307
00:24:33,759 --> 00:24:36,729
intuitive reeled of asynchronous code.

308
00:24:36,729 --> 00:24:42,259
It improves error handling compared to traditional
promises and can be handled with simple try

309
00:24:42,259 --> 00:24:43,379
catch blocks.

310
00:24:43,379 --> 00:24:48,989
It is so easy to use asynch await that one
of its slight dangers that you forget you're

311
00:24:48,989 --> 00:24:52,019
writing asynchronous code at all.

312
00:24:52,019 --> 00:24:58,379
Ultimately, the best tool to use for a job
is going to be the one that is most specific

313
00:24:58,379 --> 00:25:00,190
to the job that you're doing.

314
00:25:00,190 --> 00:25:06,559
Now, I hope you'll have a firmer grasp on
what exactly makes each of these tools a best

315
00:25:06,559 --> 00:25:08,730
fit for certain jobs.

316
00:25:08,730 --> 00:25:13,840
And be able to use them with the deeper understanding
of what is going on at a granular level.

317
00:25:13,840 --> 00:25:15,549
Thank you very much.

