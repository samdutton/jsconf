1
00:00:10,080 --> 00:00:15,200
Hi, I hope you have a lot of water
lying around because between mine and Ryan's

2
00:00:15,210 --> 00:00:21,910
talk, we are going to have a lot of "node"
among other things — mentioned.

3
00:00:21,910 --> 00:00:27,180
This is merge conflict and management development
for developers.

4
00:00:27,180 --> 00:00:32,000
I'm at Samsung Next.

5
00:00:32,000 --> 00:00:42,229
By day and other hours I'm working on Node
in the community and a cat-herder of conferences.

6
00:00:42,229 --> 00:00:46,399
You can find me on GitHub and Twitter, and
the far corners of the internet as @hackygolucky

7
00:00:48,050 --> 00:00:53,729
Thanks for being here and listening for me
for a few minutes about some of this stuff.

8
00:00:53,729 --> 00:00:58,219
A disclaimer: I'm not a licensed psychotherapist.

9
00:00:58,219 --> 00:01:03,570
My undergraduate education was a bachelor
of science degree in psychology and sociology,

10
00:01:03,570 --> 00:01:08,780
but what that mostly means is I spent four
years trying to diagnose myself with some

11
00:01:08,780 --> 00:01:09,780
disorder.

12
00:01:09,780 --> 00:01:14,050
I'm frame of mind trained in crisis counselling
as well as peer mediation conflict management,

13
00:01:14,050 --> 00:01:20,079
and had experience in practising that, but
this talk is not a substitution for going

14
00:01:20,079 --> 00:01:24,780
and getting trained yourself and being supervised
by licensed experts to teach you how to execute

15
00:01:24,780 --> 00:01:29,250
on some of these lessons.

16
00:01:29,250 --> 00:01:35,060
As the education manage of Node, and now on
the moderation team, I'm leading the conflict

17
00:01:35,060 --> 00:01:40,010
management tree-shake programme for Node leadership
and collaborators, the folk who keep the project

18
00:01:40,010 --> 00:01:41,880
ticking for millions of users.

19
00:01:41,880 --> 00:01:49,659
We will walk through applying that to open-source
developers distributed across the globe and

20
00:01:49,659 --> 00:01:57,420
removing barriers to stability by improving
productivity with healthy collaboration as

21
00:01:57,420 --> 00:02:00,010
peer conflict management.

22
00:02:00,010 --> 00:02:05,909
So back when programmers were running tests
and prepping for the Y2K bug and GDPR was

23
00:02:05,909 --> 00:02:11,530
a millennial lifetime away, my middle school
leaders found themselves at an impasse with

24
00:02:11,530 --> 00:02:14,410
a pretty impossible challenge on their hands.

25
00:02:14,410 --> 00:02:18,230
Tons of fights and lots of physical violence
was going on.

26
00:02:18,230 --> 00:02:20,350
I went to a public school.

27
00:02:20,350 --> 00:02:25,670
Students were pouring into the guidance counsellor
with, what seemed to the adults, to be small

28
00:02:25,670 --> 00:02:28,510
arguments mostly fuelled by puberty.

29
00:02:28,510 --> 00:02:36,100
Along dismissing those problems, they finally
agreed to bring in an experiment, a peer mediate

30
00:02:36,100 --> 00:02:37,100
programme.

31
00:02:37,100 --> 00:02:39,780
Every student in the school was required to
take the training.

32
00:02:39,780 --> 00:02:44,500
A room, a space for the peer mediation, was
dedicated.

33
00:02:44,500 --> 00:02:50,830
A teacher was only in there to sit and watch
and stay quiet before the peers, we were required

34
00:02:50,830 --> 00:02:54,561
to visit and volunteer in the peer peer mediation
classroom once a week as if it was a study

35
00:02:54,561 --> 00:02:55,561
hall.

36
00:02:55,561 --> 00:03:01,270
The teachers and guidance counsellors were
no longer breaking up the fights.

37
00:03:01,270 --> 00:03:10,381
They trusted the students to solve their problems,
how to communicate what they're feeling, why

38
00:03:10,381 --> 00:03:15,880
they're feeling and, and to be calmly dialogue
about their disagreements and the occurrences

39
00:03:15,880 --> 00:03:19,030
of fighting dropped dramatically.

40
00:03:19,030 --> 00:03:26,311
So, someone you relate to, going through the
same history quizzes and algebra exams, they

41
00:03:26,311 --> 00:03:31,540
don't look or act like you but they have to
make it to the other side like you.

42
00:03:31,540 --> 00:03:36,900
Something hiding on the other surface of the
story is we don't wake up having these tools

43
00:03:36,900 --> 00:03:43,040
to facilitate conflict naturally, it has to
be cultivated by kid or as adults.

44
00:03:43,040 --> 00:03:47,840
This is a gift given to me by the secondary
education, and I thought it might translate

45
00:03:47,840 --> 00:03:53,250
to our distributed online world if done with
wear.

46
00:03:53,250 --> 00:03:56,550
We're programmers and also human.

47
00:03:56,550 --> 00:03:59,770
I get very, very fired up in debates.

48
00:03:59,770 --> 00:04:04,730
It feels good, if only temporary, to think
that you're right.

49
00:04:04,730 --> 00:04:09,430
When you've taken it too far, though, built
up this idea of another person on the other

50
00:04:09,430 --> 00:04:14,510
side of the screen who is doing something
so intentionally malicious, you're talking

51
00:04:14,510 --> 00:04:15,880
past each other.

52
00:04:15,880 --> 00:04:18,380
There's no understanding motivations.

53
00:04:18,380 --> 00:04:23,080
The words on your screen are the surface layer
of what is going on.

54
00:04:23,080 --> 00:04:24,770
So what is conflict?

55
00:04:24,770 --> 00:04:27,210
Conflict gets a really bad rap but that's
a bit unfair.

56
00:04:27,210 --> 00:04:29,730
It's not inherently bad.

57
00:04:29,730 --> 00:04:35,570
Modern theories consider conflict a natural
and inevitable outcome of human interaction.

58
00:04:35,570 --> 00:04:39,800
Conflict situations also often lead to the
generation of new ideas and positive change.

59
00:04:39,800 --> 00:04:44,130
So, that's a lot to unpack.

60
00:04:44,130 --> 00:04:48,470
Let's talk some approaches that we can use
as instruments to put in our tool boxes to

61
00:04:48,470 --> 00:04:52,290
communicate a little more kindly in our everyday
work.

62
00:04:52,290 --> 00:04:57,040
So the work we've done thus far with the Node
moderation team has, through honing governance

63
00:04:57,040 --> 00:05:02,720
and taking a deep look at what we need to
change to modify behaviour, incidentally mirrored

64
00:05:02,720 --> 00:05:10,530
when a Nobel Prize winning economist spoke
of evidence-based social design.

65
00:05:10,530 --> 00:05:16,190
Limit effects of bad behaviour, and that is
through moderation systems, making inappropriate

66
00:05:16,190 --> 00:05:22,960
posts less prominent, keeping consistent moderation
policies, including community members in the

67
00:05:22,960 --> 00:05:27,690
moderation, offering reversion tools and introducing
filters.

68
00:05:27,690 --> 00:05:30,020
Limit bad behaviour itself.

69
00:05:30,020 --> 00:05:36,380
You can do that through activity quotas, temporary
or permanent bans, and consistent criteria

70
00:05:36,380 --> 00:05:39,740
for the bans outlined with process.

71
00:05:39,740 --> 00:05:45,520
Encourage volunteering and compliance by ensuring
people learn the norms, showing examples of

72
00:05:45,520 --> 00:05:51,030
appropriate or inappropriate behaviour but
not too often and dwelling on it, displaying

73
00:05:51,030 --> 00:05:55,330
statistics on the normative behaviour, and
reminding people about the norms at the point

74
00:05:55,330 --> 00:05:58,130
of action.

75
00:05:58,130 --> 00:06:02,100
So with the advent of social coding through
GitHub, online communities have broken down

76
00:06:02,100 --> 00:06:07,970
physical location differences in communication
barriers, creating a new challenge with folks

77
00:06:07,970 --> 00:06:12,620
who are not employed by the same company but
collaborating on a common goal.

78
00:06:12,620 --> 00:06:19,790
The speed at which we pass both positive and
negative information, it is a break neck pace.

79
00:06:19,790 --> 00:06:26,560
Even if we were to be at the same company,
a well-meaning manager, a very well-staffed

80
00:06:26,560 --> 00:06:31,600
HR firm, or internal team, they would have
a hard time-keeping up.

81
00:06:31,600 --> 00:06:36,590
So, with volunteer contributes, as is much
of the the way of many open-source projects,

82
00:06:36,590 --> 00:06:39,640
attention and time are a limited resource.

83
00:06:39,640 --> 00:06:45,190
Low-quality contributions such as commenting
without seeking out some context prior, creates

84
00:06:45,190 --> 00:06:47,020
a social dilemma.

85
00:06:47,020 --> 00:06:51,419
These contributions drown out other contributions
with time and emotional labour, and often

86
00:06:51,419 --> 00:06:54,540
exhaust the available attention.

87
00:06:54,540 --> 00:07:01,419
So conflict researchers have studied this,
and the effects on code source software development

88
00:07:01,419 --> 00:07:03,020
is easier to track.

89
00:07:03,020 --> 00:07:09,800
Dr Steve Sawyer surveyed 40 package software
development teams and concluded how people

90
00:07:09,800 --> 00:07:15,430
work together and mitigate conflict is more
important than the individual skills and ability

91
00:07:15,430 --> 00:07:20,340
of the team's members in predicting their
software developer performance.

92
00:07:20,340 --> 00:07:23,290
So, — yes.

93
00:07:23,290 --> 00:07:24,770
[Applause].

94
00:07:24,770 --> 00:07:28,990
What do you think Node project activity looks
like when we've ended up in big fights on

95
00:07:28,990 --> 00:07:35,800
Twitter, or on long essays of debates going
back and forth on GitHub long derailed the

96
00:07:35,800 --> 00:07:37,520
issue at hand?

97
00:07:37,520 --> 00:07:42,600
PRs and pushes dropped to a drawl when comments
shoot up.

98
00:07:42,600 --> 00:07:49,800
So, we are makers, and there's no doubt we
love to fix things, and we are paid to problem-solve.

99
00:07:49,800 --> 00:07:54,169
But we can't fix them all, and we can certainly
not do all of this good work alone.

100
00:07:54,169 --> 00:07:59,320
But we try through trial and error in iterating
over governance, moderation policies, and

101
00:07:59,320 --> 00:08:02,940
codes of conducts, and in value consensus.

102
00:08:02,940 --> 00:08:08,330
So, as moderators in open source, we lay the
ground work for participants to understand

103
00:08:08,330 --> 00:08:10,080
one another's perspectives.

104
00:08:10,080 --> 00:08:15,820
For a content management system to work, we
had to establish that proper grounding first.

105
00:08:15,820 --> 00:08:23,730
We don't have to agree to get along, but a
common understanding and a value system context

106
00:08:23,730 --> 00:08:26,460
is important to effective interaction.

107
00:08:26,460 --> 00:08:33,280
So, last year, the first thing that we did
was meet as the top-level project committees,

108
00:08:33,280 --> 00:08:36,379
and reran a core values session at collaboration
summit.

109
00:08:36,379 --> 00:08:41,560
Even with its global impact, Node had relied
on an implicit understanding of community

110
00:08:41,560 --> 00:08:43,949
members' expectations.

111
00:08:43,949 --> 00:08:50,829
Core values serve as the boundaries within
which an organisation will operate in pursuit

112
00:08:50,829 --> 00:08:52,019
of its vision.

113
00:08:52,019 --> 00:08:59,200
Moving forward, we codify expectations so
we can work effectively together and empower

114
00:08:59,200 --> 00:09:02,790
members in the best interests of a global
Node.

115
00:09:02,790 --> 00:09:10,779
It is vital that we address good behaviour
practices, so we created the member expectations

116
00:09:10,779 --> 00:09:11,779
file.

117
00:09:11,779 --> 00:09:16,550
It is important that members of our leadership
group, that was the TSE community committee,

118
00:09:16,550 --> 00:09:21,880
also the members of the board, act in a way
that not only complies with the code but that

119
00:09:21,880 --> 00:09:28,240
models the vision, mission, and operating
principles of the Node project that we are

120
00:09:28,240 --> 00:09:29,240
seeking.

121
00:09:29,240 --> 00:09:34,339
Cultural acceptance: so cultural elements
underline conflict are really important considerations

122
00:09:34,339 --> 00:09:36,100
we need to bear in mind.

123
00:09:36,100 --> 00:09:41,769
Adding an extra edge and degree of sensitivity
to the difficult tasks of mediation and peace-building.

124
00:09:41,769 --> 00:09:46,920
This includes perception-checking, how our
own perception is affecting the conflict we

125
00:09:46,920 --> 00:09:52,069
are part of, and what influences our mental
programming has on how we are proceeding.

126
00:09:52,069 --> 00:09:57,350
Creative ways of handling conflicts emerges
from the adoption of a flexible outlook.

127
00:09:57,350 --> 00:10:01,290
In short, one size does not fit all.

128
00:10:01,290 --> 00:10:07,240
A nuanced approach to conflict through list
he can first, gaining contacts from parties,

129
00:10:07,240 --> 00:10:12,889
proceeding with care in the spaces, with which
the parties feel comfortable, often allow

130
00:10:12,889 --> 00:10:17,709
for early resolve instead of continued management.

131
00:10:17,709 --> 00:10:22,939
The tooling: so, I would be remiss not to
dive in a bit to the cooling constrains that

132
00:10:22,939 --> 00:10:26,860
we as open-source moderators of conflict have.

133
00:10:26,860 --> 00:10:29,069
Where do your communities live?

134
00:10:29,069 --> 00:10:35,300
For Node, we live on GitHub, we live on Twitter,
we, in fact, for some time, had a magnitude

135
00:10:35,300 --> 00:10:40,230
more tweets than the next most active programme
language, Java.

136
00:10:40,230 --> 00:10:44,260
I'm not kidding, or being hyperbolic.

137
00:10:44,260 --> 00:10:46,870
Node has grown up with GitHub.

138
00:10:46,870 --> 00:10:51,429
We felt the pain of what it means to limit
permissions of contributors for security's

139
00:10:51,429 --> 00:10:56,809
sake, and then moderators don't have access
to act swiftly or ban bad actors.

140
00:10:56,809 --> 00:11:01,399
We've celebrated the awesome work they've
done in recent years with incredible features

141
00:11:01,399 --> 00:11:06,939
giving the power to maintainers to better
fine-tune permissions, reduce noise, and ensure

142
00:11:06,939 --> 00:11:14,499
productive through user-blocking and apply
community guidelines through a repo.

143
00:11:14,499 --> 00:11:16,939
And then there is scope.

144
00:11:16,939 --> 00:11:22,649
We had to take a step back and look at what
spaces our ecosystem interacts in but also

145
00:11:22,649 --> 00:11:24,839
what we have control over.

146
00:11:24,839 --> 00:11:29,759
We can work to improve the environment in
GitHub because we control that space.

147
00:11:29,759 --> 00:11:33,149
We have the permissions and the administrative
tools do do that.

148
00:11:33,149 --> 00:11:34,290
What about Twitter?

149
00:11:34,290 --> 00:11:36,709
Or Reddit, or Hacker News.

150
00:11:36,709 --> 00:11:45,160
We chose a strategy of the scope we could
commit to, so as GitHub, select Slack and

151
00:11:45,160 --> 00:11:48,290
IRC groups, and event.

152
00:11:48,290 --> 00:11:52,600
That can be tough when many of us have found
sub committees in these spaces that are really

153
00:11:52,600 --> 00:11:56,790
helpful but we spend a lot of time trying
to help in these spaces and we've ended up

154
00:11:56,790 --> 00:12:00,070
with over exposed and attacked community members.

155
00:12:00,070 --> 00:12:02,790
So the who.

156
00:12:02,790 --> 00:12:04,089
The Node moderation team.

157
00:12:04,089 --> 00:12:09,739
We have an elevated responsibility to observe
patterns, audit processes and draft new governance

158
00:12:09,739 --> 00:12:13,000
to improve our work spaces of the Node project.

159
00:12:13,000 --> 00:12:18,309
The top-level committees, the TSC, the technical
steering committee, and the community committee,

160
00:12:18,309 --> 00:12:23,850
are voting members who jointly select or object
to any person on the moderation team.

161
00:12:23,850 --> 00:12:31,259
And the process verifies the shared trust
contributors have who are ending up selected.

162
00:12:31,259 --> 00:12:35,170
So let's be clear, though, as I move through
these examples.

163
00:12:35,170 --> 00:12:39,600
As I've said already, perspective is vital
to being effective in these challenges, and

164
00:12:39,600 --> 00:12:42,569
we still lack in diversity on the moderation
team.

165
00:12:42,569 --> 00:12:47,560
I think that's echoed through much of the
Node project, which also means we have gaps

166
00:12:47,560 --> 00:12:49,589
in time zone coverage.

167
00:12:49,589 --> 00:12:55,230
We will never be as effective as a group when
the make-up of our team doesn't mirror the

168
00:12:55,230 --> 00:12:59,910
make-up of the environment community we would
like to see in Node.

169
00:12:59,910 --> 00:13:02,480
This is an uphill battle worth fighting.

170
00:13:02,480 --> 00:13:08,700
As moderators, we respect that maintaining
trust is key to being effective.

171
00:13:08,700 --> 00:13:16,929
In conflict management, we get to be the bridge-builders
—

172
00:13:16,929 --> 00:13:21,790
we remove conflict barriers as facilitators
of conversations, so now that we've got the

173
00:13:21,790 --> 00:13:24,619
who, what, and why, let's how.

174
00:13:24,619 --> 00:13:29,420
So, anyone that wants to request moderation
can do so.

175
00:13:29,420 --> 00:13:32,959
They do have to be a member of our organisation.

176
00:13:32,959 --> 00:13:36,500
Requesting moderation of a post can be accomplished
in one of four ways.

177
00:13:36,500 --> 00:13:39,670
The first is to mail to report at node.js.org.

178
00:13:39,670 --> 00:13:47,189
A second is a private email to our members
listed in our readme with their email and

179
00:13:47,189 --> 00:13:49,589
full contact information.

180
00:13:49,589 --> 00:13:56,449
You can also file an issue in the same — a
new post in the same thread as the post with

181
00:13:56,449 --> 00:13:57,910
the moderation request.

182
00:13:57,910 --> 00:14:07,850
We can also request moderation via a new issue
in Node.js moderation repo.

183
00:14:07,850 --> 00:14:16,899
Collaborators can collaborate non-collaborator
posts at any time without submitting a request.

184
00:14:16,899 --> 00:14:19,290
Or getting a request by someone else.

185
00:14:19,290 --> 00:14:24,490
So this is because, while we have a moderation
team, anyone with a collaborator status is

186
00:14:24,490 --> 00:14:30,019
helping contribute to the values expressed
through repeated interactions with participants.

187
00:14:30,019 --> 00:14:36,480
The moderation team helps set policy and modelling
but all collaborators can and will moderate,

188
00:14:36,480 --> 00:14:37,670
or can and moderate by default.

189
00:14:37,670 --> 00:14:42,879
We're going to talk a little later about how
we are working to the intention al and better

190
00:14:42,879 --> 00:14:45,970
prepare the collaborators for all this.

191
00:14:45,970 --> 00:14:51,889
When a request is sent by email to report
at node.js.org or directly to a moderate team

192
00:14:51,889 --> 00:14:56,699
member, a new issue detailing that request
has to be logged in Node.js/moderation.

193
00:14:56,699 --> 00:15:05,759
The identity of the individual submitting
the request is omitted from the issue unless

194
00:15:05,759 --> 00:15:14,920
the — when you're having a conflict with
a co-co-worker, does your manager or HR sit

195
00:15:14,920 --> 00:15:18,240
you down in an open office or talk to you
about it?

196
00:15:18,240 --> 00:15:19,240
No.

197
00:15:19,240 --> 00:15:24,459
They take you into a private secretary where
you feel comfortable to talk candidly and

198
00:15:24,459 --> 00:15:29,790
gain perspective without feeling judged, or
feeling judged but that is easier to swallow

199
00:15:29,790 --> 00:15:31,420
in private.

200
00:15:31,420 --> 00:15:39,189
The moderation repo is a private repo, but
everyone who is a collaborate or has permission

201
00:15:39,189 --> 00:15:41,970
to view and interact on these threads.

202
00:15:41,970 --> 00:15:43,779
Hundreds of folks.

203
00:15:43,779 --> 00:15:48,310
We do this so folks are able to offer help,
insight, and context.

204
00:15:48,310 --> 00:15:54,350
By reducing the scope of exposure when dealing
with these issues filed, we are also avoiding

205
00:15:54,350 --> 00:15:56,499
the drive-byes.

206
00:15:56,499 --> 00:16:01,279
Scope and audience are vital to managing what
is within your control of change, and what

207
00:16:01,279 --> 00:16:06,290
requires tackling from multiple dependencies
or groups to effect change on the scale that

208
00:16:06,290 --> 00:16:07,540
is required.

209
00:16:07,540 --> 00:16:18,910
A great example of this is when momentum builds
off a Reddit post.

210
00:16:18,910 --> 00:16:23,529
When a harassing post is made on Reddit, if
it is reported to us and we don't have the

211
00:16:23,529 --> 00:16:29,100
bandwidth to alert on everything that is happening
in Node trolling on the internet, we will

212
00:16:29,100 --> 00:16:31,160
try to address it.

213
00:16:31,160 --> 00:16:33,600
We learned the hard way with this one, though.

214
00:16:33,600 --> 00:16:38,609
We can reach out to moderators of node Reddit
as an example for them to rectify but we can't

215
00:16:38,609 --> 00:16:41,069
force them to do anything.

216
00:16:41,069 --> 00:16:45,959
We can look to see if the harassers are current
contributors to the project and sanction them.

217
00:16:45,959 --> 00:16:50,799
We can make a public statement to reiterate
what we do and do not do tolerate as behaviour,

218
00:16:50,799 --> 00:16:57,549
but what we can do if it is someone not invested
in the project, does not operate in our spaces,

219
00:16:57,549 --> 00:17:03,350
so banning doesn't punish them, what do we
do with this drive-by harassment?

220
00:17:03,350 --> 00:17:06,100
We give them no platform.

221
00:17:06,100 --> 00:17:09,889
Because they are trolls, and they are curbies
of negative energy, and they will be empowered

222
00:17:09,889 --> 00:17:11,919
by us responding.

223
00:17:11,919 --> 00:17:16,829
We log the users and look for future activity
in the project if they ever engage and try

224
00:17:16,829 --> 00:17:19,490
to bring that toxicity.

225
00:17:19,490 --> 00:17:25,699
Thanks to these experiences as moderators,
we established that requests for moderation

226
00:17:25,699 --> 00:17:30,230
that do not appear to have been submitted
in good faith with the intent to address a

227
00:17:30,230 --> 00:17:34,670
legitimate code of conduct violation, we will
ignore it.

228
00:17:34,670 --> 00:17:40,100
It turns out some folks will try to manipulate
your moderators to use them as an attack vector

229
00:17:40,100 --> 00:17:42,780
for their harassment targets.

230
00:17:42,780 --> 00:17:49,200
So, before moderating a post, collaborators
and moderation teams specifically consider

231
00:17:49,200 --> 00:17:53,649
the possible intent of the author, as I've
just said, and we especially try to assume

232
00:17:53,649 --> 00:17:55,460
folks are acting in good faith.

233
00:17:55,460 --> 00:18:01,340
I mentioned trolls before but we do not operate
under the assumption on first look that anyone

234
00:18:01,340 --> 00:18:02,360
is a troll.

235
00:18:02,360 --> 00:18:06,370
It's possible that the author is simply made
has error or is not yet familiar with the

236
00:18:06,370 --> 00:18:07,730
code of conduct.

237
00:18:07,730 --> 00:18:11,600
It may be that cultural differences exist
or that the author is unaware that certain

238
00:18:11,600 --> 00:18:13,450
content is considered inappropriate.

239
00:18:13,450 --> 00:18:18,610
And in these cases, we make no assumption
of malintent and give the author an opportunity

240
00:18:18,610 --> 00:18:21,519
to correct any error that may have been made.

241
00:18:21,519 --> 00:18:28,381
But unfamiliarity or mis interpretations of
the conduct does not excuse a post for moderation.

242
00:18:28,381 --> 00:18:41,190
Moderation and team members will exclude or
block an individual from the node GitHub-org.

243
00:18:41,190 --> 00:18:45,940
Identifying the GitHub account beak acted
upon must be posted to this moderation repo

244
00:18:45,940 --> 00:18:52,169
for all collaborators to see with an explanation
provided by us on the moderation team.

245
00:18:52,169 --> 00:18:56,340
Any individual blocked from the node GitHub
org will be recommended for exclusion from

246
00:18:56,340 --> 00:18:59,429
any node foundation event as well.

247
00:18:59,429 --> 00:19:05,000
If the author of the reporting posting disagrees
that moderation is required, such as they

248
00:19:05,000 --> 00:19:10,559
won't edit or retract what they've been asked
to, the matter can be escalated to the method

249
00:19:10,559 --> 00:19:16,659
race team as well if the other collaborate
resource' requests haven't been met.

250
00:19:16,659 --> 00:19:22,040
Moderation action — no moderation act should
be take until a decision by the moderation

251
00:19:22,040 --> 00:19:23,040
team is made.

252
00:19:23,040 --> 00:19:28,010
I will explain in a little bit about why we
do that and don't let a single individual

253
00:19:28,010 --> 00:19:30,690
make that call.

254
00:19:30,690 --> 00:19:35,470
Trusted folks: these are the collaborators,
folks who are active in engaging in the project.

255
00:19:35,470 --> 00:19:42,559
When the post is authored by another collaborator
for an issue of potential violation, as a

256
00:19:42,559 --> 00:19:47,950
moderator, I must explain the justification
for moderating the post, identify all changes

257
00:19:47,950 --> 00:19:53,049
made to the post, identify the steps previously
taken to resolve the issue.

258
00:19:53,049 --> 00:19:58,720
If the moderation action included blocking,
as I said before, we have to make sure and

259
00:19:58,720 --> 00:20:04,320
file an issue that demonstrates the justification
for the action.

260
00:20:04,320 --> 00:20:09,210
Explanations of moderation actions on collaborator
posts must be provided in, and a new post

261
00:20:09,210 --> 00:20:18,030
within the original thread, a new issue within
the Node.js moderation repo, and any collaborator

262
00:20:18,030 --> 00:20:23,440
habitually violating the code of conduct,
or this moderation policy, may be blocked

263
00:20:23,440 --> 00:20:26,950
temporarily, or in extreme cases removed and
blocked indefinitely.

264
00:20:26,950 --> 00:20:33,120
We don't have a three strikes and you're out
because that's not sensitive enough for the

265
00:20:33,120 --> 00:20:37,000
levels of interpretation that we need.

266
00:20:37,000 --> 00:20:41,230
So we spend time documenting this activity
for educational purposes and reinforcement

267
00:20:41,230 --> 00:20:42,820
of values.

268
00:20:42,820 --> 00:20:46,850
We don't want to scare good humans away from
making a mistake.

269
00:20:46,850 --> 00:20:50,200
Repeated mistakes with no record of listening
or learning is another story.

270
00:20:50,200 --> 00:20:56,259
Separately, there are a lot of folks who don't
hop in threads but observing the modelling,

271
00:20:56,259 --> 00:21:00,830
logging actions and requirements hold us accountable
for consistency so moderators reduce their

272
00:21:00,830 --> 00:21:02,330
likelihood of being partial.

273
00:21:02,330 --> 00:21:07,620
This is vital for the advocacy working together
day-to-day and most important for those in

274
00:21:07,620 --> 00:21:11,090
the leadership of the context.

275
00:21:11,090 --> 00:21:17,030
Unknown folks: these are participants who
have not yet established themselves as repeated

276
00:21:17,030 --> 00:21:18,289
contributors to the project.

277
00:21:18,289 --> 00:21:23,210
When a post is authored by another — when
is a post is authored by one of them, the

278
00:21:23,210 --> 00:21:31,179
big difference here is that we have to dig
up any history that we can find on interactions

279
00:21:31,179 --> 00:21:35,580
with these folks, because we don't have a
history, it is much harder for us to go and

280
00:21:35,580 --> 00:21:39,840
interpret, so oftentimes, it's reaching out
to the individual any way we can to talk to

281
00:21:39,840 --> 00:21:41,920
them privately.

282
00:21:41,920 --> 00:21:46,271
And then, also consulting with other members
of the moderation team to see if there is

283
00:21:46,271 --> 00:21:48,950
something that can be done such as he had
indicating.

284
00:21:48,950 --> 00:21:55,600
If they don't respond, in a way that feels
like they are learning, then we know what

285
00:21:55,600 --> 00:21:57,159
we need to do.

286
00:21:57,159 --> 00:22:03,710
But as part of that, because they don't have
access to the collaborators' private moderation

287
00:22:03,710 --> 00:22:11,160
repo, we have then to try and make a decision,
and then make sure to log it in the public

288
00:22:11,160 --> 00:22:13,789
place that this person can see it.

289
00:22:13,789 --> 00:22:19,000
There are circumstances where we won't do
that, though.

290
00:22:19,000 --> 00:22:24,870
Again, no moderator makes thee decisions alone,
and no-one bears the burden of that decision

291
00:22:24,870 --> 00:22:25,870
alone.

292
00:22:25,870 --> 00:22:30,899
Historically moderating leads to retaliation
or escalation of inappropriate behaviour by

293
00:22:30,899 --> 00:22:36,679
the individual whose post is being moderated,
and I should say it can, it doesn't necessarily.

294
00:22:36,679 --> 00:22:42,270
This is the true intent of individuals whose
true intent is to hoar rats, disrupt, or annoy

295
00:22:42,270 --> 00:22:43,539
a member of the community.

296
00:22:43,539 --> 00:22:48,680
In these cases, it's best to handle the moderation
as quickly and quietly as possible without

297
00:22:48,680 --> 00:22:51,049
drawing any further attention.

298
00:22:51,049 --> 00:22:56,100
This reduces the velocity and intensity of
the attacks and protects the teams from emotional

299
00:22:56,100 --> 00:22:58,370
labour exhaustion.

300
00:22:58,370 --> 00:23:05,340
So, interaction limits: one of the cool tools
that GitHub offers us is a cooldown.

301
00:23:05,340 --> 00:23:09,950
So, what we do is take advantage of GitHub's
temporary interaction limits.

302
00:23:09,950 --> 00:23:16,440
We will temporarily limit who can comment,
create pull requests and make issues between

303
00:23:16,440 --> 00:23:18,370
collaborators and contributors.

304
00:23:18,370 --> 00:23:25,330
After 24 hours, the limit expires and the
users go back to participating in the discussion.

305
00:23:25,330 --> 00:23:28,299
And then we move on to temporary and permabans.

306
00:23:28,299 --> 00:23:31,360
A temporary block is time-limited as well.

307
00:23:31,360 --> 00:23:35,790
The time frame is decided on by our team at
the time of issuing, depending on the severity

308
00:23:35,790 --> 00:23:37,590
of the issue.

309
00:23:37,590 --> 00:23:43,149
The recommended defaults for us are 24 hours,
48 hours, and seven days.

310
00:23:43,149 --> 00:23:47,299
An indefinite block is set for an unspecified
amount of time, and may only be lifted for

311
00:23:47,299 --> 00:23:52,850
an individual through a simple majority vote
of the moderation team.

312
00:23:52,850 --> 00:23:57,100
Moderation of posts authored by non-collaborators
may result in these non-collaboratives being

313
00:23:57,100 --> 00:24:03,179
blocked temporarily or indefinitely from further
participation in the org.

314
00:24:03,179 --> 00:24:06,559
In the case where a GitHub account appears
to have been created with no intention to

315
00:24:06,559 --> 00:24:11,960
collaborate in good faith, we will swiftly
act without following the above procedures

316
00:24:11,960 --> 00:24:16,840
including removing posts, blocking indefinitely
and get accounts to GitHub, but that's after

317
00:24:16,840 --> 00:24:19,850
receiving plus-ones from team-mate.

318
00:24:19,850 --> 00:24:23,820
Accounts reasonably believed to be bots are
subject to immediate blocking.

319
00:24:23,820 --> 00:24:29,660
We're pretty conservative on handing out blocks.

320
00:24:29,660 --> 00:24:32,272
Temp blocks we set reminders to revisit the
bans.

321
00:24:32,272 --> 00:24:44,710
These tend to be removed where — I have
not seen in my history permanent bans revisited

322
00:24:44,710 --> 00:24:45,710
and lifted.

323
00:24:45,710 --> 00:24:51,090
I don't know of an instant where we've regretted
the scenarios because we're very cautious

324
00:24:51,090 --> 00:24:56,379
to exercise that in the first place, and multiple
plus-ones including the group they were interacting

325
00:24:56,379 --> 00:24:59,549
with are considered.

326
00:24:59,549 --> 00:25:06,440
So why haven't I rehashed all of the gory
details of our flame wars and ravenous trolls?

327
00:25:06,440 --> 00:25:10,820
For one, it's all still there in issues, and
Twitter, if you would like to waste your be

328
00:25:10,820 --> 00:25:15,610
bi- reading those old ghost stories, but I
don't think it's good to spend energy this

329
00:25:15,610 --> 00:25:16,610
way.

330
00:25:16,610 --> 00:25:21,420
I think it's best to find energy what we've
made mistakes on and fix and then building.

331
00:25:21,420 --> 00:25:24,149
We have rules around this in Node.

332
00:25:24,149 --> 00:25:30,200
Any collaborator found to be violating the
privacy of the node operation repo by sharing

333
00:25:30,200 --> 00:25:36,279
or discussing details of the issues, and any
public forum or social media, risks being

334
00:25:36,279 --> 00:25:39,620
permanently removed from the Node GitHub organisation.

335
00:25:39,620 --> 00:25:43,730
To be removed means you cannot contribution
to Node, the project.

336
00:25:43,730 --> 00:25:50,860
So, collaborators, maintainers, leaders, there
is power in showing off in doing work on a

337
00:25:50,860 --> 00:25:51,950
regular cadence.

338
00:25:51,950 --> 00:26:03,019
Open source, because so many of us volunteer,
words often comes — through ... . The ones

339
00:26:03,019 --> 00:26:08,320
who are trusted most often have the most to
lose, but can also be a win the lottery and

340
00:26:08,320 --> 00:26:11,809
disappear factor for the ecosystem.

341
00:26:11,809 --> 00:26:15,990
What if a person in these legacy groups is
seen as a bad actor?

342
00:26:15,990 --> 00:26:19,570
This goes far beyond the moderation team's
purview.

343
00:26:19,570 --> 00:26:23,830
What if your project doesn't have a way to
address this?

344
00:26:23,830 --> 00:26:29,230
That doesn't mean you can't act, but it means
you need to act with extreme care and intention.

345
00:26:29,230 --> 00:26:34,059
With excellent and consistent communication,
including the folks who have been reported

346
00:26:34,059 --> 00:26:35,250
on.

347
00:26:35,250 --> 00:26:40,650
How many people do you know are good at addressing
elephants in@room?

348
00:26:40,650 --> 00:26:44,980
How about being able to look someone in the
eye that you work with every day and tell

349
00:26:44,980 --> 00:26:48,919
them they need to stop a behaviour that other
groups have been — other people have been

350
00:26:48,919 --> 00:26:51,280
enable willing for years?

351
00:26:51,280 --> 00:26:54,610
Most of us aren't taught these skills.

352
00:26:54,610 --> 00:27:00,490
So what we know in that scenario is that it
leads to a lot of people hurt, lost trust,

353
00:27:00,490 --> 00:27:01,490
and declined productivity.

354
00:27:01,490 --> 00:27:07,480
It takes a long time to recover and instill
lasting changes, so all of this, feeling like

355
00:27:07,480 --> 00:27:11,410
we had a licensing way to go, we called in
the experts.

356
00:27:11,410 --> 00:27:14,390
In searching for a group that would be able
to address our concerns for training, we knew

357
00:27:14,390 --> 00:27:20,620
we would need folks who were trained to train,
and understand our globally distributed set

358
00:27:20,620 --> 00:27:21,700
of individuals.

359
00:27:21,700 --> 00:27:27,170
So, it turns out this isn't as common a domain
you would think in spite of being this large

360
00:27:27,170 --> 00:27:28,580
world we operate in.

361
00:27:28,580 --> 00:27:34,250
We engaged with online peer mediation platform
team, known for building conflict management

362
00:27:34,250 --> 00:27:38,039
programmes in universities and workplace settings.

363
00:27:38,039 --> 00:27:45,159
They had the following credentials: so, the
plan is that the moderation team and leadership,

364
00:27:45,159 --> 00:27:48,120
including the project of the board, are the
first round of trainees.

365
00:27:48,120 --> 00:27:54,749
So, we are going through six modules, this
is an hour and a half per week, and this is

366
00:27:54,749 --> 00:28:00,860
going to include reviewing materials ahead
of time as well as evaluation, discussion,

367
00:28:00,860 --> 00:28:06,080
role playing, and simulations, including GitHub
commenting, and practising with feedback.

368
00:28:06,080 --> 00:28:16,720
And that includes in curriculum, things like
like emotional intelligence, culture and conflict,

369
00:28:16,720 --> 00:28:22,820
and online conflict resolution skills which
are very unique skill set to have, of course.

370
00:28:22,820 --> 00:28:27,210
So then we are going to be rolling that out
to the wider collaborator base, raising the

371
00:28:27,210 --> 00:28:32,919
level of fluency and calmly and effectively
communicating through and beyond conflict

372
00:28:32,919 --> 00:28:34,490
with our collaborators in Node.

373
00:28:34,490 --> 00:28:40,320
It's a very exciting prospect and we're really
grateful to have the resources.

374
00:28:40,320 --> 00:28:46,350
So we have great examples, training, and improving
governance but a final component missing:

375
00:28:46,350 --> 00:28:47,490
self-care.

376
00:28:47,490 --> 00:28:50,499
If you aren't a whole rested person, how do
you build others up?

377
00:28:50,499 --> 00:28:53,970
Moderation and conflict management take a
lot of emotional energy.

378
00:28:53,970 --> 00:28:58,220
Each of us who volunteer on this work have
to carve out time to replenish meaningful

379
00:28:58,220 --> 00:28:59,940
to us.

380
00:28:59,940 --> 00:29:01,309
In the community we talk about this.

381
00:29:01,309 --> 00:29:04,039
In the moderation team, we take care.

382
00:29:04,039 --> 00:29:09,899
That can include therapy, exercise, having
other people who hold you to disengage from

383
00:29:09,899 --> 00:29:14,240
this good work.

384
00:29:14,240 --> 00:29:17,289
We like to think that we are still in the
wild west, and that we are responsible for

385
00:29:17,289 --> 00:29:22,370
coming up with solutions because the answers
don't exist but we don't need to reinvent

386
00:29:22,370 --> 00:29:24,840
the wheel for our human relations problems.

387
00:29:24,840 --> 00:29:32,279
There are whole professions devoted to the
science of making these experiences better.

388
00:29:32,279 --> 00:29:34,919
Great communication begins with connection.

389
00:29:34,919 --> 00:29:38,740
What makes us different from one another is
so much less important that had a what makes

390
00:29:38,740 --> 00:29:39,990
us alike.

391
00:29:39,990 --> 00:29:43,340
We all long for acceptance and significance.

392
00:29:43,340 --> 00:29:47,970
When we recognise those needs in ourselves,
we can better understand them in others, and

393
00:29:47,970 --> 00:29:49,139
[sound distorted].

394
00:29:49,139 --> 00:29:52,679
That's it, thank you.

