1
00:00:09,310 --> 00:00:12,310

so yeah again Jenna this is parsing

2
00:00:12,310 --> 00:00:15,520
cursors and I am a senior front-end

3
00:00:15,520 --> 00:00:18,580
engineer at slack I'm on the search and

4
00:00:18,580 --> 00:00:20,230
discovery team we're based in New York

5
00:00:20,230 --> 00:00:22,930
City I spend a lot of time thinking

6
00:00:22,930 --> 00:00:25,600
about the quick switcher and other art

7
00:00:25,600 --> 00:00:27,520
of completes throughout the product some

8
00:00:27,520 --> 00:00:29,770
other things I do in New York include

9
00:00:29,770 --> 00:00:32,440
organizing to JavaScript communities one

10
00:00:32,440 --> 00:00:34,900
is Empire Jas which is an annual

11
00:00:34,900 --> 00:00:37,059
JavaScript conference yeah there is

12
00:00:37,059 --> 00:00:39,010
Brooklyn Jas which is a monthly

13
00:00:39,010 --> 00:00:40,690
JavaScript Meetup

14
00:00:40,690 --> 00:00:43,629
so I know firsthand how much effort it

15
00:00:43,629 --> 00:00:45,489
takes to pull off an event like this so

16
00:00:45,489 --> 00:00:46,780
can we get a round of applause for all

17
00:00:46,780 --> 00:00:48,820
with organizers volunteers and everyone

18
00:00:48,820 --> 00:00:57,489
else so my twitter handle is Zygon

19
00:00:57,489 --> 00:00:59,739
vector you can feel free to tweet

20
00:00:59,739 --> 00:01:02,739
questions comments and compliments at me

21
00:01:02,739 --> 00:01:05,320
there I'll also tweet out the link to my

22
00:01:05,320 --> 00:01:07,420
slides which just happens to be on this

23
00:01:07,420 --> 00:01:10,150
slide she also mentioned there's a lot

24
00:01:10,150 --> 00:01:12,369
of information here so I've included

25
00:01:12,369 --> 00:01:14,110
some citations at the bottom of my

26
00:01:14,110 --> 00:01:16,210
bottom of my slides there's probably

27
00:01:16,210 --> 00:01:19,119
like entire college courses on parsers

28
00:01:19,119 --> 00:01:22,439
but I have to do this in 25 minutes so

29
00:01:22,439 --> 00:01:24,789
there's gonna be a lot of information in

30
00:01:24,789 --> 00:01:26,649
a short amount of time some of its going

31
00:01:26,649 --> 00:01:28,299
to be high-level some of its gonna be

32
00:01:28,299 --> 00:01:30,030
fast sorry

33
00:01:30,030 --> 00:01:32,350
so if you want to learn more please

34
00:01:32,350 --> 00:01:35,740
check out those links all right let's

35
00:01:35,740 --> 00:01:38,829
parse some parsers so I think to really

36
00:01:38,829 --> 00:01:42,219
understand parsers like understand what

37
00:01:42,219 --> 00:01:44,439
they're doing we need to learn a little

38
00:01:44,439 --> 00:01:47,200
bit about what makes languages language

39
00:01:47,200 --> 00:01:50,770
what makes languages languages so we'll

40
00:01:50,770 --> 00:01:53,170
talk a little bit about that and then as

41
00:01:53,170 --> 00:01:54,880
I was building the talk I just realized

42
00:01:54,880 --> 00:01:57,340
that the best way to learn about parsers

43
00:01:57,340 --> 00:01:59,710
is to build one which we will be

44
00:01:59,710 --> 00:02:01,840
stepping through the code for because

45
00:02:01,840 --> 00:02:03,490
I'm not brave enough to live code on

46
00:02:03,490 --> 00:02:07,210
stage so it'll be small it'll be a

47
00:02:07,210 --> 00:02:09,429
little too a parser but hopefully you

48
00:02:09,429 --> 00:02:12,069
can learn some things that I learned and

49
00:02:12,069 --> 00:02:13,780
feel the joy that I felt while building

50
00:02:13,780 --> 00:02:17,070
it so let's learn about language

51
00:02:17,070 --> 00:02:19,780
language is a structured system of

52
00:02:19,780 --> 00:02:22,190
communication might seem obvious

53
00:02:22,190 --> 00:02:24,620
we're starting at the basics here so we

54
00:02:24,620 --> 00:02:26,950
are using language to encode information

55
00:02:26,950 --> 00:02:31,760
to send between two entities like two

56
00:02:31,760 --> 00:02:34,040
people two computers a person and a

57
00:02:34,040 --> 00:02:37,850
computer etc the language that we're

58
00:02:37,850 --> 00:02:41,240
used to is called natural language we

59
00:02:41,240 --> 00:02:43,790
humans we speak it we sign it we write

60
00:02:43,790 --> 00:02:46,340
it we understand it innately because our

61
00:02:46,340 --> 00:02:48,710
brains evolved to understand it there

62
00:02:48,710 --> 00:02:50,690
are rules that govern how we put words

63
00:02:50,690 --> 00:02:52,490
together and how we put letters together

64
00:02:52,490 --> 00:02:55,780
to form words but we don't necessarily

65
00:02:55,780 --> 00:02:59,510
know these rules explicitly we might

66
00:02:59,510 --> 00:03:01,880
learn them in English class or in

67
00:03:01,880 --> 00:03:03,470
whatever class like that where you learn

68
00:03:03,470 --> 00:03:06,080
the rules of grammar but we don't

69
00:03:06,080 --> 00:03:08,360
necessarily know these rules explicitly

70
00:03:08,360 --> 00:03:10,790
some of these rules might be that now

71
00:03:10,790 --> 00:03:14,360
it's combined with verbs an adverb might

72
00:03:14,360 --> 00:03:17,390
come in to modify that verb but again we

73
00:03:17,390 --> 00:03:19,610
understand language and we've learned

74
00:03:19,610 --> 00:03:21,860
these rules without ever even really

75
00:03:21,860 --> 00:03:23,630
trying because our brains have evolved

76
00:03:23,630 --> 00:03:26,420
seamlessly to acquire language and even

77
00:03:26,420 --> 00:03:28,610
if we break these rules it's okay you

78
00:03:28,610 --> 00:03:30,980
generally understand what the other

79
00:03:30,980 --> 00:03:34,970
person is trying to say formal languages

80
00:03:34,970 --> 00:03:37,190
on the other hand are a bit more well

81
00:03:37,190 --> 00:03:39,830
formal they're more math class than

82
00:03:39,830 --> 00:03:41,930
English or Spanish class formal

83
00:03:41,930 --> 00:03:44,690
languages are also made up of words that

84
00:03:44,690 --> 00:03:46,820
are made up of letters from an alphabet

85
00:03:46,820 --> 00:03:49,100
both of which can be combined at each

86
00:03:49,100 --> 00:03:52,040
level based on specific rules which is

87
00:03:52,040 --> 00:03:54,320
called the languages grammar programming

88
00:03:54,320 --> 00:03:56,510
languages are formal languages which

89
00:03:56,510 --> 00:03:58,670
mean to that they have an alphabet like

90
00:03:58,670 --> 00:04:00,890
unicode and a grammar which we sometimes

91
00:04:00,890 --> 00:04:03,230
called the syntax that tells us how to

92
00:04:03,230 --> 00:04:05,330
write our code all the way down to the

93
00:04:05,330 --> 00:04:08,900
punctuation so as I said languages

94
00:04:08,900 --> 00:04:11,209
grammar is the set of rules for that

95
00:04:11,209 --> 00:04:14,720
language formal grammars put these rules

96
00:04:14,720 --> 00:04:17,120
in terms of rules of replacement which

97
00:04:17,120 --> 00:04:20,510
are called production rules so to get a

98
00:04:20,510 --> 00:04:22,280
sense of what I mean by replacement

99
00:04:22,280 --> 00:04:24,050
let's take a look at this little

100
00:04:24,050 --> 00:04:26,390
sentence diagram for this very short

101
00:04:26,390 --> 00:04:29,419
sentence Jenna gave the talk so we can

102
00:04:29,419 --> 00:04:31,940
kind of see that a sentence can be

103
00:04:31,940 --> 00:04:34,190
broken down into a noun and a verb

104
00:04:34,190 --> 00:04:36,150
phrase a verb phrase can

105
00:04:36,150 --> 00:04:38,940
replaced by a verb and a noun phrase etc

106
00:04:38,940 --> 00:04:41,130
all the way down the line so here are

107
00:04:41,130 --> 00:04:43,860
these rules put another way so you can

108
00:04:43,860 --> 00:04:46,170
see that sentence now a plus verb phrase

109
00:04:46,170 --> 00:04:48,960
verb phrase verb plus noun phrase down

110
00:04:48,960 --> 00:04:51,030
phrase can be broken down into a direct

111
00:04:51,030 --> 00:04:53,070
object and a noun and neither of these

112
00:04:53,070 --> 00:04:57,430
can be broken down any further

113
00:04:57,440 --> 00:04:59,700
programming languages have their

114
00:04:59,700 --> 00:05:02,370
grammars defined in a spec if any of you

115
00:05:02,370 --> 00:05:04,290
have ever been brave enough to try and

116
00:05:04,290 --> 00:05:06,180
read the Ekman script spec you might

117
00:05:06,180 --> 00:05:07,610
have seen that there is a section on

118
00:05:07,610 --> 00:05:10,130
grammars and a good chunk of it is

119
00:05:10,130 --> 00:05:12,870
describing how we put the bits of

120
00:05:12,870 --> 00:05:14,610
JavaScript together to create proper

121
00:05:14,610 --> 00:05:18,480
JavaScript so let's start our journey

122
00:05:18,480 --> 00:05:20,760
towards building our parser and first

123
00:05:20,760 --> 00:05:24,000
define our language and its grammar so I

124
00:05:24,000 --> 00:05:26,310
wanted to choose a language that had a

125
00:05:26,310 --> 00:05:28,530
few moving parts that I knew well and

126
00:05:28,530 --> 00:05:30,480
then I could explain how it works and

127
00:05:30,480 --> 00:05:32,790
what it means so I chose a language that

128
00:05:32,790 --> 00:05:34,830
was right there in front of me every day

129
00:05:34,830 --> 00:05:38,340
seven days a week you might be familiar

130
00:05:38,340 --> 00:05:40,650
with it it is the search query language

131
00:05:40,650 --> 00:05:42,360
from slack if you're not familiar with

132
00:05:42,360 --> 00:05:45,540
it explain what's going on here and our

133
00:05:45,540 --> 00:05:47,910
goal ultimately will be to build an even

134
00:05:47,910 --> 00:05:48,960
better visualizer

135
00:05:48,960 --> 00:05:51,870
for this language so here's an example

136
00:05:51,870 --> 00:05:54,420
of the search query language we have

137
00:05:54,420 --> 00:05:57,200
there are terms here like JavaScript

138
00:05:57,200 --> 00:05:59,910
phrases like front end in a single round

139
00:05:59,910 --> 00:06:03,330
of quotation marks there's these filters

140
00:06:03,330 --> 00:06:06,150
like in random and in general which say

141
00:06:06,150 --> 00:06:08,970
which messages we want to find which

142
00:06:08,970 --> 00:06:10,590
channels we want to search for messages

143
00:06:10,590 --> 00:06:14,340
in and from filters like from Jenna you

144
00:06:14,340 --> 00:06:16,290
want to find all the messages that are

145
00:06:16,290 --> 00:06:19,830
from me so here's what this grammar is

146
00:06:19,830 --> 00:06:22,410
going to look like a query can just be a

147
00:06:22,410 --> 00:06:24,530
term you can search for just JavaScript

148
00:06:24,530 --> 00:06:27,810
query can also be a term plus more query

149
00:06:27,810 --> 00:06:29,700
if we were to lock JavaScript off the

150
00:06:29,700 --> 00:06:31,290
beginning that would still be a valid

151
00:06:31,290 --> 00:06:34,260
query query can just be a filter you

152
00:06:34,260 --> 00:06:35,520
want to search for all the messages in

153
00:06:35,520 --> 00:06:38,520
random you can just do that and then you

154
00:06:38,520 --> 00:06:40,560
can search for all of the messages that

155
00:06:40,560 --> 00:06:42,420
have the word JavaScript in them in the

156
00:06:42,420 --> 00:06:44,580
random Channel and that's our little

157
00:06:44,580 --> 00:06:47,820
grammar for our language then I want us

158
00:06:47,820 --> 00:06:49,390
to build something that looks like

159
00:06:49,390 --> 00:06:51,580
that highlights the different types of

160
00:06:51,580 --> 00:06:53,440
bits of language in their own color

161
00:06:53,440 --> 00:06:55,560
whether it be green purple or light pink

162
00:06:55,560 --> 00:06:56,770
okay

163
00:06:56,770 --> 00:07:00,180
parsers that's what we are all here for

164
00:07:00,180 --> 00:07:04,210
so what what is a parser well it parses

165
00:07:04,210 --> 00:07:06,220
which is the process of analyzing

166
00:07:06,220 --> 00:07:08,650
language against the rules of its

167
00:07:08,650 --> 00:07:10,720
grammar so we're going to take the

168
00:07:10,720 --> 00:07:12,460
language and break it down into its

169
00:07:12,460 --> 00:07:14,320
components to find its underlying

170
00:07:14,320 --> 00:07:16,720
structure to see if it adheres to the

171
00:07:16,720 --> 00:07:17,980
rules of the language that it was

172
00:07:17,980 --> 00:07:20,350
written for this process also helps us

173
00:07:20,350 --> 00:07:22,120
turn language into something the

174
00:07:22,120 --> 00:07:24,240
computer can better use and maybe

175
00:07:24,240 --> 00:07:26,410
understand if we're going to think about

176
00:07:26,410 --> 00:07:30,040
it in human terms Bursar's can be really

177
00:07:30,040 --> 00:07:32,950
complicated but in the end all they have

178
00:07:32,950 --> 00:07:36,340
to do is take they all have to do is be

179
00:07:36,340 --> 00:07:38,650
a function that takes raw input and

180
00:07:38,650 --> 00:07:41,830
turns it into meaningful data that is

181
00:07:41,830 --> 00:07:44,670
created from the input or it's going to

182
00:07:44,670 --> 00:07:48,790
send off an error so again if it takes

183
00:07:48,790 --> 00:07:51,490
some unstructured language and turns it

184
00:07:51,490 --> 00:07:53,110
into something that is more structure

185
00:07:53,110 --> 00:07:56,310
and is more meaningful that's a parser

186
00:07:56,310 --> 00:07:57,490
Purser's

187
00:07:57,490 --> 00:08:00,340
in general when they're more complicated

188
00:08:00,340 --> 00:08:02,500
they usually have two parts to them they

189
00:08:02,500 --> 00:08:05,320
have a lexer and a parser which is the

190
00:08:05,320 --> 00:08:07,240
main event because you know it takes on

191
00:08:07,240 --> 00:08:10,360
the whole word right so the lexer is

192
00:08:10,360 --> 00:08:13,150
going to take the text and break it down

193
00:08:13,150 --> 00:08:16,150
into meaningful units called tokens

194
00:08:16,150 --> 00:08:18,310
these meaningful units are going to be

195
00:08:18,310 --> 00:08:21,940
the words the punctuation etc the first

196
00:08:21,940 --> 00:08:25,000
step in lexing is going to be the

197
00:08:25,000 --> 00:08:27,100
scanner so it's going to go through and

198
00:08:27,100 --> 00:08:29,650
break the string of characters into the

199
00:08:29,650 --> 00:08:31,840
proper chunks Jirka lexemes and these

200
00:08:31,840 --> 00:08:34,410
lexemes are the words in the language

201
00:08:34,410 --> 00:08:37,240
they can be key words literals like a

202
00:08:37,240 --> 00:08:40,030
number or string punctuation etc and

203
00:08:40,030 --> 00:08:42,610
this process is often accomplished by

204
00:08:42,610 --> 00:08:46,180
using Magilla expressions so let's dig

205
00:08:46,180 --> 00:08:53,510
into some code

206
00:08:53,520 --> 00:08:58,329
[Music]

207
00:08:58,339 --> 00:09:00,740
all right so we have a regular

208
00:09:00,740 --> 00:09:03,199
expressions here that define the four

209
00:09:03,199 --> 00:09:05,180
types of things that we can have an in

210
00:09:05,180 --> 00:09:08,059
filter from filter a phrase within those

211
00:09:08,059 --> 00:09:10,939
quotation marks and just a single term

212
00:09:10,939 --> 00:09:15,199
so just one word and this is pretty much

213
00:09:15,199 --> 00:09:17,089
just gonna be our lexer it's going to

214
00:09:17,089 --> 00:09:19,759
take those regular expressions and match

215
00:09:19,759 --> 00:09:22,189
them against the string that we put in

216
00:09:22,189 --> 00:09:24,949
so let's see what happens when we use

217
00:09:24,949 --> 00:09:32,379
our example a little bit so we can see

218
00:09:32,379 --> 00:09:37,240
here that these are our lexemes just

219
00:09:37,240 --> 00:09:40,790
smaller strings made from the initial

220
00:09:40,790 --> 00:09:44,480
input which was JavaScript front-end in

221
00:09:44,480 --> 00:09:51,350
general from jena etc well so let's also

222
00:09:51,350 --> 00:09:53,540
take a look at what javascript is doing

223
00:09:53,540 --> 00:09:59,509
because that's also interesting so

224
00:09:59,509 --> 00:10:02,029
javascript is going to take this little

225
00:10:02,029 --> 00:10:04,639
snippet of code and turn it into

226
00:10:04,639 --> 00:10:07,790
something that looks like this not very

227
00:10:07,790 --> 00:10:09,199
different but you can see it's going to

228
00:10:09,199 --> 00:10:11,240
break it down into its lexemes

229
00:10:11,240 --> 00:10:13,879
which include just const the variable

230
00:10:13,879 --> 00:10:17,209
name lexeme that equals sign which is

231
00:10:17,209 --> 00:10:20,600
punctuation the next step is the

232
00:10:20,600 --> 00:10:22,939
evaluator is going to combine the

233
00:10:22,939 --> 00:10:25,990
lexemes type with its value to create a

234
00:10:25,990 --> 00:10:29,899
token so first let's take a look at our

235
00:10:29,899 --> 00:10:36,170
code and you can see this next little

236
00:10:36,170 --> 00:10:45,620
bit so we're gonna take the tokens and

237
00:10:45,620 --> 00:10:48,559
combine them with their type which we

238
00:10:48,559 --> 00:10:50,360
can figure out because we know exactly

239
00:10:50,360 --> 00:10:52,370
what an in token looks like based on its

240
00:10:52,370 --> 00:10:54,139
regular expression or diff from token

241
00:10:54,139 --> 00:10:56,540
looks like based on that and etc so we

242
00:10:56,540 --> 00:11:01,220
can take those and turn them into the

243
00:11:01,220 --> 00:11:03,319
types of tokens that they are which just

244
00:11:03,319 --> 00:11:05,209
like a little object wrapper nothing too

245
00:11:05,209 --> 00:11:07,160
complicated because again little

246
00:11:07,160 --> 00:11:10,930
language little parser

247
00:11:10,940 --> 00:11:20,060
so javascript is going to take its

248
00:11:20,060 --> 00:11:23,190
lexemes like this and it's going to put

249
00:11:23,190 --> 00:11:26,940
them up into the mash them up with their

250
00:11:26,940 --> 00:11:29,430
type and turn them into these tokens and

251
00:11:29,430 --> 00:11:31,980
shout out to spree mahir which is a very

252
00:11:31,980 --> 00:11:33,810
popular parser that folks use for

253
00:11:33,810 --> 00:11:35,430
javascript that back some of our

254
00:11:35,430 --> 00:11:37,110
favorite JavaScript tools that do you

255
00:11:37,110 --> 00:11:39,720
like source transformation demo tools

256
00:11:39,720 --> 00:11:41,640
link at the bottom so if you want to you

257
00:11:41,640 --> 00:11:45,180
know see how it shakes out with whatever

258
00:11:45,180 --> 00:11:46,440
whatever your favorite snippet of

259
00:11:46,440 --> 00:11:48,570
JavaScript is you can do that there and

260
00:11:48,570 --> 00:11:51,980
this is what it is actually going to

261
00:11:51,980 --> 00:11:55,230
spit out it's really simple it has this

262
00:11:55,230 --> 00:12:00,180
type and it's the value never showed you

263
00:12:00,180 --> 00:12:02,640
what our little parser ends up doing so

264
00:12:02,640 --> 00:12:15,450
let's look at that hello tokens

265
00:12:15,450 --> 00:12:17,130
it's either the tokens from our little

266
00:12:17,130 --> 00:12:20,160
language so we have a term and in filter

267
00:12:20,160 --> 00:12:22,470
C not too much more complicated but they

268
00:12:22,470 --> 00:12:23,910
still have a little bit more meaning we

269
00:12:23,910 --> 00:12:25,740
can you know that this is an in filter

270
00:12:25,740 --> 00:12:27,450
you know this is a from filter and

271
00:12:27,450 --> 00:12:29,190
that's something that the computer might

272
00:12:29,190 --> 00:12:30,570
be able to do a little bit more with

273
00:12:30,570 --> 00:12:33,450
than just those fair strings that we had

274
00:12:33,450 --> 00:12:37,990
from lexemes

275
00:12:38,000 --> 00:12:43,410
all right so now we're onto the main

276
00:12:43,410 --> 00:12:45,620
event the parser which is going to

277
00:12:45,620 --> 00:12:47,790
analyze the tokens that were produced by

278
00:12:47,790 --> 00:12:49,980
the lexer checking that the syntax is

279
00:12:49,980 --> 00:12:52,350
correct based on the prescribed rules of

280
00:12:52,350 --> 00:12:54,690
the language while creating again that

281
00:12:54,690 --> 00:12:57,240
structure based on the production rules

282
00:12:57,240 --> 00:13:00,120
the result of parsing is usually a tree

283
00:13:00,120 --> 00:13:01,560
you might have heard about parse trees

284
00:13:01,560 --> 00:13:04,260
or syntax trees so that's what usually

285
00:13:04,260 --> 00:13:06,990
gets created and then if the parser

286
00:13:06,990 --> 00:13:09,420
cannot create a tree you end up with a

287
00:13:09,420 --> 00:13:12,210
syntax error so what we're gonna want

288
00:13:12,210 --> 00:13:14,370
out of this is a tree that kind of looks

289
00:13:14,370 --> 00:13:16,380
like this because that's what we need to

290
00:13:16,380 --> 00:13:18,690
build our visualizer parsers in the end

291
00:13:18,690 --> 00:13:20,310
or just around to help us achieve our

292
00:13:20,310 --> 00:13:22,830
end we can build a parser in different

293
00:13:22,830 --> 00:13:24,690
ways to achieve different goals

294
00:13:24,690 --> 00:13:26,700
and this is all we need we need to know

295
00:13:26,700 --> 00:13:28,890
that all of these tokens wrap up into a

296
00:13:28,890 --> 00:13:34,350
single query so let's take a look at our

297
00:13:34,350 --> 00:13:37,800
code and how it ends up spitting out our

298
00:13:37,800 --> 00:13:43,650
little tree so I'm gonna actually go to

299
00:13:43,650 --> 00:13:48,270
PS code okay so our parser isn't

300
00:13:48,270 --> 00:13:54,270
actually that much more complicated so

301
00:13:54,270 --> 00:13:56,880
we're gonna take we're gonna make a base

302
00:13:56,880 --> 00:13:58,650
query which is going to be our top level

303
00:13:58,650 --> 00:14:01,200
and just give it the tokens because

304
00:14:01,200 --> 00:14:03,360
that's all that we need to create our

305
00:14:03,360 --> 00:14:05,460
parser the way that we need it to be

306
00:14:05,460 --> 00:14:08,010
created creating this tree structure for

307
00:14:08,010 --> 00:14:13,320
our visualizer so then let's take a look

308
00:14:13,320 --> 00:14:21,480
at what it spits out Oh parse tree we

309
00:14:21,480 --> 00:14:24,390
have tokens top levels the query and

310
00:14:24,390 --> 00:14:28,920
then the tokens are here spit out we

311
00:14:28,920 --> 00:14:30,570
just have the single level these don't

312
00:14:30,570 --> 00:14:32,940
get broken down any further we are at

313
00:14:32,940 --> 00:14:40,260
the end cool so Java Script or something

314
00:14:40,260 --> 00:14:45,210
a little bit more complicated here going

315
00:14:45,210 --> 00:14:47,630
to have this program that eventually

316
00:14:47,630 --> 00:14:54,660
filters down into this tree of the you

317
00:14:54,660 --> 00:14:57,150
know I can't help but notice that like

318
00:14:57,150 --> 00:14:58,560
the leaves here are the thing that

319
00:14:58,560 --> 00:15:00,000
really matters right like we have like

320
00:15:00,000 --> 00:15:02,040
the variable names at the bottom the

321
00:15:02,040 --> 00:15:04,050
strings the method names that's like the

322
00:15:04,050 --> 00:15:05,820
stuff that really has meaning to us and

323
00:15:05,820 --> 00:15:07,530
then the rest of it was just there to

324
00:15:07,530 --> 00:15:09,420
help the purser figure out what was

325
00:15:09,420 --> 00:15:13,890
going on and this is what a stream is

326
00:15:13,890 --> 00:15:16,110
going to spit out it's a lot for such a

327
00:15:16,110 --> 00:15:17,850
little snippet of JavaScript and this I

328
00:15:17,850 --> 00:15:19,530
had to cut it off so you could even have

329
00:15:19,530 --> 00:15:21,240
a fighting chance of reading any of it

330
00:15:21,240 --> 00:15:26,089
so it's a lot but anything that helps us

331
00:15:26,089 --> 00:15:29,880
helps the computer make our JavaScript

332
00:15:29,880 --> 00:15:32,910
to do what we want it to do come to

333
00:15:32,910 --> 00:15:35,040
throw a little curveball into our little

334
00:15:35,040 --> 00:15:38,470
language here I think that we should

335
00:15:38,470 --> 00:15:41,650
I like these tokens these entities

336
00:15:41,650 --> 00:15:43,270
because they're they're their own

337
00:15:43,270 --> 00:15:46,150
separate meaningful unit right so what

338
00:15:46,150 --> 00:15:48,070
do we have to do to make our visualizer

339
00:15:48,070 --> 00:15:50,890
be able to do this well first we have to

340
00:15:50,890 --> 00:15:52,540
change our grammar around a little bit

341
00:15:52,540 --> 00:15:54,160
before we had it so that a filter

342
00:15:54,160 --> 00:15:56,650
couldn't be broken down any further but

343
00:15:56,650 --> 00:15:58,990
now it can into a modifier and an entity

344
00:15:58,990 --> 00:16:02,050
which they themselves could not be

345
00:16:02,050 --> 00:16:05,590
broken down anymore and then our tree is

346
00:16:05,590 --> 00:16:09,210
going to end up looking like this a

347
00:16:09,210 --> 00:16:11,590
little bit more complicated one more

348
00:16:11,590 --> 00:16:13,770
layer surely we can do this in our

349
00:16:13,770 --> 00:16:18,460
little parser with what we have so let's

350
00:16:18,460 --> 00:16:30,810
take a look back at our code

351
00:16:30,820 --> 00:16:35,000
second round maybe you know the first

352
00:16:35,000 --> 00:16:37,580
step is the lexer right we're gonna try

353
00:16:37,580 --> 00:16:39,410
and use our regular expressions but I

354
00:16:39,410 --> 00:16:41,930
don't see a way for us to be able to use

355
00:16:41,930 --> 00:16:44,120
just these regular expressions and be

356
00:16:44,120 --> 00:16:46,490
able to maintain some connection between

357
00:16:46,490 --> 00:16:50,780
the N and the the channel that we're

358
00:16:50,780 --> 00:16:52,370
looking in or the from and the person

359
00:16:52,370 --> 00:16:53,930
there's no way to maintain the

360
00:16:53,930 --> 00:16:56,150
connection between the modifier and

361
00:16:56,150 --> 00:16:59,570
their entity but what we do know is how

362
00:16:59,570 --> 00:17:03,260
to decompose a in token into its

363
00:17:03,260 --> 00:17:05,240
modifier and its entity we know that

364
00:17:05,240 --> 00:17:08,990
production rule so if we can just you

365
00:17:08,990 --> 00:17:12,350
know say okay this is our parser we do

366
00:17:12,350 --> 00:17:14,150
what we want to we know how to take and

367
00:17:14,150 --> 00:17:15,770
in token and then we're tokenizing we

368
00:17:15,770 --> 00:17:18,170
know how to take it's like lex IAM and

369
00:17:18,170 --> 00:17:20,780
split it apart we know that an in token

370
00:17:20,780 --> 00:17:22,850
the modifier is going to be an in

371
00:17:22,850 --> 00:17:25,130
modifier and we know that the filter is

372
00:17:25,130 --> 00:17:28,730
going to be this particular entity which

373
00:17:28,730 --> 00:17:31,370
is anything after the in filters pull in

374
00:17:31,370 --> 00:17:33,140
and maybe a space so we know how to

375
00:17:33,140 --> 00:17:34,790
break these two things apart because we

376
00:17:34,790 --> 00:17:37,370
know the production rule for turning and

377
00:17:37,370 --> 00:17:39,440
in token into its modifier and its

378
00:17:39,440 --> 00:17:42,050
entity so why not this is our parser

379
00:17:42,050 --> 00:17:45,530
then we can then make a mini tree out of

380
00:17:45,530 --> 00:17:49,100
this in token and then we can you know

381
00:17:49,100 --> 00:17:51,590
in our parse step we still have these

382
00:17:51,590 --> 00:17:54,050
tokens that all roll up into that query

383
00:17:54,050 --> 00:17:57,740
and we end up getting a tree that is a

384
00:17:57,740 --> 00:18:10,040
little bit more complicated let's do so

385
00:18:10,040 --> 00:18:13,310
our tree is going to be one more layer

386
00:18:13,310 --> 00:18:19,010
deep in token now turns into a modifier

387
00:18:19,010 --> 00:18:27,380
and an entity cool cool all right so now

388
00:18:27,380 --> 00:18:28,310
we're gonna get into a little bit more

389
00:18:28,310 --> 00:18:29,750
theory which is what this was all

390
00:18:29,750 --> 00:18:34,790
building up to why was the regex enough

391
00:18:34,790 --> 00:18:37,190
for the first example but not for the

392
00:18:37,190 --> 00:18:39,500
second you know there's a lot going on

393
00:18:39,500 --> 00:18:40,040
here

394
00:18:40,040 --> 00:18:41,810
seems pretty powerful right we were able

395
00:18:41,810 --> 00:18:43,730
to pretty much capsule

396
00:18:43,730 --> 00:18:45,890
everything that we needed to do our

397
00:18:45,890 --> 00:18:48,410
parse for our first smaller language but

398
00:18:48,410 --> 00:18:50,420
once we added that extra layer the

399
00:18:50,420 --> 00:18:52,250
regular expression wasn't enough anymore

400
00:18:52,250 --> 00:18:55,190
to be able to really encapsulate the

401
00:18:55,190 --> 00:18:57,860
entire languages grammar that's because

402
00:18:57,860 --> 00:19:01,130
the first language that we had was a

403
00:19:01,130 --> 00:19:03,590
regular grammar that grammar was able to

404
00:19:03,590 --> 00:19:07,730
be described by this most simple type of

405
00:19:07,730 --> 00:19:09,020
language which is called a regular

406
00:19:09,020 --> 00:19:11,060
language that has a regular grammar and

407
00:19:11,060 --> 00:19:13,730
all the production rules are of the

408
00:19:13,730 --> 00:19:17,690
following type you have the thing on the

409
00:19:17,690 --> 00:19:19,670
left can be broken down farther it is

410
00:19:19,670 --> 00:19:21,500
called a non-terminal gonna be a lot

411
00:19:21,500 --> 00:19:24,260
easier for me to use that term and then

412
00:19:24,260 --> 00:19:26,210
thing on the right is cannot be broken

413
00:19:26,210 --> 00:19:28,370
down any further and it is called a

414
00:19:28,370 --> 00:19:31,220
terminal the other way that a rule can

415
00:19:31,220 --> 00:19:33,170
look is that a terminal can be broken

416
00:19:33,170 --> 00:19:36,590
down into one non-terminal and one

417
00:19:36,590 --> 00:19:39,320
terminal so if we take a look at our

418
00:19:39,320 --> 00:19:41,030
Whittle language end up getting

419
00:19:41,030 --> 00:19:42,950
something that looks like that either

420
00:19:42,950 --> 00:19:45,400
have the non terminal on the left

421
00:19:45,400 --> 00:19:47,420
turning into something that can't be

422
00:19:47,420 --> 00:19:50,000
broken down any further or it turns into

423
00:19:50,000 --> 00:19:52,850
a combination of just one thing that can

424
00:19:52,850 --> 00:19:54,680
be broken down further and one thing

425
00:19:54,680 --> 00:19:56,270
that could not be broken down any

426
00:19:56,270 --> 00:19:56,780
further

427
00:19:56,780 --> 00:20:00,700
but once we added in that next

428
00:20:00,700 --> 00:20:03,110
production rule so we could break down

429
00:20:03,110 --> 00:20:05,020
the filter into a modifier and entity

430
00:20:05,020 --> 00:20:08,420
ended up not being able to describe this

431
00:20:08,420 --> 00:20:10,310
with the regular grammar anymore so the

432
00:20:10,310 --> 00:20:12,290
regular expression was no longer able to

433
00:20:12,290 --> 00:20:14,840
be just our friend and we needed to add

434
00:20:14,840 --> 00:20:15,950
an something else

435
00:20:15,950 --> 00:20:19,970
that knew how to get that bit into our

436
00:20:19,970 --> 00:20:22,220
language and allow us to represent that

437
00:20:22,220 --> 00:20:26,450
as the structure that we needed so the

438
00:20:26,450 --> 00:20:29,060
next level of complexity in languages is

439
00:20:29,060 --> 00:20:31,790
called a context-free grammar it has

440
00:20:31,790 --> 00:20:37,660
rules that follow this these rules so

441
00:20:37,660 --> 00:20:40,880
alpha it's a little bit you know

442
00:20:40,880 --> 00:20:42,380
intimidating but all the means is that

443
00:20:42,380 --> 00:20:45,230
it's any combination of things that can

444
00:20:45,230 --> 00:20:46,760
be broken down further and things that

445
00:20:46,760 --> 00:20:49,340
cannot be broken down further and it's

446
00:20:49,340 --> 00:20:51,860
just a little bit more power that lets

447
00:20:51,860 --> 00:20:54,170
us do a lot more things so the classic

448
00:20:54,170 --> 00:20:56,940
example here is that now we can

449
00:20:56,940 --> 00:21:00,120
do you nesting which includes matching

450
00:21:00,120 --> 00:21:03,570
parentheses so regular expressions can't

451
00:21:03,570 --> 00:21:05,220
do this because they don't have any

452
00:21:05,220 --> 00:21:08,010
concept of memory whereas we need to

453
00:21:08,010 --> 00:21:11,460
know if like verify if we indeed do have

454
00:21:11,460 --> 00:21:14,040
matching parentheses if when we see a

455
00:21:14,040 --> 00:21:16,710
closing parentheses if we'd seen the

456
00:21:16,710 --> 00:21:19,950
opening one earlier and not seen or

457
00:21:19,950 --> 00:21:21,630
maybe we'd seen another opening one

458
00:21:21,630 --> 00:21:23,550
beforehand but we need to have some type

459
00:21:23,550 --> 00:21:26,190
of memory to know if we are actually

460
00:21:26,190 --> 00:21:28,590
closing something based on the rules of

461
00:21:28,590 --> 00:21:31,620
the grammar that's why you might have

462
00:21:31,620 --> 00:21:34,440
heard that HTML isn't possible by

463
00:21:34,440 --> 00:21:37,380
regular expressions might be really

464
00:21:37,380 --> 00:21:39,480
tempting such a simple language of

465
00:21:39,480 --> 00:21:41,100
course it should be possible by regular

466
00:21:41,100 --> 00:21:43,290
expressions that's again because of the

467
00:21:43,290 --> 00:21:45,390
nesting we need to know if our divs are

468
00:21:45,390 --> 00:21:49,740
closing properly so I mean you might be

469
00:21:49,740 --> 00:21:51,930
thinking oh but like look ahead in

470
00:21:51,930 --> 00:21:53,760
regular expressions it's because regular

471
00:21:53,760 --> 00:21:55,260
expressions these days are more power

472
00:21:55,260 --> 00:21:57,780
powerful than just a regular grammar so

473
00:21:57,780 --> 00:21:58,830
they have that little bit of memory

474
00:21:58,830 --> 00:22:00,810
that's necessary to give it that little

475
00:22:00,810 --> 00:22:03,360
extra boost and and make them just a

476
00:22:03,360 --> 00:22:04,830
little bit more powerful than just a

477
00:22:04,830 --> 00:22:09,360
normal regular grammar so HTML like most

478
00:22:09,360 --> 00:22:11,100
if not all programming language grammars

479
00:22:11,100 --> 00:22:13,800
fall into the context-free family so you

480
00:22:13,800 --> 00:22:15,720
can do a lot with just this little extra

481
00:22:15,720 --> 00:22:18,090
bit of power that this little stack of

482
00:22:18,090 --> 00:22:22,350
memory that these parsers have so I've

483
00:22:22,350 --> 00:22:24,060
been talking a lot about like oh this is

484
00:22:24,060 --> 00:22:26,580
like a toy parser this isn't necessarily

485
00:22:26,580 --> 00:22:28,140
how these things necessarily work in the

486
00:22:28,140 --> 00:22:30,180
real world it's because writing one by

487
00:22:30,180 --> 00:22:32,070
hand would be a little bit

488
00:22:32,070 --> 00:22:34,470
time-consuming most of the time if

489
00:22:34,470 --> 00:22:36,300
you're gonna build a parser for a

490
00:22:36,300 --> 00:22:38,490
language you have a program that builds

491
00:22:38,490 --> 00:22:40,170
the purse or for you which is called a

492
00:22:40,170 --> 00:22:44,970
purse or generator so let's just go into

493
00:22:44,970 --> 00:22:47,280
what these things are doing at a higher

494
00:22:47,280 --> 00:22:51,540
level so if we were doing this following

495
00:22:51,540 --> 00:22:54,690
the more like suitable way of doing it

496
00:22:54,690 --> 00:22:58,020
we would end up lexing those terms down

497
00:22:58,020 --> 00:23:00,270
into their leaves so you would end up

498
00:23:00,270 --> 00:23:02,730
with these terms and then the modifier

499
00:23:02,730 --> 00:23:06,240
and entity would be their own lexemes

500
00:23:06,240 --> 00:23:09,690
and tokens in the end then the next

501
00:23:09,690 --> 00:23:10,410
thing that the parser

502
00:23:10,410 --> 00:23:12,720
going to do is go through and match the

503
00:23:12,720 --> 00:23:15,240
tokens to production rules there's a

504
00:23:15,240 --> 00:23:16,860
bunch of ways for doing this but let's

505
00:23:16,860 --> 00:23:18,720
step through one which is the top-down

506
00:23:18,720 --> 00:23:21,120
method so we're gonna take the tokens

507
00:23:21,120 --> 00:23:24,030
and then we're gonna start with the

508
00:23:24,030 --> 00:23:26,010
highest level of non-terminal that we

509
00:23:26,010 --> 00:23:28,080
have which is a query you know the

510
00:23:28,080 --> 00:23:31,020
queries can be broken down into other

511
00:23:31,020 --> 00:23:33,720
things in a myriad of different ways

512
00:23:33,720 --> 00:23:36,660
let's just say we got lucky and we chose

513
00:23:36,660 --> 00:23:38,100
the one that was going to work for our

514
00:23:38,100 --> 00:23:41,520
language first right off the bat so we

515
00:23:41,520 --> 00:23:43,770
say okay query can be broken down into a

516
00:23:43,770 --> 00:23:46,440
term and another query does that work

517
00:23:46,440 --> 00:23:49,140
with the tokens that we have at hand yes

518
00:23:49,140 --> 00:23:51,930
yes it does we can't break down a term

519
00:23:51,930 --> 00:23:52,710
anymore

520
00:23:52,710 --> 00:23:54,270
we can't break down a query anymore

521
00:23:54,270 --> 00:23:58,380
let's try that rule again cool that

522
00:23:58,380 --> 00:23:59,700
worked for us because we were able to

523
00:23:59,700 --> 00:24:04,100
pop that term off of our list of tokens

524
00:24:04,100 --> 00:24:07,680
feeling lucky let's try that rule again

525
00:24:07,680 --> 00:24:12,390
oh no didn't work we don't have another

526
00:24:12,390 --> 00:24:15,750
term let's try the next rule Oh looks

527
00:24:15,750 --> 00:24:18,230
like we got maybe lucky this time

528
00:24:18,230 --> 00:24:23,360
because let's let you know let's see

529
00:24:23,360 --> 00:24:26,880
what is a filter it can be turned into a

530
00:24:26,880 --> 00:24:30,510
modifier and an entity oh cool we got

531
00:24:30,510 --> 00:24:30,840
lucky

532
00:24:30,840 --> 00:24:32,900
that was like best-case scenario I think

533
00:24:32,900 --> 00:24:38,010
we only had to backtrack once okay

534
00:24:38,010 --> 00:24:40,860
so running out of time luckily I've

535
00:24:40,860 --> 00:24:43,800
reached the end of the talk I hope if

536
00:24:43,800 --> 00:24:48,540
you've learned anything it's that a

537
00:24:48,540 --> 00:24:50,930
parser is just something that takes

538
00:24:50,930 --> 00:24:53,160
unstructured language and turns it into

539
00:24:53,160 --> 00:24:56,280
structured language based on the grammar

540
00:24:56,280 --> 00:24:59,160
that that language is that the grammar

541
00:24:59,160 --> 00:25:01,170
for that language when I started this

542
00:25:01,170 --> 00:25:02,970
talk I wanted to learn more about

543
00:25:02,970 --> 00:25:06,180
parsers and once I realized that and I

544
00:25:06,180 --> 00:25:08,130
was building my own it became a lot more

545
00:25:08,130 --> 00:25:11,940
let give it a lot less intimidating so I

546
00:25:11,940 --> 00:25:13,980
hope if anything you take that away and

547
00:25:13,980 --> 00:25:15,960
maybe one day you'll have to write your

548
00:25:15,960 --> 00:25:18,150
own search query parser so you'll have

549
00:25:18,150 --> 00:25:19,710
this under your belt and then maybe you

550
00:25:19,710 --> 00:25:21,390
want to write your own JavaScript parser

551
00:25:21,390 --> 00:25:23,590
that's cool too

552
00:25:23,590 --> 00:25:26,289
hope this helped you so thank you for

553
00:25:26,289 --> 00:25:29,140
your time feel free to tweet at me and

554
00:25:29,140 --> 00:25:31,150
you can find my slides at that link

555
00:25:31,150 --> 00:25:32,690
thanks again

