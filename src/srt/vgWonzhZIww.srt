1
00:00:07,760 --> 00:00:12,349

so imagine this you grab your device

2
00:00:12,349 --> 00:00:17,220
open an app do some doodles midair watch

3
00:00:17,220 --> 00:00:20,789
your art appear on the screen is this

4
00:00:20,789 --> 00:00:24,359
the future no it's right around the

5
00:00:24,359 --> 00:00:27,720
corner and when you get to learn to

6
00:00:27,720 --> 00:00:30,420
build something like this you will call

7
00:00:30,420 --> 00:00:34,980
all of this amazing I am Prince iam and

8
00:00:34,980 --> 00:00:41,370
I love JavaScript so

9
00:00:41,380 --> 00:00:45,460
I am from Bangalore and I work for all

10
00:00:45,460 --> 00:00:47,500
education startup called guru ji

11
00:00:47,500 --> 00:00:50,620
learning labs I work on lodges building

12
00:00:50,620 --> 00:00:55,180
back in solutions yeah I participated

13
00:00:55,180 --> 00:00:58,600
the early morning today in this Jays

14
00:00:58,600 --> 00:01:01,780
party I was not sure because it was

15
00:01:01,780 --> 00:01:04,979
before my talk and I was already nervous

16
00:01:04,979 --> 00:01:08,170
but yes thanks to y'all lovely audience

17
00:01:08,170 --> 00:01:12,190
I think I just got lucky

18
00:01:12,190 --> 00:01:16,420
ok so the way we interacted with

19
00:01:16,420 --> 00:01:20,080
computers on a large scale was stuck in

20
00:01:20,080 --> 00:01:24,369
place for roughly 20 years from mouse -

21
00:01:24,369 --> 00:01:28,680
keyboard to joystick it is game over

22
00:01:28,680 --> 00:01:34,030
today it is the era of gestures today's

23
00:01:34,030 --> 00:01:38,050
gamers can do everything from slice and

24
00:01:38,050 --> 00:01:41,259
dice and fruit ninja to quest for a

25
00:01:41,259 --> 00:01:44,950
dragon and Skyrim from these early

26
00:01:44,950 --> 00:01:47,890
successes in 3d gesture-based

27
00:01:47,890 --> 00:01:51,729
input we now see high growth market

28
00:01:51,729 --> 00:01:58,060
emerging across multiple industries so

29
00:01:58,060 --> 00:02:01,270
this is what I am going to boil with for

30
00:02:01,270 --> 00:02:05,590
the next 30 minutes so by the end of

31
00:02:05,590 --> 00:02:08,700
this talk the such as computing

32
00:02:08,700 --> 00:02:12,280
augmented reality virtual reality will

33
00:02:12,280 --> 00:02:15,970
no more be alien to Yan any technology

34
00:02:15,970 --> 00:02:18,400
enthusiasts can start getting their

35
00:02:18,400 --> 00:02:21,070
hands dirty with these latest cool

36
00:02:21,070 --> 00:02:25,540
technology you get to learn to build the

37
00:02:25,540 --> 00:02:28,980
next generation of natural immersive

38
00:02:28,980 --> 00:02:32,850
intuitive apps hands and finger tracking

39
00:02:32,850 --> 00:02:37,090
facial recognition gesture analysis 3d

40
00:02:37,090 --> 00:02:41,410
scanning the list goes on and on now let

41
00:02:41,410 --> 00:02:44,320
me tell you the best thing you wouldn't

42
00:02:44,320 --> 00:02:48,010
need a hardware that is a 3d camera or a

43
00:02:48,010 --> 00:02:50,859
motion sensing device to test out the

44
00:02:50,859 --> 00:02:51,640
SDK

45
00:02:51,640 --> 00:02:55,660
Auto Bell a hello one sample I shall

46
00:02:55,660 --> 00:02:58,360
tell you some secret to test the SDK

47
00:02:58,360 --> 00:03:02,740
merely through JavaScript go and scold

48
00:03:02,740 --> 00:03:05,530
3d objects explore outer space or gain

49
00:03:05,530 --> 00:03:11,440
some magical powers okay so let's get

50
00:03:11,440 --> 00:03:14,470
into the basics for the stock 3d camera

51
00:03:14,470 --> 00:03:18,970
a type of camera with two or more lenses

52
00:03:18,970 --> 00:03:22,660
with separate image sensors a film frame

53
00:03:22,660 --> 00:03:26,650
for each lens 3d cameras give you the

54
00:03:26,650 --> 00:03:29,680
visual ability to perceive the world and

55
00:03:29,680 --> 00:03:31,780
the distance of an object in

56
00:03:31,780 --> 00:03:36,640
three-dimensional perceptual computing

57
00:03:36,640 --> 00:03:40,950
the ability for a computer to recognize

58
00:03:40,950 --> 00:03:43,480
what is going around it

59
00:03:43,480 --> 00:03:46,570
more specifically the computer can

60
00:03:46,570 --> 00:03:49,390
perceive the environment and the users

61
00:03:49,390 --> 00:03:52,970
in that environment

62
00:03:52,980 --> 00:03:57,070
augmented reality direct or indirect

63
00:03:57,070 --> 00:03:58,690
view of a physical real-world

64
00:03:58,690 --> 00:04:01,120
environment whose elements are augmented

65
00:04:01,120 --> 00:04:04,480
by computer-generated sensory inputs

66
00:04:04,480 --> 00:04:08,650
such as sound video graphics etc here a

67
00:04:08,650 --> 00:04:11,290
view of reality is modified by a

68
00:04:11,290 --> 00:04:15,430
computer as a result the technology

69
00:04:15,430 --> 00:04:18,160
functions by enhancing one's current

70
00:04:18,160 --> 00:04:20,410
perception of reality

71
00:04:20,410 --> 00:04:24,850
by contrast virtual reality replaces the

72
00:04:24,850 --> 00:04:27,960
real world with a stimulated one

73
00:04:27,960 --> 00:04:31,030
augmentation is conventionally in real

74
00:04:31,030 --> 00:04:34,210
time and in semantic context with

75
00:04:34,210 --> 00:04:42,340
environmental elements so we need to

76
00:04:42,340 --> 00:04:44,770
know more about these motion sensing

77
00:04:44,770 --> 00:04:49,180
input devices here are the few ones

78
00:04:49,180 --> 00:04:53,010
which I have tested out for the SDKs

79
00:04:53,010 --> 00:04:55,900
statutory warning here these are just

80
00:04:55,900 --> 00:04:58,750
listed in alphabetical order I am NOT

81
00:04:58,750 --> 00:05:02,600
representing any of these companies so

82
00:05:02,600 --> 00:05:04,490
virtual computing augmented reality

83
00:05:04,490 --> 00:05:08,240
virtual reality isn't new devices like

84
00:05:08,240 --> 00:05:10,490
these intel's realsense leap motion

85
00:05:10,490 --> 00:05:13,520
Microsoft Kinect has been around for a

86
00:05:13,520 --> 00:05:17,660
while you can control these devices with

87
00:05:17,660 --> 00:05:22,700
a wave a wink swipe and a smile with

88
00:05:22,700 --> 00:05:25,940
these you can scan real life things like

89
00:05:25,940 --> 00:05:29,780
a piece of art a child's toy all your

90
00:05:29,780 --> 00:05:34,300
own face and create a digital 3d version

91
00:05:34,300 --> 00:05:38,420
the technology behind these is around a

92
00:05:38,420 --> 00:05:41,420
webcam style added as a peripheral

93
00:05:41,420 --> 00:05:45,800
device it enables users to control and

94
00:05:45,800 --> 00:05:49,250
interact with their computer without the

95
00:05:49,250 --> 00:05:52,370
need for a game controller through a

96
00:05:52,370 --> 00:05:55,190
natural user interface using gestures

97
00:05:55,190 --> 00:05:58,700
and spoken commands these devices

98
00:05:58,700 --> 00:06:02,390
feature an RGB camera depth sensor and

99
00:06:02,390 --> 00:06:05,780
multi array microphone this technology

100
00:06:05,780 --> 00:06:08,060
could vary across devices because leap

101
00:06:08,060 --> 00:06:11,720
motion doesn't support wise or facial

102
00:06:11,720 --> 00:06:17,220
recognition Kinect and real sense does

103
00:06:17,230 --> 00:06:20,360
so let me tell you the motivation behind

104
00:06:20,360 --> 00:06:24,260
this idea few months back I was

105
00:06:24,260 --> 00:06:26,360
preparing for my talk on perceptual

106
00:06:26,360 --> 00:06:29,120
computing and I was supposed to give a

107
00:06:29,120 --> 00:06:32,350
demo on intel realsense JavaScript SDK

108
00:06:32,350 --> 00:06:36,800
this SDK works only on Windows two days

109
00:06:36,800 --> 00:06:39,350
before my talk windows in my laptop

110
00:06:39,350 --> 00:06:43,580
crashed yes I did not have a backup of

111
00:06:43,580 --> 00:06:48,200
this code and panic mode turned on this

112
00:06:48,200 --> 00:06:51,280
is when I thought of this web simulator

113
00:06:51,280 --> 00:06:53,450
by the way when I was preparing these

114
00:06:53,450 --> 00:06:55,100
slides I used Google Docs

115
00:06:55,100 --> 00:06:57,680
I didn't want any sort of laptop mushafs

116
00:06:57,680 --> 00:07:00,740
hacking in a foreign country I also

117
00:07:00,740 --> 00:07:02,780
thought that would be nice to conduct

118
00:07:02,780 --> 00:07:05,120
workshops seminars for a larger audience

119
00:07:05,120 --> 00:07:07,610
who would be intending to learn a new

120
00:07:07,610 --> 00:07:10,490
technology but wouldn't be having the

121
00:07:10,490 --> 00:07:13,380
required hardware C or real sense

122
00:07:13,380 --> 00:07:16,530
motion or a Kinect that is well this web

123
00:07:16,530 --> 00:07:21,480
simulator is very helpful when idea

124
00:07:21,480 --> 00:07:24,570
clicked and started wondering how is it

125
00:07:24,570 --> 00:07:27,020
that an external motion sensing device

126
00:07:27,020 --> 00:07:29,850
interacts with the computer natural

127
00:07:29,850 --> 00:07:33,240
question all these 3d cameras are

128
00:07:33,240 --> 00:07:37,650
connected through a USB port and the 3d

129
00:07:37,650 --> 00:07:41,400
camera SDKs access the 3d camera through

130
00:07:41,400 --> 00:07:46,050
the USB port okay so far so good we have

131
00:07:46,050 --> 00:07:48,770
one thing in common that is the USB port

132
00:07:48,770 --> 00:07:51,870
now all these SDKs have one thing

133
00:07:51,870 --> 00:07:53,550
another thing in common for that

134
00:07:53,550 --> 00:07:56,760
applications that is JavaScript is the

135
00:07:56,760 --> 00:08:00,330
primary language and in addition there

136
00:08:00,330 --> 00:08:02,760
is another thing common which is used to

137
00:08:02,760 --> 00:08:06,030
transmit the data from the camera to the

138
00:08:06,030 --> 00:08:10,400
computer and this is done using

139
00:08:10,400 --> 00:08:14,610
WebSockets so this is my secret these

140
00:08:14,610 --> 00:08:18,240
SDKs create a WebSocket which is part of

141
00:08:18,240 --> 00:08:21,210
the whole application and the secret

142
00:08:21,210 --> 00:08:26,550
behind the simulator is creating nodejs

143
00:08:26,550 --> 00:08:30,690
based WebSocket server which replaces

144
00:08:30,690 --> 00:08:34,560
the default one used by the SDKs that's

145
00:08:34,560 --> 00:08:36,900
it that's the secret so far the

146
00:08:36,900 --> 00:08:40,020
simulator for my simulator I create a

147
00:08:40,020 --> 00:08:42,300
noches WebSocket streaming server and

148
00:08:42,300 --> 00:08:45,300
replace it with the default one which is

149
00:08:45,300 --> 00:08:51,360
used by the SDKs so let's try to

150
00:08:51,360 --> 00:08:54,420
understand what a WebSocket is the

151
00:08:54,420 --> 00:08:57,270
explanation might seem too technical so

152
00:08:57,270 --> 00:08:59,910
to put it simple data can be sent

153
00:08:59,910 --> 00:09:04,440
between client and server the WebSocket

154
00:09:04,440 --> 00:09:07,920
specification was developed as part of

155
00:09:07,920 --> 00:09:11,490
the html5 initiative and this introduced

156
00:09:11,490 --> 00:09:17,790
the WebSocket JavaScript interface here

157
00:09:17,790 --> 00:09:19,760
is some code for a WebSocket

158
00:09:19,760 --> 00:09:23,150
implementation to connect to an endpoint

159
00:09:23,150 --> 00:09:25,100
just create

160
00:09:25,100 --> 00:09:27,710
a new WebSocket instance the first line

161
00:09:27,710 --> 00:09:31,190
they're providing the new object with

162
00:09:31,190 --> 00:09:35,060
the URL that represents the endpoint to

163
00:09:35,060 --> 00:09:38,800
which you wish to connect as shown here

164
00:09:38,800 --> 00:09:42,650
one thing to notice here is that to

165
00:09:42,650 --> 00:09:44,300
whoever is new to WebSockets

166
00:09:44,300 --> 00:09:48,170
a WebSocket connection is established by

167
00:09:48,170 --> 00:09:51,860
upgrading from the HTTP protocol to the

168
00:09:51,860 --> 00:09:54,740
WebSockets protocol during the initial

169
00:09:54,740 --> 00:09:57,020
handshake between the client and the

170
00:09:57,020 --> 00:10:00,350
server which is why the URL begins with

171
00:10:00,350 --> 00:10:03,980
the ws and not whether HTTP for secure

172
00:10:03,980 --> 00:10:08,120
it would be WSS before connecting to an

173
00:10:08,120 --> 00:10:11,840
endpoint and sending a message you can

174
00:10:11,840 --> 00:10:15,440
associate a series of event listeners to

175
00:10:15,440 --> 00:10:17,840
handle each face of the connection

176
00:10:17,840 --> 00:10:21,200
lifecycle as shown here so we have a

177
00:10:21,200 --> 00:10:23,900
bunch of event listeners like an open on

178
00:10:23,900 --> 00:10:27,710
message on clothes on error as well we

179
00:10:27,710 --> 00:10:30,950
can include that now to send a message

180
00:10:30,950 --> 00:10:33,980
to the server from the client simply

181
00:10:33,980 --> 00:10:34,490
called

182
00:10:34,490 --> 00:10:37,430
send the last orbit the last code

183
00:10:37,430 --> 00:10:40,250
snippet here and provide the content you

184
00:10:40,250 --> 00:10:43,070
wish to deliver after sending the

185
00:10:43,070 --> 00:10:46,160
message call close to terminate the

186
00:10:46,160 --> 00:10:49,580
connection as you can see it really

187
00:10:49,580 --> 00:10:52,880
couldn't be much easier just do this

188
00:10:52,880 --> 00:10:55,640
WebSocket implementation and we can test

189
00:10:55,640 --> 00:11:02,840
out the 3d camera SDKs so I am uploaded

190
00:11:02,840 --> 00:11:05,780
the code here and I will share my slice

191
00:11:05,780 --> 00:11:06,590
shortly

192
00:11:06,590 --> 00:11:09,470
the last windows crashed with a teach me

193
00:11:09,470 --> 00:11:12,560
this lesson and since then whenever I've

194
00:11:12,560 --> 00:11:16,040
been working I make a backup but my

195
00:11:16,040 --> 00:11:19,220
github reputation is quite bad I am sort

196
00:11:19,220 --> 00:11:21,080
of a new one to the open this

197
00:11:21,080 --> 00:11:22,900
contribution

198
00:11:22,900 --> 00:11:28,190
yeah I have told myself that I need to

199
00:11:28,190 --> 00:11:29,900
be active and do more sort of these

200
00:11:29,900 --> 00:11:31,820
contributions so coming back to this

201
00:11:31,820 --> 00:11:33,040
code I have worked

202
00:11:33,040 --> 00:11:35,139
demos uploaded for real sense and leap

203
00:11:35,139 --> 00:11:37,779
motion and I'll upload the code related

204
00:11:37,779 --> 00:11:44,079
to connect shortly so to pick a few good

205
00:11:44,079 --> 00:11:45,970
snippets which could be the starting

206
00:11:45,970 --> 00:11:47,740
point for y'all to get started

207
00:11:47,740 --> 00:11:51,790
couple of things here each SDK has its

208
00:11:51,790 --> 00:11:54,569
own comfortable ways of receiving data

209
00:11:54,569 --> 00:11:58,360
leap motion what it does is captures the

210
00:11:58,360 --> 00:12:01,089
frames from the controller writes the

211
00:12:01,089 --> 00:12:04,269
JSON data to a file and sends this JSON

212
00:12:04,269 --> 00:12:08,500
output over WebSockets so the JSON data

213
00:12:08,500 --> 00:12:10,569
is pretty big and it looks something

214
00:12:10,569 --> 00:12:15,430
like this it's a huge one so Lee portion

215
00:12:15,430 --> 00:12:18,100
what it does is captures the frames from

216
00:12:18,100 --> 00:12:19,180
the controller the leap motion

217
00:12:19,180 --> 00:12:22,300
controller writes this JSON data to a

218
00:12:22,300 --> 00:12:25,029
file and sends this JSON output over

219
00:12:25,029 --> 00:12:28,420
WebSockets so a leap motion expects a

220
00:12:28,420 --> 00:12:31,389
pre-processed json input whereas

221
00:12:31,389 --> 00:12:33,970
realsense on the other hand expects the

222
00:12:33,970 --> 00:12:37,779
raw image frames over WebSockets the SDK

223
00:12:37,779 --> 00:12:40,810
then processes this data and performs

224
00:12:40,810 --> 00:12:43,209
facial gesture recognition algorithms

225
00:12:43,209 --> 00:12:46,510
which are part of the SDK the difference

226
00:12:46,510 --> 00:12:48,850
to be noted here is that leap motion

227
00:12:48,850 --> 00:12:52,389
expects the WebSocket server to process

228
00:12:52,389 --> 00:12:54,670
the raw data and generate meaningful

229
00:12:54,670 --> 00:12:57,940
JSON output like this whereas realsense

230
00:12:57,940 --> 00:13:01,149
takes only the raw data from web socket

231
00:13:01,149 --> 00:13:03,930
and the SDK then processes this raw data

232
00:13:03,930 --> 00:13:07,360
the complex facial gesture algorithms

233
00:13:07,360 --> 00:13:13,149
are part of the SDK independent SDKs so

234
00:13:13,149 --> 00:13:16,630
this is from realsense dot JS file after

235
00:13:16,630 --> 00:13:20,260
you have downloaded the realsense sdk so

236
00:13:20,260 --> 00:13:23,050
you can search for socket in the file

237
00:13:23,050 --> 00:13:24,490
you can search for the keyword socket

238
00:13:24,490 --> 00:13:25,930
and the file and you'll find something

239
00:13:25,930 --> 00:13:29,110
like this so here we have socket URL

240
00:13:29,110 --> 00:13:31,000
which is an array and it tries

241
00:13:31,000 --> 00:13:32,740
connecting to these a bunch of for

242
00:13:32,740 --> 00:13:35,019
WebSocket URLs this is how you make a

243
00:13:35,019 --> 00:13:37,569
WebSocket server call as we already

244
00:13:37,569 --> 00:13:40,630
discussed so instead of HTTP it would be

245
00:13:40,630 --> 00:13:44,410
our WS and then you can associate any

246
00:13:44,410 --> 00:13:48,940
port number the last few lines I am

247
00:13:48,940 --> 00:13:50,529
showing you all the WebSocket methods

248
00:13:50,529 --> 00:13:52,269
and the event handlers so this is

249
00:13:52,269 --> 00:13:56,050
exactly what appears in the SDK on open

250
00:13:56,050 --> 00:13:59,589
on message on error on closed special

251
00:13:59,589 --> 00:14:02,110
thing to note here is binary type which

252
00:14:02,110 --> 00:14:05,350
is set to array buffer this needs to be

253
00:14:05,350 --> 00:14:07,660
done for WebSockets when you saw it sent

254
00:14:07,660 --> 00:14:10,750
raw data because the real cells expects

255
00:14:10,750 --> 00:14:13,509
the raw data over the web sockets which

256
00:14:13,509 --> 00:14:20,980
is then processed by the SDK this is

257
00:14:20,980 --> 00:14:23,319
what you'll get from leap dodges after

258
00:14:23,319 --> 00:14:26,220
you have downloaded the leap motion SDK

259
00:14:26,220 --> 00:14:28,649
pretty much similar to the previous one

260
00:14:28,649 --> 00:14:32,500
expect except the data comes pre

261
00:14:32,500 --> 00:14:34,990
processed that is in JSON format here

262
00:14:34,990 --> 00:14:37,420
and no array buffer setting is needed

263
00:14:37,420 --> 00:14:40,000
for WebSockets so as I told this is this

264
00:14:40,000 --> 00:14:41,709
could be the main difference while

265
00:14:41,709 --> 00:14:44,050
trying out the different SDKs the

266
00:14:44,050 --> 00:14:47,529
realsense expects raw data which you why

267
00:14:47,529 --> 00:14:50,100
you'll have to set the array buffer type

268
00:14:50,100 --> 00:14:55,300
to binary and the leap motion uses the

269
00:14:55,300 --> 00:15:00,350
JSON output pre-process to JSON output

270
00:15:00,360 --> 00:15:06,279
so this is how you are right on OGS

271
00:15:06,279 --> 00:15:10,720
WebSocket server now after no J's put

272
00:15:10,720 --> 00:15:12,670
javascript firmly on the back end and

273
00:15:12,670 --> 00:15:15,220
angularjs made us realized that client

274
00:15:15,220 --> 00:15:16,689
business logic needs to be moved

275
00:15:16,689 --> 00:15:18,689
entirely on the client-side

276
00:15:18,689 --> 00:15:21,069
possibilities for JavaScript were

277
00:15:21,069 --> 00:15:24,459
endless javascript phones robots and

278
00:15:24,459 --> 00:15:28,600
whatnot here uh no J's based WebSocket

279
00:15:28,600 --> 00:15:31,269
server has been implemented for this web

280
00:15:31,269 --> 00:15:34,300
simulator the port number as you'll see

281
00:15:34,300 --> 00:15:37,180
and the second line there is changeable

282
00:15:37,180 --> 00:15:39,639
we need to replace this value with the

283
00:15:39,639 --> 00:15:42,040
port number used by the SDK so the leaf

284
00:15:42,040 --> 00:15:44,170
motion on default the port number was

285
00:15:44,170 --> 00:15:46,000
six four three seven or six four three

286
00:15:46,000 --> 00:15:48,790
six or intel's realsense it was the five

287
00:15:48,790 --> 00:15:52,569
digit number the clients per a represent

288
00:15:52,569 --> 00:15:54,400
us the SDKs

289
00:15:54,400 --> 00:15:57,400
the connect to this web server this is a

290
00:15:57,400 --> 00:15:59,950
client-server model so Aaron

291
00:15:59,950 --> 00:16:02,590
this server is written in node.js and

292
00:16:02,590 --> 00:16:07,600
the clients are one of the 3d camera SDK

293
00:16:07,600 --> 00:16:10,450
so architecture looks something like

294
00:16:10,450 --> 00:16:10,990
this

295
00:16:10,990 --> 00:16:12,600
it's a client-server architecture

296
00:16:12,600 --> 00:16:15,760
wherein the server is this noches

297
00:16:15,760 --> 00:16:18,490
WebSocket server and the clients could

298
00:16:18,490 --> 00:16:21,190
be the SDKs plus it needs to be one of

299
00:16:21,190 --> 00:16:23,980
the browser which actually detects the

300
00:16:23,980 --> 00:16:27,880
native camera now in html5 we can access

301
00:16:27,880 --> 00:16:30,600
the native camera using getusermedia and

302
00:16:30,600 --> 00:16:35,170
so once you turn on this sdk you so the

303
00:16:35,170 --> 00:16:36,820
server will be listening it's a node.js

304
00:16:36,820 --> 00:16:40,200
server and you open a HTML browser

305
00:16:40,200 --> 00:16:44,680
wherein you have some code which will be

306
00:16:44,680 --> 00:16:46,530
the client which has the getusermedia

307
00:16:46,530 --> 00:16:50,380
which captures the user flames that is

308
00:16:50,380 --> 00:16:52,480
which captures the frames from the

309
00:16:52,480 --> 00:16:55,000
native camera and then transmits this

310
00:16:55,000 --> 00:16:57,310
binary data for your sense or rough

311
00:16:57,310 --> 00:17:00,040
processes it has a JSON and sends it to

312
00:17:00,040 --> 00:17:03,580
the WebSocket server so since this is a

313
00:17:03,580 --> 00:17:06,580
client-server architecture this camera

314
00:17:06,580 --> 00:17:09,010
client sends data to the web socket and

315
00:17:09,010 --> 00:17:11,440
this web socket in turn sends this data

316
00:17:11,440 --> 00:17:13,870
to the client to the next client which

317
00:17:13,870 --> 00:17:16,300
is our SDK that is it could be the real

318
00:17:16,300 --> 00:17:19,540
sense or the SDK so that's all you

319
00:17:19,540 --> 00:17:21,220
capture the input from the native camera

320
00:17:21,220 --> 00:17:24,070
process it and give it to the SDK so

321
00:17:24,070 --> 00:17:27,360
once these SDKs get the data it's now

322
00:17:27,360 --> 00:17:30,670
quite easy to test these SDKs go through

323
00:17:30,670 --> 00:17:33,760
the code or do some manipulations use

324
00:17:33,760 --> 00:17:37,750
some gestures or use some keyboard

325
00:17:37,750 --> 00:17:40,540
controls instead of gestures one thing

326
00:17:40,540 --> 00:17:43,450
is this simulator right now doesn't

327
00:17:43,450 --> 00:17:45,850
replace the holes or Hardware simulator

328
00:17:45,850 --> 00:17:48,100
that is it's not able to identify depth

329
00:17:48,100 --> 00:17:51,160
but if somebody gives you or what

330
00:17:51,160 --> 00:17:53,440
exactly the depth information comes we

331
00:17:53,440 --> 00:17:55,270
can just tweak these values and then

332
00:17:55,270 --> 00:17:56,860
maybe lights we can build some other

333
00:17:56,860 --> 00:17:58,990
applications say or just your controls

334
00:17:58,990 --> 00:18:02,170
not your head or like wave and then

335
00:18:02,170 --> 00:18:05,290
change ppts or do some cool animations

336
00:18:05,290 --> 00:18:06,210
on the sly

337
00:18:06,210 --> 00:18:08,520
and so on that is exactly what sleep

338
00:18:08,520 --> 00:18:12,450
motion or the real sense does so now

339
00:18:12,450 --> 00:18:14,460
we're coming back to my code I need to

340
00:18:14,460 --> 00:18:16,200
assemble all the code and make this as a

341
00:18:16,200 --> 00:18:18,150
universal simulator right now it's three

342
00:18:18,150 --> 00:18:19,890
different versions sitting for like real

343
00:18:19,890 --> 00:18:25,800
sense if motion or Microsoft Kinect so

344
00:18:25,800 --> 00:18:28,950
lastly you can go and Skutt some 3d

345
00:18:28,950 --> 00:18:32,010
objects explore outer space and gain

346
00:18:32,010 --> 00:18:37,830
some magical powers okay

347
00:18:37,830 --> 00:18:43,620
I still have some time and if you all

348
00:18:43,620 --> 00:18:46,410
have any questions y'all can ask me I

349
00:18:46,410 --> 00:18:49,560
would be happy to answer here or I could

350
00:18:49,560 --> 00:18:51,510
take it offline give you show you the

351
00:18:51,510 --> 00:18:55,110
demo what I have you could also tweet me

352
00:18:55,110 --> 00:18:58,890
at Lindsey and ask or yeah I would thank

353
00:18:58,890 --> 00:19:01,200
Jess can't Asia for giving me this

354
00:19:01,200 --> 00:19:03,480
wonderful opportunity to come here and

355
00:19:03,480 --> 00:19:06,870
present here I hope I didn't bore y'all

356
00:19:06,870 --> 00:19:11,550
I was not sure what to be shown on the

357
00:19:11,550 --> 00:19:13,500
slides or how much of the demo needs to

358
00:19:13,500 --> 00:19:16,260
be shown so just to prevent any shots of

359
00:19:16,260 --> 00:19:18,390
mushafs I don't have working demo but

360
00:19:18,390 --> 00:19:20,580
yes I have a working demo but I've not

361
00:19:20,580 --> 00:19:21,960
included part of the presentation

362
00:19:21,960 --> 00:19:24,570
because the gestures of svehla getting

363
00:19:24,570 --> 00:19:27,330
to Ori when it came to the light but yes

364
00:19:27,330 --> 00:19:30,600
I have some cool just obeys the demos or

365
00:19:30,600 --> 00:19:32,760
like swiping based demos y'all can come

366
00:19:32,760 --> 00:19:35,220
and check it out I'll be present here

367
00:19:35,220 --> 00:19:36,330
today tomorrow

368
00:19:36,330 --> 00:19:39,870
please come and feel free to bother me I

369
00:19:39,870 --> 00:19:42,990
would love to and yeah any questions

