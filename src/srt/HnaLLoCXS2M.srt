1
00:00:07,639 --> 00:00:10,379

thank you very much I'm so happy to be

2
00:00:10,379 --> 00:00:15,429
here how have you enjoyed past two days

3
00:00:15,439 --> 00:00:20,200
that wasn't that much have you liked it

4
00:00:20,210 --> 00:00:23,580
that's the spirit and so maybe first of

5
00:00:23,580 --> 00:00:25,769
all we've had great talks and you're all

6
00:00:25,769 --> 00:00:28,019
great people so maybe give a big hand to

7
00:00:28,019 --> 00:00:38,350
the organizers give it up for them

8
00:00:38,360 --> 00:00:43,290
so last talked let's do this before I

9
00:00:43,290 --> 00:00:44,970
start I want to give a trigger warning

10
00:00:44,970 --> 00:00:47,430
for this talk this hope will include

11
00:00:47,430 --> 00:00:49,560
mention of harassment misogyny

12
00:00:49,560 --> 00:00:52,920
transphobia homophobia racism sexism

13
00:00:52,920 --> 00:00:56,940
rape and death threats and abuse so as

14
00:00:56,940 --> 00:00:58,980
Jake so eloquently said my name is Lena

15
00:00:58,980 --> 00:01:01,800
vinod I'm a team leader consultant

16
00:01:01,800 --> 00:01:04,350
writer and photographer and Carly live

17
00:01:04,350 --> 00:01:06,810
in Berlin in Germany and if you're on

18
00:01:06,810 --> 00:01:08,940
Twitter my user handle there is a tell

19
00:01:08,940 --> 00:01:11,340
our and RD sarto remember remember so I

20
00:01:11,340 --> 00:01:15,390
put it on the slides and today I want to

21
00:01:15,390 --> 00:01:17,100
talk to you about software bugs because

22
00:01:17,100 --> 00:01:19,440
that's such a great topic raise your

23
00:01:19,440 --> 00:01:23,450
hands who of you is a software developer

24
00:01:23,450 --> 00:01:26,509
that's quite plenty maybe sixty percent

25
00:01:26,509 --> 00:01:31,940
two of you like software with bugs maybe

26
00:01:31,940 --> 00:01:35,190
10 people I want to have a conversation

27
00:01:35,190 --> 00:01:37,890
with you later and two of you enjoys

28
00:01:37,890 --> 00:01:39,570
that moment when you fix the bug and

29
00:01:39,570 --> 00:01:42,570
software works again that's almost

30
00:01:42,570 --> 00:01:45,870
everyone awesome so bug fixing what are

31
00:01:45,870 --> 00:01:49,710
bugs software bugs are errors flaws or

32
00:01:49,710 --> 00:01:52,260
failures in software that cause the

33
00:01:52,260 --> 00:01:54,540
software to produce incorrect undesired

34
00:01:54,540 --> 00:01:57,900
or unexpected output a but can be many

35
00:01:57,900 --> 00:02:00,360
things like a system error performance

36
00:02:00,360 --> 00:02:02,850
problem configuration issue or an issue

37
00:02:02,850 --> 00:02:07,710
with functionality at all points in the

38
00:02:07,710 --> 00:02:09,660
development cycle we can end up with

39
00:02:09,660 --> 00:02:13,170
thoughts and our software so we need to

40
00:02:13,170 --> 00:02:15,660
debug it we need to find and resolve

41
00:02:15,660 --> 00:02:17,489
these defects that we have in a system

42
00:02:17,489 --> 00:02:20,400
or in a software but debugging can be

43
00:02:20,400 --> 00:02:22,950
hard and it becomes even harder the more

44
00:02:22,950 --> 00:02:27,269
complex or software becomes in debugging

45
00:02:27,269 --> 00:02:29,010
one of the most interesting and

46
00:02:29,010 --> 00:02:31,549
difficult challenges is spaghetti code

47
00:02:31,549 --> 00:02:34,019
spaghetti code is slang for code that's

48
00:02:34,019 --> 00:02:36,530
unnecessarily complex convoluted and

49
00:02:36,530 --> 00:02:39,120
difficult to read or follow by human

50
00:02:39,120 --> 00:02:41,340
just like it's very difficult to follow

51
00:02:41,340 --> 00:02:43,560
one single piece of spaghetti when you

52
00:02:43,560 --> 00:02:46,740
have a pastor mountain on your plate

53
00:02:46,740 --> 00:02:48,810
spaghetti code can be code that's not

54
00:02:48,810 --> 00:02:51,180
organized uses lots of go-to statements

55
00:02:51,180 --> 00:02:53,430
has many interdependencies or jumps

56
00:02:53,430 --> 00:02:55,580
around between different areas or files

57
00:02:55,580 --> 00:02:58,410
it has often grown over many years and

58
00:02:58,410 --> 00:03:01,220
many people have contributed to it and

59
00:03:01,220 --> 00:03:05,910
it's very difficult to debug as people

60
00:03:05,910 --> 00:03:09,480
in tech were used to bugs they kept

61
00:03:09,480 --> 00:03:11,940
their part of our daily lives but

62
00:03:11,940 --> 00:03:13,560
there's another thing that's part of our

63
00:03:13,560 --> 00:03:15,210
lives a software developers and other

64
00:03:15,210 --> 00:03:17,730
people in tech another system that

65
00:03:17,730 --> 00:03:20,670
contains bugs the tech industry itself

66
00:03:20,670 --> 00:03:24,480
in this talk I will show you in which

67
00:03:24,480 --> 00:03:27,150
ways this industry is buggy why we

68
00:03:27,150 --> 00:03:29,850
should care about that and how to debug

69
00:03:29,850 --> 00:03:34,500
it the tech industry is a lot like a big

70
00:03:34,500 --> 00:03:36,960
system of spaghetti code it has grown

71
00:03:36,960 --> 00:03:38,490
over time and many people have

72
00:03:38,490 --> 00:03:41,310
contributed to it it's also a system

73
00:03:41,310 --> 00:03:43,020
that contains many different intertwined

74
00:03:43,020 --> 00:03:45,630
parts with dependencies and it it's

75
00:03:45,630 --> 00:03:47,610
important it's an important system with

76
00:03:47,610 --> 00:03:49,830
huge impact it's still one of the

77
00:03:49,830 --> 00:03:51,980
fastest growing industries worldwide and

78
00:03:51,980 --> 00:03:55,320
technology or lack thereof influences

79
00:03:55,320 --> 00:03:58,010
the daily lives of many people worldwide

80
00:03:58,010 --> 00:04:00,180
this is why we need to look at this

81
00:04:00,180 --> 00:04:05,430
industry and its effects to understand

82
00:04:05,430 --> 00:04:07,560
the system it helps understand it its

83
00:04:07,560 --> 00:04:10,110
parts so let's look at which parts

84
00:04:10,110 --> 00:04:12,620
define the tech industry as a system

85
00:04:12,620 --> 00:04:15,540
I've created a simplified Venn diagram

86
00:04:15,540 --> 00:04:19,830
to show them to you first of all you can

87
00:04:19,830 --> 00:04:22,950
see society much like software systems

88
00:04:22,950 --> 00:04:25,140
don't exist in isolation the tech

89
00:04:25,140 --> 00:04:26,970
industry also belongs to something

90
00:04:26,970 --> 00:04:30,540
larger part of the tech industry are

91
00:04:30,540 --> 00:04:33,420
communities like floss or free libre and

92
00:04:33,420 --> 00:04:35,100
open source software communities or

93
00:04:35,100 --> 00:04:38,790
local tech communities then we have

94
00:04:38,790 --> 00:04:41,310
companies some companies or the people

95
00:04:41,310 --> 00:04:43,230
in them contribute to communities or a

96
00:04:43,230 --> 00:04:45,090
part of them so we have an overlap here

97
00:04:45,090 --> 00:04:49,230
and finally there are humans and here

98
00:04:49,230 --> 00:04:51,780
you can see one of us this is me and

99
00:04:51,780 --> 00:04:55,169
this is you some of us work at companies

100
00:04:55,169 --> 00:04:57,960
some of us are part of communities all

101
00:04:57,960 --> 00:04:59,910
of us are in some way in tech

102
00:04:59,910 --> 00:05:02,760
and all these parts together influence

103
00:05:02,760 --> 00:05:07,710
this industry one of the most common

104
00:05:07,710 --> 00:05:09,810
problems in handling bugs as you may all

105
00:05:09,810 --> 00:05:11,550
know is the misconception of what

106
00:05:11,550 --> 00:05:14,430
actually constitutes a bug the classic

107
00:05:14,430 --> 00:05:18,050
question is it a bug or is it a feature

108
00:05:18,050 --> 00:05:21,030
when debugging software systems we bring

109
00:05:21,030 --> 00:05:22,890
our very own personal and technical

110
00:05:22,890 --> 00:05:25,880
skills preferences knowledge 'as and

111
00:05:25,880 --> 00:05:29,700
limitations so when you want to

112
00:05:29,700 --> 00:05:31,350
understand how these different parts

113
00:05:31,350 --> 00:05:33,330
we've looked at our influence the tech

114
00:05:33,330 --> 00:05:35,700
industry we need to understand ourselves

115
00:05:35,700 --> 00:05:39,060
first our own skills abilities and

116
00:05:39,060 --> 00:05:44,910
limitations some effects can exist in

117
00:05:44,910 --> 00:05:47,240
our society with ease and can influence

118
00:05:47,240 --> 00:05:50,040
which gives us advantages relative to

119
00:05:50,040 --> 00:05:52,700
other people we have privileged

120
00:05:52,700 --> 00:05:54,900
privileged comes from various factors

121
00:05:54,900 --> 00:05:58,700
like our gender race class education

122
00:05:58,700 --> 00:06:01,800
upbringing our ability appearance

123
00:06:01,800 --> 00:06:05,090
physical and mental health and many more

124
00:06:05,090 --> 00:06:07,680
privilege is a shield that protects us

125
00:06:07,680 --> 00:06:10,140
from problems and it blocks parts of our

126
00:06:10,140 --> 00:06:14,700
perception privilege is like being in

127
00:06:14,700 --> 00:06:17,460
your cozy sunny home over there reading

128
00:06:17,460 --> 00:06:20,280
a book and not even noticing that a

129
00:06:20,280 --> 00:06:21,780
thunderstorm is about to happen around

130
00:06:21,780 --> 00:06:24,540
you the thunderstorm that could cause

131
00:06:24,540 --> 00:06:27,320
the people outside their lives

132
00:06:27,320 --> 00:06:29,850
privileged in tech is when you can

133
00:06:29,850 --> 00:06:31,560
attend a conference party without fear

134
00:06:31,560 --> 00:06:34,020
that someone will harass you when you

135
00:06:34,020 --> 00:06:35,460
can have drinks with colleagues every

136
00:06:35,460 --> 00:06:36,900
other night because you don't have to

137
00:06:36,900 --> 00:06:38,550
take care of the child or elderly

138
00:06:38,550 --> 00:06:41,970
relatives at home privileged in tech is

139
00:06:41,970 --> 00:06:43,950
when you can stand in the daily stand-up

140
00:06:43,950 --> 00:06:46,020
meeting and don't have to sit because of

141
00:06:46,020 --> 00:06:49,350
a disability or illness and when you can

142
00:06:49,350 --> 00:06:51,240
publish a post about a framework online

143
00:06:51,240 --> 00:06:53,070
without getting rape or death threats in

144
00:06:53,070 --> 00:06:57,690
return privilege is a classic example of

145
00:06:57,690 --> 00:07:00,840
but it works on my machine or but it

146
00:07:00,840 --> 00:07:03,690
works in my life it puts us in a

147
00:07:03,690 --> 00:07:05,430
position where we don't see problems in

148
00:07:05,430 --> 00:07:07,200
tech because we're not personally

149
00:07:07,200 --> 00:07:10,140
affected by them a position where we

150
00:07:10,140 --> 00:07:11,700
don't even have to think about the fact

151
00:07:11,700 --> 00:07:13,710
that not all lives and all

152
00:07:13,710 --> 00:07:16,860
jeans are the same privilege is a

153
00:07:16,860 --> 00:07:20,550
comfortable position of ignorance and we

154
00:07:20,550 --> 00:07:21,930
have to actively work through our

155
00:07:21,930 --> 00:07:24,840
privileges to make sure we see more than

156
00:07:24,840 --> 00:07:27,360
our tiny portion of the world and to

157
00:07:27,360 --> 00:07:29,610
understand what the tech industry really

158
00:07:29,610 --> 00:07:34,410
looks like another factor that limits

159
00:07:34,410 --> 00:07:37,520
our perception our biases every moment

160
00:07:37,520 --> 00:07:40,500
our brains receive 11 million pieces of

161
00:07:40,500 --> 00:07:43,320
information but we can only process 40

162
00:07:43,320 --> 00:07:44,730
of those pieces pieces with our

163
00:07:44,730 --> 00:07:48,150
conscious biases our assumptions we use

164
00:07:48,150 --> 00:07:50,070
to deal with this huge amount of

165
00:07:50,070 --> 00:07:52,220
information that our brains receive and

166
00:07:52,220 --> 00:07:55,080
biases are attached to the idea that we

167
00:07:55,080 --> 00:07:56,940
can judge something just by looking at

168
00:07:56,940 --> 00:08:00,170
it they're based on our past knowledge

169
00:08:00,170 --> 00:08:04,860
experiences and cultural norms biases

170
00:08:04,860 --> 00:08:07,080
are great for seeing there's an animal

171
00:08:07,080 --> 00:08:11,460
it has four legs lots of hair it's light

172
00:08:11,460 --> 00:08:14,010
brown and it's not a dog or cat this is

173
00:08:14,010 --> 00:08:18,150
a lion I should run but biases are not

174
00:08:18,150 --> 00:08:20,340
good for judging people that we use them

175
00:08:20,340 --> 00:08:23,250
for it and we even think that we're

176
00:08:23,250 --> 00:08:27,600
being objective while doing so these

177
00:08:27,600 --> 00:08:31,080
biases lead to unfair preferences women

178
00:08:31,080 --> 00:08:33,120
earn less money for the exact same job

179
00:08:33,120 --> 00:08:35,550
than men do candidates who are

180
00:08:35,550 --> 00:08:37,230
interviewed on sunny days have a better

181
00:08:37,230 --> 00:08:39,270
chance of being hired then candidus

182
00:08:39,270 --> 00:08:40,860
candidates were interviewed on rainy

183
00:08:40,860 --> 00:08:44,400
days and tall men move into leadership

184
00:08:44,400 --> 00:08:46,710
positions more frequently than shorter

185
00:08:46,710 --> 00:08:50,660
mean we all have these biases

186
00:08:50,660 --> 00:08:52,740
understanding in which ways we're biased

187
00:08:52,740 --> 00:08:55,020
can help us understand the text adders

188
00:08:55,020 --> 00:08:57,630
of tech better and who are personally

189
00:08:57,630 --> 00:09:02,190
contributing to it an extremely

190
00:09:02,190 --> 00:09:04,080
important skill all of us need is

191
00:09:04,080 --> 00:09:06,390
empathy and many people have mentioned

192
00:09:06,390 --> 00:09:09,690
it over the past two days empathy is the

193
00:09:09,690 --> 00:09:11,970
ability to relate to another person as

194
00:09:11,970 --> 00:09:14,070
though they were us it's a powerful

195
00:09:14,070 --> 00:09:16,050
skill that enables us to think of the

196
00:09:16,050 --> 00:09:18,330
consequences of our words and actions on

197
00:09:18,330 --> 00:09:21,530
people and as humans working on software

198
00:09:21,530 --> 00:09:25,440
empathy is our responsibility

199
00:09:25,450 --> 00:09:27,520
and we also needed to understand the

200
00:09:27,520 --> 00:09:31,600
status of the tech industry as we've

201
00:09:31,600 --> 00:09:33,760
seen up to now understanding our

202
00:09:33,760 --> 00:09:35,950
privileges working through our biases

203
00:09:35,950 --> 00:09:37,780
and practicing empathy helps us

204
00:09:37,780 --> 00:09:46,730
understand the status of our system now

205
00:09:46,740 --> 00:09:49,690
let's use this knowledge to run a

206
00:09:49,690 --> 00:09:51,670
systems diagnosis of the tech industry

207
00:09:51,670 --> 00:09:55,780
and its parts the smallest entity in the

208
00:09:55,780 --> 00:09:58,330
system is one human and we've talked

209
00:09:58,330 --> 00:09:59,890
about ourselves already but our

210
00:09:59,890 --> 00:10:03,060
privileges biases and lack of empathy

211
00:10:03,060 --> 00:10:07,360
next up we have companies Conway's law

212
00:10:07,360 --> 00:10:09,850
says that systems which are designed in

213
00:10:09,850 --> 00:10:12,190
organizations are copies of the

214
00:10:12,190 --> 00:10:14,050
communication structures in these

215
00:10:14,050 --> 00:10:17,080
organizations this means that our

216
00:10:17,080 --> 00:10:18,670
company structures will directly

217
00:10:18,670 --> 00:10:20,860
influence the software we build whether

218
00:10:20,860 --> 00:10:24,880
we are aware of it or not so what do the

219
00:10:24,880 --> 00:10:26,560
structures in our organizations look

220
00:10:26,560 --> 00:10:30,190
like most European tech companies

221
00:10:30,190 --> 00:10:33,190
consist mostly of sis white mini and sis

222
00:10:33,190 --> 00:10:35,620
means that a person's experience of

223
00:10:35,620 --> 00:10:37,900
their own gender matches the sex they

224
00:10:37,900 --> 00:10:41,740
were assigned at Birth in Europe less

225
00:10:41,740 --> 00:10:43,690
than thirty percent of employees in tech

226
00:10:43,690 --> 00:10:46,060
are women in less than ten percent

227
00:10:46,060 --> 00:10:48,910
worker software developers so more than

228
00:10:48,910 --> 00:10:50,890
ninety percent of software developers in

229
00:10:50,890 --> 00:10:54,700
Europe arsis white min and we don't even

230
00:10:54,700 --> 00:10:56,640
have data on other aspects of humanity

231
00:10:56,640 --> 00:10:59,050
we don't even have numbers on how many

232
00:10:59,050 --> 00:11:01,750
people of color lesbian gay bisexual

233
00:11:01,750 --> 00:11:06,010
queer non-binary intersexual people or

234
00:11:06,010 --> 00:11:07,960
disabled people work in tech here and

235
00:11:07,960 --> 00:11:10,660
these are just examples of many groups

236
00:11:10,660 --> 00:11:11,860
that are currently hugely

237
00:11:11,860 --> 00:11:16,330
underrepresented in this industry what

238
00:11:16,330 --> 00:11:19,690
we have are homogeneous organizations we

239
00:11:19,690 --> 00:11:21,310
have a huge lack of diversity in

240
00:11:21,310 --> 00:11:24,300
ethnicities genders backgrounds

241
00:11:24,300 --> 00:11:27,610
education upbringing life experiences

242
00:11:27,610 --> 00:11:32,050
ages languages ideas disabilities and

243
00:11:32,050 --> 00:11:37,360
abilities and more but creativity is an

244
00:11:37,360 --> 00:11:39,270
important driver for good design

245
00:11:39,270 --> 00:11:41,970
nearing but our ability to be truly

246
00:11:41,970 --> 00:11:45,150
creative in our teams depends on exactly

247
00:11:45,150 --> 00:11:49,110
these factors this is one of the reasons

248
00:11:49,110 --> 00:11:51,110
why our lack of diversity is so harmful

249
00:11:51,110 --> 00:11:54,060
it even blocks our ability to be truly

250
00:11:54,060 --> 00:11:55,920
creative when we design and build

251
00:11:55,920 --> 00:12:00,060
software we all live in diverse

252
00:12:00,060 --> 00:12:02,550
societies but our organizations don't

253
00:12:02,550 --> 00:12:05,640
reflect that the products we build in

254
00:12:05,640 --> 00:12:07,650
these homogenous organizations right now

255
00:12:07,650 --> 00:12:09,300
just don't work for our diverse

256
00:12:09,300 --> 00:12:12,270
population which even makes many of our

257
00:12:12,270 --> 00:12:14,640
products completely unusable for so many

258
00:12:14,640 --> 00:12:21,300
people thing is even if tech companies

259
00:12:21,300 --> 00:12:24,030
manage to hire a diverse workforce most

260
00:12:24,030 --> 00:12:26,540
of the times they don't keep them

261
00:12:26,540 --> 00:12:29,220
forty-one percent of women leave careers

262
00:12:29,220 --> 00:12:31,590
in technology after ten years that's

263
00:12:31,590 --> 00:12:34,890
more than twice the number of min the

264
00:12:34,890 --> 00:12:36,660
reason for these bad retention rates is

265
00:12:36,660 --> 00:12:40,310
that our companies fail at inclusion

266
00:12:40,310 --> 00:12:43,230
inclusion means that all individuals in

267
00:12:43,230 --> 00:12:45,450
a group are being valued respected and

268
00:12:45,450 --> 00:12:47,880
supported and it means facilitating

269
00:12:47,880 --> 00:12:51,270
cultures practices and relationships to

270
00:12:51,270 --> 00:12:55,010
support a diverse workforce so right now

271
00:12:55,010 --> 00:12:57,060
it's hard getting members of

272
00:12:57,060 --> 00:12:58,710
underrepresented groups into tech

273
00:12:58,710 --> 00:13:00,180
because it's such a hostile environment

274
00:13:00,180 --> 00:13:03,390
and as soon as they are in we largely

275
00:13:03,390 --> 00:13:05,340
drive these skilled experts out again in

276
00:13:05,340 --> 00:13:07,590
a very short time because we don't

277
00:13:07,590 --> 00:13:11,250
really care about them this goes for our

278
00:13:11,250 --> 00:13:13,800
companies and also goes for our

279
00:13:13,800 --> 00:13:16,860
communities the lack of diversity and

280
00:13:16,860 --> 00:13:18,930
inclusion in our communities is even

281
00:13:18,930 --> 00:13:22,560
worse than an average companies 85 to 95

282
00:13:22,560 --> 00:13:24,870
percent of all contributors to free

283
00:13:24,870 --> 00:13:26,790
labor and open source software projects

284
00:13:26,790 --> 00:13:29,760
are min they're also mostly white and

285
00:13:29,760 --> 00:13:31,820
most of them are software developers

286
00:13:31,820 --> 00:13:34,650
very few people with other professions

287
00:13:34,650 --> 00:13:36,210
and expertise contribute to these

288
00:13:36,210 --> 00:13:40,410
projects and since these contributions

289
00:13:40,410 --> 00:13:42,630
are mostly expected to be done in

290
00:13:42,630 --> 00:13:45,240
people's airtime everyone who has other

291
00:13:45,240 --> 00:13:47,700
obligations by caring for children is

292
00:13:47,700 --> 00:13:51,240
excluded and most projects are neither

293
00:13:51,240 --> 00:13:52,680
accessible no

294
00:13:52,680 --> 00:13:56,700
coming for beginners another big issue

295
00:13:56,700 --> 00:14:00,450
in communities is harassment there are

296
00:14:00,450 --> 00:14:02,399
hundreds of reports of harassment

297
00:14:02,399 --> 00:14:05,960
misogyny transphobia homophobia racism

298
00:14:05,960 --> 00:14:09,720
threats sexism and abuse that people

299
00:14:09,720 --> 00:14:11,610
have experienced in floss projects in

300
00:14:11,610 --> 00:14:15,990
the communities and at events our tech

301
00:14:15,990 --> 00:14:18,510
communities are completely unsafe space

302
00:14:18,510 --> 00:14:20,310
for underrepresented groups in tech

303
00:14:20,310 --> 00:14:25,130
right now and on top of all of that our

304
00:14:25,130 --> 00:14:27,779
society's influence as personally and

305
00:14:27,779 --> 00:14:31,230
the tech industry we live in patriarchy

306
00:14:31,230 --> 00:14:33,330
a social construct that is oppressive on

307
00:14:33,330 --> 00:14:36,839
humans our societies are also capitalist

308
00:14:36,839 --> 00:14:38,610
systems that have led to wealth and

309
00:14:38,610 --> 00:14:41,700
income inequalities and we live in

310
00:14:41,700 --> 00:14:43,860
racist societies that Center upon the

311
00:14:43,860 --> 00:14:45,540
false belief that white people are

312
00:14:45,540 --> 00:14:47,580
superior to add people of other racial

313
00:14:47,580 --> 00:14:51,390
backgrounds together patriarchy

314
00:14:51,390 --> 00:14:53,670
capitalism and racism have led to

315
00:14:53,670 --> 00:14:57,209
oppressive systems these systems are big

316
00:14:57,209 --> 00:15:00,209
influencers on ourselves our beliefs and

317
00:15:00,209 --> 00:15:05,880
our work in tech we've now looked at all

318
00:15:05,880 --> 00:15:08,760
these parts isolated from each other but

319
00:15:08,760 --> 00:15:10,380
a system is more than just the sum of

320
00:15:10,380 --> 00:15:12,600
its parts but I mean your developers you

321
00:15:12,600 --> 00:15:15,510
know that all parts that influence the

322
00:15:15,510 --> 00:15:17,390
tech industry are intertwined and

323
00:15:17,390 --> 00:15:19,410
accumulate characteristics of other

324
00:15:19,410 --> 00:15:21,690
poets which has made many of them even

325
00:15:21,690 --> 00:15:25,770
worse as a system the tech industry is a

326
00:15:25,770 --> 00:15:29,040
place full of privilege biases that legs

327
00:15:29,040 --> 00:15:32,790
empathy diversity and inclusion is full

328
00:15:32,790 --> 00:15:34,770
of harassment and is shaped by

329
00:15:34,770 --> 00:15:41,339
patriarchy capitalism and racism so how

330
00:15:41,339 --> 00:15:46,580
do we handle this

331
00:15:46,590 --> 00:15:49,300
when we want to understand and debug an

332
00:15:49,300 --> 00:15:51,490
unfamiliar system it helps to play

333
00:15:51,490 --> 00:15:53,800
around with variables and see how they

334
00:15:53,800 --> 00:15:56,830
affect the output one of the outputs of

335
00:15:56,830 --> 00:15:58,960
the tech industry as a system is the

336
00:15:58,960 --> 00:16:01,450
software we build so let's see what the

337
00:16:01,450 --> 00:16:05,470
software looks like software can have

338
00:16:05,470 --> 00:16:07,410
positive impact on people's lives

339
00:16:07,410 --> 00:16:09,850
software can help satisfy our basic

340
00:16:09,850 --> 00:16:12,250
human needs for safety belonging and

341
00:16:12,250 --> 00:16:15,550
self-actualization for example by

342
00:16:15,550 --> 00:16:17,350
helping us communicate with others for

343
00:16:17,350 --> 00:16:20,260
applications or by making information

344
00:16:20,260 --> 00:16:22,210
and communication tools accessible for

345
00:16:22,210 --> 00:16:25,750
people through screen readers software

346
00:16:25,750 --> 00:16:28,080
like the application be my eyes also

347
00:16:28,080 --> 00:16:30,780
helps people with visual impairments

348
00:16:30,780 --> 00:16:34,480
catalpa certain tasks and some software

349
00:16:34,480 --> 00:16:36,100
can also help people with mental or

350
00:16:36,100 --> 00:16:38,170
physical illnesses improve their

351
00:16:38,170 --> 00:16:39,760
situation through online self-help

352
00:16:39,760 --> 00:16:44,560
programs but software also causes lots

353
00:16:44,560 --> 00:16:46,660
of harm and it can even endanger

354
00:16:46,660 --> 00:16:50,430
people's lives our software is sexist

355
00:16:50,430 --> 00:16:53,050
when virtual assistants like Apple's

356
00:16:53,050 --> 00:16:55,990
Siri Google now or Microsoft Cortana are

357
00:16:55,990 --> 00:16:58,780
told that a user had a heart attack they

358
00:16:58,780 --> 00:17:01,780
redirect them to help but none of these

359
00:17:01,780 --> 00:17:03,400
assistance has been programmed to

360
00:17:03,400 --> 00:17:05,080
recognize what it means when a user

361
00:17:05,080 --> 00:17:07,600
sense that they're being abused which

362
00:17:07,600 --> 00:17:11,560
affects one in three women worldwide our

363
00:17:11,560 --> 00:17:13,960
software is racist face recognition

364
00:17:13,960 --> 00:17:16,690
algorithms in camera sensors keep on

365
00:17:16,690 --> 00:17:18,790
failing to recognize the faces of people

366
00:17:18,790 --> 00:17:23,080
of color correctly our software worsens

367
00:17:23,080 --> 00:17:26,530
issues in societies vacation rental and

368
00:17:26,530 --> 00:17:28,720
accommodation sharing sites like Airbnb

369
00:17:28,720 --> 00:17:30,670
are contributing to a growing housing

370
00:17:30,670 --> 00:17:33,250
crisis in cities like New York London

371
00:17:33,250 --> 00:17:36,340
and Berlin by removing rental stock from

372
00:17:36,340 --> 00:17:40,480
already tight housing markets our

373
00:17:40,480 --> 00:17:42,040
software also exposes people to

374
00:17:42,040 --> 00:17:44,710
harassment and abuse major tech

375
00:17:44,710 --> 00:17:46,600
companies like Twitter and Facebook have

376
00:17:46,600 --> 00:17:48,130
been failing to address the harassment

377
00:17:48,130 --> 00:17:50,130
issues on their platforms for years

378
00:17:50,130 --> 00:17:52,690
which has made many of these important

379
00:17:52,690 --> 00:17:54,490
technologies completely unusable for

380
00:17:54,490 --> 00:17:57,020
many people

381
00:17:57,020 --> 00:18:00,890
our software also puts people at risk on

382
00:18:00,890 --> 00:18:03,050
a regular basis we expose users too

383
00:18:03,050 --> 00:18:04,640
dangerous through security flaws and

384
00:18:04,640 --> 00:18:06,620
we've built tools that have enabled

385
00:18:06,620 --> 00:18:09,650
personal data to be exposed online which

386
00:18:09,650 --> 00:18:11,210
has put people's personal safety at

387
00:18:11,210 --> 00:18:14,600
stake and car dispatch startups like

388
00:18:14,600 --> 00:18:17,060
uber keep not doing anything to ensure

389
00:18:17,060 --> 00:18:19,430
passenger safety in the cars despite

390
00:18:19,430 --> 00:18:21,380
several cases of assault against

391
00:18:21,380 --> 00:18:25,040
passengers over the past years and our

392
00:18:25,040 --> 00:18:27,700
software is actively making people sick

393
00:18:27,700 --> 00:18:30,440
the animations in our operating systems

394
00:18:30,440 --> 00:18:32,570
apps and websites can trigger panic

395
00:18:32,570 --> 00:18:35,690
attacks to people and software has

396
00:18:35,690 --> 00:18:37,970
helped cars emit more pollution on the

397
00:18:37,970 --> 00:18:40,700
road than in regulatory tests pollution

398
00:18:40,700 --> 00:18:45,710
that is making people sick this is the

399
00:18:45,710 --> 00:18:47,800
output of the tech industry as a system

400
00:18:47,800 --> 00:18:51,080
we are part of the system and this is

401
00:18:51,080 --> 00:18:55,970
what all worked us to people and even if

402
00:18:55,970 --> 00:18:57,530
the technology you're working on right

403
00:18:57,530 --> 00:18:59,900
now may feel like a good project for you

404
00:18:59,900 --> 00:19:02,050
and you feel like it doesn't do any harm

405
00:19:02,050 --> 00:19:06,020
you need to care about that as well what

406
00:19:06,020 --> 00:19:07,850
we need to understand is that as people

407
00:19:07,850 --> 00:19:09,590
in tech we have a collective

408
00:19:09,590 --> 00:19:12,530
responsibility we keep pretending that

409
00:19:12,530 --> 00:19:15,290
the technology we build is neutral we

410
00:19:15,290 --> 00:19:17,120
still believe that we can be a political

411
00:19:17,120 --> 00:19:20,090
as people in check we keep pretending

412
00:19:20,090 --> 00:19:22,880
that our algorithms on you troll and we

413
00:19:22,880 --> 00:19:24,680
don't care about the ethical aspects of

414
00:19:24,680 --> 00:19:27,410
our work and most of us are in a

415
00:19:27,410 --> 00:19:30,160
position where we don't have to care but

416
00:19:30,160 --> 00:19:33,100
it's our responsibility to understand

417
00:19:33,100 --> 00:19:36,920
technology is not neutral or code is not

418
00:19:36,920 --> 00:19:40,850
neutral our work is political and our

419
00:19:40,850 --> 00:19:44,800
work has consequences on actual lives

420
00:19:44,800 --> 00:19:47,510
what we have right now is a completely

421
00:19:47,510 --> 00:19:51,380
broken system right now this industry is

422
00:19:51,380 --> 00:19:53,840
system built on privilege by privileged

423
00:19:53,840 --> 00:19:57,290
people for privileged people this system

424
00:19:57,290 --> 00:19:59,120
works for sis white men inside and

425
00:19:59,120 --> 00:20:01,250
outside of this industry but for almost

426
00:20:01,250 --> 00:20:05,810
no one else right now we're failing many

427
00:20:05,810 --> 00:20:07,850
underrepresented people inside of tech

428
00:20:07,850 --> 00:20:10,850
and the system come generate meaningful

429
00:20:10,850 --> 00:20:13,340
put we're failing to build real

430
00:20:13,340 --> 00:20:15,620
solutions for our software User's actual

431
00:20:15,620 --> 00:20:19,880
problems this is why we need to change

432
00:20:19,880 --> 00:20:22,490
this industry's inner mechanisms and its

433
00:20:22,490 --> 00:20:25,730
output to something meaningful we need

434
00:20:25,730 --> 00:20:33,560
to debug it but who is we as we've seen

435
00:20:33,560 --> 00:20:35,870
one reason for this industry's problem

436
00:20:35,870 --> 00:20:37,820
exists between keyboard and chair and

437
00:20:37,820 --> 00:20:41,360
this time it's not our users this time

438
00:20:41,360 --> 00:20:44,690
it's us as humans we are contributing to

439
00:20:44,690 --> 00:20:48,020
the status of this tech industry but

440
00:20:48,020 --> 00:20:50,150
we're also part of the solution for

441
00:20:50,150 --> 00:20:54,920
these problems here's wine if you look

442
00:20:54,920 --> 00:20:56,650
closely at this Venn diagram again

443
00:20:56,650 --> 00:20:59,300
you'll see that there's one spot where

444
00:20:59,300 --> 00:21:02,780
all pods overlap this one's bought with

445
00:21:02,780 --> 00:21:05,330
one person who is in tech as part of a

446
00:21:05,330 --> 00:21:08,900
team or community or by themselves this

447
00:21:08,900 --> 00:21:13,250
person is you this place right where you

448
00:21:13,250 --> 00:21:15,530
are this is where debugging the tech

449
00:21:15,530 --> 00:21:18,860
industry happens every one of us has

450
00:21:18,860 --> 00:21:22,010
this area where we can fix things every

451
00:21:22,010 --> 00:21:23,710
one of us is part of something bigger

452
00:21:23,710 --> 00:21:26,450
we're working at companies some of us

453
00:21:26,450 --> 00:21:28,490
are part of communities we know other

454
00:21:28,490 --> 00:21:31,640
people in this industry whatever you do

455
00:21:31,640 --> 00:21:37,010
in tech you have such an area the sizes

456
00:21:37,010 --> 00:21:39,560
of our areas defer the more privilege

457
00:21:39,560 --> 00:21:41,930
and power we have the bigger our area is

458
00:21:41,930 --> 00:21:44,030
in which we can make this change happen

459
00:21:44,030 --> 00:21:46,940
and the more it is our responsibility to

460
00:21:46,940 --> 00:21:51,680
do just that but what we experience

461
00:21:51,680 --> 00:21:53,930
right now as an industry is another case

462
00:21:53,930 --> 00:21:56,600
of it works on my machine so your

463
00:21:56,600 --> 00:22:00,470
problem isn't real right now many areas

464
00:22:00,470 --> 00:22:03,380
for change go unused because many of us

465
00:22:03,380 --> 00:22:05,180
don't know or don't care about the

466
00:22:05,180 --> 00:22:07,880
brokenness of the system because the

467
00:22:07,880 --> 00:22:10,280
system works for us and we benefit from

468
00:22:10,280 --> 00:22:14,930
the status quo right now most of the

469
00:22:14,930 --> 00:22:16,370
people who are already working on

470
00:22:16,370 --> 00:22:18,740
debugging this industry are members of

471
00:22:18,740 --> 00:22:21,650
underrepresented groups in tech that's a

472
00:22:21,650 --> 00:22:23,210
bit like telling the QA team in your

473
00:22:23,210 --> 00:22:24,260
company

474
00:22:24,260 --> 00:22:25,760
that they have to fix the bugs they find

475
00:22:25,760 --> 00:22:27,500
themselves because you have better

476
00:22:27,500 --> 00:22:31,700
things to do but it's the responsibility

477
00:22:31,700 --> 00:22:34,640
of all of us to help debug this industry

478
00:22:34,640 --> 00:22:37,460
it's my responsibility and it's your

479
00:22:37,460 --> 00:22:40,490
responsibility change thoughts in this

480
00:22:40,490 --> 00:22:43,880
area change starts with me and change

481
00:22:43,880 --> 00:22:53,700
thoughts with you

482
00:22:53,710 --> 00:22:56,539
over the next minutes I'll show you 11

483
00:22:56,539 --> 00:22:58,460
debugging tools and techniques that you

484
00:22:58,460 --> 00:23:00,320
can use to support the debugging process

485
00:23:00,320 --> 00:23:05,179
in the tech industry debugging starts

486
00:23:05,179 --> 00:23:07,460
with ourselves and the basis for all

487
00:23:07,460 --> 00:23:11,720
debugging work step 1 learning we need

488
00:23:11,720 --> 00:23:13,640
to educate ourselves and learn about

489
00:23:13,640 --> 00:23:15,700
systemic issues and depression in tech

490
00:23:15,700 --> 00:23:18,020
there are many great resources online

491
00:23:18,020 --> 00:23:19,880
that can help you understand to this

492
00:23:19,880 --> 00:23:22,429
debugging process it's not the

493
00:23:22,429 --> 00:23:24,760
responsibility of others to educate us

494
00:23:24,760 --> 00:23:26,840
learning about debugging the tech

495
00:23:26,840 --> 00:23:31,260
industry is our personal responsibility

496
00:23:31,270 --> 00:23:35,360
we need to practice empathy empathy and

497
00:23:35,360 --> 00:23:37,250
actually caring about other people is a

498
00:23:37,250 --> 00:23:40,730
choice and a skill we can improve we

499
00:23:40,730 --> 00:23:42,409
need to understand that not everyone is

500
00:23:42,409 --> 00:23:44,870
like us and understand that the life

501
00:23:44,870 --> 00:23:46,700
experiences of people who are different

502
00:23:46,700 --> 00:23:50,860
from us are just as valid as our own

503
00:23:50,860 --> 00:23:53,360
empathy also means understanding that

504
00:23:53,360 --> 00:23:54,679
our software is a personal experience

505
00:23:54,679 --> 00:23:58,190
for our users all expressions and

506
00:23:58,190 --> 00:23:59,990
interactions we build in our software

507
00:23:59,990 --> 00:24:02,450
are choices that affect the way our

508
00:24:02,450 --> 00:24:05,809
users feel we can't be good designers

509
00:24:05,809 --> 00:24:07,640
and software developers if we don't

510
00:24:07,640 --> 00:24:13,309
actively work on our empathy step three

511
00:24:13,309 --> 00:24:15,169
is to understand our position in the

512
00:24:15,169 --> 00:24:18,730
world as people in tech we have power

513
00:24:18,730 --> 00:24:21,500
the tech industry has turned this notion

514
00:24:21,500 --> 00:24:23,899
of power into a culture of celebrating

515
00:24:23,899 --> 00:24:26,330
so called coder ninjas rock stars and

516
00:24:26,330 --> 00:24:29,960
unicorns I hate to break the news to you

517
00:24:29,960 --> 00:24:33,440
but we're not none of us are ninjas rock

518
00:24:33,440 --> 00:24:37,159
stars unicorns all of us are humans and

519
00:24:37,159 --> 00:24:40,130
all of us fail this should fill us with

520
00:24:40,130 --> 00:24:41,899
humbleness and awareness of our own

521
00:24:41,899 --> 00:24:45,289
limitations and should have us work on

522
00:24:45,289 --> 00:24:50,899
all humility step four is understanding

523
00:24:50,899 --> 00:24:53,840
our privileges we need to understand how

524
00:24:53,840 --> 00:24:55,460
our position in the world has been

525
00:24:55,460 --> 00:24:57,320
shaped in terms of privilege and class

526
00:24:57,320 --> 00:25:00,470
and race and in which ways we benefit

527
00:25:00,470 --> 00:25:04,010
from the existing systems around us this

528
00:25:04,010 --> 00:25:05,750
can be a chance for us to learn which

529
00:25:05,750 --> 00:25:06,890
mistakes we've made in the

530
00:25:06,890 --> 00:25:08,720
costs and how we can prevent these

531
00:25:08,720 --> 00:25:11,990
mistakes in the future we also need to

532
00:25:11,990 --> 00:25:14,270
use a privilege for good work on

533
00:25:14,270 --> 00:25:16,970
ourselves and set positive examples for

534
00:25:16,970 --> 00:25:22,340
our peers we need to work through our

535
00:25:22,340 --> 00:25:25,490
biases we need to be conscious about our

536
00:25:25,490 --> 00:25:28,520
past present and huge yourself and be

537
00:25:28,520 --> 00:25:30,110
deliberate about our actions and

538
00:25:30,110 --> 00:25:33,560
interactions with people practically

539
00:25:33,560 --> 00:25:35,720
this also means being deliberate about

540
00:25:35,720 --> 00:25:38,120
the software we build and making sure

541
00:25:38,120 --> 00:25:40,310
that the software is not only appealing

542
00:25:40,310 --> 00:25:43,940
to people who are like us every app icon

543
00:25:43,940 --> 00:25:47,950
matters and every image matters

544
00:25:47,950 --> 00:25:50,450
companies and communities need to put

545
00:25:50,450 --> 00:25:52,640
policies in place to work through biases

546
00:25:52,640 --> 00:25:55,190
and avoid basing our work on assumptions

547
00:25:55,190 --> 00:25:57,740
about the people we work with and the

548
00:25:57,740 --> 00:26:02,690
people who use our software we need to

549
00:26:02,690 --> 00:26:04,970
listen to what underrepresented people

550
00:26:04,970 --> 00:26:07,430
in tech have to say follow them on

551
00:26:07,430 --> 00:26:08,990
Twitter read their blogs and

552
00:26:08,990 --> 00:26:11,390
publications and look outside of your

553
00:26:11,390 --> 00:26:14,450
existing networks we need to actively

554
00:26:14,450 --> 00:26:16,370
look for the voices we haven't heard

555
00:26:16,370 --> 00:26:20,750
before and we need to amplify these

556
00:26:20,750 --> 00:26:23,600
voices the voices of people whose

557
00:26:23,600 --> 00:26:26,120
stories often remain unheard to help

558
00:26:26,120 --> 00:26:30,020
them reach border audiences amplifying

559
00:26:30,020 --> 00:26:32,470
others voices also means speaking less

560
00:26:32,470 --> 00:26:34,730
there is no need to comment on

561
00:26:34,730 --> 00:26:36,470
everything that underrepresented people

562
00:26:36,470 --> 00:26:43,310
in tech are sharing we need to listen we

563
00:26:43,310 --> 00:26:46,490
also need to work on diversity first and

564
00:26:46,490 --> 00:26:48,800
foremost diversity is our moral

565
00:26:48,800 --> 00:26:51,830
obligation it's the only way to do

566
00:26:51,830 --> 00:26:54,410
software development right the only way

567
00:26:54,410 --> 00:26:56,900
to do right by the people in tech and by

568
00:26:56,900 --> 00:27:01,070
our software uses diversity also enables

569
00:27:01,070 --> 00:27:02,600
us to build products that are actually

570
00:27:02,600 --> 00:27:06,590
useful for people it also allows us to

571
00:27:06,590 --> 00:27:08,480
solve complex complex problems better

572
00:27:08,480 --> 00:27:11,810
and faster be more creative make better

573
00:27:11,810 --> 00:27:15,460
decisions and generate more innovation

574
00:27:15,460 --> 00:27:17,810
companies with diverse leadership have

575
00:27:17,810 --> 00:27:19,450
better sales revenue

576
00:27:19,450 --> 00:27:22,179
customers higher market share and higher

577
00:27:22,179 --> 00:27:25,840
profits than their competitors diversity

578
00:27:25,840 --> 00:27:27,389
also helps companies with hiring

579
00:27:27,389 --> 00:27:30,220
learning leads to better software and

580
00:27:30,220 --> 00:27:34,870
happier customers and still diversity is

581
00:27:34,870 --> 00:27:37,690
our moral obligation it's the only way

582
00:27:37,690 --> 00:27:40,090
to do software right there is no

583
00:27:40,090 --> 00:27:44,769
alternative and there's no alternative

584
00:27:44,769 --> 00:27:48,039
to inclusion either we need to work on

585
00:27:48,039 --> 00:27:49,450
inclusion in our workplaces and

586
00:27:49,450 --> 00:27:51,730
communities we need to foster

587
00:27:51,730 --> 00:27:53,740
environments in which diverse groups of

588
00:27:53,740 --> 00:27:56,320
people can thrive it's our

589
00:27:56,320 --> 00:27:58,480
responsibility as privileged people in

590
00:27:58,480 --> 00:28:01,450
tech to facilitate spaces in which under

591
00:28:01,450 --> 00:28:05,620
represented people want to be we also

592
00:28:05,620 --> 00:28:07,450
need policies for equality and social

593
00:28:07,450 --> 00:28:09,250
conduct and we need to communicate

594
00:28:09,250 --> 00:28:12,909
openly about our values we need to do

595
00:28:12,909 --> 00:28:15,460
everything to make spaces welcoming and

596
00:28:15,460 --> 00:28:19,720
safe for everyone and our efforts that

597
00:28:19,720 --> 00:28:21,880
going to inclusion show how much we

598
00:28:21,880 --> 00:28:27,309
actually care about diversity we also

599
00:28:27,309 --> 00:28:29,679
need to give give our knowledge

600
00:28:29,679 --> 00:28:32,500
technical skills time and money to

601
00:28:32,500 --> 00:28:34,059
groups or individuals in this industry

602
00:28:34,059 --> 00:28:37,360
who I need of support we can become

603
00:28:37,360 --> 00:28:40,149
coaches at meetups or become mentors we

604
00:28:40,149 --> 00:28:42,070
can donate money to organizations like

605
00:28:42,070 --> 00:28:44,919
trans heck women who code rails girls

606
00:28:44,919 --> 00:28:47,830
black girls code or Model View culture

607
00:28:47,830 --> 00:28:50,260
that do important work to debug this

608
00:28:50,260 --> 00:28:55,929
industry and each of us needs to work on

609
00:28:55,929 --> 00:28:58,000
being an ally to underrepresented groups

610
00:28:58,000 --> 00:29:01,450
in tech being an ally means supporting

611
00:29:01,450 --> 00:29:04,090
these people by following the tender for

612
00:29:04,090 --> 00:29:07,649
mentioned steps educating ourselves

613
00:29:07,649 --> 00:29:10,360
practicing empathy working on our

614
00:29:10,360 --> 00:29:12,970
humility working through our privileges

615
00:29:12,970 --> 00:29:16,450
and biases listening amplifying their

616
00:29:16,450 --> 00:29:18,880
voices working on diversity and

617
00:29:18,880 --> 00:29:23,590
inclusion and by giving and by

618
00:29:23,590 --> 00:29:25,570
continuing to learn and work on

619
00:29:25,570 --> 00:29:29,010
ourselves being an ally is ongoing work

620
00:29:29,010 --> 00:29:32,320
but as allies we can support the people

621
00:29:32,320 --> 00:29:32,890
who are

622
00:29:32,890 --> 00:29:36,820
fighting to debug this industry this is

623
00:29:36,820 --> 00:29:40,090
what we need to do and we need to do it

624
00:29:40,090 --> 00:29:46,990
now the Cody riding today will soon be

625
00:29:46,990 --> 00:29:49,540
obsolete the software we're building

626
00:29:49,540 --> 00:29:51,940
today will already be outdated in a few

627
00:29:51,940 --> 00:29:54,820
weeks the bugs we're producing today

628
00:29:54,820 --> 00:29:57,820
will be fixed and the features we build

629
00:29:57,820 --> 00:30:01,960
will change again what we have now is a

630
00:30:01,960 --> 00:30:03,430
chance to build something bigger

631
00:30:03,430 --> 00:30:07,690
something that lasts what we have now is

632
00:30:07,690 --> 00:30:09,550
the chance to debug the tech industry

633
00:30:09,550 --> 00:30:13,000
and make it a better system that is

634
00:30:13,000 --> 00:30:17,320
about justice and equality this

635
00:30:17,320 --> 00:30:19,630
debugging is already happening and it

636
00:30:19,630 --> 00:30:21,940
can't be stopped it is the biggest

637
00:30:21,940 --> 00:30:24,220
challenge and the biggest task we have

638
00:30:24,220 --> 00:30:27,640
as people in tech right now now is the

639
00:30:27,640 --> 00:30:30,160
time for us to debug this industry and

640
00:30:30,160 --> 00:30:33,060
make technology a place for everyone

641
00:30:33,060 --> 00:30:35,680
this is our chance to build our own

642
00:30:35,680 --> 00:30:40,320
legacy this change that's with all of us

643
00:30:40,320 --> 00:30:46,490
it starts with me it starts with you

644
00:30:46,500 --> 00:30:49,540
problem exists between keyboard and

645
00:30:49,540 --> 00:30:52,690
chair solution exists between keyboard

646
00:30:52,690 --> 00:30:57,400
and chair and the question is now that

647
00:30:57,400 --> 00:31:00,970
we are debugging the tech industry will

648
00:31:00,970 --> 00:31:14,190
you join us thank

