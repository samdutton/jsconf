1
00:00:09,800 --> 00:00:10,720
Hello, Berlin?

2
00:00:10,720 --> 00:00:11,820
How is everyone?

3
00:00:11,820 --> 00:00:15,340
It's a pleasure to be here on the stage.

4
00:00:15,340 --> 00:00:19,180
I've been coming to JSConf for years and so
privileged, and it's a pleasure to be back

5
00:00:19,180 --> 00:00:22,340
on the stage and give back to the community.

6
00:00:22,340 --> 00:00:27,769
Sad that I'm not here with my family because
coming back to JSConf every time feels like

7
00:00:27,769 --> 00:00:32,660
coming back to see my family, and I think
that's because of the amazing community we

8
00:00:32,660 --> 00:00:34,350
have built here, and the organisers built.

9
00:00:34,350 --> 00:00:40,430
A massive round of applause for the organisers
for allows us all to be here to do this.

10
00:00:40,430 --> 00:00:41,430
[Applause].

11
00:00:41,430 --> 00:00:42,480
My name is Patrick Hamann.

12
00:00:42,480 --> 00:00:51,790
I work for the Edge Cloud provider Fastly
where we specialise in real time content delivery

13
00:00:51,790 --> 00:00:53,070
for the world's leading brands.

14
00:00:53,070 --> 00:00:58,740
I there get a lot of time to sit, think about,
and research how we can make our customers'

15
00:00:58,740 --> 00:01:04,330
websites load as fast as possible, and that's
what I'm here to talk to you about today.

16
00:01:04,330 --> 00:01:10,369
Why am I actually here and what does the clickbait-y
Buzzfeed headline of to push or not to push

17
00:01:10,369 --> 00:01:11,450
mean?

18
00:01:11,450 --> 00:01:16,350
I'm not going to quote Hamlet to you now.

19
00:01:16,350 --> 00:01:19,130
The reason I'm here is because of this.

20
00:01:19,130 --> 00:01:20,930
I hear this all the tile.

21
00:01:20,930 --> 00:01:26,759
I've sat on stages and said exactly this that
HTTP/2 is going to solve this problem, literally

22
00:01:26,759 --> 00:01:27,759
everyone.

23
00:01:27,759 --> 00:01:30,340
The problem is that it's not.

24
00:01:30,340 --> 00:01:35,770
Resource diabetic loading in the browser is
very, very hard.

25
00:01:35,770 --> 00:01:39,369
After this talk, hopefully, you will have
a better understanding of why it's hard and

26
00:01:39,369 --> 00:01:45,149
the techniques we have today to overcome the
problems it produces.

27
00:01:45,149 --> 00:01:46,990
Why is it hard?

28
00:01:46,990 --> 00:01:52,340
Performance is coupled to latency.

29
00:01:52,340 --> 00:01:54,900
Connection s costs are high.

30
00:01:54,900 --> 00:02:01,539
TCP's congestion control algorithm is there
for very good reasons but penalises us at

31
00:02:01,539 --> 00:02:04,189
the beginning after connection when it's most
important.

32
00:02:04,189 --> 00:02:07,409
Our critical resources can be hidden to the
browsers.

33
00:02:07,409 --> 00:02:11,599
Browsers are extremely powerful things and
have speculative parses but they simply are

34
00:02:11,599 --> 00:02:17,430
not magic enough to know the resources that
you as an application developer want to load.

35
00:02:17,430 --> 00:02:22,069
Because of that, bandwidth is often under
utilised, leaving idle connections open where

36
00:02:22,069 --> 00:02:27,099
we could be sending resources but we can't
do that yet because of the way that browsers

37
00:02:27,099 --> 00:02:29,150
and servers interact with each other.

38
00:02:29,150 --> 00:02:36,900
Finally, once we do get it down script, it
is extremely to expensive to parse and execute

39
00:02:36,900 --> 00:02:40,790
and we waste idle time on the network again
because of that.

40
00:02:40,790 --> 00:02:44,180
How can we load our resources mostly?

41
00:02:44,180 --> 00:02:48,599
What patterns and techniques can we use today
and what is coming up in the future to enable

42
00:02:48,599 --> 00:02:54,459
us to do in the most efficient and speedy
way?

43
00:02:54,459 --> 00:02:58,000
Think about the product or website that you're
designing today.

44
00:02:58,000 --> 00:03:02,840
If you are only allowed to send three resources
down the wire, would what they be?

45
00:03:02,840 --> 00:03:04,299
Is it your fonts?

46
00:03:04,299 --> 00:03:10,019
The lazy-loaded related comments on the bottom
of this ft.com home page or adverts?

47
00:03:10,019 --> 00:03:11,739
I don't think so.

48
00:03:11,739 --> 00:03:16,019
What did the user come here for?

49
00:03:16,019 --> 00:03:22,909
Bench wars from Calibre, who is sitting with
us here today, when we talk about loading,

50
00:03:22,909 --> 00:03:28,049
we talk about a critical request path, and
he defines a critical request as one that

51
00:03:28,049 --> 00:03:33,040
contains an asset that is essential to the
content to the user's view port.

52
00:03:33,040 --> 00:03:36,790
What are your critical resources.

53
00:03:36,790 --> 00:03:41,049
I want you really to take this away from my
talk as I want you to think about what are

54
00:03:41,049 --> 00:03:45,470
the two or three things you need to send down
as soon as possible so that browser can get

55
00:03:45,470 --> 00:03:49,090
on with rendering and creating a good user
experience for your users.

56
00:03:49,090 --> 00:03:52,250
A critical CSS for your initial route?

57
00:03:52,250 --> 00:03:54,609
Font or hero images.

58
00:03:54,609 --> 00:03:57,599
One we don't discuss enough is the application
bootstrap data.

59
00:03:57,599 --> 00:04:03,859
A lot of client-side rendered applications
probably make a JSON request that is hidden

60
00:04:03,859 --> 00:04:04,859
to the browser.

61
00:04:04,859 --> 00:04:08,879
It is known as a hidden sub resource and the
browser doesn't know about it upfront.

62
00:04:08,879 --> 00:04:13,319
We need to be able to tell the browser what
the resource is specifically to our need,

63
00:04:13,319 --> 00:04:17,259
and to create the delightful user experiences.

64
00:04:17,259 --> 00:04:21,989
Once you've determined what your critical
requests are, you need to think about how

65
00:04:21,989 --> 00:04:24,150
they contribute to the user's experience.

66
00:04:24,150 --> 00:04:27,180
After all, performance is a user experience
problem.

67
00:04:27,180 --> 00:04:30,260
What resources do you need to get a first
meaningful paint?

68
00:04:30,260 --> 00:04:34,710
What resources do you have to deliver so that
users can start interacting with your website

69
00:04:34,710 --> 00:04:36,540
as fast as possible.

70
00:04:36,540 --> 00:04:41,280
It's this section here we will focus on today,
this initial loading experience, and how we

71
00:04:41,280 --> 00:04:46,970
can tell the browser, make, allow the browser
to make informed decisions about what it load

72
00:04:46,970 --> 00:04:49,990
so we can have delightful users' experience.

73
00:04:49,990 --> 00:04:54,540
So I summarise a good loading strategy as
one that prioritises above the file rendering,

74
00:04:54,540 --> 00:04:55,880
prioritising interactivity.

75
00:04:55,880 --> 00:05:01,410
It is easy to use because some we look at
today aren't necessarily, and innovate importantly,

76
00:05:01,410 --> 00:05:02,410
measurable.

77
00:05:02,410 --> 00:05:08,130
The first solution to overcoming a performance
problem is to measure your current performance,

78
00:05:08,130 --> 00:05:11,340
if then optimise for it.

79
00:05:11,340 --> 00:05:14,150
So the first technique that we are doing,
now that we've identified what we should be

80
00:05:14,150 --> 00:05:16,919
loading, let's see how we can do this efficiently.

81
00:05:16,919 --> 00:05:19,800
The first I'm going to discuss is the preload
API.

82
00:05:19,800 --> 00:05:24,030
What if we could tell the browser ahead of
time what the critical resources are required

83
00:05:24,030 --> 00:05:25,069
for this?

84
00:05:25,069 --> 00:05:31,940
The problem is earlier on we identified fonts,
and application bootstrap data, as being critical

85
00:05:31,940 --> 00:05:32,940
resources.

86
00:05:32,940 --> 00:05:34,270
However, they're hidden from the browser.

87
00:05:34,270 --> 00:05:35,270
Why is this?

88
00:05:35,270 --> 00:05:40,690
First, you make a get request for the home
page been we wait for the response of that.

89
00:05:40,690 --> 00:05:45,460
HTML can be parsed I can be mentally so, as
the bytes come down the wire, the browser

90
00:05:45,460 --> 00:05:50,180
can start constructing the DOM without waiting
for the HTML file to be delivered.

91
00:05:50,180 --> 00:05:57,570
They have speculative parses that goes ahead
while it's constructing the DOM, finds the

92
00:05:57,570 --> 00:06:02,830
file sheets and script tags references in
the page and initiates fetches for them ahead

93
00:06:02,830 --> 00:06:04,180
of time.

94
00:06:04,180 --> 00:06:08,639
But with CSS, unfortunately, it is render-blocking
and can't be parsed incrementally.

95
00:06:08,639 --> 00:06:12,669
We have to wait for all the bytes to come
down first because if we didn't, there would

96
00:06:12,669 --> 00:06:16,520
be lots of painting flashing on the screen
because of the way the cascade works.

97
00:06:16,520 --> 00:06:21,229
Eventually, it is only until this point that
the CSS object it model and the document object

98
00:06:21,229 --> 00:06:23,770
model combine to form the render tree.

99
00:06:23,770 --> 00:06:28,240
It is only at this point when we have the
render tree and we've done the networking

100
00:06:28,240 --> 00:06:32,639
first which is when the browser will dispatch
the font request.

101
00:06:32,639 --> 00:06:37,919
Your CSS may reference five or six font files
but only two are being used for the initial

102
00:06:37,919 --> 00:06:38,919
load.

103
00:06:38,919 --> 00:06:42,610
This is why fonts are known as criticals hidden
sub resources.

104
00:06:42,610 --> 00:06:45,069
The browser can't know about them up front.

105
00:06:45,069 --> 00:06:50,470
The idea of preload is what if we could provide
a declarative fetch primitive that initiates

106
00:06:50,470 --> 00:06:58,229
an early fetch, decoupling that logic, saying
to the browser, "I know you're going to find

107
00:06:58,229 --> 00:07:02,090
the font later on, and I know you need it,
or for your JavaScript application, I know

108
00:07:02,090 --> 00:07:07,430
you're going to make a request about a JSON
file to the user, you won't find it later

109
00:07:07,430 --> 00:07:11,570
in the process," I know about it, perform
the networking for it now.

110
00:07:11,570 --> 00:07:14,110
That's why it is extremely powerful.

111
00:07:14,110 --> 00:07:23,150
Here, we have three new primitives, one via
HTML, and one by JavaScript, by our HTTP link

112
00:07:23,150 --> 00:07:24,150
headers.

113
00:07:24,150 --> 00:07:32,060
We also have had module preload specification
for those shipping the native browsers already.

114
00:07:32,060 --> 00:07:37,960
Fonts have to be requested as non-origin,
so this is really powerful.

115
00:07:37,960 --> 00:07:44,580
By adding three HTTP headers, we can tell
the browser upfront about our critical resources.

116
00:07:44,580 --> 00:07:48,300
So if we were to look at the network waterfall
for featherweight dominate, for instance,

117
00:07:48,300 --> 00:07:53,250
before applying this, you will see that the
font files are really low priority here, and

118
00:07:53,250 --> 00:07:58,310
because they haven't been discovered until
the CSS file has been parsed, but just by

119
00:07:58,310 --> 00:08:04,160
adding the preload headers, we can instantly
prioritise and initiate those fetches early,

120
00:08:04,160 --> 00:08:07,729
and so the browser can get on with it.

121
00:08:07,729 --> 00:08:17,030
Customers saw they had 50 per cent, 1.2 seconds,
improvement by adding preload headers for

122
00:08:17,030 --> 00:08:19,660
their font files and hidden sub roars.

123
00:08:19,660 --> 00:08:26,530
I've never known a single technique that's
one line of code that can have a two-second

124
00:08:26,530 --> 00:08:31,979
average improvement on the user experience
of loading up a page.

125
00:08:31,979 --> 00:08:37,180
The question that I want to ask, and propose
to you, is: is indicating resource hints via

126
00:08:37,180 --> 00:08:43,360
the HTML like this, in fact, too late in the
connection flow, too late in the loading experience

127
00:08:43,360 --> 00:08:44,360
of the page?

128
00:08:44,360 --> 00:08:50,880
And that is what HTTP/2 server push comes
in, or was specifically designed to solve.

129
00:08:50,880 --> 00:08:53,170
Let's look at how it can help us.

130
00:08:53,170 --> 00:08:59,490
First, let's look at the traditional request
flow that you to make when you're loading

131
00:08:59,490 --> 00:09:00,490
a page.

132
00:09:00,490 --> 00:09:02,130
You perform a get request to your server.

133
00:09:02,130 --> 00:09:08,060
The server has server think time and perform
a database action, or render some template.

134
00:09:08,060 --> 00:09:15,560
All of the time this is thinking, and, then
eventually, it will respond with your index.html.

135
00:09:15,560 --> 00:09:18,940
Then the browser stars parsing it.

136
00:09:18,940 --> 00:09:24,821
This makes me sad because we've left the connection
open for so long whilst the browser, the server

137
00:09:24,821 --> 00:09:25,940
was doing that think time.

138
00:09:25,940 --> 00:09:31,350
At Fastly, we see an average server think
time of 200 to 400 milliseconds wasted on

139
00:09:31,350 --> 00:09:38,029
the wire here, and round-trip can be 800 to
1,000 milliseconds on a good 3G connection.

140
00:09:38,029 --> 00:09:44,700
What if the server could predict the next
thing the client is going to request is that

141
00:09:44,700 --> 00:09:51,940
main CSS file and flush the bytes for it down
as soon as it receives that get request.

142
00:09:51,940 --> 00:09:53,420
How soon can I use push?

143
00:09:53,420 --> 00:10:03,050
If you have an HTTP/2 server enabled today,
Node natively supports it, we've converged

144
00:10:03,050 --> 00:10:09,620
using our link preload header to use as the
semantic of "I want to push this resource,"

145
00:10:09,620 --> 00:10:16,490
so if your server is HTTP/2 enabled, it will
read these and initiate pushes for you.

146
00:10:16,490 --> 00:10:18,200
Really super quick win.

147
00:10:18,200 --> 00:10:23,290
If you don't want to push and you still want
the semantics of preload, you can add the

148
00:10:23,290 --> 00:10:28,630
no-push attribute there, and at Fastly, we
realise that you might only want to push and

149
00:10:28,630 --> 00:10:33,480
not have a race between push and preload,
and we allow you to say that and will strip

150
00:10:33,480 --> 00:10:35,380
the header on the way out.

151
00:10:35,380 --> 00:10:38,570
What benefit does this actually give us?

152
00:10:38,570 --> 00:10:43,500
If we look to our common waterfall for loading
a page, we've got the index file, then we

153
00:10:43,500 --> 00:10:48,180
look for the CSS, we find that, and then perform
the networking for the JavaScript, and the

154
00:10:48,180 --> 00:10:49,180
CSS.

155
00:10:49,180 --> 00:10:53,660
By pushing the resource, we are saving one
round trip here, the light-shaded bit.

156
00:10:53,660 --> 00:10:59,380
The round-trip time is the time it takes for
the client to send the request to hit the

157
00:10:59,380 --> 00:11:02,190
server and back again until we start receiving
the first bytes.

158
00:11:02,190 --> 00:11:08,760
Again, on a 3G connection in Europe, that
could be as about 800 milliseconds, in some

159
00:11:08,760 --> 00:11:10,639
other developing areas, that could be seconds.

160
00:11:10,639 --> 00:11:12,130
So it's great.

161
00:11:12,130 --> 00:11:17,930
It gives us a one round-trip time saving to
improve our loading experience.

162
00:11:17,930 --> 00:11:22,660
But in the here it's idle time still left
on the connection.

163
00:11:22,660 --> 00:11:26,889
This makes me really, really sad.

164
00:11:26,889 --> 00:11:27,889
Why is this?

165
00:11:27,889 --> 00:11:29,940
Let's look again at this request flow.

166
00:11:29,940 --> 00:11:34,810
As a server push is indicated via the link
header, we have to wait for the server to

167
00:11:34,810 --> 00:11:40,100
do its think time in responding before we
as a server, or your proxy layer, your CDN,

168
00:11:40,100 --> 00:11:48,410
if you use Apache is only until we've received
all of the HTML bytes that we initiate that

169
00:11:48,410 --> 00:11:49,410
push.

170
00:11:49,410 --> 00:11:52,891
That is far too late in the connection flow
because we've still got this idle connection

171
00:11:52,891 --> 00:11:54,600
time.

172
00:11:54,600 --> 00:11:55,769
This makes me really sad.

173
00:11:55,769 --> 00:11:59,680
Wasn't this what push was designed to solve?

174
00:11:59,680 --> 00:12:05,579
To summarise, push gives us a round trip saving,
I would argue the fact that, if you need,

175
00:12:05,579 --> 00:12:09,029
with , you have got no that long server think
time, you should be optimising your servers

176
00:12:09,029 --> 00:12:10,470
instead.

177
00:12:10,470 --> 00:12:14,089
Is link header far too late in the connection
flow?

178
00:12:14,089 --> 00:12:19,310
And this is where asynch push comes in.

179
00:12:19,310 --> 00:12:24,029
To be able to truly utilise push, we need
to decouple the pushing behaviour from our

180
00:12:24,029 --> 00:12:29,339
applications HTML response, and do it right
at the beginning of the connection flow.

181
00:12:29,339 --> 00:12:35,770
So a more common architecture as I discussed
you may have a CDN or a proxy as it receives

182
00:12:35,770 --> 00:12:40,960
that request it is only there and then whilst
we have that server think time, we can push

183
00:12:40,960 --> 00:12:42,250
the bytes down the wire.

184
00:12:42,250 --> 00:12:47,440
I forgot to mention earlier on that the way
that push works is HTTP/2 has a binary data

185
00:12:47,440 --> 00:12:48,710
framing layer.

186
00:12:48,710 --> 00:12:53,880
This is a magical thing that allows us no
longer just plain text on the wire, on our

187
00:12:53,880 --> 00:12:59,019
TCP connection, now we have binary frames
allowing us to interleave separate data frames

188
00:12:59,019 --> 00:13:03,070
for subsequent requests or multiple questions
at the same time, called multiplexing.

189
00:13:03,070 --> 00:13:08,850
This is why we can have a single HTTP/2 open
and deliver hundreds of resources at the same

190
00:13:08,850 --> 00:13:09,850
time.

191
00:13:09,850 --> 00:13:15,029
Push works by sending a push promise frame,
as you can see here, a data frame sent to

192
00:13:15,029 --> 00:13:23,040
the client saying I'm going to send you these
bytes, and here they are, go and have them.

193
00:13:23,040 --> 00:13:26,660
Utilising idle connection time like this makes
me extremely happy.

194
00:13:26,660 --> 00:13:28,800
Again you're wondering how you can do this.

195
00:13:28,800 --> 00:13:32,670
This is using Node standard HTTP/2 standard
library.

196
00:13:32,670 --> 00:13:34,190
I've got a request handler here.

197
00:13:34,190 --> 00:13:36,889
I checked to see if the URL matches.

198
00:13:36,889 --> 00:13:42,449
If it does, I want to initiate a push, here
is where you can flush down your critical

199
00:13:42,449 --> 00:13:46,529
resources that you've identified, piping they
think them down a extreme, and then you can,

200
00:13:46,529 --> 00:13:54,850
down a stream, and then you can — so let's
see the benefits that this has on our waterfall.

201
00:13:54,850 --> 00:13:59,370
As you can see here, when our push example,
we had the one round-trip saving when using

202
00:13:59,370 --> 00:14:00,519
the link header.

203
00:14:00,519 --> 00:14:06,529
By using asynch push, we've hit the Holy Grail
that we are pushing the styles that JavaScript

204
00:14:06,529 --> 00:14:10,399
required to render the screen before the HTML
is even consumed.

205
00:14:10,399 --> 00:14:15,310
Now the browser has all of the information
it needs instantly to render as soon as the

206
00:14:15,310 --> 00:14:16,560
HTML is finished.

207
00:14:16,560 --> 00:14:19,450
That makes Patrick extremely happy!

208
00:14:19,450 --> 00:14:22,660
But what about the repeat view I hear you
asking?

209
00:14:22,660 --> 00:14:24,839
I definitely ask this a lot.

210
00:14:24,839 --> 00:14:30,709
We have already sent the assets to the clients.

211
00:14:30,709 --> 00:14:34,820
The client should have that asset in its patch.

212
00:14:34,820 --> 00:14:38,800
The problem is that we've got no way of indicating
that the serve questioner and what is in its

213
00:14:38,800 --> 00:14:39,860
cache.

214
00:14:39,860 --> 00:14:48,160
What will happen is on the repeat view and
will be detrimental here and create tension

215
00:14:48,160 --> 00:14:54,230
on the underlying network link and end up
worse than when you [sound feed distorted].

216
00:14:54,230 --> 00:15:23,389
The request

217
00:15:23,389 --> 00:15:28,940
never even goes out to the network, and so
we don't have to push, so we benefit from

218
00:15:28,940 --> 00:15:35,100
not having to worry about the cache state.

219
00:15:35,100 --> 00:15:38,560
But that's only if you have a service worker,
and a lot of us may not have.

220
00:15:38,560 --> 00:15:42,170
So the server has got no knowledge of the
class state, and this is a really, really

221
00:15:42,170 --> 00:15:45,090
big problem.

222
00:15:45,090 --> 00:15:46,090
What is the problem?

223
00:15:46,090 --> 00:15:49,430
The theory there is great: push should be
amazing.

224
00:15:49,430 --> 00:15:54,310
We should be able to give the client all of
the information it needs before I've even

225
00:15:54,310 --> 00:15:57,970
received the HTML but the adoption is extremely
low.

226
00:15:57,970 --> 00:15:58,970
Why is that?

227
00:15:58,970 --> 00:15:59,970
What is the problem?

228
00:15:59,970 --> 00:16:04,270
I also want to make a poll here: who is using
H2 in production right now?

229
00:16:04,270 --> 00:16:09,180
Leave your hands up if you're also using push.

230
00:16:09,180 --> 00:16:14,149
So only about ten per cent of the people that
were using push, and there was only probably

231
00:16:14,149 --> 00:16:17,079
only about 20 per cent of the room using H2
at all.

232
00:16:17,079 --> 00:16:18,079
What is the problem?

233
00:16:18,079 --> 00:16:21,130
Why is no-one adopting it?

234
00:16:21,130 --> 00:16:23,470
To do that, let's take a look at the request
flow again.

235
00:16:23,470 --> 00:16:27,920
Once we've sent the get requests, and we start
pushing the bytes down the wire, I lied to

236
00:16:27,920 --> 00:16:29,010
you earlier on.

237
00:16:29,010 --> 00:16:34,389
Even though the browser doesn't have a mechanism
for telling its cache state, it has a mechanism

238
00:16:34,389 --> 00:16:39,490
to reset that stream, so you can send a reset
stream saying I don't want those bytes any

239
00:16:39,490 --> 00:16:42,449
more, I've got it in my cache.

240
00:16:42,449 --> 00:16:47,910
Unfortunately, we've got a race condition
here that, by the time the client has initiated

241
00:16:47,910 --> 00:16:52,660
the reset stream but by the time that gets
to the server, because our critical resources

242
00:16:52,660 --> 00:16:58,149
are normally small, we have flushed the bytes
down the wire already, or, if more importantly,

243
00:16:58,149 --> 00:17:04,630
they left the user space, it's inside their
TCP buffer, and once something is in the kernel's

244
00:17:04,630 --> 00:17:10,660
TCP space, there's no way for an application
to prevent those being flushed down the physical

245
00:17:10,660 --> 00:17:11,660
listening.

246
00:17:11,660 --> 00:17:17,360
We've got a race conditions here which isn't
a good thing.

247
00:17:17,360 --> 00:17:24,100
The new quick protocol that was — QUIC protocol
is going to hopefully solve a lot of those

248
00:17:24,100 --> 00:17:30,630
problems by moving a lot of the application
layer out of the kernel into user space and

249
00:17:30,630 --> 00:17:34,300
allow us to do amazing things here.

250
00:17:34,300 --> 00:17:40,880
Another common area of misconception of HTTP/2
server push is how the servers cache that

251
00:17:40,880 --> 00:17:42,210
resource.

252
00:17:42,210 --> 00:17:47,530
Once I pushed all the bytes down, still a
request that is initiated from your page needs

253
00:17:47,530 --> 00:17:52,790
to claim that resource from the HTTP/2's push
cache.

254
00:17:52,790 --> 00:17:57,610
A push cache is not connected to the HTTP
cache, it is connected to the lifetime of

255
00:17:57,610 --> 00:18:01,890
that single HTTP/2 connection, so, for every
H2 connection you have to an origin, you're

256
00:18:01,890 --> 00:18:04,440
going to have a dedicated push cache for that.

257
00:18:04,440 --> 00:18:08,040
One of the problems is that the push cache
is the last to be requested.

258
00:18:08,040 --> 00:18:12,720
As the request leaves the page, first it will
go to the memory cache attached to that document,

259
00:18:12,720 --> 00:18:16,780
it's all of the resources that document has
already requested.

260
00:18:16,780 --> 00:18:21,140
Then it will be looked up in the service worker
cache, then the HTTP cache, the service worker

261
00:18:21,140 --> 00:18:26,550
caches are shared globally where the memory
caches are pushed, and finally, it will try

262
00:18:26,550 --> 00:18:28,550
and look inside the push cache.

263
00:18:28,550 --> 00:18:32,620
It's highly likely a lot of the time the push
cache will never be claimed, and therefore

264
00:18:32,620 --> 00:18:37,290
therefore you've wasted sending bytes down
the wire.

265
00:18:37,290 --> 00:18:42,820
The other tricky thing here to note is that
HTTP/2 connections are credentialed or non-credentialed

266
00:18:42,820 --> 00:18:48,470
which is why a font file has to be served
as a non-credentialed resource.

267
00:18:48,470 --> 00:18:55,300
If a CSS file was to push a font file, the
CSS file is credentialed and so actually won't

268
00:18:55,300 --> 00:18:58,890
be able to claim the font file request.

269
00:18:58,890 --> 00:19:04,280
So to summarise, the problem here is the push
cache is hats to be authoritative for it,

270
00:19:04,280 --> 00:19:06,630
a single cache per connection.

271
00:19:06,630 --> 00:19:10,700
The items can only be claimed once, so, if
you have multiple tabs open for the single

272
00:19:10,700 --> 00:19:14,700
one, the push can only be sent once, and you
have to repeat that push.

273
00:19:14,700 --> 00:19:25,600
The thing that I find is that the cache behaviour
is not specced as part of the implementation.

274
00:19:25,600 --> 00:19:30,510
If you do consider using HTTP/2 push, I urge
you to read this blog post by Jake Archbold,

275
00:19:30,510 --> 00:19:35,090
where he goes into great detail and the browser
inconsistencies, and it's tougher than we

276
00:19:35,090 --> 00:19:36,090
thought it was.

277
00:19:36,090 --> 00:19:49,720
A tl;dr summarisation of that, we can only
ably use it in Chrome and Firefox.

278
00:19:49,720 --> 00:19:54,800
The networking stack is — Edge have done
great work.

279
00:19:54,800 --> 00:20:00,560
One of the great things that Jake did in this
post was to document all the problems and

280
00:20:00,560 --> 00:20:04,960
create tickets on all of the browsers bug
trackers, so my hat's off to Jake for doing

281
00:20:04,960 --> 00:20:05,960
that.

282
00:20:05,960 --> 00:20:09,130
Edge are improving but not yet.

283
00:20:09,130 --> 00:20:12,270
Still one connection per tag.

284
00:20:12,270 --> 00:20:15,090
This leaves us to UA sniff for push.

285
00:20:15,090 --> 00:20:19,100
That's really, really bad, and we know what
happens when we start going down that route

286
00:20:19,100 --> 00:20:20,960
of UA sniffing.

287
00:20:20,960 --> 00:20:24,220
The race of adoption.

288
00:20:24,220 --> 00:20:30,410
For instance as at Fastly, we only see 0.008
requests — that's 800 questions out of a

289
00:20:30,410 --> 00:20:35,500
million, we do around 6 million requests a
second, that we see a push initiated.

290
00:20:35,500 --> 00:20:39,680
If it was so good, everybody should be using
it, but they're not.

291
00:20:39,680 --> 00:20:44,880
This lack of adoption has got so bad that
certain vendors have considered ripping push

292
00:20:44,880 --> 00:20:48,630
out of the HTTP/2 specification entirely.

293
00:20:48,630 --> 00:20:49,740
When should you push?

294
00:20:49,740 --> 00:20:54,700
Only if you have long round-trip times or
an app shell architecture and you could use

295
00:20:54,700 --> 00:21:00,460
the purple appear or if you could manage your
own cache state natively, or if you've got

296
00:21:00,460 --> 00:21:04,260
a native application or an electron app.

297
00:21:04,260 --> 00:21:10,650
Is that round-trip worth the complexity of
the benefits it gives us, and are there simple

298
00:21:10,650 --> 00:21:12,770
solutions out there that we can use?

299
00:21:12,770 --> 00:21:20,060
This is why I want to talk about what is ahead
for us in the future.

300
00:21:20,060 --> 00:21:26,480
Can we just fix the HTTP push problems?

301
00:21:26,480 --> 00:21:27,950
They're quite simple.

302
00:21:27,950 --> 00:21:29,390
What can we do to fix that?

303
00:21:29,390 --> 00:21:32,900
That is where the cached digest specification
comes in.

304
00:21:32,900 --> 00:21:36,950
What if the browser, whenever it created a
new connection could send a frame called a

305
00:21:36,950 --> 00:21:43,000
cache digest that contained a cuckoo filter
which is a probabilistic data structure representing

306
00:21:43,000 --> 00:21:46,630
all the items the browser has for the clash
of that host name?

307
00:21:46,630 --> 00:21:50,420
Then the server can be much more intelligent
about what it wants to push.

308
00:21:50,420 --> 00:21:56,840
It's I'm not going to push main.css but I
will send you the new version of my JavaScript

309
00:21:56,840 --> 00:22:00,990
application because you don't have the latest
version of that.

310
00:22:00,990 --> 00:22:06,050
I'm excited by not just for solving push,
this opens up a lot of great opportunity for

311
00:22:06,050 --> 00:22:10,600
us for instance in the JavaScript bundling
and modules world that we could choose and

312
00:22:10,600 --> 00:22:15,140
be more intelligence of what we bundle and
what we send down and we have a bit more knowledge

313
00:22:15,140 --> 00:22:17,970
about the client cache state.

314
00:22:17,970 --> 00:22:22,560
Going back to the repeat view, if we had cache
digests for our first view we could push and

315
00:22:22,560 --> 00:22:27,280
on the subsequent view, the client says I've
got that in my resource and we wouldn't have

316
00:22:27,280 --> 00:22:30,130
to push it.

317
00:22:30,130 --> 00:22:34,080
Cache digest specification is an experimental
in ITF at the moment.

318
00:22:34,080 --> 00:22:39,850
It was proposed by my colleague, and it's
been worked on, but I think we're going to

319
00:22:39,850 --> 00:22:42,280
see implementations land in browsers soon.

320
00:22:42,280 --> 00:22:46,260
Fastly have got the first implementation of
the server side as that of that in that you

321
00:22:46,260 --> 00:22:51,970
are open source server, but this seems too
complicated.

322
00:22:51,970 --> 00:22:56,550
Like we are still having to maintain a lot
of logic to manage state between the client

323
00:22:56,550 --> 00:22:57,890
and the server.

324
00:22:57,890 --> 00:23:01,780
Http after all is a stateless protocol, why
it's so beautiful.

325
00:23:01,780 --> 00:23:03,460
It is complicated.

326
00:23:03,460 --> 00:23:06,980
This is where the 103 early-hint specification
comes in.

327
00:23:06,980 --> 00:23:09,160
This is again pursued by my colleague.

328
00:23:09,160 --> 00:23:13,090
Who has heard of 100 informational ranges
at all?

329
00:23:13,090 --> 00:23:15,610
I hadn't at all until this came out.

330
00:23:15,610 --> 00:23:20,890
New HTTP response code that allows the server
to indicate to the client the resource that

331
00:23:20,890 --> 00:23:25,550
is are going to be required for the 200 response
that is coming.

332
00:23:25,550 --> 00:23:30,920
It looks like this, when we perform a Get
request, we then send down an initial response

333
00:23:30,920 --> 00:23:37,370
just containing headers using our friend link
preload and the browser gets to decide I've

334
00:23:37,370 --> 00:23:41,940
got this and don't have that, and initiates
the fetches early during the think time.

335
00:23:41,940 --> 00:23:44,170
This is what it would look like on the wire.

336
00:23:44,170 --> 00:23:47,180
It is as simple as that.

337
00:23:47,180 --> 00:23:51,650
This is why it's more powerful than push because
we are moving that logic and decision process

338
00:23:51,650 --> 00:23:56,670
back to the browser where it belongs, so the
server can send down a 103 response saying

339
00:23:56,670 --> 00:24:01,790
here are the critical resources for this page,
you decide what you want to do with it and

340
00:24:01,790 --> 00:24:03,440
follow up with a 200.

341
00:24:03,440 --> 00:24:06,950
Again, this has been accepted by ITF in experimental
mode.

342
00:24:06,950 --> 00:24:11,380
We've got a working implementation on the
server side but the problem is at the moment,

343
00:24:11,380 --> 00:24:15,580
many browser are worried about the complexity
this adds to the networking stack and worried

344
00:24:15,580 --> 00:24:20,670
we will break the internet because middle
proxies don't understand the 100 range but

345
00:24:20,670 --> 00:24:24,080
only served over TLS to overcome the problems.

346
00:24:24,080 --> 00:24:28,051
Early hints gives us all the same benefits
as push but possession simpler and we can

347
00:24:28,051 --> 00:24:34,260
leverage the browser cache now not have the
complexities of the H2 server push cache and

348
00:24:34,260 --> 00:24:40,160
it's great because it allows the client to
do the decision-making.

349
00:24:40,160 --> 00:24:47,790
We've got preload to do the headers, and new
specification coming out that allows us to

350
00:24:47,790 --> 00:24:53,860
decorate our HTML with resources saying I
know this hero image is high priority but

351
00:24:53,860 --> 00:24:55,030
this fetch request is low.

352
00:24:55,030 --> 00:25:00,020
I urge you to go and check out the specification
and add to the GitHub page here.

353
00:25:00,020 --> 00:25:04,410
So, in closing, I've run out of time, so I've
got to wrap up.

354
00:25:04,410 --> 00:25:08,660
Eve only scratched the surface here of methodologies
but I hope I've given you techniques to use

355
00:25:08,660 --> 00:25:09,680
today.

356
00:25:09,680 --> 00:25:14,430
HTTP/2 doesn't solve everything but there
are a lot of things to solve this.

357
00:25:14,430 --> 00:25:19,310
Resource-loading in the browser is hard but
I'm excited by the future.

358
00:25:19,310 --> 00:25:22,160
Most importantly, performance is for humans.

359
00:25:22,160 --> 00:25:26,200
Optimise for a good user experience, not for
the networking stack.

360
00:25:26,200 --> 00:25:29,350
Measure your experience and optimise for that.

361
00:25:29,350 --> 00:25:34,970
So, the checklist, if I was going to do today,
identify your critical resources, preload

362
00:25:34,970 --> 00:25:40,050
any hidden sub resources, avoid push for possible
and the future is looking great.

363
00:25:40,050 --> 00:25:44,470
We can use early hints when they become available.

364
00:25:44,470 --> 00:25:45,470
Thank you very much.

