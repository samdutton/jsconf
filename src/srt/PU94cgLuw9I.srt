1
00:00:03,100 --> 00:00:28,000
"Making the Jump: How Desktop-Era Frameworks
Can Thrive on Mobile"

2
00:00:28,000 --> 00:00:29,490
Tom Dale

3
00:00:29,490 --> 00:00:30,490
>> Thank you so much, Ashley.

4
00:00:30,490 --> 00:00:31,490
That was really amazing.

5
00:00:31,490 --> 00:00:32,490
And before you go, I took a photo of this.

6
00:00:32,490 --> 00:00:33,490
So this store, in New York, that sells karate
hip hop action/drama headphones and luxury

7
00:00:33,490 --> 00:00:34,490
items.

8
00:00:34,490 --> 00:00:35,490
Have you ever been in this store?

9
00:00:35,490 --> 00:00:36,490
ASHLEY: No, I just stood outside.

10
00:00:36,490 --> 00:00:37,490
I'll come back and let you know.

11
00:00:37,490 --> 00:00:38,490
>> Awesome.

12
00:00:38,490 --> 00:00:39,490
Thank you, Ashley.

13
00:00:39,490 --> 00:00:40,490
Okay.

14
00:00:40,490 --> 00:00:41,490
We have two more talks left today.

15
00:00:41,490 --> 00:00:42,490
We're next, welcoming to the stage Tom Dale.

16
00:00:42,490 --> 00:00:43,490
He is from New York City, of course.

17
00:00:43,490 --> 00:00:44,490
He's a JavaScript thinkfluencer.

18
00:00:44,490 --> 00:00:45,490
So this is going to be a think-piece talk,
I think.

19
00:00:45,490 --> 00:00:46,490
He's wearing a suit today because he's a contrarian,
apparently and I think he wants everyone to

20
00:00:46,490 --> 00:00:47,490
take a photo with him in the photobooth truck,
which every time I walk past, there's not

21
00:00:47,490 --> 00:00:48,490
enough people in there.

22
00:00:48,490 --> 00:00:49,490
So I hope you've all had a turn in the photobooth
truck.

23
00:00:49,490 --> 00:00:50,490
So Tom's also wearing a suit because he wants
you to join his professional network.

24
00:00:50,490 --> 00:00:51,490
He works at LinkedIn.

25
00:00:51,490 --> 00:00:52,490
[ Laughter ]

26
00:00:52,490 --> 00:00:53,490
He looks very professional.

27
00:00:53,490 --> 00:00:54,490
So he's going to give a talk today on how
desktop-era frameworks can thrive on mobile.

28
00:00:54,490 --> 00:00:55,490
I'm a little bit sad that he's actually in
the completing the look with the bowtie and

29
00:00:55,490 --> 00:00:56,490
didn't go all the way.

30
00:00:56,490 --> 00:00:57,490
Thank you, Tom.

31
00:00:57,490 --> 00:00:58,490
TOM: Thank you very much.

32
00:00:58,490 --> 00:00:59,490
Thank you all for having me here today.

33
00:00:59,490 --> 00:01:00,490
It really is an honor to be here.

34
00:01:00,490 --> 00:01:01,490
My name is Tom.

35
00:01:01,490 --> 00:01:02,490
JSConf is a very special conference for me.

36
00:01:02,490 --> 00:01:03,490
I was here about four years ago, which is
when I met Zahra, who you saw earlier.

37
00:01:03,490 --> 00:01:04,490
Jed introduced us on the plane and then two
years after that, I proposed and we're getting

38
00:01:04,490 --> 00:01:05,490
married in August.

39
00:01:05,490 --> 00:01:06,490
So, for me, in particular, JSConf EU has been
particularly life-changing and hopefully many

40
00:01:06,490 --> 00:01:07,490
of you can develop specially similar relationships,
professionally, I mean.

41
00:01:07,490 --> 00:01:09,329
So today I want to talk to you about smartphones.

42
00:01:09,329 --> 00:01:15,930
And in particular, I want to talk about how
tools that grew up on the desktop like Ember,

43
00:01:15,930 --> 00:01:20,600
Angular, and React, can make the jump to the
mobile future.

44
00:01:20,600 --> 00:01:26,609
And I think when people think about adapting
apps to phones, they often focus on the more

45
00:01:26,609 --> 00:01:28,000
obvious differences.

46
00:01:28,000 --> 00:01:31,020
So, for example, things like the difference
in screen size.

47
00:01:31,020 --> 00:01:36,299
The difference in CPU performance, the different
input devices, touch versus a mouse.

48
00:01:36,299 --> 00:01:40,329
But I think where the device is used is important,
too.

49
00:01:40,329 --> 00:01:44,500
So, for example, a user on a mobile phone
is more likely to be distracted than someone

50
00:01:44,500 --> 00:01:48,320
who might be focused on a task at their desk.

51
00:01:48,320 --> 00:01:53,840
Or they might have a more intermittent network
connection than having a broadband Wi-Fi router

52
00:01:53,840 --> 00:01:55,530
in their apartment.

53
00:01:55,530 --> 00:02:01,210
So when phones can be used anywhere, there
are very few assumptions we can make, whether

54
00:02:01,210 --> 00:02:05,369
that's how attentive the user is, or whenever
they have that Internet connection at all.

55
00:02:05,369 --> 00:02:10,580
So I started working at LinkedIn in December
and one thing about working at a site like

56
00:02:10,580 --> 00:02:15,560
LinkedIn is it reminds me of how truly global
the web can be.

57
00:02:15,560 --> 00:02:22,190
In many cases, adapting to smartphones really
means adapting to new users.

58
00:02:22,190 --> 00:02:25,470
For many people, their first computer is a
smartphone.

59
00:02:25,470 --> 00:02:29,330
That means millions, maybe even billions of
people are going to be participating online

60
00:02:29,330 --> 00:02:32,280
without ever owning a desktop computer.

61
00:02:32,280 --> 00:02:36,780
And the more global your app is, the more
combinations of devices and networks you'll

62
00:02:36,780 --> 00:02:37,970
have to deal with.

63
00:02:37,970 --> 00:02:43,530
CPU power can range from a feature phone to
a low-end smartphone, to the latest iPhone,

64
00:02:43,530 --> 00:02:46,120
up to a beefy desktop computer.

65
00:02:46,120 --> 00:02:52,400
And network connectivity can range from GPRS,
to gigabit fiber, to nothing at all, just

66
00:02:52,400 --> 00:02:56,820
ride the subway in New York.

67
00:02:56,820 --> 00:03:04,640
So the problem with this is that without careful
design, it's easy to optimize for one combination

68
00:03:04,640 --> 00:03:06,950
at the cost of another.

69
00:03:06,950 --> 00:03:09,350
So let's take a look at two different users.

70
00:03:09,350 --> 00:03:11,550
Let's imagine these two scenarios.

71
00:03:11,550 --> 00:03:14,890
So user A has a very low-end smartphone.

72
00:03:14,890 --> 00:03:22,440
It has a CPU has easily overheats and starts
throttling itself, and it would be borderline

73
00:03:22,440 --> 00:03:28,210
useless except for the fact that it's not
full.

74
00:03:28,210 --> 00:03:37,950
It Opera Mini which heavily processes requests
before the user gets it.

75
00:03:37,950 --> 00:03:44,810
User B has a phone with a CPU that might rival
a desktop computer and they've got plenty

76
00:03:44,810 --> 00:03:45,860
of fast storage.

77
00:03:45,860 --> 00:03:50,700
But the problem is this person is traveling
without any cellular data.

78
00:03:50,700 --> 00:03:55,590
So while they have sometimes access to broadband
Internet, it's only when they're within range

79
00:03:55,590 --> 00:03:59,450
of a Wi-Fi network that it's useful.

80
00:03:59,450 --> 00:04:05,910
For user A, anything that's JavaScript is
probably not going to be helpful at all.

81
00:04:05,910 --> 00:04:12,540
Even if they stopped using Opera's proxy,
with the slow CPU meaning that getting the

82
00:04:12,540 --> 00:04:17,580
JavaScript means long load times.

83
00:04:17,580 --> 00:04:24,280
It's about keeping the file size as small
as possible.

84
00:04:24,280 --> 00:04:28,730
For user B, we want our web app to work more
like a native application.

85
00:04:28,730 --> 00:04:35,031
In fact, we'd be willing to spend more time
up front to load the entire app and as much

86
00:04:35,031 --> 00:04:36,640
data possible on the phone.

87
00:04:36,640 --> 00:04:38,670
That's basically what the App Store does,
right?

88
00:04:38,670 --> 00:04:42,561
So that meant that he could use it when we
were away from the Wi-Fi connection that we

89
00:04:42,561 --> 00:04:48,450
were relying on, and this user probably has
higher expectations on this app, as well.

90
00:04:48,450 --> 00:04:54,780
It would be worth sending a bit more code
to get 60 frames per second animation and

91
00:04:54,780 --> 00:05:00,750
buttery smooth scrolling if their device can
handle it.

92
00:05:00,750 --> 00:05:06,460
So best experience on a slow device is often
radical different for the best experience

93
00:05:06,460 --> 00:05:10,660
on a faster device.

94
00:05:10,660 --> 00:05:19,180
And the more we try to take advantage of higher
end phones, the worst we've made the experience

95
00:05:19,180 --> 00:05:21,480
for the majority of the world.

96
00:05:21,480 --> 00:05:26,020
So what do you all think is the solution to
this problem?

97
00:05:26,020 --> 00:05:31,790
I'll give you a hint, the initials are, "PE."

98
00:05:31,790 --> 00:05:34,330
Any guesses?

99
00:05:34,330 --> 00:05:35,330
That's right!

100
00:05:35,330 --> 00:05:39,350
Panic and evacuate the building!

101
00:05:39,350 --> 00:05:41,000
Very good.

102
00:05:41,000 --> 00:05:46,080
The answer is supposed to be progressive enhancement
but one thing that's implicit, at least in

103
00:05:46,080 --> 00:05:50,830
all the advice that I've received about progressive
enhancement is that you're supposed to do

104
00:05:50,830 --> 00:05:51,830
it yourself.

105
00:05:51,830 --> 00:05:56,840
It almost always means rendering on the server,
and denying yourself the temptation of using

106
00:05:56,840 --> 00:06:00,070
too much JavaScript.

107
00:06:00,070 --> 00:06:05,570
And browsers in the last ten years, let's
say, have advanced at a remarkable rate.

108
00:06:05,570 --> 00:06:11,660
To me, it feels like the web has never had
more momentum add feature after feature.

109
00:06:11,660 --> 00:06:18,980
And, yet, despite all this incredible innovation
from index.db to web workers, it doesn't actually

110
00:06:18,980 --> 00:06:24,960
feel to me the experience of using web apps
day to day has improved that much in the last

111
00:06:24,960 --> 00:06:26,570
three or four years.

112
00:06:26,570 --> 00:06:32,360
So why is it that these radical improvements
in the browser don't seem to be translating

113
00:06:32,360 --> 00:06:37,830
into radically improved web applications?

114
00:06:37,830 --> 00:06:46,900
And I would argue the reason for this is the
cost of code is too damn high.

115
00:06:46,900 --> 00:06:51,820
Taking advantage of all of those new features
in the browser requires a lot of code.

116
00:06:51,820 --> 00:06:56,440
Native apps that work offline with beautiful
user experiences with hundreds of megabytes

117
00:06:56,440 --> 00:07:02,040
and that's not even factoring in the SDK that
ships with the operating system on the phone.

118
00:07:02,040 --> 00:07:07,320
On the web, just parsing and downloading JavaScript
can be enough to turn phones janky, and when

119
00:07:07,320 --> 00:07:12,120
you start bundling your JavaScript into a
file, every byte starts to count.

120
00:07:12,120 --> 00:07:20,270
And in turn, misaligned libraries have to
compete on file size rather than robustness.

121
00:07:20,270 --> 00:07:24,760
So how do they achieve these improbably small
file sizes?

122
00:07:24,760 --> 00:07:30,070
Often it's by persuading you that the old
thing is unnecessarily complex, the cardinal

123
00:07:30,070 --> 00:07:36,590
sin in JavaScript but they've seen through
the BS and built something simple and that

124
00:07:36,590 --> 00:07:39,100
leads to us the JavaScript simplicity fetish.

125
00:07:39,100 --> 00:07:44,380
It is this emphasis on file size that leaves
the JavaScript community to this fetish, when

126
00:07:44,380 --> 00:07:51,470
file size relies on simplicity and speed relies
on file size, and speed is paramount on the

127
00:07:51,470 --> 00:07:55,840
web, we have to pretend that simple tools
are the best tools because what other choice

128
00:07:55,840 --> 00:07:58,180
do we have?

129
00:07:58,180 --> 00:08:04,790
The only way to run an app that run well on
slower phones and networks is write less JavaScript,

130
00:08:04,790 --> 00:08:12,419
too often, handling edge cases and higher
levels of abstraction.

131
00:08:12,419 --> 00:08:17,979
We eventually start to collapse under our
own page weight.

132
00:08:17,979 --> 00:08:18,979
That's rational.

133
00:08:18,979 --> 00:08:20,880
We've seen this play out several times now.

134
00:08:20,880 --> 00:08:25,620
The more sophistication equals more code,
equals slower load times.

135
00:08:25,620 --> 00:08:33,110
So the time period from 2011 to that we have
could be roughly broken up into the Backbone

136
00:08:33,110 --> 00:08:36,449
era, and the Angular era and the Ember era.

137
00:08:36,449 --> 00:08:45,779
This trio of eras can sometimes also been
known as the Ember era.

138
00:08:45,779 --> 00:08:52,220
Now it's easy to become enamored with the
complexity of a tool.

139
00:08:52,220 --> 00:08:58,759
And let's go back to 2011 and the most cutting-edge
tool that people were using was Backbone.

140
00:08:58,759 --> 00:09:06,149
And people were saying, I love it, I can clone
it from GitHub, and read the source code within

141
00:09:06,149 --> 00:09:08,329
a day.

142
00:09:08,329 --> 00:09:13,810
But whenever my model changes, everything
breaks.

143
00:09:13,810 --> 00:09:17,850
I heard about this new library called Angular.

144
00:09:17,850 --> 00:09:19,860
Two-way binding is so simple.

145
00:09:19,860 --> 00:09:22,970
You just change it, and it changes it on the
screen.

146
00:09:22,970 --> 00:09:30,379
But a year later, it's like my app contains
a controller with 3 million lines of code.

147
00:09:30,379 --> 00:09:40,800
But don't worry, React is amazing and so simple
because it's just the "V" in MVC and a year

148
00:09:40,800 --> 00:09:50,369
or two into building your app you realize
it's 7 megabytes and takes two years to build.

149
00:09:50,369 --> 00:09:58,240
So Don Norman what you may know as the author
of design of Everyday things, wrote this:

150
00:09:58,240 --> 00:10:04,210
The numerous defeats in security measures
prompts my slogan, the more secure you try

151
00:10:04,210 --> 00:10:07,189
to make something, the less secure it becomes.

152
00:10:07,189 --> 00:10:08,379
Why?

153
00:10:08,379 --> 00:10:14,360
Because when security gets in the way, sensible
and well meaning people develop hacks.

154
00:10:14,360 --> 00:10:21,259
Like password rules are too annoying, people
just write the password and put it on their

155
00:10:21,259 --> 00:10:22,259
desk.

156
00:10:22,259 --> 00:10:32,740
So I would like to offer a different corollary
because when simplicity gets in the way, sensible,

157
00:10:32,740 --> 00:10:38,459
and well meaning people develop hacks to defeat
the simplicity.

158
00:10:38,459 --> 00:10:40,800
So how do we break out of this local maxima.

159
00:10:40,800 --> 00:10:45,430
How do we write one app that can scale up
and down across these different devices and

160
00:10:45,430 --> 00:10:47,230
performance characteristics?

161
00:10:47,230 --> 00:10:53,610
Well, I think we can learn from native developers
because they've had to tackle a similar problem.

162
00:10:53,610 --> 00:10:59,209
So these are different CPU architectures and
different CPU architectures have different

163
00:10:59,209 --> 00:11:00,209
instruction sets.

164
00:11:00,209 --> 00:11:12,200
If you write some code for x86 and you want
to run on ARM, they're totally different.

165
00:11:12,200 --> 00:11:15,759
If this is how software was written, there
probably wouldn't be that much cross-platform

166
00:11:15,759 --> 00:11:21,999
code and introducing new CPU architectures
would be borderline impossible.

167
00:11:21,999 --> 00:11:27,290
We've figured out, a long time ago, that a
compiler can take a higher level program and

168
00:11:27,290 --> 00:11:31,680
get it to run across all of these architectures
and if a new architecture comes along, you

169
00:11:31,680 --> 00:11:35,170
just have to update the compiler and not rewrite
every app in existence.

170
00:11:35,170 --> 00:11:41,439
So here's an existence of plying an LVM, and
taking C code and taking an architecture that

171
00:11:41,439 --> 00:11:46,070
didn't exist in the '70s, which was WebAssembly.

172
00:11:46,070 --> 00:11:52,320
And best of all, the compiler makes our code
not only run on all these architectures, but

173
00:11:52,320 --> 00:11:58,660
it can be used to opt my our code differently
for particular characteristics of that platform.

174
00:11:58,660 --> 00:12:05,110
So, for example, here's a paper about optimizing
GCC, where they said, finally, a new target-independent

175
00:12:05,110 --> 00:12:09,269
feature could be implemented to take into
account certain specific features of the target.

176
00:12:09,269 --> 00:12:16,959
For example, to make advantage of the Intel
Itanium, it's dating the paper, we've implemented

177
00:12:16,959 --> 00:12:19,989
the support in the instruction scheduler.

178
00:12:19,989 --> 00:12:25,559
And this is something that Ashley said in
her talk when I totally agree with, if there's

179
00:12:25,559 --> 00:12:30,309
one thing that I want you to take away from
this talk is that modern web toolkits are

180
00:12:30,309 --> 00:12:39,990
transforming away into something like a compiler
where instead of compiling your into native

181
00:12:39,990 --> 00:12:44,879
code, it's going into a highly optimized version.

182
00:12:44,879 --> 00:12:50,399
And I think this would mean taking an app
and delivering the most optimized version

183
00:12:50,399 --> 00:12:51,689
to your device.

184
00:12:51,689 --> 00:12:59,529
This could be like delivering new ES6 builds,
or transpiled ES5 builds and/or transitioning

185
00:12:59,529 --> 00:13:04,509
from server-side rendering and client-side
rendering based on the network speed detected.

186
00:13:04,509 --> 00:13:11,720
But most importantly, these tools can decouple
the file size.

187
00:13:11,720 --> 00:13:18,160
If we can shift the complexity to our build
tools rather than being these monolithic runtime

188
00:13:18,160 --> 00:13:22,989
libraries, we can reduce this pressure to
be simple.

189
00:13:22,989 --> 00:13:28,769
So unfortunately I don't have that much time
for you today but I wanted to highlight three

190
00:13:28,769 --> 00:13:32,970
things that the teams behind React, Ember,
and Angular are working on, in order to demonstrate

191
00:13:32,970 --> 00:13:36,119
that these things are becoming mobile on compilers.

192
00:13:36,119 --> 00:13:42,410
And so the first thing that I want to talk
about is React, and also Prepack which is

193
00:13:42,410 --> 00:13:47,720
an open source tool for optimizing JavaScript
validation.

194
00:13:47,720 --> 00:13:52,939
Prepack was released while on the plane on
my plane to Berlin.

195
00:13:52,939 --> 00:14:01,610
But it was definitely true, the Prepack website
uses quite a bit of computer science terminology

196
00:14:01,610 --> 00:14:03,949
to explain what it's doing.

197
00:14:03,949 --> 00:14:10,579
It's genuinely exciting and novel but you
don't need to understand heap serialization

198
00:14:10,579 --> 00:14:16,449
to understand why Prepack is cool for optimizing
web apps.

199
00:14:16,449 --> 00:14:23,860
So to understand why Prepack is school, let's
see how something like a Rollup works.

200
00:14:23,860 --> 00:14:29,569
It starts by analyzing which file it imports.

201
00:14:29,569 --> 00:14:32,649
For each of those files.

202
00:14:32,649 --> 00:14:37,480
Once it's analyzed the entire graph, it builds
a new JavaScript file that includes just the

203
00:14:37,480 --> 00:14:43,860
modules that were actually used.

204
00:14:43,860 --> 00:14:55,730
And once --

205
00:14:55,730 --> 00:14:57,989
the final output is on the right.

206
00:14:57,989 --> 00:15:02,199
Everything we've imported is inlined right
into that file and modules that aren't imported

207
00:15:02,199 --> 00:15:05,069
with excluded.

208
00:15:05,069 --> 00:15:09,170
This gives us smaller files by eliminating
the files that we don't actually use.

209
00:15:09,170 --> 00:15:11,209
But it's not just modules.

210
00:15:11,209 --> 00:15:16,470
Rollup can do other things if it sees things
that we didn't use.

211
00:15:16,470 --> 00:15:25,259
Notice that we've added a new class to animal.js,
that's because Rollup is smart enough not

212
00:15:25,259 --> 00:15:38,899
to include the feral animal class

213
00:15:38,899 --> 00:15:43,600
static analysis just means figuring out things
about how a program will run without actually

214
00:15:43,600 --> 00:15:44,920
having to run it.

215
00:15:44,920 --> 00:15:49,250
Rollup isn't running your code, it's just
scanning to figure out what gets imported

216
00:15:49,250 --> 00:15:51,369
and what gets exported.

217
00:15:51,369 --> 00:15:58,149
And modules don't work inside of conditionals
so it knows with 100% certainty.

218
00:15:58,149 --> 00:16:02,670
That's roll-up.

219
00:16:02,670 --> 00:16:04,819
Let's take a look at V8.

220
00:16:04,819 --> 00:16:10,209
Specifically, I mean, any JavaScript virtual
mean but we'll look at V8 specifically.

221
00:16:10,209 --> 00:16:12,350
V8 can't help you with file size.

222
00:16:12,350 --> 00:16:18,119
By definition, it has to have downloaded the
JavaScript file already but it can help with

223
00:16:18,119 --> 00:16:20,079
making your code faster.

224
00:16:20,079 --> 00:16:25,220
So this is a high level view of the architecture,
V8 and there's three major components.

225
00:16:25,220 --> 00:16:28,420
I think there are V8 people here so please
forgive me if I get anything wrong.

226
00:16:28,420 --> 00:16:33,089
So the parser which turns your JavaScript
into the instruction, and then the interpreter

227
00:16:33,089 --> 00:16:39,389
ignition which evaluates your JavaScript and
then the Turbofan which turns your JavaScript

228
00:16:39,389 --> 00:16:47,619
into something more time to generate but it
can run at truly ridiculous speeds.

229
00:16:47,619 --> 00:16:54,980
And as your program executes, it keeps track
of how they're run and based on this information

230
00:16:54,980 --> 00:17:07,040
it will ask Turbo fan to make optimized versions
of your that it thinks it will make it run

231
00:17:07,040 --> 00:17:08,040
faster.

232
00:17:08,040 --> 00:17:11,640
Not running it JavaScript probably would be
considered a bug because because it relies

233
00:17:11,640 --> 00:17:16,860
on how the program actually runs, you have
to use the unoptimized code for a while until

234
00:17:16,860 --> 00:17:23,089
V8 can make discussions and that that means
that every user pays that cost even though

235
00:17:23,089 --> 00:17:26,909
the ended result is more or less the same
for everyone.

236
00:17:26,909 --> 00:17:34,539
This is the tension that we have with static
analysis and dynamic analysis you pay the

237
00:17:34,539 --> 00:17:39,970
cost once and all your users benefit but static
analysis can only get you so far because you

238
00:17:39,970 --> 00:17:43,620
can only perform optimizations you're 100%
sure about.

239
00:17:43,620 --> 00:17:48,549
If the module might get use, Rollup can't
use it because if it guesses wrong, the app

240
00:17:48,549 --> 00:17:49,549
breaks.

241
00:17:49,549 --> 00:17:52,870
Information about the runtime analysis can
collect information about how the program

242
00:17:52,870 --> 00:17:57,280
actually runs so they don't have to guess
but requiring the program to run in order

243
00:17:57,280 --> 00:18:04,450
to optimize it is a bit of a catch-22.

244
00:18:04,450 --> 00:18:07,931
And then that's the opposite of what we want
on the web where things typically want to

245
00:18:07,931 --> 00:18:09,080
feel instant.

246
00:18:09,080 --> 00:18:10,840
So that's what makes Prepack so cool.

247
00:18:10,840 --> 00:18:13,590
What it does is actually run you are why code.

248
00:18:13,590 --> 00:18:18,779
Similar to V8, it's an actual JavaScript virtual
machine but rather than running apps, though,

249
00:18:18,779 --> 00:18:24,960
it runs at build time and it reverse-engineers
a version that's faster for your JavaScript

250
00:18:24,960 --> 00:18:30,080
to execute than the first time.

251
00:18:30,080 --> 00:18:35,000
So this whole thing is a talk into itself
and I'm still digesting how it works internally

252
00:18:35,000 --> 00:18:36,720
but let's just take a quick look at how it
works.

253
00:18:36,720 --> 00:18:42,210
I know I showed an example also put so imagine
we're writing a library that prints the data

254
00:18:42,210 --> 00:18:50,730
of JSConf EU, so publish -- so if we run this
through Prepack, you can see that it's turned

255
00:18:50,730 --> 00:18:57,260
it you will into a string literal.

256
00:18:57,260 --> 00:19:02,070
But instead of every user having to allocate
a data object, parse a date string, initialize

257
00:19:02,070 --> 00:19:10,610
a date object, and generating an ISO-601 string,
and this is a contrived example.

258
00:19:10,610 --> 00:19:16,820
And each of these small stakes may start to
really add up in codebase the sizes Ember,

259
00:19:16,820 --> 00:19:18,100
Angular, or React.

260
00:19:18,100 --> 00:19:24,220
And I'm hearing a rumor that Jason Miller
is going to release something called pre-Prepack,

261
00:19:24,220 --> 00:19:30,550
that does everything that Prepack does in
only 600 bytes of code.

262
00:19:30,550 --> 00:19:43,200
So let's look at Angular, it's on Typescript
that's just a subset of JavaScript, and those

263
00:19:43,200 --> 00:19:52,519
types makes refactoring much easier as your
project grows, but to me, the most exciting

264
00:19:52,519 --> 00:19:59,820
and underappreciated reasons for is the potential
for using that type information to more aggressively

265
00:19:59,820 --> 00:20:01,510
minify your builds.

266
00:20:01,510 --> 00:20:11,870
So 
in this examiner we've renamed this variable,

267
00:20:11,870 --> 00:20:17,460
fruit, to be called o and because these variables
inside this go nowhere outside of this function

268
00:20:17,460 --> 00:20:21,799
can access it, so whatever we call inside
it is arbitrary.

269
00:20:21,799 --> 00:20:25,780
Let's change this example a little bit and
instead of making fruit a string, we make

270
00:20:25,780 --> 00:20:31,779
it an object with name property and even though
the variable fruit gets mangled, the property

271
00:20:31,779 --> 00:20:35,360
name stays the same.

272
00:20:35,360 --> 00:20:44,730
Now uglify.js has a property -- 
renaming properties can break things.

273
00:20:44,730 --> 00:20:48,370
In fact, the readme of uglify says, note,
this will probably break your code, which

274
00:20:48,370 --> 00:20:52,330
doesn't instill a lot of confidence.

275
00:20:52,330 --> 00:20:59,059
So, for example, if we have an element and
we change its onclick property, if that gets

276
00:20:59,059 --> 00:21:02,110
renamed to something else, then this is just
going to fail silently.

277
00:21:02,110 --> 00:21:06,559
That click handler that we thought we were
handling just doesn't exist anymore.

278
00:21:06,559 --> 00:21:12,139
And similarly if we look at a component, this
is a React component, for example, there are

279
00:21:12,139 --> 00:21:18,299
parts of this object that are private and
then there are other things that are public,

280
00:21:18,299 --> 00:21:21,929
meaning things like a library or a platform
rely on it.

281
00:21:21,929 --> 00:21:25,880
Really what we want to do is mangle the private
stuff but make sure that the library can keep

282
00:21:25,880 --> 00:21:28,820
using the public stuff and there's good news.

283
00:21:28,820 --> 00:21:33,299
Google's closure compiler already supports
this advanced minification for JavaScript.

284
00:21:33,299 --> 00:21:40,330
Unfortunately, it requires an notating types
with js style comments and -- approximately

285
00:21:40,330 --> 00:21:44,529
seven people on the planet outside of Google
have actually gotten this to work.

286
00:21:44,529 --> 00:21:51,270
Now the Angular team has released an amazing
tool called Sickle that translates a type

287
00:21:51,270 --> 00:21:59,200
script project who the bizarre format that
compiler, and because Angular is written in

288
00:21:59,200 --> 00:22:09,360
Typescript two, closure can do some advanced
minification.

289
00:22:09,360 --> 00:22:21,899
The idea it more accessible to broader world,
and integrating into this NGCLI by default

290
00:22:21,899 --> 00:22:28,820
I think would make a huge impact into basically
every Angular app.

291
00:22:28,820 --> 00:22:35,340
So lastly I just want to talk about Ember,
and specifically Glimmer, which is the rendering

292
00:22:35,340 --> 00:22:38,409
engineer in Ember, and also the library that
we extracted to be used standalone outside

293
00:22:38,409 --> 00:22:40,630
of Ember a month or two ago.

294
00:22:40,630 --> 00:22:46,700
So now in thinking about the rendering engine
is there's three things to consider.

295
00:22:46,700 --> 00:22:54,000
How fast does it take to load.

296
00:22:54,000 --> 00:22:58,399
But then once you have something within reasonable
bound of time, you want to look at how long

297
00:22:58,399 --> 00:23:01,559
does it take to render a component for the
first time when you have to create brand-new

298
00:23:01,559 --> 00:23:02,870
DOM elements.

299
00:23:02,870 --> 00:23:07,080
And third, how long does it take to rerender
a component updating its existing DOM elements

300
00:23:07,080 --> 00:23:10,149
instead of replacing them when the data backing
that component changes.

301
00:23:10,149 --> 00:23:11,149
Okay.

302
00:23:11,149 --> 00:23:13,149
So who remembers this app?

303
00:23:13,149 --> 00:23:16,820
Yeah, the db bain of my existence.

304
00:23:16,820 --> 00:23:26,509
This is Ryan Florence's dbmon demo app, which
heights the differential app and everyone

305
00:23:26,509 --> 00:23:28,710
was competing to have the fastest score on
it.

306
00:23:28,710 --> 00:23:33,370
And it's all anyone ever focused on but then
more recently the community's focus has been

307
00:23:33,370 --> 00:23:38,490
on initial load times as people have grappled
with how we deal with these low-end phones

308
00:23:38,490 --> 00:23:40,630
and slow networks.

309
00:23:40,630 --> 00:23:44,429
And the tricky thing is trying to find the
sweet spot that balances between optimizing

310
00:23:44,429 --> 00:23:46,950
the first render and optimizing rerenders.

311
00:23:46,950 --> 00:23:49,490
Fundamentally, this is an issue of bookkeeping.

312
00:23:49,490 --> 00:23:53,659
The more bookkeeping you do in the initial
render to make subsequent renders faster,

313
00:23:53,659 --> 00:23:56,409
the longer that that render is going to take.

314
00:23:56,409 --> 00:24:00,980
So consider a render using Bootstrap markup
on VirtualJS.

315
00:24:00,980 --> 00:24:04,280
That makes a lot of sense.

316
00:24:04,280 --> 00:24:09,250
This is basically just instructions for how
to create the real DOM but if a single part

317
00:24:09,250 --> 00:24:14,049
changes we have to run the entire render function
again and that's quite a few allocations of

318
00:24:14,049 --> 00:24:17,870
virtual DOM objects, not to mention that once
you have them, you have to then do this diffing

319
00:24:17,870 --> 00:24:23,539
step to kind of reverse-engineer what changed
between last render and this render.

320
00:24:23,539 --> 00:24:29,399
So the performance cost is probably negligible
but in larger apps you can see how it starts

321
00:24:29,399 --> 00:24:31,220
to add up.

322
00:24:31,220 --> 00:24:39,950
And in Glimmer we use Handlebar templates
and success how do we compile them into.

323
00:24:39,950 --> 00:24:46,050
Come Ember's history, this answer changed
three times, first it was strings and then

324
00:24:46,050 --> 00:24:54,179
DOM, and into with glimmer, byte code.

325
00:24:54,179 --> 00:25:03,289
[Inaudible], and 
a virtual machine that runs that compiled

326
00:25:03,289 --> 00:25:04,289
code.

327
00:25:04,289 --> 00:25:07,021
So in Glimmer we compiled this template into
a JSON object that looks like this.

328
00:25:07,021 --> 00:25:11,250
Now, this probably doesn't book meaningful
to you but what this object represents is

329
00:25:11,250 --> 00:25:21,929
a series of op codes, or instructions how
to build -- into integers, string literals,

330
00:25:21,929 --> 00:25:24,830
so parsing is fast and memory consumption
is much lower.

331
00:25:24,830 --> 00:25:29,750
When we landed Glimmer in ember 2.10, many
apps found their template sizes dropped from

332
00:25:29,750 --> 00:25:31,460
75-85% which is significant.

333
00:25:31,460 --> 00:25:39,529
Now if you look closely as 30 but we use integers
to represent instructions for compactness

334
00:25:39,529 --> 00:25:47,039
and for certainly V8 operations but if we
were to operate it in a hypothetical linearized

335
00:25:47,039 --> 00:25:52,020
set of instructions so when we take those
instructions and we execute them on top of

336
00:25:52,020 --> 00:25:55,740
the Glimmer VM, it looks a little bit something
like this.

337
00:25:55,740 --> 00:25:59,299
We have an instruction pointer that just goes
through this sequence and so this is going

338
00:25:59,299 --> 00:26:05,000
to build an li element and then we're going
to move on and run the static add p code and

339
00:26:05,000 --> 00:26:08,490
that's going to set the attribute and then
we're going to add another static attribute

340
00:26:08,490 --> 00:26:12,379
which is the active class and then that's
the whole template and then we're going to

341
00:26:12,379 --> 00:26:16,190
flush the element which tells Glimmer that
this is something to go to put in the DOM.

342
00:26:16,190 --> 00:26:20,710
Now this isn't this is an easy example because
this is static.

343
00:26:20,710 --> 00:26:27,490
But what I want mentioned yet is the Glimmer
VM is made up of two VMs.

344
00:26:27,490 --> 00:26:36,360
One is constructing DOM initial on initial
render and the other is for updates.

345
00:26:36,360 --> 00:26:40,049
So this is the program for initially rendering
this template.

346
00:26:40,049 --> 00:26:42,659
Now we could run this again for updates, right?

347
00:26:42,659 --> 00:26:46,759
But there's a lot of static content in here
and spending time executing op codes for static

348
00:26:46,759 --> 00:26:49,700
content we know hasn't changed isn't a good
use of time.

349
00:26:49,700 --> 00:26:56,070
In fact, we just want to focus on this dynamic
part and the way that we optimize is through

350
00:26:56,070 --> 00:26:58,639
a technique called partial evaluation.

351
00:26:58,639 --> 00:27:03,800
And partial evaluation simply means to generate
an optimize program by evaluating an initial

352
00:27:03,800 --> 00:27:04,800
program.

353
00:27:04,800 --> 00:27:08,090
And we use this technique to generate it automatically.

354
00:27:08,090 --> 00:27:15,990
So initially as the initial program is being
run, we're generating a more optimized version

355
00:27:15,990 --> 00:27:17,370
when the data changes.

356
00:27:17,370 --> 00:27:21,730
Essentially these operations in the initial
rendering program are responsible for generating

357
00:27:21,730 --> 00:27:23,730
their own subsequent code.

358
00:27:23,730 --> 00:27:26,990
So the way this works is that we're going
to go through our op code for the initial

359
00:27:26,990 --> 00:27:30,999
render as before that's going to open a new
div and we're going to set some status traits

360
00:27:30,999 --> 00:27:38,429
on this, so in addition to appending that
text content to the DOM, we're also going

361
00:27:38,429 --> 00:27:43,809
to generate an updating code which is to update
that content and it's going to include a reference

362
00:27:43,809 --> 00:27:47,350
to what value what you were putting in it
as well as a reference to the text value that

363
00:27:47,350 --> 00:27:50,360
you created.

364
00:27:50,360 --> 00:27:54,539
Now when that data value behind that component
updates instead of going that whole process

365
00:27:54,539 --> 00:27:58,929
again, all we have to do is evaluate our highly
optimized updating program which is just going

366
00:27:58,929 --> 00:28:02,450
to take the old data out of the DOM and update
it.

367
00:28:02,450 --> 00:28:05,389
And you can think of it doing as something
-- it's a little more complex than this -- but

368
00:28:05,389 --> 00:28:14,280
you can think of why it ends up being fast
because it needs -- notice that basically

369
00:28:14,280 --> 00:28:19,470
all the rendering library benchmarks only
tested pure dynamic content but it's not representative

370
00:28:19,470 --> 00:28:23,330
of apps in the world.

371
00:28:23,330 --> 00:28:28,409
So we created benchmarks that had a mix of
both static and dynamic content and what we

372
00:28:28,409 --> 00:28:34,909
noticed was that initial I'm not putting the
other names here because it's not a competition.

373
00:28:34,909 --> 00:28:37,960
I think I wanted to show that we're basically
in the same ballpark.

374
00:28:37,960 --> 00:28:42,929
However, when we moved to updating other performance
what we noticed was that it seems like having

375
00:28:42,929 --> 00:28:49,330
this optimized bytecode makes a big difference,
which can make a big difference, especially

376
00:28:49,330 --> 00:28:50,669
on lower end phones.

377
00:28:50,669 --> 00:28:53,850
So today we've talked about three popular
frameworks and things that they're doing to

378
00:28:53,850 --> 00:29:01,009
improve performance on mobile devices.

379
00:29:01,009 --> 00:29:11,289
It's -- there's an exciting trend towards
more sophisticated tools that can analyze

380
00:29:11,289 --> 00:29:16,240
your app, perform optimizations that can be
time consuming, practically impossible to

381
00:29:16,240 --> 00:29:17,559
do by hand.

382
00:29:17,559 --> 00:29:23,149
Best of all code that clearly conveys intent
to other humans has a funny way of conveying

383
00:29:23,149 --> 00:29:28,210
the intent for optimizing compilers, too,
p so in that we have be the idea that build

384
00:29:28,210 --> 00:29:35,450
tools are -- sophisticated build process of
a modern web app.

385
00:29:35,450 --> 00:29:39,159
This morning, Addy showed a bunch of techniques
for measuring and improving the performance

386
00:29:39,159 --> 00:29:40,600
for your web apps.

387
00:29:40,600 --> 00:29:45,360
That's awesome information but not everyone
can be Addy standing over them and reminding

388
00:29:45,360 --> 00:29:50,809
them to take care of performance and spend
time learning about these techniques so I'm

389
00:29:50,809 --> 00:29:56,129
incredibly excited about a community that
can help democratize and commoditize that

390
00:29:56,129 --> 00:30:00,860
performance know-how.

391
00:30:00,860 --> 00:30:06,340
So the best approach of approaching frameworks
and compilers isn't that they just help today's

392
00:30:06,340 --> 00:30:09,940
by reducing the cost of code, we can build
better apps that don't collapse under the

393
00:30:09,940 --> 00:30:20,679
weight of their own complexity.

394
00:30:20,679 --> 00:30:23,460
This is a very exciting time to be a JavaScript
developer.

395
00:30:23,460 --> 00:30:28,340
I for one am really looking forward to web
apps that load instantly, work offline, feel

396
00:30:28,340 --> 00:30:30,240
great to use for everyone.

