1
00:00:00,110 --> 00:00:08,730

[Music]

2
00:00:08,730 --> 00:00:13,500
[Applause]

3
00:00:13,510 --> 00:00:28,570
[Music]

4
00:00:28,580 --> 00:00:31,920
hi so I'm Matthew Sean I'm I work for

5
00:00:31,920 --> 00:00:34,500
the BBC and today I'm going to talk to

6
00:00:34,500 --> 00:00:36,300
you about doing dynamic video in the

7
00:00:36,300 --> 00:00:39,870
browser but the for all of that I want

8
00:00:39,870 --> 00:00:42,030
to give you a brief history of

9
00:00:42,030 --> 00:00:46,260
broadcasting in emoji so in the

10
00:00:46,260 --> 00:00:47,730
beginning people transferred knowledge

11
00:00:47,730 --> 00:00:49,890
News knowledge and stories by word of

12
00:00:49,890 --> 00:00:52,320
mouth and this information would change

13
00:00:52,320 --> 00:00:56,010
and adapt over time then the written

14
00:00:56,010 --> 00:00:58,170
word came along and this allowed these

15
00:00:58,170 --> 00:01:00,270
news information and stories to be

16
00:01:00,270 --> 00:01:01,829
locked down to a single representation

17
00:01:01,829 --> 00:01:05,220
and this was almost the first form of

18
00:01:05,220 --> 00:01:06,930
broadcasting except it was very very

19
00:01:06,930 --> 00:01:13,140
slow then radio came along and for the

20
00:01:13,140 --> 00:01:15,390
first time information could be

21
00:01:15,390 --> 00:01:16,950
delivered to millions of people live

22
00:01:16,950 --> 00:01:21,840
from a single central authority that was

23
00:01:21,840 --> 00:01:23,909
shortly followed by TV which was very

24
00:01:23,909 --> 00:01:26,030
much the same except we added pictures

25
00:01:26,030 --> 00:01:30,780
and then Along Came the Internet this

26
00:01:30,780 --> 00:01:32,759
distributed network of communication

27
00:01:32,759 --> 00:01:34,860
that had the potential to let anyone

28
00:01:34,860 --> 00:01:37,740
speak to millions of people and it was

29
00:01:37,740 --> 00:01:42,329
amazing and a bunch of really good

30
00:01:42,329 --> 00:01:45,810
people worked really really hard and we

31
00:01:45,810 --> 00:01:47,759
learned how to fit the radio and the

32
00:01:47,759 --> 00:01:49,530
television over the same pipes of the

33
00:01:49,530 --> 00:01:55,070
cats but the internet isn't broadcasting

34
00:01:55,070 --> 00:01:57,450
it's something different with its own

35
00:01:57,450 --> 00:02:00,329
exciting possibilities and that could be

36
00:02:00,329 --> 00:02:02,460
a bit of an existential crisis for a

37
00:02:02,460 --> 00:02:05,909
company with broadcasting in its name so

38
00:02:05,909 --> 00:02:08,009
hello I'm Matthew chaton I work in

39
00:02:08,009 --> 00:02:09,509
research and development in the UX team

40
00:02:09,509 --> 00:02:12,590
at the British Broadcasting Corporation

41
00:02:12,590 --> 00:02:14,209
I love making things as well this is

42
00:02:14,209 --> 00:02:15,470
some stuff I made I just put it in

43
00:02:15,470 --> 00:02:17,209
because I really love making stuff so I

44
00:02:17,209 --> 00:02:19,430
like physical things so it is like 3d

45
00:02:19,430 --> 00:02:21,650
printers and giant torches and stuff but

46
00:02:21,650 --> 00:02:23,750
I'm going to talk to you today about a

47
00:02:23,750 --> 00:02:25,190
software project I've been building at

48
00:02:25,190 --> 00:02:30,080
work called the video context so the

49
00:02:30,080 --> 00:02:32,239
video context is an open source library

50
00:02:32,239 --> 00:02:35,840
developed by BBC R&D and its aim is to

51
00:02:35,840 --> 00:02:37,610
make it really easy to make interactive

52
00:02:37,610 --> 00:02:40,910
video on the web and can I get a quick

53
00:02:40,910 --> 00:02:42,830
hands up who's use the Web Audio API at

54
00:02:42,830 --> 00:02:46,010
all okay so a couple if that's cool so

55
00:02:46,010 --> 00:02:48,440
like the video context is very similar

56
00:02:48,440 --> 00:02:52,069
to the Web Audio API but the video it

57
00:02:52,069 --> 00:02:54,620
allows you to sequence and play HTML

58
00:02:54,620 --> 00:02:57,080
media elements like videos images and

59
00:02:57,080 --> 00:03:00,980
canvases it's also pretty fast so all

60
00:03:00,980 --> 00:03:03,019
image processing operations are done in

61
00:03:03,019 --> 00:03:06,069
shaders using WebGL and it's built using

62
00:03:06,069 --> 00:03:11,660
modern open web technologies so now dive

63
00:03:11,660 --> 00:03:14,599
right in and show you some code so this

64
00:03:14,599 --> 00:03:17,209
is a full example of a really simple

65
00:03:17,209 --> 00:03:21,130
video context composition so this is a

66
00:03:21,130 --> 00:03:24,799
HTML document the video context is

67
00:03:24,799 --> 00:03:27,200
brought in at the top and then we have a

68
00:03:27,200 --> 00:03:28,700
canvas and that's going to be we're

69
00:03:28,700 --> 00:03:30,440
going to render too so I'm going to zoom

70
00:03:30,440 --> 00:03:31,579
in a bit more on this code so you can

71
00:03:31,579 --> 00:03:33,940
see what's going on

72
00:03:33,940 --> 00:03:38,630
so we first get a reference to the

73
00:03:38,630 --> 00:03:41,359
canvas and then we pass it into a new

74
00:03:41,359 --> 00:03:44,359
video context instance and then we

75
00:03:44,359 --> 00:03:46,970
create some image source nodes so source

76
00:03:46,970 --> 00:03:49,280
nodes in the video context are is

77
00:03:49,280 --> 00:03:52,100
anything that'll output some form of

78
00:03:52,100 --> 00:03:55,310
media and so the video context is all

79
00:03:55,310 --> 00:03:57,590
graph based as well so in order to see

80
00:03:57,590 --> 00:03:59,540
the output of these image nodes need to

81
00:03:59,540 --> 00:04:01,310
connect them to the destination so the

82
00:04:01,310 --> 00:04:03,380
destination is a special case in the

83
00:04:03,380 --> 00:04:05,239
video context and it represents the

84
00:04:05,239 --> 00:04:06,530
final canvas that things are going to

85
00:04:06,530 --> 00:04:09,859
get rendered to we then need to sequence

86
00:04:09,859 --> 00:04:11,630
these source nodes for playback so the

87
00:04:11,630 --> 00:04:12,920
first image will play from time 0 to

88
00:04:12,920 --> 00:04:14,870
time for the second image will play from

89
00:04:14,870 --> 00:04:18,739
time for to time 8 and then we're going

90
00:04:18,739 --> 00:04:22,099
to tell the video context to play so I

91
00:04:22,099 --> 00:04:23,330
talked about how it was a rendering

92
00:04:23,330 --> 00:04:25,350
graph this is a really

93
00:04:25,350 --> 00:04:26,820
simple representation of that graphic so

94
00:04:26,820 --> 00:04:28,710
you have the two image notes one from

95
00:04:28,710 --> 00:04:30,150
time zero it's time for one print time

96
00:04:30,150 --> 00:04:31,620
for two time eight and we have the

97
00:04:31,620 --> 00:04:33,120
destination we have the connections

98
00:04:33,120 --> 00:04:36,210
between the two so this is thought that

99
00:04:36,210 --> 00:04:39,180
looks like some pretty glorious space

100
00:04:39,180 --> 00:04:42,060
caps so this has a bit of extra stuff

101
00:04:42,060 --> 00:04:44,220
thrown in to visualize it a bit easier

102
00:04:44,220 --> 00:04:46,170
we have a time line down the bottom that

103
00:04:46,170 --> 00:04:47,910
shows the images being played back from

104
00:04:47,910 --> 00:04:50,880
time 0.44 to time eight and then there's

105
00:04:50,880 --> 00:04:52,830
that graph view the side that shows you

106
00:04:52,830 --> 00:04:57,780
when things are rendering so this isn't

107
00:04:57,780 --> 00:04:59,070
so interesting at the moment it's just

108
00:04:59,070 --> 00:05:00,930
two two pictures rolling around so let's

109
00:05:00,930 --> 00:05:04,830
make it a bit more interesting so to do

110
00:05:04,830 --> 00:05:10,710
that we're going to add video so this is

111
00:05:10,710 --> 00:05:12,180
a video source node and you create

112
00:05:12,180 --> 00:05:13,590
exactly the same ways you create an

113
00:05:13,590 --> 00:05:16,050
image source node we can pass in a link

114
00:05:16,050 --> 00:05:18,960
to a video file you then connect it into

115
00:05:18,960 --> 00:05:21,930
the rendering wrap and we're going to

116
00:05:21,930 --> 00:05:24,210
set it playing again from time 0 to time

117
00:05:24,210 --> 00:05:27,000
II and I should say all of these image

118
00:05:27,000 --> 00:05:28,650
and video source knows a black back

119
00:05:28,650 --> 00:05:32,630
underneath by HTML media elements so

120
00:05:32,630 --> 00:05:35,910
buried inside the image node is a just a

121
00:05:35,910 --> 00:05:38,160
regular image element buried inside the

122
00:05:38,160 --> 00:05:42,720
video note is a html5 video element so

123
00:05:42,720 --> 00:05:44,460
playing and this is what the new graph

124
00:05:44,460 --> 00:05:45,270
looks like so it's a bit more

125
00:05:45,270 --> 00:05:46,650
complicated we still got our same view

126
00:05:46,650 --> 00:05:48,390
image node we have a video know down the

127
00:05:48,390 --> 00:05:50,220
bottom and that's clicked as the

128
00:05:50,220 --> 00:05:51,930
destination and this is what that looks

129
00:05:51,930 --> 00:05:53,480
like

130
00:05:53,480 --> 00:05:56,580
so this is a bit disappointing we've

131
00:05:56,580 --> 00:06:00,300
lost our space cats and the reason that

132
00:06:00,300 --> 00:06:03,090
happened is because the video context

133
00:06:03,090 --> 00:06:04,680
will render the media in the order that

134
00:06:04,680 --> 00:06:07,020
it gets connected so our two cat

135
00:06:07,020 --> 00:06:08,310
pictures are still being rendered but

136
00:06:08,310 --> 00:06:09,390
they're being rendered behind Shia

137
00:06:09,390 --> 00:06:13,830
LaBeouf so you might have noticed that

138
00:06:13,830 --> 00:06:15,840
child buff was conveniently against a

139
00:06:15,840 --> 00:06:18,510
green screen so I'm going to take a

140
00:06:18,510 --> 00:06:20,610
brief aside and talk about how green

141
00:06:20,610 --> 00:06:24,660
screening is done so this is

142
00:06:24,660 --> 00:06:26,580
traditionally quite an expensive thing

143
00:06:26,580 --> 00:06:28,620
to compute because you need to iterate

144
00:06:28,620 --> 00:06:32,400
out of every pixel inside an image tests

145
00:06:32,400 --> 00:06:35,040
whether it's green this is greater than

146
00:06:35,040 --> 00:06:36,660
a certain threshold and if it isn't make

147
00:06:36,660 --> 00:06:37,690
it transparent

148
00:06:37,690 --> 00:06:39,220
and this is one of the ways that weather

149
00:06:39,220 --> 00:06:40,330
presenters are put in front of their

150
00:06:40,330 --> 00:06:43,180
interactive weather maps so yeah this is

151
00:06:43,180 --> 00:06:46,750
quite expensive in a 1920 by 1080 image

152
00:06:46,750 --> 00:06:49,750
at about two million pixels at 25 frames

153
00:06:49,750 --> 00:06:51,850
per second that's 15 million pixels per

154
00:06:51,850 --> 00:06:55,000
second we need to process but web

155
00:06:55,000 --> 00:06:56,980
fortunately web GL shaders pride a

156
00:06:56,980 --> 00:06:58,360
really convenient way to do this

157
00:06:58,360 --> 00:07:01,150
efficiently so a WebGL shader is a chunk

158
00:07:01,150 --> 00:07:04,030
of code which runs on the GPU and

159
00:07:04,030 --> 00:07:05,830
they're typically written in a c-lite

160
00:07:05,830 --> 00:07:08,200
language called GLSL and they describe

161
00:07:08,200 --> 00:07:09,970
operations which get run in parallel

162
00:07:09,970 --> 00:07:11,830
across many processing units on the GPU

163
00:07:11,830 --> 00:07:14,020
and this makes them perfect for doing

164
00:07:14,020 --> 00:07:15,700
simple operations across many many

165
00:07:15,700 --> 00:07:21,130
pixels so back to the code I'm going to

166
00:07:21,130 --> 00:07:23,890
now create a color threshold node so

167
00:07:23,890 --> 00:07:26,670
this is similar to the source nodes

168
00:07:26,670 --> 00:07:29,770
except it's an effect and you pass into

169
00:07:29,770 --> 00:07:32,530
it a definition and this describes what

170
00:07:32,530 --> 00:07:36,100
that effect should do we then disconnect

171
00:07:36,100 --> 00:07:37,900
the video node from destination and

172
00:07:37,900 --> 00:07:39,610
connect to the color threshold node then

173
00:07:39,610 --> 00:07:40,780
connect the call threshold node to the

174
00:07:40,780 --> 00:07:44,530
destination so quickly I'll give you a

175
00:07:44,530 --> 00:07:46,180
brief look into what one of those

176
00:07:46,180 --> 00:07:48,670
definitions look like and this is super

177
00:07:48,670 --> 00:07:50,290
complicated and don't worry about if you

178
00:07:50,290 --> 00:07:51,850
don't understand any of it it's it's

179
00:07:51,850 --> 00:07:54,550
mostly shader code and so the bit in the

180
00:07:54,550 --> 00:07:55,930
white box is the fragment shader code

181
00:07:55,930 --> 00:07:59,500
that does our green streaming so the

182
00:07:59,500 --> 00:08:00,940
video context has a bunch of effects

183
00:08:00,940 --> 00:08:03,730
built in but it also is quite a nice

184
00:08:03,730 --> 00:08:05,080
environment for playing around and

185
00:08:05,080 --> 00:08:06,220
experimenting with building your own

186
00:08:06,220 --> 00:08:12,100
shaders so back to the code we've

187
00:08:12,100 --> 00:08:14,050
created that graph which looks like this

188
00:08:14,050 --> 00:08:16,150
r2 image nodes we have a video node

189
00:08:16,150 --> 00:08:17,410
which is now connected the effect nodes

190
00:08:17,410 --> 00:08:19,630
then connect to the destination and that

191
00:08:19,630 --> 00:08:24,100
results in this which is much better we

192
00:08:24,100 --> 00:08:29,720
can see our space caps again thank you

193
00:08:29,730 --> 00:08:32,530
yeah so we're going to take you walk

194
00:08:32,530 --> 00:08:34,720
through that route one more time we're

195
00:08:34,720 --> 00:08:35,950
going to introduce transitions because

196
00:08:35,950 --> 00:08:37,390
transitions are really important in

197
00:08:37,390 --> 00:08:39,670
video editing so a transition is how you

198
00:08:39,670 --> 00:08:41,110
might move from one video clip to the

199
00:08:41,110 --> 00:08:44,410
next so rather than just doing a

200
00:08:44,410 --> 00:08:45,460
straight cut you might have like a

201
00:08:45,460 --> 00:08:47,260
crossfade we might have a star light you

202
00:08:47,260 --> 00:08:49,480
might do something a bit more jazzy so

203
00:08:49,480 --> 00:08:52,780
we're going to create a new video note

204
00:08:52,780 --> 00:08:56,770
and this is created using the same

205
00:08:56,770 --> 00:08:59,530
source the first video note but we're

206
00:08:59,530 --> 00:09:01,060
having we have this dispaly at the end

207
00:09:01,060 --> 00:09:03,400
in this 10.5 and that tells the video

208
00:09:03,400 --> 00:09:05,770
context how far in for that source video

209
00:09:05,770 --> 00:09:07,930
to seek before it starts playing back so

210
00:09:07,930 --> 00:09:09,880
this is how you can sort of cut up pre

211
00:09:09,880 --> 00:09:11,800
existing video files but using this

212
00:09:11,800 --> 00:09:15,370
library so you can create a transition

213
00:09:15,370 --> 00:09:16,600
note and this is really similar to get

214
00:09:16,600 --> 00:09:18,540
effect mode except we pass in a

215
00:09:18,540 --> 00:09:22,720
transition definition and then we call

216
00:09:22,720 --> 00:09:24,250
transition on it so this is going to

217
00:09:24,250 --> 00:09:26,710
transition from time three two times six

218
00:09:26,710 --> 00:09:28,840
from the first input the second input of

219
00:09:28,840 --> 00:09:32,620
the transition node we then connect our

220
00:09:32,620 --> 00:09:34,360
to video notice the transition knows a

221
00:09:34,360 --> 00:09:35,830
transition note of the color threshold

222
00:09:35,830 --> 00:09:39,610
node and then we set up our second video

223
00:09:39,610 --> 00:09:45,160
node start playing and this produces a

224
00:09:45,160 --> 00:09:46,270
graph that looks like this is getting a

225
00:09:46,270 --> 00:09:47,710
bit complicated now and might be a bit

226
00:09:47,710 --> 00:09:57,220
hard to read but results in this so

227
00:09:57,220 --> 00:09:59,200
we've got Shia LaBeouf the in green

228
00:09:59,200 --> 00:10:00,880
screen for the two green screen videos

229
00:10:00,880 --> 00:10:10,280
are being transitioned between

230
00:10:10,290 --> 00:10:14,380
but wait there's more so as I said the

231
00:10:14,380 --> 00:10:16,480
video context has a bunch of effects

232
00:10:16,480 --> 00:10:17,680
built in and a bunch of transitions

233
00:10:17,680 --> 00:10:23,800
built in and this is a demonstration I

234
00:10:23,800 --> 00:10:26,590
put together to kind of try and push the

235
00:10:26,590 --> 00:10:29,440
limits so this is a level 11

236
00:10:29,440 --> 00:10:32,260
simultaneous effects and five transition

237
00:10:32,260 --> 00:10:37,300
effects happening in real time on full

238
00:10:37,300 --> 00:10:40,480
frame images and this was rendered live

239
00:10:40,480 --> 00:10:44,020
in the browser and then each one was

240
00:10:44,020 --> 00:10:46,890
scaled to fit into this this grid and

241
00:10:46,890 --> 00:10:49,420
this really shows the power of shaders

242
00:10:49,420 --> 00:10:50,470
that you're able to do this much

243
00:10:50,470 --> 00:10:52,480
processing this quickly in the browser

244
00:10:52,480 --> 00:10:57,850
it's crazy so are the features

245
00:10:57,850 --> 00:10:59,200
everything I've shown you by the video

246
00:10:59,200 --> 00:11:02,050
context so far has been very much set up

247
00:11:02,050 --> 00:11:03,400
a processing graphs at the park playing

248
00:11:03,400 --> 00:11:07,810
times and say running but it allows you

249
00:11:07,810 --> 00:11:10,030
to do everything dynamically as well so

250
00:11:10,030 --> 00:11:11,230
at any point I could have disconnected

251
00:11:11,230 --> 00:11:13,210
or reconnected those nodes any point I

252
00:11:13,210 --> 00:11:14,620
prefer craters new effects

253
00:11:14,620 --> 00:11:16,210
I could have set of new media's replay

254
00:11:16,210 --> 00:11:18,700
back this makes it makes it quite a rich

255
00:11:18,700 --> 00:11:20,260
environment for building interactive

256
00:11:20,260 --> 00:11:22,750
video experiences it also has a limited

257
00:11:22,750 --> 00:11:24,490
mobile support which I'll I'll go into

258
00:11:24,490 --> 00:11:27,040
in a bit and if you're into making sort

259
00:11:27,040 --> 00:11:29,170
of 360 interactive video it integrates

260
00:11:29,170 --> 00:11:33,700
really nicely with a frame as well so

261
00:11:33,700 --> 00:11:34,630
I'm going to take a bit of time now to

262
00:11:34,630 --> 00:11:37,810
go through some of the challenges we

263
00:11:37,810 --> 00:11:39,970
came up across when we built the video

264
00:11:39,970 --> 00:11:42,430
from text and these challenges are

265
00:11:42,430 --> 00:11:44,320
pretty agnostic the video context work

266
00:11:44,320 --> 00:11:47,170
and the likely come off if you're trying

267
00:11:47,170 --> 00:11:48,670
to build interactive video experiences

268
00:11:48,670 --> 00:11:54,550
yourself so most browsers are limited to

269
00:11:54,550 --> 00:11:56,710
about six to eight simultaneous HTTP

270
00:11:56,710 --> 00:11:59,650
connections for domain and if you have

271
00:11:59,650 --> 00:12:01,089
many clips to play that you want to play

272
00:12:01,089 --> 00:12:02,890
back to back a naive way of doing this

273
00:12:02,890 --> 00:12:04,390
to make sure they all play properly is

274
00:12:04,390 --> 00:12:07,270
to create HTML video elements for each

275
00:12:07,270 --> 00:12:08,800
of those clips of front and set them pre

276
00:12:08,800 --> 00:12:11,740
loading but this quickly saturates the

277
00:12:11,740 --> 00:12:13,630
number of available requests to a single

278
00:12:13,630 --> 00:12:14,800
domain and you can make your website

279
00:12:14,800 --> 00:12:17,500
really slow and responsive so the

280
00:12:17,500 --> 00:12:19,210
solution to this is the video context

281
00:12:19,210 --> 00:12:20,830
will load clips just in time so

282
00:12:20,830 --> 00:12:23,260
all HTML media elements they create

283
00:12:23,260 --> 00:12:24,490
about four seconds before they're

284
00:12:24,490 --> 00:12:26,110
actually needs needed which gives it

285
00:12:26,110 --> 00:12:27,519
enough time to kind of preload things

286
00:12:27,519 --> 00:12:33,519
and get it working so that's all it

287
00:12:33,519 --> 00:12:35,170
needs to be a master clock to sync

288
00:12:35,170 --> 00:12:38,110
everything to in the video context and

289
00:12:38,110 --> 00:12:39,550
the natural fit for this would seem to

290
00:12:39,550 --> 00:12:43,230
be the video current time attribute

291
00:12:43,230 --> 00:12:44,920
unfortunately the rightest updates

292
00:12:44,920 --> 00:12:48,880
varies between browsers so if you're

293
00:12:48,880 --> 00:12:51,130
doing things that require frame accurate

294
00:12:51,130 --> 00:12:54,070
cutting between Clips if your current

295
00:12:54,070 --> 00:12:55,570
time attribute is only updating every

296
00:12:55,570 --> 00:12:59,380
bit of a second it can break things so

297
00:12:59,380 --> 00:13:00,550
the solution to this was to use a

298
00:13:00,550 --> 00:13:02,769
requestanimationframe as a master time

299
00:13:02,769 --> 00:13:04,630
source which gave us millisecond level

300
00:13:04,630 --> 00:13:09,550
accuracy and frame accurate updates this

301
00:13:09,550 --> 00:13:11,470
doesn't come without its own problems so

302
00:13:11,470 --> 00:13:13,870
if you switch tabs the crest animation

303
00:13:13,870 --> 00:13:16,480
frame callback gets halted and this

304
00:13:16,480 --> 00:13:18,700
means so traditionally on the vid on the

305
00:13:18,700 --> 00:13:20,050
web if you're playing back video and you

306
00:13:20,050 --> 00:13:21,279
switch the tabs you'd expect the video

307
00:13:21,279 --> 00:13:23,740
to keep playing in the background but

308
00:13:23,740 --> 00:13:25,450
the video context won't both do that if

309
00:13:25,450 --> 00:13:28,660
it only is a requestanimationframe so

310
00:13:28,660 --> 00:13:30,640
the solution we came up for this is - as

311
00:13:30,640 --> 00:13:32,050
soon as you switch tabs spin out a

312
00:13:32,050 --> 00:13:34,089
webworker and inside the web worker run

313
00:13:34,089 --> 00:13:36,100
a set timeout loop and this won't be as

314
00:13:36,100 --> 00:13:38,380
accurate as a requestanimationframe but

315
00:13:38,380 --> 00:13:41,290
it will give you enough timing to keep

316
00:13:41,290 --> 00:13:47,800
the video context ticking over okay I'm

317
00:13:47,800 --> 00:13:49,180
a little bit ashamed of this one so

318
00:13:49,180 --> 00:13:55,480
they're with me so on mobile there's no

319
00:13:55,480 --> 00:13:57,160
water playing video and this is to

320
00:13:57,160 --> 00:14:00,100
prevent videos also playing and using

321
00:14:00,100 --> 00:14:05,290
Foley on mobile data and the way so the

322
00:14:05,290 --> 00:14:08,170
reason for this is all control calls to

323
00:14:08,170 --> 00:14:10,120
a video element must originate from or

324
00:14:10,120 --> 00:14:11,709
the first one must originate from a user

325
00:14:11,709 --> 00:14:13,540
action in order for a video element to

326
00:14:13,540 --> 00:14:16,589
be controlled programmatically on mobile

327
00:14:16,589 --> 00:14:19,000
so the solution to this in video context

328
00:14:19,000 --> 00:14:20,949
is we create a pool of elements with no

329
00:14:20,949 --> 00:14:25,230
source and they're all there

330
00:14:25,230 --> 00:14:28,630
with no source and when you call play

331
00:14:28,630 --> 00:14:30,209
for the first time in the video context

332
00:14:30,209 --> 00:14:32,980
play gets called on all of those video

333
00:14:32,980 --> 00:14:33,880
elements but nothing

334
00:14:33,880 --> 00:14:35,620
because there's no source attribute but

335
00:14:35,620 --> 00:14:37,089
it puts them in this activated state

336
00:14:37,089 --> 00:14:39,009
where we can then control them

337
00:14:39,009 --> 00:14:41,949
programmatically so the video context

338
00:14:41,949 --> 00:14:43,720
then manages this pool of activated

339
00:14:43,720 --> 00:14:45,339
video elements when it needs one little

340
00:14:45,339 --> 00:14:46,690
porn out of the pool it will use it to

341
00:14:46,690 --> 00:14:48,130
play my video and I'll put it back into

342
00:14:48,130 --> 00:14:52,329
the pool so this allows us to play back

343
00:14:52,329 --> 00:14:54,880
video on mobile that doesn't start at

344
00:14:54,880 --> 00:14:59,110
the very beginning foot sequences okay

345
00:14:59,110 --> 00:15:02,560
so finally this is kind of a biggie

346
00:15:02,560 --> 00:15:05,980
there's no low-level API for frame

347
00:15:05,980 --> 00:15:08,860
accurate sync of multiple videos and

348
00:15:08,860 --> 00:15:10,000
this is kind of a problem because we

349
00:15:10,000 --> 00:15:12,160
have quite complex timing requirements

350
00:15:12,160 --> 00:15:14,649
in the video context we have videos

351
00:15:14,649 --> 00:15:16,750
playing on a timeline at any point we

352
00:15:16,750 --> 00:15:19,959
also have offsets within those videos if

353
00:15:19,959 --> 00:15:21,970
you're taking a clip out of them we need

354
00:15:21,970 --> 00:15:24,160
to make sure they all stay in sync the

355
00:15:24,160 --> 00:15:27,310
solution to this one yeah you kind of

356
00:15:27,310 --> 00:15:28,930
you've got to set them playing and then

357
00:15:28,930 --> 00:15:30,639
hope for the best basically you can do

358
00:15:30,639 --> 00:15:33,310
some quite naive things so if a video

359
00:15:33,310 --> 00:15:35,470
starts buffering then pause will do of

360
00:15:35,470 --> 00:15:36,699
your videos and liquid start playing

361
00:15:36,699 --> 00:15:39,160
again and it turns out perceptually this

362
00:15:39,160 --> 00:15:41,139
isn't so bad like people have an

363
00:15:41,139 --> 00:15:43,930
expectation of video on the web that it

364
00:15:43,930 --> 00:15:45,550
might buffer now and again which if in

365
00:15:45,550 --> 00:15:46,959
broadcasting world if that happens

366
00:15:46,959 --> 00:15:49,300
it'd be a massive no-no but you can kind

367
00:15:49,300 --> 00:15:50,769
of get away with it on the web a bit

368
00:15:50,769 --> 00:15:55,120
more okay so this is the big question

369
00:15:55,120 --> 00:15:58,149
like why okay why we do this is all well

370
00:15:58,149 --> 00:16:00,639
and unlike as much as some others might

371
00:16:00,639 --> 00:16:02,709
want to turn broadcasting into cat gifs

372
00:16:02,709 --> 00:16:04,630
and Shia LaBeouf it's probably not the

373
00:16:04,630 --> 00:16:09,639
future unfortunately so this is the

374
00:16:09,639 --> 00:16:12,970
BBC's mission statement and of note it

375
00:16:12,970 --> 00:16:15,069
doesn't actually contain any mention of

376
00:16:15,069 --> 00:16:17,529
broadcasting which may be avert sites or

377
00:16:17,529 --> 00:16:22,740
central crisis so in R&D where I work

378
00:16:22,740 --> 00:16:27,550
our role is to use new technologies in a

379
00:16:27,550 --> 00:16:30,370
way that lets the BBC inform educate and

380
00:16:30,370 --> 00:16:32,589
entertain people so it's faster cheaper

381
00:16:32,589 --> 00:16:34,569
and better for now into the future

382
00:16:34,569 --> 00:16:36,610
and specifically the user experience

383
00:16:36,610 --> 00:16:39,189
team where I work we use user led design

384
00:16:39,189 --> 00:16:41,350
to create novel experiences to drive

385
00:16:41,350 --> 00:16:43,060
technological change

386
00:16:43,060 --> 00:16:45,580
and for this tool the choices generally

387
00:16:45,580 --> 00:16:47,950
the web so I'm going to show you a quick

388
00:16:47,950 --> 00:16:49,660
demo video and this is one of the

389
00:16:49,660 --> 00:16:51,160
prototypes you put together building the

390
00:16:51,160 --> 00:16:52,510
video context and we've built a whole

391
00:16:52,510 --> 00:16:54,910
range of these but I'll let just show

392
00:16:54,910 --> 00:17:05,010
you this one

393
00:17:05,020 --> 00:17:07,569
forecaster and the BBC R&D labs

394
00:17:07,569 --> 00:17:09,589
demonstrates how a new approach

395
00:17:09,589 --> 00:17:11,750
delivering programs would open the door

396
00:17:11,750 --> 00:17:14,390
to more personal flexible experiences

397
00:17:14,390 --> 00:17:17,839
for our audiences in this demonstrator

398
00:17:17,839 --> 00:17:20,209
we transmit each of the media elements

399
00:17:20,209 --> 00:17:22,280
separately and because of this we have

400
00:17:22,280 --> 00:17:24,169
the ability to control each of these

401
00:17:24,169 --> 00:17:26,480
individual elements in isolation from

402
00:17:26,480 --> 00:17:29,510
one another the timeline tracks you see

403
00:17:29,510 --> 00:17:31,700
the bottom of the footage represent the

404
00:17:31,700 --> 00:17:33,950
timelines for each media object in the

405
00:17:33,950 --> 00:17:34,549
forecast

406
00:17:34,549 --> 00:17:37,460
to illustrate this you can see how the

407
00:17:37,460 --> 00:17:39,500
on-screen graphics can be toggled on or

408
00:17:39,500 --> 00:17:42,950
off or the whole backdrop removed to

409
00:17:42,950 --> 00:17:45,830
reveal the raw green screen footage by

410
00:17:45,830 --> 00:17:48,409
delivering content in this way one of

411
00:17:48,409 --> 00:17:50,030
the biggest potentials lies in the

412
00:17:50,030 --> 00:17:53,030
enhancements of accessibility replacing

413
00:17:53,030 --> 00:17:55,039
the standard presenter with a signer the

414
00:17:55,039 --> 00:17:56,840
first-class presence from the video for

415
00:17:56,840 --> 00:18:00,140
example or rearranging the on-screen

416
00:18:00,140 --> 00:18:01,880
graphics when subtitle elements are

417
00:18:01,880 --> 00:18:05,390
present to avoid overlap you could also

418
00:18:05,390 --> 00:18:07,370
change the background map to a higher

419
00:18:07,370 --> 00:18:09,140
contrast view to aid the visually

420
00:18:09,140 --> 00:18:12,830
impaired if media were delivered in this

421
00:18:12,830 --> 00:18:14,840
way we could also have the footage

422
00:18:14,840 --> 00:18:17,510
adapting to suit your screen size rather

423
00:18:17,510 --> 00:18:19,789
than forcing a single aspect ratio or

424
00:18:19,789 --> 00:18:23,780
font size on all devices here we can see

425
00:18:23,780 --> 00:18:25,640
how a mobile portrait view would look

426
00:18:25,640 --> 00:18:28,250
with a larger font size and a rearranged

427
00:18:28,250 --> 00:18:31,370
view to include more of the map in the

428
00:18:31,370 --> 00:18:33,679
future we could also link content to

429
00:18:33,679 --> 00:18:35,840
your personal calendar or or the

430
00:18:35,840 --> 00:18:37,789
third-party data services and feature

431
00:18:37,789 --> 00:18:41,720
relevant local information as you can

432
00:18:41,720 --> 00:18:44,210
see the ability to send media elements

433
00:18:44,210 --> 00:18:47,059
or objects separately rather than as a

434
00:18:47,059 --> 00:18:49,280
single video stream gives much greater

435
00:18:49,280 --> 00:18:51,650
flexibility for playback allowing

436
00:18:51,650 --> 00:18:53,870
content automatically adapt to the

437
00:18:53,870 --> 00:18:55,549
screen size and preferences of the

438
00:18:55,549 --> 00:18:59,659
viewer the flexibility of an object

439
00:18:59,659 --> 00:19:01,340
based approach won't just benefits

440
00:19:01,340 --> 00:19:02,799
audiences though

441
00:19:02,799 --> 00:19:05,840
BBC R&D is also testing how it could

442
00:19:05,840 --> 00:19:08,059
make production more efficient giving

443
00:19:08,059 --> 00:19:10,100
programme makers time to flex their

444
00:19:10,100 --> 00:19:12,990
creative muscles in new ways

445
00:19:12,990 --> 00:19:14,580
we hope you've enjoyed the sneak peek

446
00:19:14,580 --> 00:19:16,890
into the potential of IP production in

447
00:19:16,890 --> 00:19:19,200
the future this demonstrator does not

448
00:19:19,200 --> 00:19:21,090
represent a new service and has used

449
00:19:21,090 --> 00:19:25,529
non-broadcast maps and feeds only I love

450
00:19:25,529 --> 00:19:36,390
that disclaimer again thank you so in

451
00:19:36,390 --> 00:19:39,149
that you heard the phrase object based

452
00:19:39,149 --> 00:19:41,669
media and this is what R&D are calling

453
00:19:41,669 --> 00:19:44,520
this new approach to broadcasting and it

454
00:19:44,520 --> 00:19:46,289
might feel quite familiar if you've been

455
00:19:46,289 --> 00:19:49,140
on the web for a while but we like to

456
00:19:49,140 --> 00:19:50,700
think of it as bringing responsive

457
00:19:50,700 --> 00:19:52,890
design to broadcasting making content

458
00:19:52,890 --> 00:19:56,159
that adapts to the user to the device

459
00:19:56,159 --> 00:19:58,559
and to the environment are in and that

460
00:19:58,559 --> 00:20:00,029
was one of a bunch of experiments we're

461
00:20:00,029 --> 00:20:04,140
building to explore this area more so

462
00:20:04,140 --> 00:20:09,690
finally as well as a new way to deliver

463
00:20:09,690 --> 00:20:12,090
content the web is a new medium for

464
00:20:12,090 --> 00:20:15,270
storytelling in and of itself and we're

465
00:20:15,270 --> 00:20:16,799
really excited to be exploring this area

466
00:20:16,799 --> 00:20:18,899
and we hope that by releasing this layer

467
00:20:18,899 --> 00:20:20,190
we make it a bit easier for the people

468
00:20:20,190 --> 00:20:22,830
to do so as well and super excited to

469
00:20:22,830 --> 00:20:24,730
see what you might make with it thanks

470
00:20:24,730 --> 00:20:26,410
[Applause]

471
00:20:26,410 --> 00:20:29,730
[Music]

