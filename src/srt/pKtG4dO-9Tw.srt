1
00:00:26,920 --> 00:00:32,590
Good morning everyone, so I am talking today
about cognitive computing, the name of my

2
00:00:32,590 --> 00:00:38,900
talk is Domo Arigato, Mr Roboto, I do not
speak Japanese, I copied that straight from

3
00:00:38,900 --> 00:00:52,120
Wikipedia, I'll talk about cognitive computing,
my slides are

4
00:00:52,120 --> 00:00:57,710
available online, ‘snugug’ is the bit
that's important, that's where I'm on the

5
00:00:57,710 --> 00:01:01,940
internet, Github, Twitter, you can find me
there.

6
00:01:01,940 --> 00:01:07,380
So let's talk about the world of cognitive
computing, shall we.

7
00:01:07,380 --> 00:01:10,159
This is Pepper.

8
00:01:10,159 --> 00:01:19,950
Pepper is a robot, built by Soft Bank a Japanese
company, pepper is designed to be one of the

9
00:01:19,950 --> 00:01:26,450
worlds first human computer interactive Android
type things.

10
00:01:26,450 --> 00:01:30,850
It's using the power of cognitive computing
to make this interaction between humans and

11
00:01:30,850 --> 00:01:37,700
computers a little bit easier something not
like the programming we do everyday.

12
00:01:37,700 --> 00:01:44,409
If we talk about cognitive computing we should
probably define what cognitive computing is.

13
00:01:44,409 --> 00:01:50,250
So cognitive computing is a new field of computing,
the types of problem that cognitive computing

14
00:01:50,250 --> 00:01:56,719
can solve are unlike any problems we have
been able to try and work on before.

15
00:01:56,719 --> 00:02:01,759
It's for working with human complex problems,
so the type of problems that were normally

16
00:02:01,759 --> 00:02:07,880
used to be solving in computer science are
not really human complex problems, being problems

17
00:02:07,880 --> 00:02:13,000
that really require a human to solve, usually
things that can be solved with just maths

18
00:02:13,000 --> 00:02:19,200
or just data analysis, but cognitive computing
aims to be able to solve problems that otherwise

19
00:02:19,200 --> 00:02:20,790
we wouldn't be able to do.

20
00:02:20,790 --> 00:02:24,680
It does this by using machine learning and
artificial intelligence.

21
00:02:24,680 --> 00:02:29,770
So not a single path towards a cynical solution,
but rather, single solution, but rather a

22
00:02:29,770 --> 00:02:34,540
problem is tick solution to problems.

23
00:02:34,540 --> 00:02:40,400
It's a very different way to thinking about
computing than we are normally used to it.

24
00:02:40,400 --> 00:02:48,410
It works with human natural input and output,
so think instead of putting in numbers and

25
00:02:48,410 --> 00:02:54,150
getting numbers back or putting in key word
searches, think rather putting in long form

26
00:02:54,150 --> 00:02:59,540
text, like whole webpages and being able to
answer questions on whole webpages without

27
00:02:59,540 --> 00:03:04,950
converting it into anything, or speaking into
them computing and getting things back, or

28
00:03:04,950 --> 00:03:12,190
having the computer understand audio, video
or images and being able to output audio,

29
00:03:12,190 --> 00:03:16,140
video ipages, other forms of long form text.

30
00:03:16,140 --> 00:03:19,910
This is the type of problem solving and the
type of solutions we can do with cognitive

31
00:03:19,910 --> 00:03:25,170
computing it's why it's the new type of computing
and problem solving, I think it's really cool

32
00:03:25,170 --> 00:03:30,790
and lends itself to new types of applications.

33
00:03:30,790 --> 00:03:41,489
Yah, what does that mean, I bet you have all
used a cognitive application, if not today,

34
00:03:41,489 --> 00:03:42,569
recently.

35
00:03:42,569 --> 00:03:53,750
Who here has used Google Now, or Siri, they
are all cognitive applications, they are called

36
00:03:53,750 --> 00:03:59,510
the personal assistant, it's one of the patterns
that we find at Watson that people use all

37
00:03:59,510 --> 00:04:01,050
the time.

38
00:04:01,050 --> 00:04:04,670
Let's breakdown what that personal assistant
cognitive application is.

39
00:04:04,670 --> 00:04:10,150
It's speech in, speech gets transformed into
text.

40
00:04:10,150 --> 00:04:16,940
That text is then run through usually what
we call a natural language classifier to figure

41
00:04:16,940 --> 00:04:19,769
out what the subject of the

42
00:04:19,769 --> 00:04:25,120
sentence is or the subject of the text is
pool out the individual pieces, then runs

43
00:04:25,120 --> 00:04:29,600
the business logic underneath it to figure
out if you are talking about the weather and

44
00:04:29,600 --> 00:04:36,130
you have your location, what is go and find
the weather application, then runs a Speech-to-Text

45
00:04:36,130 --> 00:04:40,190
to transform that into synthesized speech
and tells you what it is, or if you are doing

46
00:04:40,190 --> 00:04:46,610
a Google search or web search it will go and
find what that is and possibly pull back here

47
00:04:46,610 --> 00:04:52,800
are the results for you, or look in alpha
and pull out the individual pieces, these

48
00:04:52,800 --> 00:04:57,730
are all different types of speech input and
then business logic and output.

49
00:04:57,730 --> 00:05:02,560
So not everything inside of a cognitive application
needs to be cognitive or fit the cognitive

50
00:05:02,560 --> 00:05:09,041
paradigm the application as a whole becomes
cognitive when we provide it, when we use

51
00:05:09,041 --> 00:05:14,020
these types of cognitive input and output
to work with it.

52
00:05:14,020 --> 00:05:17,380
That's what I want - yeah.

53
00:05:17,380 --> 00:05:21,780
So... let's talk about, let's see what some
of these examples are.

54
00:05:21,780 --> 00:05:22,970
Let's play a little bit.

55
00:05:22,970 --> 00:05:27,140
I like pepper dancing, pepper is fun.

56
00:05:27,140 --> 00:05:33,220
So, the first application that we're going
to talk about is this little thing that I

57
00:05:33,220 --> 00:05:39,630
built, a little tiny Chrome extension, using
Watson's text analysis tool.

58
00:05:39,630 --> 00:05:46,700
What it does, it's a Chrome extension for
Github, whereas you are typing it analyses

59
00:05:46,700 --> 00:05:52,220
the speech that you, the actual long form
text you are writing in the comment box if

60
00:05:52,220 --> 00:05:56,970
it finds the text is negative, if the content
of your text is negative, it switches the

61
00:05:56,970 --> 00:06:05,170
comment submit button from green to red, if
it becomes angry it disables the comment button,

62
00:06:05,170 --> 00:06:06,650
right!

63
00:06:06,650 --> 00:06:10,470
That's pretty fun!

64
00:06:10,470 --> 00:06:13,720
\{Applause\}.

65
00:06:13,720 --> 00:06:18,410
So it's also about this, one of the reasons
why I'm talking to you about this, even though

66
00:06:18,410 --> 00:06:23,500
you might be able, you might not think well
this is probably really super expensive and

67
00:06:23,500 --> 00:06:28,870
probably something that I get access to because
I'm Watson, this is built with a single publicly

68
00:06:28,870 --> 00:06:34,190
available API that you can go and use right
now.

69
00:06:34,190 --> 00:06:39,700
Watson isn't the only group doing this, we
happen to have a whole lot of cognitive APIs

70
00:06:39,700 --> 00:06:46,030
that you can use right now by searching the
Watson developer cloud, this is one called

71
00:06:46,030 --> 00:06:53,190
tone analyser, what winds up happening here,
as you type on key up, the Chrome extension

72
00:06:53,190 --> 00:07:00,960
sends all of your text off to a little tiny
server I made, that runs through tone analyser,

73
00:07:00,960 --> 00:07:09,360
comes back and tone analyser splits your text
into one of three different tones, happy,

74
00:07:09,360 --> 00:07:12,220
negative or angry.

75
00:07:12,220 --> 00:07:18,780
If negative is one or above, I tell you that
you probably shouldn't send that and if angry

76
00:07:18,780 --> 00:07:21,430
is one or above I disable it.

77
00:07:21,430 --> 00:07:25,509
Usually you are angry and negative, but you
can be negative without being angry, that's

78
00:07:25,509 --> 00:07:27,700
why it's kind of that three layer thing.

79
00:07:27,700 --> 00:07:33,470
So this is the first type of cognitive application
you can build.

80
00:07:33,470 --> 00:07:37,200
The second one gets a little bit more complex.

81
00:07:37,200 --> 00:07:46,741
So, this is something I wrote called 'Babel
Fish', those of you that don't know, it's

82
00:07:46,741 --> 00:07:51,990
the weirdest thing in the universe, you put
it in your ear and it translates all speech

83
00:07:51,990 --> 00:08:00,250
into other speech, it's from hitchhikers guide
to the galaxy, Watson as three, Speech-to-Text,

84
00:08:00,250 --> 00:08:07,680
language translation API and text to speech
API, when it's combined you can create a Babel

85
00:08:07,680 --> 00:08:19,540
fish, I will use media to get text input,
it will run through the Speech-to-Text algorithm,

86
00:08:19,540 --> 00:08:26,210
it is then going to translate that text using
text or language translation, then going to

87
00:08:26,210 --> 00:08:28,130
spit it out in that native language.

88
00:08:28,130 --> 00:08:31,230
Unfortunate German isn't supported, but French
is.

89
00:08:31,230 --> 00:08:38,680
What I'm going to do is say English and go
to go to French, I'm going to do it not on

90
00:08:38,680 --> 00:08:39,680
my speaker

91
00:08:39,680 --> 00:08:54,010
notes... hello JSConf.

92
00:08:54,010 --> 00:08:57,959
Live demos are always fun!

93
00:08:57,959 --> 00:09:07,310
\{Laughter\} \{French\} close...!

94
00:09:07,310 --> 00:09:10,430
\{Laughter\}.

95
00:09:10,430 --> 00:09:13,550
\{Applause\}.

96
00:09:13,550 --> 00:09:19,629
I guess JSConf isn't something that Speech-to-Text
understands, so let's try something else.

97
00:09:19,629 --> 00:09:43,139
'The breakfast this morning was fantastic'...
\{French\} that's a little bit better I think.

98
00:09:43,139 --> 00:09:49,550
What do the APIs look like under the hood,
is the way that - what you get back from Speech-to-Text

99
00:09:49,550 --> 00:09:51,600
is you get a confidence meter.

100
00:09:51,600 --> 00:09:58,120
This is where cognitive applications sort
of differ from normal APIs that you may wind

101
00:09:58,120 --> 00:09:59,720
up working with.

102
00:09:59,720 --> 00:10:08,459
Speech-to-Text is a little bit iffy it's working
of probability, not confidence, you get the

103
00:10:08,459 --> 00:10:16,500
translated text but you also get a confidence
meter from 0 - 1, 0 to 100% basically.

104
00:10:16,500 --> 00:10:19,140
That is going to tell you how confident it
is in your results.

105
00:10:19,140 --> 00:10:24,720
The first one not so confident, this is pretty
confident, this is more or less spot on.

106
00:10:24,720 --> 00:10:28,230
Then language translation does a one-to-one
translation.

107
00:10:28,230 --> 00:10:34,300
Translation happened between different domains,
you could have - right now there is a news

108
00:10:34,300 --> 00:10:39,949
domain and a medical and a travel domain,
but one of the great things about this is

109
00:10:39,949 --> 00:10:45,720
because cognitive computing is based off of
artificial intelligence and machine learning,

110
00:10:45,720 --> 00:10:51,689
you can learn, you can train it, you can have
it understand your specific domain, if you

111
00:10:51,689 --> 00:10:57,529
wanted to create, let's say a food application,
you could train these APIs, you can train

112
00:10:57,529 --> 00:11:01,019
cognitive systems to understand the domain
of food.

113
00:11:01,019 --> 00:11:09,680
So you don't have to know, necessarily, what
a croissant is in English or French, you don't

114
00:11:09,680 --> 00:11:15,480
have to know what the words are, but you are
able to translate them by training the applications

115
00:11:15,480 --> 00:11:20,350
with APIs I'm using a standard news domain.

116
00:11:20,350 --> 00:11:27,439
Text to speech synth sizes text in one of
a variety of different languages, that just

117
00:11:27,439 --> 00:11:33,829
takes what ever text and goes straight off,
so it's cognitive input, human natural input,

118
00:11:33,829 --> 00:11:38,770
with language translation which is trainable
to understand the different domains you are

119
00:11:38,770 --> 00:11:49,689
working in, then text to speech, a human understandable
output, it makes a new way of working and

120
00:11:49,689 --> 00:11:58,790
interacting with your user, there are only
really three APIs being used here.

121
00:11:58,790 --> 00:12:08,230
The final bit that we have is a little bit
more fun, it's cognitive computing.

122
00:12:08,230 --> 00:12:14,950
So, the first example that we showed is something
that you can build today with a single API,

123
00:12:14,950 --> 00:12:23,699
it's a simple example of what cognitive computing
can be, one API, one natural language text

124
00:12:23,699 --> 00:12:27,540
input, goes off to server, comes back, you
do stuff.

125
00:12:27,540 --> 00:12:34,480
The second one a little bit more complex,
three APIs being used, one turns speech into

126
00:12:34,480 --> 00:12:38,230
text, then it does stuff in the back ground
and gives you speech out.

127
00:12:38,230 --> 00:12:43,309
Be able to hold full conversations with other
people that you otherwise couldn't.

128
00:12:43,309 --> 00:12:48,189
That's also available as three public APIs,
this a little bit future state, it's available

129
00:12:48,189 --> 00:12:56,449
now, just not as APIs, Watson is built on
what we call Watson Discovery Advisor, it's

130
00:12:56,449 --> 00:13:01,970
a system for understanding connections and
being able to find connections between things

131
00:13:01,970 --> 00:13:07,569
you wouldn't otherwise be able to see, in
this case food.

132
00:13:07,569 --> 00:13:16,009
So what we have done here, we have ingested
all of the recipes that bon appetite magazine

133
00:13:16,009 --> 00:13:17,939
has written.

134
00:13:17,939 --> 00:13:29,410
We have ingested all of thinkers, like artificial
intelligence, machine learning and deep learning,

135
00:13:29,410 --> 00:13:37,139
kind of do its thing on them, what you get
out of this, you get food pairings or recipes

136
00:13:37,139 --> 00:13:41,600
you wouldn't otherwise know or be able to
see.

137
00:13:41,600 --> 00:13:47,579
So one example of this, when we talk about
food and we talk about cooking, normally the

138
00:13:47,579 --> 00:13:54,269
food and the recipes that we have, those ingredients
go together \{sirens outside\}, I guess the

139
00:13:54,269 --> 00:13:56,269
police don't like me talking about food!

140
00:13:56,269 --> 00:14:01,199
\{Laughter\} So food and recipes they generally
go together and the ingredients in recipes

141
00:14:01,199 --> 00:14:03,819
generally go together because they grow together.

142
00:14:03,819 --> 00:14:06,790
They come from the same region of the world

143
00:14:06,790 --> 00:14:14,670
but things like apples and olives don't grow
in the same place but it turns out that when

144
00:14:14,670 --> 00:14:20,269
you look at the types of recipes they are
used in and their chemical compounds and how

145
00:14:20,269 --> 00:14:24,819
other things relate to those 2 ingredients,
apples and olives turn out to pair really

146
00:14:24,819 --> 00:14:28,309
well together, even though it's something
you would never think to pair together because

147
00:14:28,309 --> 00:14:30,339
they don't grow together.

148
00:14:30,339 --> 00:14:35,509
What cognitive computing and what Chef Watson
is able to do is able to find these underlying

149
00:14:35,509 --> 00:14:36,509
connections.

150
00:14:36,509 --> 00:14:42,810
It also have applications in other things,
think law enforcement, we have this demo where

151
00:14:42,810 --> 00:14:49,240
we ingested all of Wikipedia, and you ask
it questions about Wikipedia like what are

152
00:14:49,240 --> 00:14:52,839
the planets in the solar system it's able
to actual what all the planets are with all

153
00:14:52,839 --> 00:14:54,889
the evidence and all the confidence.

154
00:14:54,889 --> 00:15:00,230
You can actually trace back all the evidence
and all the different pieces that connect

155
00:15:00,230 --> 00:15:05,230
together this is how cognitive computing is
a bit different than normal key word search

156
00:15:05,230 --> 00:15:08,790
you can actually see the full evidence tree
of how got somewhere.

157
00:15:08,790 --> 00:15:13,660
Let's build a recipe.

158
00:15:13,660 --> 00:15:17,209
Chef Watson, starts with ingredients.

159
00:15:17,209 --> 00:15:22,410
Someone yell out an ingredient.

160
00:15:22,410 --> 00:15:24,740
Bacon!

161
00:15:24,740 --> 00:15:27,070
Bacon.

162
00:15:27,070 --> 00:15:32,230
It starts to think, we know it has bacon,
it makes some suggestions for us of other

163
00:15:32,230 --> 00:15:39,839
types of ingredients that are known to pair
well with bacon, smoked turkey, some navy

164
00:15:39,839 --> 00:15:44,100
beans.

165
00:15:44,100 --> 00:15:50,569
Soy sauce.

166
00:15:50,569 --> 00:15:56,520
Dark soy sauce, dark soy sauce.

167
00:15:56,520 --> 00:15:57,520
Undefined dumplings.

168
00:15:57,520 --> 00:15:58,520
Yes!

169
00:15:58,520 --> 00:16:10,529
\{applause\} \{laughter\} I 
think chef has decided to pair Bacon with

170
00:16:10,529 --> 00:16:13,579
more Bacon.

171
00:16:13,579 --> 00:16:22,839
\{laughter\} \{applause\} anyway, so cognitive
computing and specifically chef Watson it

172
00:16:22,839 --> 00:16:28,309
goes beyond just ingredients we can talk about
dishes and styles as well.

173
00:16:28,309 --> 00:16:31,940
So let's choose a dish.

174
00:16:31,940 --> 00:16:38,620
Let us do a bacon and soy sauce bloody Mary.

175
00:16:38,620 --> 00:16:46,369
How about a Caesar salad?

176
00:16:46,369 --> 00:16:53,380
Get rid of the bloody Mary.

177
00:16:53,380 --> 00:17:02,279
Maybe it won't do a dish or a style, back
to school.

178
00:17:02,279 --> 00:17:09,380
\{laughter\} there we go, so back to school
bacon dumplings.

179
00:17:09,380 --> 00:17:19,390
\{laughter\} if we load this up, we wind up
seeing is we wind up getting a brand new recipe

180
00:17:19,390 --> 00:17:22,459
that has never existed before.

181
00:17:22,459 --> 00:17:29,530
So chef Watson didn't go do a search on the
internet to find back to school bacon dumplings,

182
00:17:29,530 --> 00:17:36,210
what it's done it's used the that training
of all the recipes and used the training of

183
00:17:36,210 --> 00:17:43,450
all the different ingredients and the chemical
compounds of all the ingredients to build

184
00:17:43,450 --> 00:17:49,680
a new recipe for you a new human output recipe
for you based on other thing that, but this

185
00:17:49,680 --> 00:17:52,050
has never existed before.

186
00:17:52,050 --> 00:17:59,420
This is kind of, to me the power of cognitive
computing it's being able to not replace humans,

187
00:17:59,420 --> 00:18:05,870
but empower humans to find connections and
be able to interact with computers in ways

188
00:18:05,870 --> 00:18:08,480
that they would never have been able to interact
with before.

189
00:18:08,480 --> 00:18:12,630
In ways you wouldn't have been able to see
or use before.

190
00:18:12,630 --> 00:18:16,920
The best part about this for me anyway, I
am a little bit biased because I work for

191
00:18:16,920 --> 00:18:22,260
Watson but all of these APIs that we have
are for free, Chef Watson you can go play

192
00:18:22,260 --> 00:18:25,360
with right now, and we're not the only company

193
00:18:25,360 --> 00:18:26,360
doing it.

194
00:18:26,360 --> 00:18:28,380
Which is awesome.

195
00:18:28,380 --> 00:18:33,820
Artificial intelligence, deep learning the
foundation of cognitive computing has got

196
00:18:33,820 --> 00:18:42,530
too point where it's coming out of research
for the first time ever the APIs the ability

197
00:18:42,530 --> 00:18:51,270
to dive deep into our data beyond what we
think of as deep data, beyond deep understandable

198
00:18:51,270 --> 00:18:56,400
content is something that is available for
everyone to start using and everyone to go

199
00:18:56,400 --> 00:18:58,960
play with now.

200
00:18:58,960 --> 00:19:08,140
Which to me, means a big win for the future
of applications and the future of our work

201
00:19:08,140 --> 00:19:14,000
and I have I would have been better had it
worked the first time, yes.

202
00:19:14,000 --> 00:19:18,280
To me that means it's a big win for us, it
means it's a big win for users, like we said

203
00:19:18,280 --> 00:19:23,860
I am part of the design team I am an engineer,
a UI architect on the design team at Watson.

204
00:19:23,860 --> 00:19:32,310
To me what this provides is away for us to
design the next generation of applications.

205
00:19:32,310 --> 00:19:36,140
Screw your JavaScript frameworks, use whatever
one you want.

206
00:19:36,140 --> 00:19:40,310
To me that's not what matters I appreciate
I am a JavaScript conference I just gave an

207
00:19:40,310 --> 00:19:45,080
entire talk not talking about JavaScript,
but this is what is important.

208
00:19:45,080 --> 00:19:51,310
Our users are important, cognitive computing
and cognitive applications will provide us

209
00:19:51,310 --> 00:19:57,070
with the means of producing the next great
user experience, not react not angular, not

210
00:19:57,070 --> 00:20:04,490
ES6, they are tools to build them but cognitive
computing is what will let us actually create

211
00:20:04,490 --> 00:20:08,940
them thank you.

212
00:20:08,940 --> 00:20:21,400
\{applause\} Ok can I have the slides back again?

213
00:20:21,400 --> 00:20:28,440
Those are the links, the link to slide deck,
links to all of the source code for the first

214
00:20:28,440 --> 00:20:35,490
2 applications are available online, I am
snugug that's my website, that's Twitter,

215
00:20:35,490 --> 00:20:36,910
that's the slide deck again.

216
00:20:36,910 --> 00:20:39,880
All the links to everything are available
online including all the source code for all

217
00:20:39,880 --> 00:20:42,920
the applications.

218
00:20:42,920 --> 00:20:47,820
Thank you.

